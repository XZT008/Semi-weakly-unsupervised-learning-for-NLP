Dataset,Name,Abstract,Identifier string,Datapage URL,info url,info text,AREA,Attribute info,all data
Las Vegas Strip,Las Vegas Strip,"This dataset includes quantitative and categorical features from online reviews from 21 hotels located in Las Vegas Strip, extracted from TripAdvisor (http://www.tripadvisor.com).",Las+Vegas+Strip,https://archive.ics.uci.edu/ml//machine-learning-databases/00397/,https://archive.ics.uci.edu/ml/datasets/Las+Vegas+Strip,All the 504 reviews were collected between January and August of 2015.,Business,"The dataset contains 504 records and 20 tuned features (as of Ã¢â‚¬Å“status = includedÃ¢â‚¬Â�, from Table 1 of the article mentioned below),24 per hotel (two per each month, randomly selected), regarding the year of 2015.The CSV contains a header, with the names of the columns corresponding to the features marked as Ã¢â‚¬Å“status = includedÃ¢â‚¬Â�, from Table 1 of the aforementioned article.","This dataset includes quantitative and categorical features from online reviews from 21 hotels located in Las Vegas Strip, extracted from TripAdvisor (http://www.tripadvisor.com).All the 504 reviews were collected between January and August of 2015.The dataset contains 504 records and 20 tuned features (as of Ã¢â‚¬Å“status = includedÃ¢â‚¬Â�, from Table 1 of the article mentioned below),24 per hotel (two per each month, randomly selected), regarding the year of 2015.The CSV contains a header, with the names of the columns corresponding to the features marked as Ã¢â‚¬Å“status = includedÃ¢â‚¬Â�, from Table 1 of the aforementioned article."
clickstream data for online shopping,clickstream data for online shopping,The dataset contains information on clickstream from online store offering clothing for pregnant women. ,clickstream+data+for+online+shopping,https://archive.ics.uci.edu/ml//machine-learning-databases/00553/,https://archive.ics.uci.edu/ml/datasets/clickstream+data+for+online+shopping,"The dataset contains information on clickstream from online store offering clothing for pregnant women. Data are from five months of 2008 and include, among others, product category, location of the photo on the page, country of origin of the IP address and product price in US dollars.",Business,The dataset contains 14 variables described in a separate file (See 'Data set description'),"The dataset contains information on clickstream from online store offering clothing for pregnant women. The dataset contains information on clickstream from online store offering clothing for pregnant women. Data are from five months of 2008 and include, among others, product category, location of the photo on the page, country of origin of the IP address and product price in US dollars.The dataset contains 14 variables described in a separate file (See 'Data set description')"
Facebook metrics,Facebook metrics,Facebook performance metrics of a renowned cosmetic's brand Facebook page.,Facebook+metrics,https://archive.ics.uci.edu/ml//machine-learning-databases/00368/,https://archive.ics.uci.edu/ml/datasets/Facebook+metrics,The data is related to posts' published during the year of 2014 on the Facebook's page of a renowned cosmetics brand.This dataset contains 500 of the 790 rows and part of the features analyzed by Moro et al. (2016). The remaining were omitted due to confidentiality issues.,Business,"It includes 7 features known prior to post publication and 12 features for evaluating post impact (see Tables 2 and 3 from Moro et al., 2016 - complete reference in the 'Citation Request')","Facebook performance metrics of a renowned cosmetic's brand Facebook page.The data is related to posts' published during the year of 2014 on the Facebook's page of a renowned cosmetics brand.This dataset contains 500 of the 790 rows and part of the features analyzed by Moro et al. (2016). The remaining were omitted due to confidentiality issues.It includes 7 features known prior to post publication and 12 features for evaluating post impact (see Tables 2 and 3 from Moro et al., 2016 - complete reference in the 'Citation Request')"
Polish companies bankruptcy data,Polish companies bankruptcy data,"The dataset is about bankruptcy prediction of Polish companies.The bankrupt companies were analyzed in the period 2000-2012, while the still operating companies were evaluated from 2007 to 2013.",Polish+companies+bankruptcy+data,https://archive.ics.uci.edu/ml//machine-learning-databases/00365/,https://archive.ics.uci.edu/ml/datasets/Polish+companies+bankruptcy+data,"The dataset is about bankruptcy prediction of Polish companies. The data was collected from Emerging Markets Information Service (EMIS, [Web Link]), which is a database containing information on emerging markets around the world. The bankrupt companies were analyzed in the period 2000-2012, while the still operating companies were evaluated from 2007 to 2013.Basing on the collected data five classification cases were distinguished, that depends on the forecasting period:- 1stYear Ã¢â‚¬â€œ the data contains financial rates from 1st year of the forecasting period and corresponding class label that indicates bankruptcy status after 5 years. The data contains 7027 instances (financial statements), 271 represents bankrupted companies, 6756 firms that did not bankrupt in the forecasting period.- 2ndYear Ã¢â‚¬â€œ the data contains financial rates from 2nd year of the forecasting period and corresponding class label that indicates bankruptcy status after 4 years. The data contains 10173 instances (financial statements), 400 represents bankrupted companies, 9773 firms that did not bankrupt in the forecasting period.- 3rdYear Ã¢â‚¬â€œ the data contains financial rates from 3rd year of the forecasting period and corresponding class label that indicates bankruptcy status after 3 years. The data contains 10503 instances (financial statements), 495 represents bankrupted companies, 10008 firms that did not bankrupt in the forecasting period.- 4thYear Ã¢â‚¬â€œ the data contains financial rates from 4th year of the forecasting period and corresponding class label that indicates bankruptcy status after 2 years. The data contains 9792 instances (financial statements), 515 represents bankrupted companies, 9277 firms that did not bankrupt in the forecasting period.- 5thYear Ã¢â‚¬â€œ the data contains financial rates from 5th year of the forecasting period and corresponding class label that indicates bankruptcy status after 1 year. The data contains 5910 instances (financial statements), 410 represents bankrupted companies, 5500 firms that did not bankrupt in the forecasting period.",Business,X1	net profit / total assetsX2	total liabilities / total assetsX3	working capital / total assetsX4	current assets / short-term liabilitiesX5	[(cash + short-term securities + receivables - short-term liabilities) / (operating expenses - depreciation)] * 365X6	retained earnings / total assetsX7	EBIT / total assetsX8	book value of equity / total liabilitiesX9	sales / total assetsX10	equity / total assetsX11	(gross profit + extraordinary items + financial expenses) / total assetsX12	gross profit / short-term liabilitiesX13	(gross profit + depreciation) / salesX14	(gross profit + interest) / total assetsX15	(total liabilities * 365) / (gross profit + depreciation)X16	(gross profit + depreciation) / total liabilitiesX17	total assets / total liabilitiesX18	gross profit / total assetsX19	gross profit / salesX20	(inventory * 365) / salesX21	sales (n) / sales (n-1)X22	profit on operating activities / total assetsX23	net profit / salesX24	gross profit (in 3 years) / total assetsX25	(equity - share capital) / total assetsX26	(net profit + depreciation) / total liabilitiesX27	profit on operating activities / financial expensesX28	working capital / fixed assetsX29	logarithm of total assetsX30	(total liabilities - cash) / salesX31	(gross profit + interest) / salesX32	(current liabilities * 365) / cost of products soldX33	operating expenses / short-term liabilitiesX34	operating expenses / total liabilitiesX35	profit on sales / total assetsX36	total sales / total assetsX37	(current assets - inventories) / long-term liabilitiesX38	constant capital / total assetsX39	profit on sales / salesX40	(current assets - inventory - receivables) / short-term liabilitiesX41	total liabilities / ((profit on operating activities + depreciation) * (12/365))X42	profit on operating activities / salesX43	rotation receivables + inventory turnover in daysX44	(receivables * 365) / salesX45	net profit / inventoryX46	(current assets - inventory) / short-term liabilitiesX47	(inventory * 365) / cost of products soldX48	EBITDA (profit on operating activities - depreciation) / total assetsX49	EBITDA (profit on operating activities - depreciation) / salesX50	current assets / total liabilitiesX51	short-term liabilities / total assetsX52	(short-term liabilities * 365) / cost of products sold)X53	equity / fixed assetsX54	constant capital / fixed assetsX55	working capitalX56	(sales - cost of products sold) / salesX57	(current assets - inventory - short-term liabilities) / (sales - gross profit - depreciation)X58	total costs /total salesX59	long-term liabilities / equityX60	sales / inventoryX61	sales / receivablesX62	(short-term liabilities *365) / salesX63	sales / short-term liabilitiesX64	sales / fixed assets,"The dataset is about bankruptcy prediction of Polish companies.The bankrupt companies were analyzed in the period 2000-2012, while the still operating companies were evaluated from 2007 to 2013.The dataset is about bankruptcy prediction of Polish companies. The data was collected from Emerging Markets Information Service (EMIS, [Web Link]), which is a database containing information on emerging markets around the world. The bankrupt companies were analyzed in the period 2000-2012, while the still operating companies were evaluated from 2007 to 2013.Basing on the collected data five classification cases were distinguished, that depends on the forecasting period:- 1stYear Ã¢â‚¬â€œ the data contains financial rates from 1st year of the forecasting period and corresponding class label that indicates bankruptcy status after 5 years. The data contains 7027 instances (financial statements), 271 represents bankrupted companies, 6756 firms that did not bankrupt in the forecasting period.- 2ndYear Ã¢â‚¬â€œ the data contains financial rates from 2nd year of the forecasting period and corresponding class label that indicates bankruptcy status after 4 years. The data contains 10173 instances (financial statements), 400 represents bankrupted companies, 9773 firms that did not bankrupt in the forecasting period.- 3rdYear Ã¢â‚¬â€œ the data contains financial rates from 3rd year of the forecasting period and corresponding class label that indicates bankruptcy status after 3 years. The data contains 10503 instances (financial statements), 495 represents bankrupted companies, 10008 firms that did not bankrupt in the forecasting period.- 4thYear Ã¢â‚¬â€œ the data contains financial rates from 4th year of the forecasting period and corresponding class label that indicates bankruptcy status after 2 years. The data contains 9792 instances (financial statements), 515 represents bankrupted companies, 9277 firms that did not bankrupt in the forecasting period.- 5thYear Ã¢â‚¬â€œ the data contains financial rates from 5th year of the forecasting period and corresponding class label that indicates bankruptcy status after 1 year. The data contains 5910 instances (financial statements), 410 represents bankrupted companies, 5500 firms that did not bankrupt in the forecasting period.X1	net profit / total assetsX2	total liabilities / total assetsX3	working capital / total assetsX4	current assets / short-term liabilitiesX5	[(cash + short-term securities + receivables - short-term liabilities) / (operating expenses - depreciation)] * 365X6	retained earnings / total assetsX7	EBIT / total assetsX8	book value of equity / total liabilitiesX9	sales / total assetsX10	equity / total assetsX11	(gross profit + extraordinary items + financial expenses) / total assetsX12	gross profit / short-term liabilitiesX13	(gross profit + depreciation) / salesX14	(gross profit + interest) / total assetsX15	(total liabilities * 365) / (gross profit + depreciation)X16	(gross profit + depreciation) / total liabilitiesX17	total assets / total liabilitiesX18	gross profit / total assetsX19	gross profit / salesX20	(inventory * 365) / salesX21	sales (n) / sales (n-1)X22	profit on operating activities / total assetsX23	net profit / salesX24	gross profit (in 3 years) / total assetsX25	(equity - share capital) / total assetsX26	(net profit + depreciation) / total liabilitiesX27	profit on operating activities / financial expensesX28	working capital / fixed assetsX29	logarithm of total assetsX30	(total liabilities - cash) / salesX31	(gross profit + interest) / salesX32	(current liabilities * 365) / cost of products soldX33	operating expenses / short-term liabilitiesX34	operating expenses / total liabilitiesX35	profit on sales / total assetsX36	total sales / total assetsX37	(current assets - inventories) / long-term liabilitiesX38	constant capital / total assetsX39	profit on sales / salesX40	(current assets - inventory - receivables) / short-term liabilitiesX41	total liabilities / ((profit on operating activities + depreciation) * (12/365))X42	profit on operating activities / salesX43	rotation receivables + inventory turnover in daysX44	(receivables * 365) / salesX45	net profit / inventoryX46	(current assets - inventory) / short-term liabilitiesX47	(inventory * 365) / cost of products soldX48	EBITDA (profit on operating activities - depreciation) / total assetsX49	EBITDA (profit on operating activities - depreciation) / salesX50	current assets / total liabilitiesX51	short-term liabilities / total assetsX52	(short-term liabilities * 365) / cost of products sold)X53	equity / fixed assetsX54	constant capital / fixed assetsX55	working capitalX56	(sales - cost of products sold) / salesX57	(current assets - inventory - short-term liabilities) / (sales - gross profit - depreciation)X58	total costs /total salesX59	long-term liabilities / equityX60	sales / inventoryX61	sales / receivablesX62	(short-term liabilities *365) / salesX63	sales / short-term liabilitiesX64	sales / fixed assets"
Productivity Prediction of Garment Employees,Productivity Prediction of Garment Employees,This dataset includes important attributes of the garment manufacturing process and the productivity of the employees which had been collected manually and also been validated by the industry experts.,Productivity+Prediction+of+Garment+Employees,https://archive.ics.uci.edu/ml//machine-learning-databases/00597/,https://archive.ics.uci.edu/ml/datasets/Productivity+Prediction+of+Garment+Employees,"The Garment Industry is one of the key examples of the industrial globalization of this modern era. It is a highly labour-intensive industry with lots of manual processes. Satisfying the huge global demand for garment products is mostly dependent on the production and delivery performance of the employees in the garment manufacturing companies. So, it is highly desirable among the decision makers in the garments industry to track, analyse and predict the productivity performance of the working teams in their factories. This dataset can be used for regression purpose by predicting the productivity range (0-1) or for classification purpose by transforming the productivity range (0-1) into different classes.",Business,"01	date			:	Date in MM-DD-YYYY02	day			:	Day of the Week03	quarter			:	A portion of the month. A month was divided into four quarters04	department		:	Associated department with the instance05	team_no			:	Associated team number with the instance06	no_of_workers		:	Number of workers in each team07	no_of_style_change	:	Number of changes in the style of a particular product08	targeted_productivity	:	Targeted productivity set by the Authority for each team for each day.09	smv			:	Standard Minute Value, it is the allocated time for a task10	wip			:	Work in progress. Includes the number of unfinished items for products11	over_time		:	Represents the amount of overtime by each team in minutes12	incentive		:	Represents the amount of financial incentive (in BDT) that enables or motivates a particular course of action.13	idle_time		:	The amount of time when the production was interrupted due to several reasons14	idle_men		:	The number of workers who were idle due to production interruption15	actual_productivity	:	The actual % of productivity that was delivered by the workers. It ranges from 0-1.","This dataset includes important attributes of the garment manufacturing process and the productivity of the employees which had been collected manually and also been validated by the industry experts.The Garment Industry is one of the key examples of the industrial globalization of this modern era. It is a highly labour-intensive industry with lots of manual processes. Satisfying the huge global demand for garment products is mostly dependent on the production and delivery performance of the employees in the garment manufacturing companies. So, it is highly desirable among the decision makers in the garments industry to track, analyse and predict the productivity performance of the working teams in their factories. This dataset can be used for regression purpose by predicting the productivity range (0-1) or for classification purpose by transforming the productivity range (0-1) into different classes.01	date			:	Date in MM-DD-YYYY02	day			:	Day of the Week03	quarter			:	A portion of the month. A month was divided into four quarters04	department		:	Associated department with the instance05	team_no			:	Associated team number with the instance06	no_of_workers		:	Number of workers in each team07	no_of_style_change	:	Number of changes in the style of a particular product08	targeted_productivity	:	Targeted productivity set by the Authority for each team for each day.09	smv			:	Standard Minute Value, it is the allocated time for a task10	wip			:	Work in progress. Includes the number of unfinished items for products11	over_time		:	Represents the amount of overtime by each team in minutes12	incentive		:	Represents the amount of financial incentive (in BDT) that enables or motivates a particular course of action.13	idle_time		:	The amount of time when the production was interrupted due to several reasons14	idle_men		:	The number of workers who were idle due to production interruption15	actual_productivity	:	The actual % of productivity that was delivered by the workers. It ranges from 0-1."
Cargo 2000 Freight Tracking and Tracing,Cargo 2000 Freight Tracking and Tracing,"Sanitized and anonymized Cargo 2000 (C2K) airfreight tracking and tracing events, covering five months of business execution (3,942 process instances, 7,932 transport legs, 56,082 activities). ",Cargo+2000+Freight+Tracking+and+Tracing,https://archive.ics.uci.edu/ml//machine-learning-databases/00382/,https://archive.ics.uci.edu/ml/datasets/Cargo+2000+Freight+Tracking+and+Tracing,A description of the underlying Cargo 2000 standard and the processes reflected in the data set can be found at [Web Link].,Business,"nr - unique id for process instance of overall process  -  domain: [1Ã¢â‚¬Â¦3942]i1_legid - unique id across all transport legs (note: also to 'empty' legs are assigned an id) of incoming transport leg 1 - domain: [1..14664]i1_rcs_p - planned duration (minutes) of incoming transport leg 1 (RCS: Freight Check in) - domain: [LONGINT]i1_rcs_e - effective (i.e., actual) duration (minutes) of incoming transport leg 1 (RCS: Freight Check in) - domain: [LONGINT]i1_dep_1_p - planned duration (minutes) of incoming transport leg 1 (DEP: Departure Segment 1) - domain: [LONGINT]i1_dep_1_e - effective (i.e., actual) duration (minutes) of incoming transport leg 1 (DEP: Departure Segment 1) - domain: [LONGINT]i1_dep_1_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of incoming transport leg 1 (DEP: Departure Segment 1) - domain: [100Ã¢â‚¬Â¦816]i1_rcf_1_p - planned duration (minutes) of incoming transport leg 1 (RCF: Arrival Segment 1) - domain: [LONGINT]i1_rcf_1_e - effective (i.e., actual) duration (minutes) of incoming transport leg 1 (RCF: Arrival Segment 1) - domain: [LONGINT]i1_rcf_1_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of incoming transport leg 1 (RCF: Arrival Segment 1) - domain: [100Ã¢â‚¬Â¦816]i1_dep_2_p - planned duration (minutes) of incoming transport leg 1 (DEP: Departure Segment 2) - domain: [LONGINT]i1_dep_2_e - effective (i.e., actual) duration (minutes) of incoming transport leg 1 (DEP: Departure Segment 2) - domain: [LONGINT]i1_dep_2_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of incoming transport leg 1 (DEP: Departure Segment 2) - domain: [100Ã¢â‚¬Â¦816]i1_rcf_2_p - planned duration (minutes) of incoming transport leg 1 (RCF: Arrival Segment 2) - domain: [LONGINT]i1_rcf_2_e - effective (i.e., actual) duration (minutes) of incoming transport leg 1 (RCF: Arrival Segment 2) - domain: [LONGINT]i1_rcf_2_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of incoming transport leg 1 (RCF: Arrival Segment 2) - domain: [100Ã¢â‚¬Â¦816]i1_dep_3_p - planned duration (minutes) of incoming transport leg 1 (DEP: Departure Segment 3) - domain: [LONGINT]i1_dep_3_e - effective (i.e., actual) duration (minutes) of incoming transport leg 1 (DEP: Departure Segment 3) - domain: [LONGINT]i1_dep_3_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of incoming transport leg 1 (DEP: Departure Segment 3) - domain: [100Ã¢â‚¬Â¦816]i1_rcf_3_p - planned duration (minutes) of incoming transport leg 1 (RCF: Arrival Segment 3) - domain: [LONGINT]i1_rcf_3_e - effective (i.e., actual) duration (minutes) of incoming transport leg 1 (RCF: Arrival Segment 3) - domain: [LONGINT]i1_rcf_3_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of incoming transport leg 1 (RCF: Arrival Segment 3) - domain: [100Ã¢â‚¬Â¦816]i1_dlv_p - planned duration (minutes) of incoming transport leg 1 (DLV: Freight Delivery) - domain: [LONGINT]i1_dlv_e - effective (i.e., actual) duration (minutes) of incoming transport leg 1 (DLV: Freight Delivery) - domain: [LONGINT]i1_hops - number of segments (hops) in the transport leg of incoming transport leg 1 - domain: [1..4]i2_legid - unique id across all transport legs (note: also to 'empty' legs are assigned an id) of incoming transport leg 2    - domain: [1..14664]i2_rcs_p - planned duration (minutes) of incoming transport leg 2 (RCS: Freight Check in) - domain: [LONGINT]i2_rcs_e - effective (i.e., actual) duration (minutes) of incoming transport leg 2 (RCS: Freight Check in) - domain: [LONGINT]i2_dep_1_p - planned duration (minutes) of incoming transport leg 2 (DEP: Departure Segment 1) - domain: [LONGINT]i2_dep_1_e - effective (i.e., actual) duration (minutes) of incoming transport leg 2 (DEP: Departure Segment 1) - domain: [LONGINT]i2_dep_1_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of incoming transport leg 2 (DEP: Departure Segment 1) - domain: [100Ã¢â‚¬Â¦816]i2_rcf_1_p - planned duration (minutes) of incoming transport leg 2 (RCF: Arrival Segment 1) - domain: [LONGINT]i2_rcf_1_e - effective (i.e., actual) duration (minutes) of incoming transport leg 2 (RCF: Arrival Segment 1) - domain: [LONGINT]i2_rcf_1_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of incoming transport leg 2 (RCF: Arrival Segment 1) - domain: [100Ã¢â‚¬Â¦816]i2_dep_2_p - planned duration (minutes) of incoming transport leg 2 (DEP: Departure Segment 2) - domain: [LONGINT]i2_dep_2_e - effective (i.e., actual) duration (minutes) of incoming transport leg 2 (DEP: Departure Segment 2) - domain: [LONGINT]i2_dep_2_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of incoming transport leg 2 (DEP: Departure Segment 2) - domain: [100Ã¢â‚¬Â¦816]i2_rcf_2_p - planned duration (minutes) of incoming transport leg 2 (RCF: Arrival Segment 2) - domain: [LONGINT]i2_rcf_2_e - effective (i.e., actual) duration (minutes) of incoming transport leg 2 (RCF: Arrival Segment 2) - domain: [LONGINT]i2_rcf_2_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of incoming transport leg 2 (RCF: Arrival Segment 2) - domain: [100Ã¢â‚¬Â¦816]i2_dep_3_p - planned duration (minutes) of incoming transport leg 2 (DEP: Departure Segment 3) - domain: [LONGINT]i2_dep_3_e - effective (i.e., actual) duration (minutes) of incoming transport leg 2 (DEP: Departure Segment 3) - domain: [LONGINT]i2_dep_3_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of incoming transport leg 2 (DEP: Departure Segment 3) - domain: [100Ã¢â‚¬Â¦816]i2_rcf_3_p - planned duration (minutes) of incoming transport leg 2 (RCF: Arrival Segment 3) - domain: [LONGINT]i2_rcf_3_e - effective (i.e., actual) duration (minutes) of incoming transport leg 2 (RCF: Arrival Segment 3) - domain: [LONGINT]i2_rcf_3_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of incoming transport leg 2 (RCF: Arrival Segment 3) - domain: [100Ã¢â‚¬Â¦816]i2_dlv_p - planned duration (minutes) of incoming transport leg 2 (DLV: Freight Delivery) - domain: [LONGINT]i2_dlv_e - effective (i.e., actual) duration (minutes) of incoming transport leg 2 (DLV: Freight Delivery) - domain: [LONGINT]i2_hops - number of segments (hops) in the transport leg of incoming transport leg 2 - domain: [1..4]i3_legid - unique id across all transport legs (note: also to 'empty' legs are assigned an id) of incoming transport leg 3    - domain: [1..14664]i3_rcs_p - planned duration (minutes) of incoming transport leg 3 (RCS: Freight Check in) - domain: [LONGINT]i3_rcs_e - effective (i.e., actual) duration (minutes) of incoming transport leg 3 (RCS: Freight Check in) - domain: [LONGINT]i3_dep_1_p - planned duration (minutes) of incoming transport leg 3 (DEP: Departure Segment 1) - domain: [LONGINT]i3_dep_1_e - effective (i.e., actual) duration (minutes) of incoming transport leg 3 (DEP: Departure Segment 1) - domain: [LONGINT]i3_dep_1_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of incoming transport leg 3 (DEP: Departure Segment 1) - domain: [100Ã¢â‚¬Â¦816]i3_rcf_1_p - planned duration (minutes) of incoming transport leg 3 (RCF: Arrival Segment 1) - domain: [LONGINT]i3_rcf_1_e - effective (i.e., actual) duration (minutes) of incoming transport leg 3 (RCF: Arrival Segment 1) - domain: [LONGINT]i3_rcf_1_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of incoming transport leg 3 (RCF: Arrival Segment 1) - domain: [100Ã¢â‚¬Â¦816]i3_dep_2_p - planned duration (minutes) of incoming transport leg 3 (DEP: Departure Segment 2) - domain: [LONGINT]i3_dep_2_e - effective (i.e., actual) duration (minutes) of incoming transport leg 3 (DEP: Departure Segment 2) - domain: [LONGINT]i3_dep_2_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of incoming transport leg 3 (DEP: Departure Segment 2) - domain: [100Ã¢â‚¬Â¦816]i3_rcf_2_p - planned duration (minutes) of incoming transport leg 3 (RCF: Arrival Segment 2) - domain: [LONGINT]i3_rcf_2_e - effective (i.e., actual) duration (minutes) of incoming transport leg 3 (RCF: Arrival Segment 2) - domain: [LONGINT]i3_rcf_2_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of incoming transport leg 3 (RCF: Arrival Segment 2) - domain: [100Ã¢â‚¬Â¦816]i3_dep_3_p - planned duration (minutes) of incoming transport leg 3 (DEP: Departure Segment 3) - domain: [LONGINT]i3_dep_3_e - effective (i.e., actual) duration (minutes) of incoming transport leg 3 (DEP: Departure Segment 3) - domain: [LONGINT]i3_dep_3_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of incoming transport leg 3 (DEP: Departure Segment 3) - domain: [100Ã¢â‚¬Â¦816]i3_rcf_3_p - planned duration (minutes) of incoming transport leg 3 (RCF: Arrival Segment 3) - domain: [LONGINT]i3_rcf_3_e - effective (i.e., actual) duration (minutes) of incoming transport leg 3 (RCF: Arrival Segment 3) - domain: [LONGINT]i3_rcf_3_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of incoming transport leg 3 (RCF: Arrival Segment 3) - domain: [100Ã¢â‚¬Â¦816]i3_dlv_p - planned duration (minutes) of incoming transport leg 3 (DLV: Freight Delivery) - domain: [LONGINT]i3_dlv_e - effective (i.e., actual) duration (minutes) of incoming transport leg 3 (DLV: Freight Delivery) - domain: [LONGINT]i3_hops - number of segments (hops) in the transport leg of incoming transport leg 3 - domain: [1..4]o_legid - unique id across all transport legs (note: also to 'empty' legs are assigned an id) of outgoing transport leg    - domain: [1..14664]o_rcs_p - planned duration (minutes) of outgoing transport leg (RCS: Freight Check in) - domain: [LONGINT]o_rcs_e - effective (i.e., actual) duration (minutes) of outgoing transport leg (RCS: Freight Check in) - domain: [LONGINT]o_dep_1_p - planned duration (minutes) of outgoing transport leg (DEP: Departure Segment 1) - domain: [LONGINT]o_dep_1_e - effective (i.e., actual) duration (minutes) of outgoing transport leg (DEP: Departure Segment 1) - domain: [LONGINT]o_dep_1_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of outgoing transport leg (DEP: Departure Segment 1) - domain: [100Ã¢â‚¬Â¦816]o_rcf_1_p - planned duration (minutes) of outgoing transport leg (RCF: Arrival Segment 1) - domain: [LONGINT]o_rcf_1_e - effective (i.e., actual) duration (minutes) of outgoing transport leg (RCF: Arrival Segment 1) - domain: [LONGINT]o_rcf_1_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of outgoing transport leg (RCF: Arrival Segment 1) - domain: [100Ã¢â‚¬Â¦816]o_dep_2_p - planned duration (minutes) of outgoing transport leg (DEP: Departure Segment 2) - domain: [LONGINT]o_dep_2_e - effective (i.e., actual) duration (minutes) of outgoing transport leg (DEP: Departure Segment 2) - domain: [LONGINT]o_dep_2_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of outgoing transport leg (DEP: Departure Segment 2) - domain: [100Ã¢â‚¬Â¦816]o_rcf_2_p - planned duration (minutes) of outgoing transport leg (RCF: Arrival Segment 2) - domain: [LONGINT]o_rcf_2_e - effective (i.e., actual) duration (minutes) of outgoing transport leg (RCF: Arrival Segment 2) - domain: [LONGINT]o_rcf_2_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of outgoing transport leg (RCF: Arrival Segment 2) - domain: [100Ã¢â‚¬Â¦816]o_dep_3_p - planned duration (minutes) of outgoing transport leg (DEP: Departure Segment 3) - domain: [LONGINT]o_dep_3_e - effective (i.e., actual) duration (minutes) of outgoing transport leg (DEP: Departure Segment 3) - domain: [LONGINT]o_dep_3_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of outgoing transport leg (DEP: Departure Segment 3) - domain: [100Ã¢â‚¬Â¦816]o_rcf_3_p - planned duration (minutes) of outgoing transport leg (RCF: Arrival Segment 3) - domain: [LONGINT]o_rcf_3_e - effective (i.e., actual) duration (minutes) of outgoing transport leg (RCF: Arrival Segment 3) - domain: [LONGINT]o_rcf_3_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of outgoing transport leg (RCF: Arrival Segment 3) - domain: [100Ã¢â‚¬Â¦816]o_dlv_p - planned duration (minutes) of outgoing transport leg (DLV: Freight Delivery) - domain: [LONGINT]o_dlv_e - effective (i.e., actual) duration (minutes) of outgoing transport leg (DLV: Freight Delivery) - domain: [LONGINT]o_hops - number of segments (hops) in the transport leg of outgoing transport leg - domain: [1..4]legs - number of incoming transport legs of overall process    - domain: [1..3]","Sanitized and anonymized Cargo 2000 (C2K) airfreight tracking and tracing events, covering five months of business execution (3,942 process instances, 7,932 transport legs, 56,082 activities). A description of the underlying Cargo 2000 standard and the processes reflected in the data set can be found at [Web Link].nr - unique id for process instance of overall process  -  domain: [1Ã¢â‚¬Â¦3942]i1_legid - unique id across all transport legs (note: also to 'empty' legs are assigned an id) of incoming transport leg 1 - domain: [1..14664]i1_rcs_p - planned duration (minutes) of incoming transport leg 1 (RCS: Freight Check in) - domain: [LONGINT]i1_rcs_e - effective (i.e., actual) duration (minutes) of incoming transport leg 1 (RCS: Freight Check in) - domain: [LONGINT]i1_dep_1_p - planned duration (minutes) of incoming transport leg 1 (DEP: Departure Segment 1) - domain: [LONGINT]i1_dep_1_e - effective (i.e., actual) duration (minutes) of incoming transport leg 1 (DEP: Departure Segment 1) - domain: [LONGINT]i1_dep_1_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of incoming transport leg 1 (DEP: Departure Segment 1) - domain: [100Ã¢â‚¬Â¦816]i1_rcf_1_p - planned duration (minutes) of incoming transport leg 1 (RCF: Arrival Segment 1) - domain: [LONGINT]i1_rcf_1_e - effective (i.e., actual) duration (minutes) of incoming transport leg 1 (RCF: Arrival Segment 1) - domain: [LONGINT]i1_rcf_1_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of incoming transport leg 1 (RCF: Arrival Segment 1) - domain: [100Ã¢â‚¬Â¦816]i1_dep_2_p - planned duration (minutes) of incoming transport leg 1 (DEP: Departure Segment 2) - domain: [LONGINT]i1_dep_2_e - effective (i.e., actual) duration (minutes) of incoming transport leg 1 (DEP: Departure Segment 2) - domain: [LONGINT]i1_dep_2_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of incoming transport leg 1 (DEP: Departure Segment 2) - domain: [100Ã¢â‚¬Â¦816]i1_rcf_2_p - planned duration (minutes) of incoming transport leg 1 (RCF: Arrival Segment 2) - domain: [LONGINT]i1_rcf_2_e - effective (i.e., actual) duration (minutes) of incoming transport leg 1 (RCF: Arrival Segment 2) - domain: [LONGINT]i1_rcf_2_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of incoming transport leg 1 (RCF: Arrival Segment 2) - domain: [100Ã¢â‚¬Â¦816]i1_dep_3_p - planned duration (minutes) of incoming transport leg 1 (DEP: Departure Segment 3) - domain: [LONGINT]i1_dep_3_e - effective (i.e., actual) duration (minutes) of incoming transport leg 1 (DEP: Departure Segment 3) - domain: [LONGINT]i1_dep_3_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of incoming transport leg 1 (DEP: Departure Segment 3) - domain: [100Ã¢â‚¬Â¦816]i1_rcf_3_p - planned duration (minutes) of incoming transport leg 1 (RCF: Arrival Segment 3) - domain: [LONGINT]i1_rcf_3_e - effective (i.e., actual) duration (minutes) of incoming transport leg 1 (RCF: Arrival Segment 3) - domain: [LONGINT]i1_rcf_3_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of incoming transport leg 1 (RCF: Arrival Segment 3) - domain: [100Ã¢â‚¬Â¦816]i1_dlv_p - planned duration (minutes) of incoming transport leg 1 (DLV: Freight Delivery) - domain: [LONGINT]i1_dlv_e - effective (i.e., actual) duration (minutes) of incoming transport leg 1 (DLV: Freight Delivery) - domain: [LONGINT]i1_hops - number of segments (hops) in the transport leg of incoming transport leg 1 - domain: [1..4]i2_legid - unique id across all transport legs (note: also to 'empty' legs are assigned an id) of incoming transport leg 2    - domain: [1..14664]i2_rcs_p - planned duration (minutes) of incoming transport leg 2 (RCS: Freight Check in) - domain: [LONGINT]i2_rcs_e - effective (i.e., actual) duration (minutes) of incoming transport leg 2 (RCS: Freight Check in) - domain: [LONGINT]i2_dep_1_p - planned duration (minutes) of incoming transport leg 2 (DEP: Departure Segment 1) - domain: [LONGINT]i2_dep_1_e - effective (i.e., actual) duration (minutes) of incoming transport leg 2 (DEP: Departure Segment 1) - domain: [LONGINT]i2_dep_1_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of incoming transport leg 2 (DEP: Departure Segment 1) - domain: [100Ã¢â‚¬Â¦816]i2_rcf_1_p - planned duration (minutes) of incoming transport leg 2 (RCF: Arrival Segment 1) - domain: [LONGINT]i2_rcf_1_e - effective (i.e., actual) duration (minutes) of incoming transport leg 2 (RCF: Arrival Segment 1) - domain: [LONGINT]i2_rcf_1_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of incoming transport leg 2 (RCF: Arrival Segment 1) - domain: [100Ã¢â‚¬Â¦816]i2_dep_2_p - planned duration (minutes) of incoming transport leg 2 (DEP: Departure Segment 2) - domain: [LONGINT]i2_dep_2_e - effective (i.e., actual) duration (minutes) of incoming transport leg 2 (DEP: Departure Segment 2) - domain: [LONGINT]i2_dep_2_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of incoming transport leg 2 (DEP: Departure Segment 2) - domain: [100Ã¢â‚¬Â¦816]i2_rcf_2_p - planned duration (minutes) of incoming transport leg 2 (RCF: Arrival Segment 2) - domain: [LONGINT]i2_rcf_2_e - effective (i.e., actual) duration (minutes) of incoming transport leg 2 (RCF: Arrival Segment 2) - domain: [LONGINT]i2_rcf_2_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of incoming transport leg 2 (RCF: Arrival Segment 2) - domain: [100Ã¢â‚¬Â¦816]i2_dep_3_p - planned duration (minutes) of incoming transport leg 2 (DEP: Departure Segment 3) - domain: [LONGINT]i2_dep_3_e - effective (i.e., actual) duration (minutes) of incoming transport leg 2 (DEP: Departure Segment 3) - domain: [LONGINT]i2_dep_3_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of incoming transport leg 2 (DEP: Departure Segment 3) - domain: [100Ã¢â‚¬Â¦816]i2_rcf_3_p - planned duration (minutes) of incoming transport leg 2 (RCF: Arrival Segment 3) - domain: [LONGINT]i2_rcf_3_e - effective (i.e., actual) duration (minutes) of incoming transport leg 2 (RCF: Arrival Segment 3) - domain: [LONGINT]i2_rcf_3_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of incoming transport leg 2 (RCF: Arrival Segment 3) - domain: [100Ã¢â‚¬Â¦816]i2_dlv_p - planned duration (minutes) of incoming transport leg 2 (DLV: Freight Delivery) - domain: [LONGINT]i2_dlv_e - effective (i.e., actual) duration (minutes) of incoming transport leg 2 (DLV: Freight Delivery) - domain: [LONGINT]i2_hops - number of segments (hops) in the transport leg of incoming transport leg 2 - domain: [1..4]i3_legid - unique id across all transport legs (note: also to 'empty' legs are assigned an id) of incoming transport leg 3    - domain: [1..14664]i3_rcs_p - planned duration (minutes) of incoming transport leg 3 (RCS: Freight Check in) - domain: [LONGINT]i3_rcs_e - effective (i.e., actual) duration (minutes) of incoming transport leg 3 (RCS: Freight Check in) - domain: [LONGINT]i3_dep_1_p - planned duration (minutes) of incoming transport leg 3 (DEP: Departure Segment 1) - domain: [LONGINT]i3_dep_1_e - effective (i.e., actual) duration (minutes) of incoming transport leg 3 (DEP: Departure Segment 1) - domain: [LONGINT]i3_dep_1_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of incoming transport leg 3 (DEP: Departure Segment 1) - domain: [100Ã¢â‚¬Â¦816]i3_rcf_1_p - planned duration (minutes) of incoming transport leg 3 (RCF: Arrival Segment 1) - domain: [LONGINT]i3_rcf_1_e - effective (i.e., actual) duration (minutes) of incoming transport leg 3 (RCF: Arrival Segment 1) - domain: [LONGINT]i3_rcf_1_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of incoming transport leg 3 (RCF: Arrival Segment 1) - domain: [100Ã¢â‚¬Â¦816]i3_dep_2_p - planned duration (minutes) of incoming transport leg 3 (DEP: Departure Segment 2) - domain: [LONGINT]i3_dep_2_e - effective (i.e., actual) duration (minutes) of incoming transport leg 3 (DEP: Departure Segment 2) - domain: [LONGINT]i3_dep_2_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of incoming transport leg 3 (DEP: Departure Segment 2) - domain: [100Ã¢â‚¬Â¦816]i3_rcf_2_p - planned duration (minutes) of incoming transport leg 3 (RCF: Arrival Segment 2) - domain: [LONGINT]i3_rcf_2_e - effective (i.e., actual) duration (minutes) of incoming transport leg 3 (RCF: Arrival Segment 2) - domain: [LONGINT]i3_rcf_2_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of incoming transport leg 3 (RCF: Arrival Segment 2) - domain: [100Ã¢â‚¬Â¦816]i3_dep_3_p - planned duration (minutes) of incoming transport leg 3 (DEP: Departure Segment 3) - domain: [LONGINT]i3_dep_3_e - effective (i.e., actual) duration (minutes) of incoming transport leg 3 (DEP: Departure Segment 3) - domain: [LONGINT]i3_dep_3_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of incoming transport leg 3 (DEP: Departure Segment 3) - domain: [100Ã¢â‚¬Â¦816]i3_rcf_3_p - planned duration (minutes) of incoming transport leg 3 (RCF: Arrival Segment 3) - domain: [LONGINT]i3_rcf_3_e - effective (i.e., actual) duration (minutes) of incoming transport leg 3 (RCF: Arrival Segment 3) - domain: [LONGINT]i3_rcf_3_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of incoming transport leg 3 (RCF: Arrival Segment 3) - domain: [100Ã¢â‚¬Â¦816]i3_dlv_p - planned duration (minutes) of incoming transport leg 3 (DLV: Freight Delivery) - domain: [LONGINT]i3_dlv_e - effective (i.e., actual) duration (minutes) of incoming transport leg 3 (DLV: Freight Delivery) - domain: [LONGINT]i3_hops - number of segments (hops) in the transport leg of incoming transport leg 3 - domain: [1..4]o_legid - unique id across all transport legs (note: also to 'empty' legs are assigned an id) of outgoing transport leg    - domain: [1..14664]o_rcs_p - planned duration (minutes) of outgoing transport leg (RCS: Freight Check in) - domain: [LONGINT]o_rcs_e - effective (i.e., actual) duration (minutes) of outgoing transport leg (RCS: Freight Check in) - domain: [LONGINT]o_dep_1_p - planned duration (minutes) of outgoing transport leg (DEP: Departure Segment 1) - domain: [LONGINT]o_dep_1_e - effective (i.e., actual) duration (minutes) of outgoing transport leg (DEP: Departure Segment 1) - domain: [LONGINT]o_dep_1_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of outgoing transport leg (DEP: Departure Segment 1) - domain: [100Ã¢â‚¬Â¦816]o_rcf_1_p - planned duration (minutes) of outgoing transport leg (RCF: Arrival Segment 1) - domain: [LONGINT]o_rcf_1_e - effective (i.e., actual) duration (minutes) of outgoing transport leg (RCF: Arrival Segment 1) - domain: [LONGINT]o_rcf_1_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of outgoing transport leg (RCF: Arrival Segment 1) - domain: [100Ã¢â‚¬Â¦816]o_dep_2_p - planned duration (minutes) of outgoing transport leg (DEP: Departure Segment 2) - domain: [LONGINT]o_dep_2_e - effective (i.e., actual) duration (minutes) of outgoing transport leg (DEP: Departure Segment 2) - domain: [LONGINT]o_dep_2_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of outgoing transport leg (DEP: Departure Segment 2) - domain: [100Ã¢â‚¬Â¦816]o_rcf_2_p - planned duration (minutes) of outgoing transport leg (RCF: Arrival Segment 2) - domain: [LONGINT]o_rcf_2_e - effective (i.e., actual) duration (minutes) of outgoing transport leg (RCF: Arrival Segment 2) - domain: [LONGINT]o_rcf_2_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of outgoing transport leg (RCF: Arrival Segment 2) - domain: [100Ã¢â‚¬Â¦816]o_dep_3_p - planned duration (minutes) of outgoing transport leg (DEP: Departure Segment 3) - domain: [LONGINT]o_dep_3_e - effective (i.e., actual) duration (minutes) of outgoing transport leg (DEP: Departure Segment 3) - domain: [LONGINT]o_dep_3_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of outgoing transport leg (DEP: Departure Segment 3) - domain: [100Ã¢â‚¬Â¦816]o_rcf_3_p - planned duration (minutes) of outgoing transport leg (RCF: Arrival Segment 3) - domain: [LONGINT]o_rcf_3_e - effective (i.e., actual) duration (minutes) of outgoing transport leg (RCF: Arrival Segment 3) - domain: [LONGINT]o_rcf_3_place - unique id for airport (original IATA codes have been masked due to confidentiality reasons) of outgoing transport leg (RCF: Arrival Segment 3) - domain: [100Ã¢â‚¬Â¦816]o_dlv_p - planned duration (minutes) of outgoing transport leg (DLV: Freight Delivery) - domain: [LONGINT]o_dlv_e - effective (i.e., actual) duration (minutes) of outgoing transport leg (DLV: Freight Delivery) - domain: [LONGINT]o_hops - number of segments (hops) in the transport leg of outgoing transport leg - domain: [1..4]legs - number of incoming transport legs of overall process    - domain: [1..3]"
Real estate valuation data set,Real estate valuation data set,"The â€œreal estate valuationâ€� is a regression problem. The market historical data set of real estate valuation are collected from Sindian Dist., New Taipei City, Taiwan. ",Real+estate+valuation+data+set,https://archive.ics.uci.edu/ml//machine-learning-databases/00477/,https://archive.ics.uci.edu/ml/datasets/Real+estate+valuation+data+set,"The market historical data set of real estate valuation are collected from Sindian Dist., New Taipei City, Taiwan. The Ã¢â‚¬Å“real estate valuationÃ¢â‚¬Â� is a regression problem. The data set was randomly split into the training data set (2/3 samples) and the testing data set (1/3 samples).",Business,"The inputs are as followsX1=the transaction date (for example, 2013.250=2013 March, 2013.500=2013 June, etc.)X2=the house age (unit: year)X3=the distance to the nearest MRT station (unit: meter)X4=the number of convenience stores in the living circle on foot (integer)X5=the geographic coordinate, latitude. (unit: degree)X6=the geographic coordinate, longitude. (unit: degree)The output is as followY= house price of unit area (10000 New Taiwan Dollar/Ping, where Ping is a local unit, 1 Ping = 3.3 meter squared)","The â€œreal estate valuationâ€� is a regression problem. The market historical data set of real estate valuation are collected from Sindian Dist., New Taipei City, Taiwan. The market historical data set of real estate valuation are collected from Sindian Dist., New Taipei City, Taiwan. The Ã¢â‚¬Å“real estate valuationÃ¢â‚¬Â� is a regression problem. The data set was randomly split into the training data set (2/3 samples) and the testing data set (1/3 samples).The inputs are as followsX1=the transaction date (for example, 2013.250=2013 March, 2013.500=2013 June, etc.)X2=the house age (unit: year)X3=the distance to the nearest MRT station (unit: meter)X4=the number of convenience stores in the living circle on foot (integer)X5=the geographic coordinate, latitude. (unit: degree)X6=the geographic coordinate, longitude. (unit: degree)The output is as followY= house price of unit area (10000 New Taiwan Dollar/Ping, where Ping is a local unit, 1 Ping = 3.3 meter squared)"
CNAE-9,CNAE-9,"This is a data set containing 1080 documents of free text business descriptions of Brazilian companies categorized into a
subset of 9 categories",CNAE-9,https://archive.ics.uci.edu/ml//machine-learning-databases/00233/,https://archive.ics.uci.edu/ml/datasets/CNAE-9,"This is a data set containing 1080 documents of free text business descriptions of Brazilian companies categorized into asubset of 9 categories cataloged in a table called National Classification of Economic Activities (ClassificaÃƒÂ§ÃƒÂ£o Nacional deAtividade EconÃƒÂ´micas - CNAE). The original texts were pre-processed to obtain the current data set: initially, it was kept onlyletters and then it was removed prepositions of the texts. Next, the words were transformed to their canonical form. Finally,each document was represented as a vector, where the weight of each word is its frequency in the document. This data set ishighly sparse (99.22% of the matrix is filled with zeros).",Business,"In the data set there are 857 attributes, 1 attributes with the class of instance and 856 with word frequency: 1. category: range 1 - 9 (integer)2 - 857. word frequency: (integer)","This is a data set containing 1080 documents of free text business descriptions of Brazilian companies categorized into a
subset of 9 categoriesThis is a data set containing 1080 documents of free text business descriptions of Brazilian companies categorized into asubset of 9 categories cataloged in a table called National Classification of Economic Activities (ClassificaÃƒÂ§ÃƒÂ£o Nacional deAtividade EconÃƒÂ´micas - CNAE). The original texts were pre-processed to obtain the current data set: initially, it was kept onlyletters and then it was removed prepositions of the texts. Next, the words were transformed to their canonical form. Finally,each document was represented as a vector, where the weight of each word is its frequency in the document. This data set ishighly sparse (99.22% of the matrix is filled with zeros).In the data set there are 857 attributes, 1 attributes with the class of instance and 856 with word frequency: 1. category: range 1 - 9 (integer)2 - 857. word frequency: (integer)"
Reuters Transcribed Subset,Reuters Transcribed Subset,"This dataset is created by reading out 200 files from the 10 largest Reuters 
classes and using an Automatic Speech Recognition system to create 
corresponding transcriptions.",Reuters+Transcribed+Subset,https://archive.ics.uci.edu/ml//machine-learning-databases/reuters_transcribed/reuters_transcribed.html-mld/,https://archive.ics.uci.edu/ml/datasets/Reuters+Transcribed+Subset,"Data Characteristics:--------------------This data was created by selecting 20 files each from the 10 largest classes in the Reuters-21578 collection ([Web Link]). The files were read out by 3 Indian speakers and an Automatic Speech Recognition (ASR) system was used to generate the transcripts. More about the ASR system can be found in [1]. Such a dataset will be really helpful to study the effect of speech recognition noise on text mining algorithms. The first work which refered to this dataset was on noisy text classification[2].Data Format:----------There are 10 directories labeled by the topic name. Each contains 20 files of transcriptions.References:----------[1] L. R. Bahl, S. Balakrishnan-Aiyer, J. Bellegarda, M. Franz,P. Gopalakrishnan, D. Nahamoo, M. Novak, M. Padmanabhan,M. Picheny, and S. Roukos,Performance of the IBM large vocabulary continuous speech recognition system onthe ARPA wall street journal task. In Proc. of ICASSP â€™95,pages 41â€“44, Detroit, MI, 1995.[2] S. Agarwal, S. Godbole, D. Punjani and S. Roy,How Much Noise is too Much: A Study in Automatic Text Classification',In Proc. of ICDM 2007",Business,Provide information about each attribute in your data set.,"This dataset is created by reading out 200 files from the 10 largest Reuters 
classes and using an Automatic Speech Recognition system to create 
corresponding transcriptions.Data Characteristics:--------------------This data was created by selecting 20 files each from the 10 largest classes in the Reuters-21578 collection ([Web Link]). The files were read out by 3 Indian speakers and an Automatic Speech Recognition (ASR) system was used to generate the transcripts. More about the ASR system can be found in [1]. Such a dataset will be really helpful to study the effect of speech recognition noise on text mining algorithms. The first work which refered to this dataset was on noisy text classification[2].Data Format:----------There are 10 directories labeled by the topic name. Each contains 20 files of transcriptions.References:----------[1] L. R. Bahl, S. Balakrishnan-Aiyer, J. Bellegarda, M. Franz,P. Gopalakrishnan, D. Nahamoo, M. Novak, M. Padmanabhan,M. Picheny, and S. Roukos,Performance of the IBM large vocabulary continuous speech recognition system onthe ARPA wall street journal task. In Proc. of ICASSP â€™95,pages 41â€“44, Detroit, MI, 1995.[2] S. Agarwal, S. Godbole, D. Punjani and S. Roy,How Much Noise is too Much: A Study in Automatic Text Classification',In Proc. of ICDM 2007Provide information about each attribute in your data set."
Bank Marketing,Bank Marketing,The data is related with direct marketing campaigns (phone calls) of a Portuguese banking institution. The classification goal is to predict if the client will subscribe a term deposit (variable y).,Bank+Marketing,https://archive.ics.uci.edu/ml//machine-learning-databases/00222/,https://archive.ics.uci.edu/ml/datasets/Bank+Marketing,"The data is related with direct marketing campaigns of a Portuguese banking institution. The marketing campaigns were based on phone calls. Often, more than one contact to the same client was required, in order to access if the product (bank term deposit) would be ('yes') or not ('no') subscribed. There are four datasets: 1) bank-additional-full.csv with all examples (41188) and 20 inputs, ordered by date (from May 2008 to November 2010), very close to the data analyzed in [Moro et al., 2014]2) bank-additional.csv with 10% of the examples (4119), randomly selected from 1), and 20 inputs.3) bank-full.csv with all examples and 17 inputs, ordered by date (older version of this dataset with less inputs). 4) bank.csv with 10% of the examples and 17 inputs, randomly selected from 3 (older version of this dataset with less inputs). The smallest datasets are provided to test more computationally demanding machine learning algorithms (e.g., SVM). The classification goal is to predict if the client will subscribe (yes/no) a term deposit (variable y).",Business,"Input variables:   # bank client data:   1 - age (numeric)   2 - job : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')   3 - marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)   4 - education (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')   5 - default: has credit in default? (categorical: 'no','yes','unknown')   6 - housing: has housing loan? (categorical: 'no','yes','unknown')   7 - loan: has personal loan? (categorical: 'no','yes','unknown')   # related with the last contact of the current campaign:   8 - contact: contact communication type (categorical: 'cellular','telephone')    9 - month: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')  10 - day_of_week: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')  11 - duration: last contact duration, in seconds (numeric). Important note:  this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.   # other attributes:  12 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)  13 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)  14 - previous: number of contacts performed before this campaign and for this client (numeric)  15 - poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')   # social and economic context attributes  16 - emp.var.rate: employment variation rate - quarterly indicator (numeric)  17 - cons.price.idx: consumer price index - monthly indicator (numeric)       18 - cons.conf.idx: consumer confidence index - monthly indicator (numeric)       19 - euribor3m: euribor 3 month rate - daily indicator (numeric)  20 - nr.employed: number of employees - quarterly indicator (numeric)  Output variable (desired target):  21 - y - has the client subscribed a term deposit? (binary: 'yes','no')","The data is related with direct marketing campaigns (phone calls) of a Portuguese banking institution. The classification goal is to predict if the client will subscribe a term deposit (variable y).The data is related with direct marketing campaigns of a Portuguese banking institution. The marketing campaigns were based on phone calls. Often, more than one contact to the same client was required, in order to access if the product (bank term deposit) would be ('yes') or not ('no') subscribed. There are four datasets: 1) bank-additional-full.csv with all examples (41188) and 20 inputs, ordered by date (from May 2008 to November 2010), very close to the data analyzed in [Moro et al., 2014]2) bank-additional.csv with 10% of the examples (4119), randomly selected from 1), and 20 inputs.3) bank-full.csv with all examples and 17 inputs, ordered by date (older version of this dataset with less inputs). 4) bank.csv with 10% of the examples and 17 inputs, randomly selected from 3 (older version of this dataset with less inputs). The smallest datasets are provided to test more computationally demanding machine learning algorithms (e.g., SVM). The classification goal is to predict if the client will subscribe (yes/no) a term deposit (variable y).Input variables:   # bank client data:   1 - age (numeric)   2 - job : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')   3 - marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)   4 - education (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')   5 - default: has credit in default? (categorical: 'no','yes','unknown')   6 - housing: has housing loan? (categorical: 'no','yes','unknown')   7 - loan: has personal loan? (categorical: 'no','yes','unknown')   # related with the last contact of the current campaign:   8 - contact: contact communication type (categorical: 'cellular','telephone')    9 - month: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')  10 - day_of_week: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')  11 - duration: last contact duration, in seconds (numeric). Important note:  this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.   # other attributes:  12 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)  13 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)  14 - previous: number of contacts performed before this campaign and for this client (numeric)  15 - poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')   # social and economic context attributes  16 - emp.var.rate: employment variation rate - quarterly indicator (numeric)  17 - cons.price.idx: consumer price index - monthly indicator (numeric)       18 - cons.conf.idx: consumer confidence index - monthly indicator (numeric)       19 - euribor3m: euribor 3 month rate - daily indicator (numeric)  20 - nr.employed: number of employees - quarterly indicator (numeric)  Output variable (desired target):  21 - y - has the client subscribed a term deposit? (binary: 'yes','no')"
South German Credit,South German Credit,700 good and 300 bad credits with 20 predictor variables. Data from 1973 to 1975. Stratified sample from actual credits with bad credits heavily oversampled. A cost matrix can be used.,South+German+Credit,https://archive.ics.uci.edu/ml//machine-learning-databases/00522/,https://archive.ics.uci.edu/ml/datasets/South+German+Credit,"The widely used Statlog German credit data ([Web Link]), as of November 2019, suffers from severe errors in the coding information and does not come with any background information. The 'South German Credit' data provide a correction and some background information, based on the Open Data LMU (2010) representation of the same data and several other German language resources.",Business,"## This section contains a brief description for each attribute.## Details on attribute coding can be obtained from the accompanying R code for reading the data## or the accompanying code table,## as well as from Groemping (2019) (listed under 'Relevant Papers').Column name: laufkontVariable name: statusContent: status of the debtor's checking account with the bank (categorical)Column name: laufzeitVariable name: durationContent: credit duration in months (quantitative)Column name: moralVariable name: credit_historyContent: history of compliance with previous or concurrent credit contracts (categorical)Column name: verwVariable name: purposeContent: purpose for which the credit is needed (categorical)Column name: hoeheVariable name: amountContent: credit amount in DM (quantitative; result of monotonic transformation; actual data and type oftransformation unknown)Column name: sparkontVariable name: savingsContent: debtor's savings (categorical)Column name: beszeitVariable name: employment_durationContent: duration of debtor's employment with current employer (ordinal; discretized quantitative)Column name: rateVariable name: installment_rateContent: credit installments as a percentage of debtor's disposable income (ordinal; discretized quantitative)Column name: famgesVariable name: personal_status_sexContent: combined information on sex and marital status; categorical; sex cannot be recovered from thevariable, because male singles and female non-singles are coded with the same code (2); female widows cannotbe easily classified, because the code table does not list them in any of the female categoriesColumn name: buergeVariable name: other_debtorsContent: Is there another debtor or a guarantor for the credit? (categorical)Column name: wohnzeitVariable name: present_residenceContent: length of time (in years) the debtor lives in the present residence (ordinal; discretized quantitative)Column name: vermVariable name: propertyContent: the debtor's most valuable property, i.e. the highest possible code is used. Code 2 is used, if codes 3or 4 are not applicable and there is a car or any other relevant property that does not fall under variablesparkont. (ordinal)Column name: alterVariable name: ageContent: age in years (quantitative)Column name: weitkredVariable name: other_installment_plansContent: installment plans from providers other than the credit-giving bank (categorical)Column name: wohnVariable name: housingContent: type of housing the debtor lives in (categorical)Column name: bishkredVariable name: number_creditsContent: number of credits including the current one the debtor has (or had) at this bank (ordinal, discretizedquantitative); contrary to Fahrmeir and HamerleÃƒÂ¢Ã¢â€šÂ¬Ã¢â€žÂ¢s (1984) statement, the original data values are not available.Column name: berufVariable name: jobContent: quality of debtor's job (ordinal)Column name: persVariable name: people_liableContent: number of persons who financially depend on the debtor (i.e., are entitled to maintenance) (binary,discretized quantitative)Column name: telefVariable name: telephoneContent: Is there a telephone landline registered on the debtor's name? (binary; remember that the data arefrom the 1970s)Column name: gastarbVariable name: foreign_workerContent: Is the debtor a foreign worker? (binary)Column name: kreditVariable name: credit_riskContent: Has the credit contract been complied with (good) or not (bad) ? (binary)","700 good and 300 bad credits with 20 predictor variables. Data from 1973 to 1975. Stratified sample from actual credits with bad credits heavily oversampled. A cost matrix can be used.The widely used Statlog German credit data ([Web Link]), as of November 2019, suffers from severe errors in the coding information and does not come with any background information. The 'South German Credit' data provide a correction and some background information, based on the Open Data LMU (2010) representation of the same data and several other German language resources.## This section contains a brief description for each attribute.## Details on attribute coding can be obtained from the accompanying R code for reading the data## or the accompanying code table,## as well as from Groemping (2019) (listed under 'Relevant Papers').Column name: laufkontVariable name: statusContent: status of the debtor's checking account with the bank (categorical)Column name: laufzeitVariable name: durationContent: credit duration in months (quantitative)Column name: moralVariable name: credit_historyContent: history of compliance with previous or concurrent credit contracts (categorical)Column name: verwVariable name: purposeContent: purpose for which the credit is needed (categorical)Column name: hoeheVariable name: amountContent: credit amount in DM (quantitative; result of monotonic transformation; actual data and type oftransformation unknown)Column name: sparkontVariable name: savingsContent: debtor's savings (categorical)Column name: beszeitVariable name: employment_durationContent: duration of debtor's employment with current employer (ordinal; discretized quantitative)Column name: rateVariable name: installment_rateContent: credit installments as a percentage of debtor's disposable income (ordinal; discretized quantitative)Column name: famgesVariable name: personal_status_sexContent: combined information on sex and marital status; categorical; sex cannot be recovered from thevariable, because male singles and female non-singles are coded with the same code (2); female widows cannotbe easily classified, because the code table does not list them in any of the female categoriesColumn name: buergeVariable name: other_debtorsContent: Is there another debtor or a guarantor for the credit? (categorical)Column name: wohnzeitVariable name: present_residenceContent: length of time (in years) the debtor lives in the present residence (ordinal; discretized quantitative)Column name: vermVariable name: propertyContent: the debtor's most valuable property, i.e. the highest possible code is used. Code 2 is used, if codes 3or 4 are not applicable and there is a car or any other relevant property that does not fall under variablesparkont. (ordinal)Column name: alterVariable name: ageContent: age in years (quantitative)Column name: weitkredVariable name: other_installment_plansContent: installment plans from providers other than the credit-giving bank (categorical)Column name: wohnVariable name: housingContent: type of housing the debtor lives in (categorical)Column name: bishkredVariable name: number_creditsContent: number of credits including the current one the debtor has (or had) at this bank (ordinal, discretizedquantitative); contrary to Fahrmeir and HamerleÃƒÂ¢Ã¢â€šÂ¬Ã¢â€žÂ¢s (1984) statement, the original data values are not available.Column name: berufVariable name: jobContent: quality of debtor's job (ordinal)Column name: persVariable name: people_liableContent: number of persons who financially depend on the debtor (i.e., are entitled to maintenance) (binary,discretized quantitative)Column name: telefVariable name: telephoneContent: Is there a telephone landline registered on the debtor's name? (binary; remember that the data arefrom the 1970s)Column name: gastarbVariable name: foreign_workerContent: Is the debtor a foreign worker? (binary)Column name: kreditVariable name: credit_riskContent: Has the credit contract been complied with (good) or not (bad) ? (binary)"
South German Credit (UPDATE),South German Credit (UPDATE),700 good and 300 bad credits with 20 predictor variables. Data from 1973 to 1975. Stratified sample from actual credits with bad credits heavily oversampled. A cost matrix can be used.,South+German+Credit+%28UPDATE%29,https://archive.ics.uci.edu/ml//machine-learning-databases/00573/,https://archive.ics.uci.edu/ml/datasets/South+German+Credit+%28UPDATE%29,"The widely used Statlog German credit data ([[Web Link](german+credit+data)]), as of November 2019, suffers from severe errors in the coding information and does not come with any background information. The 'South German Credit' data provide a correction and some background information, based on the Open Data LMU (2010) representation of the same data and several other German language resources.",Business,"## This section contains a brief description for each attribute.## Details on attribute coding can be obtained from the accompanying R code for reading the data## or the accompanying code table,## as well as from Groemping (2019) (listed under 'Relevant Papers').Column name: laufkontVariable name: statusContent: status of the debtor's checking account with the bank (categorical)Column name: laufzeitVariable name: durationContent: credit duration in months (quantitative)Column name: moralVariable name: credit_historyContent: history of compliance with previous or concurrent credit contracts (categorical)Column name: verwVariable name: purposeContent: purpose for which the credit is needed (categorical)Column name: hoeheVariable name: amountContent: credit amount in DM (quantitative; result of monotonic transformation; actual data and type oftransformation unknown)Column name: sparkontVariable name: savingsContent: debtor's savings (categorical)Column name: beszeitVariable name: employment_durationContent: duration of debtor's employment with current employer (ordinal; discretized quantitative)Column name: rateVariable name: installment_rateContent: credit installments as a percentage of debtor's disposable income (ordinal; discretized quantitative)Column name: famgesVariable name: personal_status_sexContent: combined information on sex and marital status; categorical; sex cannot be recovered from thevariable, because male singles and female non-singles are coded with the same code (2); female widows cannotbe easily classified, because the code table does not list them in any of the female categoriesColumn name: buergeVariable name: other_debtorsContent: Is there another debtor or a guarantor for the credit? (categorical)Column name: wohnzeitVariable name: present_residenceContent: length of time (in years) the debtor lives in the present residence (ordinal; discretized quantitative)Column name: vermVariable name: propertyContent: the debtor's most valuable property, i.e. the highest possible code is used. Code 2 is used, if codes 3or 4 are not applicable and there is a car or any other relevant property that does not fall under variablesparkont. (ordinal)Column name: alterVariable name: ageContent: age in years (quantitative)Column name: weitkredVariable name: other_installment_plansContent: installment plans from providers other than the credit-giving bank (categorical)Column name: wohnVariable name: housingContent: type of housing the debtor lives in (categorical)Column name: bishkredVariable name: number_creditsContent: number of credits including the current one the debtor has (or had) at this bank (ordinal, discretizedquantitative); contrary to Fahrmeir and HamerleÃƒÂ¢Ã¢â€šÂ¬Ã¢â€žÂ¢s (1984) statement, the original data values are not available.Column name: berufVariable name: jobContent: quality of debtor's job (ordinal)Column name: persVariable name: people_liableContent: number of persons who financially depend on the debtor (i.e., are entitled to maintenance) (binary,discretized quantitative)Column name: telefVariable name: telephoneContent: Is there a telephone landline registered on the debtor's name? (binary; remember that the data arefrom the 1970s)Column name: gastarbVariable name: foreign_workerContent: Is the debtor a foreign worker? (binary)Column name: kreditVariable name: credit_riskContent: Has the credit contract been complied with (good) or not (bad) ? (binary)","700 good and 300 bad credits with 20 predictor variables. Data from 1973 to 1975. Stratified sample from actual credits with bad credits heavily oversampled. A cost matrix can be used.The widely used Statlog German credit data ([[Web Link](german+credit+data)]), as of November 2019, suffers from severe errors in the coding information and does not come with any background information. The 'South German Credit' data provide a correction and some background information, based on the Open Data LMU (2010) representation of the same data and several other German language resources.## This section contains a brief description for each attribute.## Details on attribute coding can be obtained from the accompanying R code for reading the data## or the accompanying code table,## as well as from Groemping (2019) (listed under 'Relevant Papers').Column name: laufkontVariable name: statusContent: status of the debtor's checking account with the bank (categorical)Column name: laufzeitVariable name: durationContent: credit duration in months (quantitative)Column name: moralVariable name: credit_historyContent: history of compliance with previous or concurrent credit contracts (categorical)Column name: verwVariable name: purposeContent: purpose for which the credit is needed (categorical)Column name: hoeheVariable name: amountContent: credit amount in DM (quantitative; result of monotonic transformation; actual data and type oftransformation unknown)Column name: sparkontVariable name: savingsContent: debtor's savings (categorical)Column name: beszeitVariable name: employment_durationContent: duration of debtor's employment with current employer (ordinal; discretized quantitative)Column name: rateVariable name: installment_rateContent: credit installments as a percentage of debtor's disposable income (ordinal; discretized quantitative)Column name: famgesVariable name: personal_status_sexContent: combined information on sex and marital status; categorical; sex cannot be recovered from thevariable, because male singles and female non-singles are coded with the same code (2); female widows cannotbe easily classified, because the code table does not list them in any of the female categoriesColumn name: buergeVariable name: other_debtorsContent: Is there another debtor or a guarantor for the credit? (categorical)Column name: wohnzeitVariable name: present_residenceContent: length of time (in years) the debtor lives in the present residence (ordinal; discretized quantitative)Column name: vermVariable name: propertyContent: the debtor's most valuable property, i.e. the highest possible code is used. Code 2 is used, if codes 3or 4 are not applicable and there is a car or any other relevant property that does not fall under variablesparkont. (ordinal)Column name: alterVariable name: ageContent: age in years (quantitative)Column name: weitkredVariable name: other_installment_plansContent: installment plans from providers other than the credit-giving bank (categorical)Column name: wohnVariable name: housingContent: type of housing the debtor lives in (categorical)Column name: bishkredVariable name: number_creditsContent: number of credits including the current one the debtor has (or had) at this bank (ordinal, discretizedquantitative); contrary to Fahrmeir and HamerleÃƒÂ¢Ã¢â€šÂ¬Ã¢â€žÂ¢s (1984) statement, the original data values are not available.Column name: berufVariable name: jobContent: quality of debtor's job (ordinal)Column name: persVariable name: people_liableContent: number of persons who financially depend on the debtor (i.e., are entitled to maintenance) (binary,discretized quantitative)Column name: telefVariable name: telephoneContent: Is there a telephone landline registered on the debtor's name? (binary; remember that the data arefrom the 1970s)Column name: gastarbVariable name: foreign_workerContent: Is the debtor a foreign worker? (binary)Column name: kreditVariable name: credit_riskContent: Has the credit contract been complied with (good) or not (bad) ? (binary)"
Statlog (Australian Credit Approval),Statlog (Australian Credit Approval),This file concerns credit card applications. This database exists elsewhere in the repository (Credit Screening Database) in a slightly different form,Statlog+%28Australian+Credit+Approval%29,https://archive.ics.uci.edu/ml//machine-learning-databases/statlog/australian/,https://archive.ics.uci.edu/ml/datasets/Statlog+%28Australian+Credit+Approval%29,"This file concerns credit card applications.  All attribute names and values have been changed to meaningless symbols to protect confidentiality of the data.  This dataset is interesting because there is a good mix of attributes -- continuous, nominal with small numbers of values, and nominal with larger numbers of values.  There are also a few missing values.",Business,"There are 6 numerical and 8 categorical attributes.  The labels have been changed for the convenience of the statistical algorithms.  For example, attribute 4 originally had 3 labels p,g,gg and these have been changed to labels 1,2,3.                             A1: 0,1    CATEGORICAL (formerly: a,b)A2: continuous.A3: continuous.A4: 1,2,3    CATEGORICAL  (formerly: p,g,gg)A5: 1, 2,3,4,5, 6,7,8,9,10,11,12,13,14    CATEGORICAL (formerly: ff,d,i,k,j,aa,m,c,w, e, q, r,cc, x)A6: 1, 2,3, 4,5,6,7,8,9    CATEGORICAL (formerly: ff,dd,j,bb,v,n,o,h,z)A7: continuous.A8: 1, 0    CATEGORICAL (formerly: t, f)A9: 1, 0	CATEGORICAL (formerly: t, f)A10:  continuous.A11:  1, 0	    CATEGORICAL (formerly t, f)A12:  1, 2, 3    CATEGORICAL (formerly: s, g, p) A13:  continuous.A14:  continuous.A15:   1,2  class attribute (formerly: +,-) ","This file concerns credit card applications. This database exists elsewhere in the repository (Credit Screening Database) in a slightly different formThis file concerns credit card applications.  All attribute names and values have been changed to meaningless symbols to protect confidentiality of the data.  This dataset is interesting because there is a good mix of attributes -- continuous, nominal with small numbers of values, and nominal with larger numbers of values.  There are also a few missing values.There are 6 numerical and 8 categorical attributes.  The labels have been changed for the convenience of the statistical algorithms.  For example, attribute 4 originally had 3 labels p,g,gg and these have been changed to labels 1,2,3.                             A1: 0,1    CATEGORICAL (formerly: a,b)A2: continuous.A3: continuous.A4: 1,2,3    CATEGORICAL  (formerly: p,g,gg)A5: 1, 2,3,4,5, 6,7,8,9,10,11,12,13,14    CATEGORICAL (formerly: ff,d,i,k,j,aa,m,c,w, e, q, r,cc, x)A6: 1, 2,3, 4,5,6,7,8,9    CATEGORICAL (formerly: ff,dd,j,bb,v,n,o,h,z)A7: continuous.A8: 1, 0    CATEGORICAL (formerly: t, f)A9: 1, 0	CATEGORICAL (formerly: t, f)A10:  continuous.A11:  1, 0	    CATEGORICAL (formerly t, f)A12:  1, 2, 3    CATEGORICAL (formerly: s, g, p) A13:  continuous.A14:  continuous.A15:   1,2  class attribute (formerly: +,-) "
Statlog (German Credit Data),Statlog (German Credit Data),This dataset classifies people described by a set of attributes as good or bad credit risks. Comes in two formats (one all numeric). Also comes with a cost matrix,Statlog+%28German+Credit+Data%29,https://archive.ics.uci.edu/ml//machine-learning-databases/statlog/german/,https://archive.ics.uci.edu/ml/datasets/Statlog+%28German+Credit+Data%29,"Two datasets are provided.  the original dataset, in the form provided by Prof. Hofmann, contains categorical/symbolic attributes and is in the file ""german.data"".    For algorithms that need numerical attributes, Strathclyde University produced the file ""german.data-numeric"".  This file has been edited and several indicator variables added to make it suitable for algorithms which cannot cope with categorical variables.   Several attributes that are ordered categorical (such as attribute 17) have been coded as integer.    This was the form used by StatLog.This dataset requires use of a cost matrix (see below) ..... 1        2----------------------------  1   0        1-----------------------  2   5        0(1 = Good,  2 = Bad)The rows represent the actual classification and the columns the predicted classification.It is worse to class a customer as good when they are bad (5), than it is to class a customer as bad when they are good (1).",Business,"Attribute 1:  (qualitative)       Status of existing checking account             A11 :      ... <    0 DM	       A12 : 0 <= ... <  200 DM	       A13 :      ... >= 200 DM / salary assignments for at least 1 year               A14 : no checking accountAttribute 2:  (numerical)	      Duration in monthAttribute 3:  (qualitative)	      Credit history	      A30 : no credits taken/ all credits paid back duly              A31 : all credits at this bank paid back duly	      A32 : existing credits paid back duly till now              A33 : delay in paying off in the past	      A34 : critical account/  other credits existing (not at this bank)Attribute 4:  (qualitative)	      Purpose	      A40 : car (new)	      A41 : car (used)	      A42 : furniture/equipment	      A43 : radio/television	      A44 : domestic appliances	      A45 : repairs	      A46 : education	      A47 : (vacation - does not exist?)	      A48 : retraining	      A49 : business	      A410 : othersAttribute 5:  (numerical)	      Credit amountAttibute 6:  (qualitative)	      Savings account/bonds	      A61 :          ... <  100 DM	      A62 :   100 <= ... <  500 DM	      A63 :   500 <= ... < 1000 DM	      A64 :          .. >= 1000 DM              A65 :   unknown/ no savings accountAttribute 7:  (qualitative)	      Present employment since	      A71 : unemployed	      A72 :       ... < 1 year	      A73 : 1  <= ... < 4 years  	      A74 : 4  <= ... < 7 years	      A75 :       .. >= 7 yearsAttribute 8:  (numerical)	      Installment rate in percentage of disposable incomeAttribute 9:  (qualitative)	      Personal status and sex	      A91 : male   : divorced/separated	      A92 : female : divorced/separated/married              A93 : male   : single	      A94 : male   : married/widowed	      A95 : female : singleAttribute 10: (qualitative)	      Other debtors / guarantors	      A101 : none	      A102 : co-applicant	      A103 : guarantorAttribute 11: (numerical)	      Present residence sinceAttribute 12: (qualitative)	      Property	      A121 : real estate	      A122 : if not A121 : building society savings agreement/ life insurance              A123 : if not A121/A122 : car or other, not in attribute 6	      A124 : unknown / no propertyAttribute 13: (numerical)	      Age in yearsAttribute 14: (qualitative)	      Other installment plans 	      A141 : bank	      A142 : stores	      A143 : noneAttribute 15: (qualitative)	      Housing	      A151 : rent	      A152 : own	      A153 : for freeAttribute 16: (numerical)              Number of existing credits at this bankAttribute 17: (qualitative)	      Job	      A171 : unemployed/ unskilled  - non-resident	      A172 : unskilled - resident	      A173 : skilled employee / official	      A174 : management/ self-employed/		     highly qualified employee/ officerAttribute 18: (numerical)	      Number of people being liable to provide maintenance forAttribute 19: (qualitative)	      Telephone	      A191 : none	      A192 : yes, registered under the customers nameAttribute 20: (qualitative)	      foreign worker	      A201 : yes	      A202 : no","This dataset classifies people described by a set of attributes as good or bad credit risks. Comes in two formats (one all numeric). Also comes with a cost matrixTwo datasets are provided.  the original dataset, in the form provided by Prof. Hofmann, contains categorical/symbolic attributes and is in the file ""german.data"".    For algorithms that need numerical attributes, Strathclyde University produced the file ""german.data-numeric"".  This file has been edited and several indicator variables added to make it suitable for algorithms which cannot cope with categorical variables.   Several attributes that are ordered categorical (such as attribute 17) have been coded as integer.    This was the form used by StatLog.This dataset requires use of a cost matrix (see below) ..... 1        2----------------------------  1   0        1-----------------------  2   5        0(1 = Good,  2 = Bad)The rows represent the actual classification and the columns the predicted classification.It is worse to class a customer as good when they are bad (5), than it is to class a customer as bad when they are good (1).Attribute 1:  (qualitative)       Status of existing checking account             A11 :      ... <    0 DM	       A12 : 0 <= ... <  200 DM	       A13 :      ... >= 200 DM / salary assignments for at least 1 year               A14 : no checking accountAttribute 2:  (numerical)	      Duration in monthAttribute 3:  (qualitative)	      Credit history	      A30 : no credits taken/ all credits paid back duly              A31 : all credits at this bank paid back duly	      A32 : existing credits paid back duly till now              A33 : delay in paying off in the past	      A34 : critical account/  other credits existing (not at this bank)Attribute 4:  (qualitative)	      Purpose	      A40 : car (new)	      A41 : car (used)	      A42 : furniture/equipment	      A43 : radio/television	      A44 : domestic appliances	      A45 : repairs	      A46 : education	      A47 : (vacation - does not exist?)	      A48 : retraining	      A49 : business	      A410 : othersAttribute 5:  (numerical)	      Credit amountAttibute 6:  (qualitative)	      Savings account/bonds	      A61 :          ... <  100 DM	      A62 :   100 <= ... <  500 DM	      A63 :   500 <= ... < 1000 DM	      A64 :          .. >= 1000 DM              A65 :   unknown/ no savings accountAttribute 7:  (qualitative)	      Present employment since	      A71 : unemployed	      A72 :       ... < 1 year	      A73 : 1  <= ... < 4 years  	      A74 : 4  <= ... < 7 years	      A75 :       .. >= 7 yearsAttribute 8:  (numerical)	      Installment rate in percentage of disposable incomeAttribute 9:  (qualitative)	      Personal status and sex	      A91 : male   : divorced/separated	      A92 : female : divorced/separated/married              A93 : male   : single	      A94 : male   : married/widowed	      A95 : female : singleAttribute 10: (qualitative)	      Other debtors / guarantors	      A101 : none	      A102 : co-applicant	      A103 : guarantorAttribute 11: (numerical)	      Present residence sinceAttribute 12: (qualitative)	      Property	      A121 : real estate	      A122 : if not A121 : building society savings agreement/ life insurance              A123 : if not A121/A122 : car or other, not in attribute 6	      A124 : unknown / no propertyAttribute 13: (numerical)	      Age in yearsAttribute 14: (qualitative)	      Other installment plans 	      A141 : bank	      A142 : stores	      A143 : noneAttribute 15: (qualitative)	      Housing	      A151 : rent	      A152 : own	      A153 : for freeAttribute 16: (numerical)              Number of existing credits at this bankAttribute 17: (qualitative)	      Job	      A171 : unemployed/ unskilled  - non-resident	      A172 : unskilled - resident	      A173 : skilled employee / official	      A174 : management/ self-employed/		     highly qualified employee/ officerAttribute 18: (numerical)	      Number of people being liable to provide maintenance forAttribute 19: (qualitative)	      Telephone	      A191 : none	      A192 : yes, registered under the customers nameAttribute 20: (qualitative)	      foreign worker	      A201 : yes	      A202 : no"
Stock keeping units,Stock keeping units,"The dataset is provided by the â€œTrialto Latvia LTDâ€�, the third-party logistics operator. Each observation stands for a distinct type of item for sale. ",Stock+keeping+units,https://archive.ics.uci.edu/ml//machine-learning-databases/00531/,https://archive.ics.uci.edu/ml/datasets/Stock+keeping+units,"The dataset is originally provided by the Ã¢â‚¬Å“Trialto Latvia LTDÃ¢â‚¬Â�, the third-party logistics operator. The dataset consists 2279 observations with 7 features.  Selected features include only  numerical  data  and  comprise a  lot  of information  beyond  that utilized by a classical ABC analysis. 3All  the  features  have  an  undeniable  impact  on  the  inventory  management  and constitute  two  core  groups:  handling-related  and  turnover-related.  Such  features  as expire  date, pallet  weight,  pallet  height  and  number  of  units  per pallet  determine  the speed  and  subtlety  of  handling.  On  the  other  hand,total  outbound  and  number  of outbound orders indicate how tradable a particular product is. The total outbound and the number  of  outbound  orders is represented  as different  attributes  despite  the  fact  of sharing some mutual information. It is done on purpose, since both the demand size and the demand frequency are important for the research. It is also worth to note that the feature Ã¢â‚¬Å“number of outbound ordersÃ¢â‚¬Â� is calculated based on arisen demand from 2017-02-06 to 2018-02-13 (537,791 orders in total). ",Business,1) Unit price - unit price in euro2) Expire date - shelf-life3) Total outbound - number of pallets sold from 2017-02-06 to 2018-02-13 4) Number of outbound orders - how many times a product was ordered from 2017-02-06 to 2018-02-13 5) Pallet weight - how much a fully-loaded pallet weights (kg)6) Pallet height - height of a fully-loaded pallet (cm) 7) Units per pallet ,"The dataset is provided by the â€œTrialto Latvia LTDâ€�, the third-party logistics operator. Each observation stands for a distinct type of item for sale. The dataset is originally provided by the Ã¢â‚¬Å“Trialto Latvia LTDÃ¢â‚¬Â�, the third-party logistics operator. The dataset consists 2279 observations with 7 features.  Selected features include only  numerical  data  and  comprise a  lot  of information  beyond  that utilized by a classical ABC analysis. 3All  the  features  have  an  undeniable  impact  on  the  inventory  management  and constitute  two  core  groups:  handling-related  and  turnover-related.  Such  features  as expire  date, pallet  weight,  pallet  height  and  number  of  units  per pallet  determine  the speed  and  subtlety  of  handling.  On  the  other  hand,total  outbound  and  number  of outbound orders indicate how tradable a particular product is. The total outbound and the number  of  outbound  orders is represented  as different  attributes  despite  the  fact  of sharing some mutual information. It is done on purpose, since both the demand size and the demand frequency are important for the research. It is also worth to note that the feature Ã¢â‚¬Å“number of outbound ordersÃ¢â‚¬Â� is calculated based on arisen demand from 2017-02-06 to 2018-02-13 (537,791 orders in total). 1) Unit price - unit price in euro2) Expire date - shelf-life3) Total outbound - number of pallets sold from 2017-02-06 to 2018-02-13 4) Number of outbound orders - how many times a product was ordered from 2017-02-06 to 2018-02-13 5) Pallet weight - how much a fully-loaded pallet weights (kg)6) Pallet height - height of a fully-loaded pallet (cm) 7) Units per pallet "
Blood Transfusion Service Center,Blood Transfusion Service Center,Data taken from the Blood Transfusion Service Center in Hsin-Chu City in Taiwan -- this is a classification problem. ,Blood+Transfusion+Service+Center,https://archive.ics.uci.edu/ml//machine-learning-databases/blood-transfusion/,https://archive.ics.uci.edu/ml/datasets/Blood+Transfusion+Service+Center,"To demonstrate the RFMTC marketing model (a modified version of RFM), this study adopted the donor database of Blood Transfusion Service Center in Hsin-Chu City in Taiwan. The center passes their blood transfusion service bus to one university in Hsin-Chu City to gather blood donated about every three months. To build a FRMTC model, we selected 748 donors at random from the donor database. These 748 donor data, each one included R (Recency - months since last donation), F (Frequency - total number of donation), M (Monetary - total blood donated in c.c.), T (Time - months since first donation), and a binary variable representing whether he/she donated blood in March 2007 (1 stand for donating blood; 0 stands for not donating blood). ",Business,"Given is the variable name, variable type, the measurement unit and a brief description. The ""Blood Transfusion Service Center"" is a classification problem. The order of this listing corresponds to the order of numerals along the rows of the database. R (Recency - months since last donation), F (Frequency - total number of donation), M (Monetary - total blood donated in c.c.), T (Time - months since first donation), and a binary variable representing whether he/she donated blood in March 2007 (1 stand for donating blood; 0 stands for not donating blood). Table 1 shows the descriptive statistics of the data. We selected 500 data at random as the training set, and the rest 248 as the testing set.Table 1. Descriptive statistics of the dataVariable	Data Type	Measurement	Description	min	max	mean	stdRecency 	quantitative	Months	Input	0.03	74.4	9.74	8.07Frequency 	quantitative	Times	Input	1	50	5.51	5.84Monetary	quantitative	c.c. blood	Input	250	12500	1378.68	1459.83Time 	quantitative	Months	Input	2.27	98.3	34.42	24.32Whether he/she donated blood in March 2007	binary	1=yes 0=no	Output	0	1	1 (24%) 0 (76%)","Data taken from the Blood Transfusion Service Center in Hsin-Chu City in Taiwan -- this is a classification problem. To demonstrate the RFMTC marketing model (a modified version of RFM), this study adopted the donor database of Blood Transfusion Service Center in Hsin-Chu City in Taiwan. The center passes their blood transfusion service bus to one university in Hsin-Chu City to gather blood donated about every three months. To build a FRMTC model, we selected 748 donors at random from the donor database. These 748 donor data, each one included R (Recency - months since last donation), F (Frequency - total number of donation), M (Monetary - total blood donated in c.c.), T (Time - months since first donation), and a binary variable representing whether he/she donated blood in March 2007 (1 stand for donating blood; 0 stands for not donating blood). Given is the variable name, variable type, the measurement unit and a brief description. The ""Blood Transfusion Service Center"" is a classification problem. The order of this listing corresponds to the order of numerals along the rows of the database. R (Recency - months since last donation), F (Frequency - total number of donation), M (Monetary - total blood donated in c.c.), T (Time - months since first donation), and a binary variable representing whether he/she donated blood in March 2007 (1 stand for donating blood; 0 stands for not donating blood). Table 1 shows the descriptive statistics of the data. We selected 500 data at random as the training set, and the rest 248 as the testing set.Table 1. Descriptive statistics of the dataVariable	Data Type	Measurement	Description	min	max	mean	stdRecency 	quantitative	Months	Input	0.03	74.4	9.74	8.07Frequency 	quantitative	Times	Input	1	50	5.51	5.84Monetary	quantitative	c.c. blood	Input	250	12500	1378.68	1459.83Time 	quantitative	Months	Input	2.27	98.3	34.42	24.32Whether he/she donated blood in March 2007	binary	1=yes 0=no	Output	0	1	1 (24%) 0 (76%)"
Online Shoppers Purchasing Intention Dataset,Online Shoppers Purchasing Intention Dataset,"Of the 12,330 sessions in the dataset,
84.5% (10,422) were negative class samples that did not
end with shopping, and the rest (1908) were positive class
samples ending with shopping.",Online+Shoppers+Purchasing+Intention+Dataset,https://archive.ics.uci.edu/ml//machine-learning-databases/00468/,https://archive.ics.uci.edu/ml/datasets/Online+Shoppers+Purchasing+Intention+Dataset,"The dataset consists of feature vectors belonging to 12,330 sessions. The dataset was formed so that each sessionwould belong to a different user in a 1-year period to avoidany tendency to a specific campaign, special day, userprofile, or period. ",Business,"The dataset consists of 10 numerical and 8 categorical attributes.The 'Revenue' attribute can be used as the class label.""Administrative"", ""Administrative Duration"", ""Informational"", ""Informational Duration"", ""Product Related"" and ""Product Related Duration"" represent the number of different types of pages visited by the visitor in that session and total time spent in each of these page categories. The values of these features are derived from the URL information of the pages visited by the user and updated in real time when a user takes an action, e.g. moving from one page to another. The ""Bounce Rate"", ""Exit Rate"" and ""Page Value"" features represent the metrics measured by ""Google Analytics"" for each page in the e-commerce site. The value of ""Bounce Rate"" feature for a web page refers to the percentage of visitors who enter the site from that page and then leave (""bounce"") without triggering any other requests to the analytics server during that session. The value of ""Exit Rate"" feature for a specific web page is calculated as for all pageviews to the page, the percentage that were the last in the session. The ""Page Value"" feature represents the average value for a web page that a user visited before completing an e-commerce transaction. The ""Special Day"" feature indicates the closeness of the site visiting time to a specific special day (e.g. Motherâ€™s Day, Valentine's Day) in which the sessions are more likely to be finalized with transaction. The value of this attribute is determined by considering the dynamics of e-commerce such as the duration between the order date and delivery date. For example, for Valentinaâ€™s day, this value takes a nonzero value between February 2 and February 12, zero before and after this date unless it is close to another special day, and its maximum value of 1 on February 8. The dataset also includes operating system, browser, region, traffic type, visitor type as returning or new visitor, a Boolean value indicating whether the date of the visit is weekend, and month of the year.","Of the 12,330 sessions in the dataset,
84.5% (10,422) were negative class samples that did not
end with shopping, and the rest (1908) were positive class
samples ending with shopping.The dataset consists of feature vectors belonging to 12,330 sessions. The dataset was formed so that each sessionwould belong to a different user in a 1-year period to avoidany tendency to a specific campaign, special day, userprofile, or period. The dataset consists of 10 numerical and 8 categorical attributes.The 'Revenue' attribute can be used as the class label.""Administrative"", ""Administrative Duration"", ""Informational"", ""Informational Duration"", ""Product Related"" and ""Product Related Duration"" represent the number of different types of pages visited by the visitor in that session and total time spent in each of these page categories. The values of these features are derived from the URL information of the pages visited by the user and updated in real time when a user takes an action, e.g. moving from one page to another. The ""Bounce Rate"", ""Exit Rate"" and ""Page Value"" features represent the metrics measured by ""Google Analytics"" for each page in the e-commerce site. The value of ""Bounce Rate"" feature for a web page refers to the percentage of visitors who enter the site from that page and then leave (""bounce"") without triggering any other requests to the analytics server during that session. The value of ""Exit Rate"" feature for a specific web page is calculated as for all pageviews to the page, the percentage that were the last in the session. The ""Page Value"" feature represents the average value for a web page that a user visited before completing an e-commerce transaction. The ""Special Day"" feature indicates the closeness of the site visiting time to a specific special day (e.g. Motherâ€™s Day, Valentine's Day) in which the sessions are more likely to be finalized with transaction. The value of this attribute is determined by considering the dynamics of e-commerce such as the duration between the order date and delivery date. For example, for Valentinaâ€™s day, this value takes a nonzero value between February 2 and February 12, zero before and after this date unless it is close to another special day, and its maximum value of 1 on February 8. The dataset also includes operating system, browser, region, traffic type, visitor type as returning or new visitor, a Boolean value indicating whether the date of the visit is weekend, and month of the year."
Online Retail II,Online Retail II,A real online retail transaction data set of two years.,Online+Retail+II,https://archive.ics.uci.edu/ml//machine-learning-databases/00502/,https://archive.ics.uci.edu/ml/datasets/Online+Retail+II,"This Online Retail II data set contains all the transactions occurring for a UK-based and registered, non-store online retail between 01/12/2009 and 09/12/2011.The company mainly sells unique all-occasion gift-ware. Many customers of the company are wholesalers.",Business,"InvoiceNo: Invoice number. Nominal. A 6-digit integral number uniquely assigned to each transaction. If this code starts with the letter 'c', it indicates a cancellation. StockCode: Product (item) code. Nominal. A 5-digit integral number uniquely assigned to each distinct product. Description: Product (item) name. Nominal. Quantity: The quantities of each product (item) per transaction. Numeric.	InvoiceDate: Invice date and time. Numeric. The day and time when a transaction was generated. UnitPrice: Unit price. Numeric. Product price per unit in sterling (Ã‚Â£). CustomerID: Customer number. Nominal. A 5-digit integral number uniquely assigned to each customer. Country: Country name. Nominal. The name of the country where a customer resides.","A real online retail transaction data set of two years.This Online Retail II data set contains all the transactions occurring for a UK-based and registered, non-store online retail between 01/12/2009 and 09/12/2011.The company mainly sells unique all-occasion gift-ware. Many customers of the company are wholesalers.InvoiceNo: Invoice number. Nominal. A 6-digit integral number uniquely assigned to each transaction. If this code starts with the letter 'c', it indicates a cancellation. StockCode: Product (item) code. Nominal. A 5-digit integral number uniquely assigned to each distinct product. Description: Product (item) name. Nominal. Quantity: The quantities of each product (item) per transaction. Numeric.	InvoiceDate: Invice date and time. Numeric. The day and time when a transaction was generated. UnitPrice: Unit price. Numeric. Product price per unit in sterling (Ã‚Â£). CustomerID: Customer number. Nominal. A 5-digit integral number uniquely assigned to each customer. Country: Country name. Nominal. The name of the country where a customer resides."
Online Retail,Online Retail,This is a transnational data set which contains all the transactions occurring between 01/12/2010 and 09/12/2011 for a UK-based and registered non-store online retail.,Online+Retail,https://archive.ics.uci.edu/ml//machine-learning-databases/00352/,https://archive.ics.uci.edu/ml/datasets/Online+Retail,This is a transnational data set which contains all the transactions occurring between 01/12/2010 and 09/12/2011 for a UK-based and registered non-store online retail.The company mainly sells unique all-occasion gifts. Many customers of the company are wholesalers.,Business,"InvoiceNo: Invoice number. Nominal, a 6-digit integral number uniquely assigned to each transaction. If this code starts with letter 'c', it indicates a cancellation. StockCode: Product (item) code. Nominal, a 5-digit integral number uniquely assigned to each distinct product.Description: Product (item) name. Nominal.Quantity: The quantities of each product (item) per transaction. Numeric.	InvoiceDate: Invice Date and time. Numeric, the day and time when each transaction was generated.UnitPrice: Unit price. Numeric, Product price per unit in sterling.CustomerID: Customer number. Nominal, a 5-digit integral number uniquely assigned to each customer.Country: Country name. Nominal, the name of the country where each customer resides. ","This is a transnational data set which contains all the transactions occurring between 01/12/2010 and 09/12/2011 for a UK-based and registered non-store online retail.This is a transnational data set which contains all the transactions occurring between 01/12/2010 and 09/12/2011 for a UK-based and registered non-store online retail.The company mainly sells unique all-occasion gifts. Many customers of the company are wholesalers.InvoiceNo: Invoice number. Nominal, a 6-digit integral number uniquely assigned to each transaction. If this code starts with letter 'c', it indicates a cancellation. StockCode: Product (item) code. Nominal, a 5-digit integral number uniquely assigned to each distinct product.Description: Product (item) name. Nominal.Quantity: The quantities of each product (item) per transaction. Numeric.	InvoiceDate: Invice Date and time. Numeric, the day and time when each transaction was generated.UnitPrice: Unit price. Numeric, Product price per unit in sterling.CustomerID: Customer number. Nominal, a 5-digit integral number uniquely assigned to each customer.Country: Country name. Nominal, the name of the country where each customer resides. "
Facebook Live Sellers in Thailand,Facebook Live Sellers in Thailand,"Facebook pages of 10 Thai fashion and cosmetics retail sellers. Posts of a different nature (video, photos, statuses, and links). Engagement metrics consist of comments, shares, and reactions.",Facebook+Live+Sellers+in+Thailand,https://archive.ics.uci.edu/ml//machine-learning-databases/00488/,https://archive.ics.uci.edu/ml/datasets/Facebook+Live+Sellers+in+Thailand,"The variability of consumer engagement is analysed through a Principal Component Analysis, highlighting the changes induced by the use of Facebook Live. The seasonal component is analysed through a study of the averages of the different engagement metrics for different time-frames (hourly, daily and monthly). Finally, we identify statistical outlier posts, that are qualitatively analyzed further, in terms of their selling approach and activities.  ",Business,status_id	status_type	status_published	num_reactions	num_comments	num_shares	num_likes	num_loves	num_wows	num_hahas	num_sads	num_angrys,"Facebook pages of 10 Thai fashion and cosmetics retail sellers. Posts of a different nature (video, photos, statuses, and links). Engagement metrics consist of comments, shares, and reactions.The variability of consumer engagement is analysed through a Principal Component Analysis, highlighting the changes induced by the use of Facebook Live. The seasonal component is analysed through a study of the averages of the different engagement metrics for different time-frames (hourly, daily and monthly). Finally, we identify statistical outlier posts, that are qualitatively analyzed further, in terms of their selling approach and activities.  status_id	status_type	status_published	num_reactions	num_comments	num_shares	num_likes	num_loves	num_wows	num_hahas	num_sads	num_angrys"
Economic Sanctions,Economic Sanctions,Domain Theory on Economic Sanctions; Undocumented,Economic+Sanctions,https://archive.ics.uci.edu/ml//machine-learning-databases/undocumented/pazzani/,https://archive.ics.uci.edu/ml/datasets/Economic+Sanctions,I think you'll find some limited documentation on Mike's database in his papers.  His dissertation would be a good reference (UCLA).  Perhaps pages 152-153 in the EWSL-1988 proceedings should help with understanding the data format.  Pages 713-718 of IJCAI-1989 should help even more.,Business,,Domain Theory on Economic Sanctions; UndocumentedI think you'll find some limited documentation on Mike's database in his papers.  His dissertation would be a good reference (UCLA).  Perhaps pages 152-153 in the EWSL-1988 proceedings should help with understanding the data format.  Pages 713-718 of IJCAI-1989 should help even more.nan
Eco-hotel,Eco-hotel,"This dataset includes Online Textual Reviews from both online (e.g., TripAdvisor) and offline (e.g., Guests' book) sources from the Areias do Seixo Eco-Resort.",Eco-hotel,https://archive.ics.uci.edu/ml//machine-learning-databases/00398/,https://archive.ics.uci.edu/ml/datasets/Eco-hotel,"The CSV holds one cell per review, except the first row, which is the header.All the 401 reviews were collected between January and August of 2015.",Business,Textual review.,"This dataset includes Online Textual Reviews from both online (e.g., TripAdvisor) and offline (e.g., Guests' book) sources from the Areias do Seixo Eco-Resort.The CSV holds one cell per review, except the first row, which is the header.All the 401 reviews were collected between January and August of 2015.Textual review."
in-vehicle coupon recommendation,in-vehicle coupon recommendation,This data studies whether a person will accept the coupon recommended to him in different driving scenarios,in-vehicle+coupon+recommendation,https://archive.ics.uci.edu/ml//machine-learning-databases/00603/,https://archive.ics.uci.edu/ml/datasets/in-vehicle+coupon+recommendation,"This data was collected via a survey on Amazon Mechanical Turk. The survey describes different driving scenarios including the destination, current time, weather, passenger, etc., and then ask the person whether he will accept the coupon if he is the driver. For more information about the dataset, please refer to the paper:Wang, Tong, Cynthia Rudin, Finale Doshi-Velez, Yimin Liu, Erica Klampfl, and Perry MacNeille. 'A bayesian framework for learning rule sets for interpretable classification.' The Journal of Machine Learning Research 18, no. 1 (2017): 2357-2393.",Business,"destination: No Urgent Place, Home, Workpassanger: Alone, Friend(s), Kid(s), Partner (who are the passengers in the car)weather: Sunny, Rainy, Snowytemperature:55, 80, 30time: 2PM, 10AM, 6PM, 7AM, 10PMcoupon: Restaurant(<$20), Coffee House, Carry out & Take away, Bar, Restaurant($20-$50)expiration: 1d, 2h (the coupon expires in 1 day or in 2 hours)gender: Female, Maleage: 21, 46, 26, 31, 41, 50plus, 36, below21maritalStatus: Unmarried partner, Single, Married partner, Divorced, Widowedhas_Children:1, 0education: Some college - no degree, Bachelors degree, Associates degree, High School Graduate, Graduate degree (Masters or Doctorate), Some High Schooloccupation: Unemployed, Architecture & Engineering, Student, Education&Training&Library, Healthcare Support, Healthcare Practitioners & Technical, Sales & Related, Management, Arts Design Entertainment Sports & Media, Computer & Mathematical, Life Physical Social Science, Personal Care & Service, Community & Social Services, Office & Administrative Support, Construction & Extraction, Legal, Retired, Installation Maintenance & Repair, Transportation & Material Moving, Business & Financial, Protective Service, Food Preparation & Serving Related, Production Occupations, Building & Grounds Cleaning & Maintenance, Farming Fishing & Forestryincome: $37500 - $49999, $62500 - $74999, $12500 - $24999, $75000 - $87499, $50000 - $62499, $25000 - $37499, $100000 or More, $87500 - $99999, Less than $12500Bar: never, less1, 1~3, gt8,  nan4~8 (feature meaning: how many times do you go to a bar every month?)CoffeeHouse: never, less1, 4~8, 1~3, gt8,  nan (feature meaning: how many times do you go to a coffeehouse every month?)CarryAway:n4~8, 1~3, gt8, less1, never (feature meaning: how many times do you get take-away food every month?)RestaurantLessThan20: 4~8, 1~3, less1, gt8,  never (feature meaning: how many times do you go to a restaurant with an average expense per person of less than $20 every month?)Restaurant20To50: 1~3, less1, never, gt8, 4~8,  nan (feature meaning: how many times do you go to a restaurant with average expense per person of $20 - $50 every month?)toCoupon_GEQ15min:0,1 (feature meaning: driving distance to the restaurant/bar for using the coupon is greater than 15 minutes)toCoupon_GEQ25min:0, 1 (feature meaning: driving distance to the restaurant/bar for using the coupon is greater than 25 minutes)direction_same:0, 1 (feature meaning: whether the restaurant/bar is in the same direction as your current destination)direction_opp:1, 0 (feature meaning: whether the restaurant/bar is in the same direction as your current destination)Y:1, 0 (whether the coupon is accepted)","This data studies whether a person will accept the coupon recommended to him in different driving scenariosThis data was collected via a survey on Amazon Mechanical Turk. The survey describes different driving scenarios including the destination, current time, weather, passenger, etc., and then ask the person whether he will accept the coupon if he is the driver. For more information about the dataset, please refer to the paper:Wang, Tong, Cynthia Rudin, Finale Doshi-Velez, Yimin Liu, Erica Klampfl, and Perry MacNeille. 'A bayesian framework for learning rule sets for interpretable classification.' The Journal of Machine Learning Research 18, no. 1 (2017): 2357-2393.destination: No Urgent Place, Home, Workpassanger: Alone, Friend(s), Kid(s), Partner (who are the passengers in the car)weather: Sunny, Rainy, Snowytemperature:55, 80, 30time: 2PM, 10AM, 6PM, 7AM, 10PMcoupon: Restaurant(<$20), Coffee House, Carry out & Take away, Bar, Restaurant($20-$50)expiration: 1d, 2h (the coupon expires in 1 day or in 2 hours)gender: Female, Maleage: 21, 46, 26, 31, 41, 50plus, 36, below21maritalStatus: Unmarried partner, Single, Married partner, Divorced, Widowedhas_Children:1, 0education: Some college - no degree, Bachelors degree, Associates degree, High School Graduate, Graduate degree (Masters or Doctorate), Some High Schooloccupation: Unemployed, Architecture & Engineering, Student, Education&Training&Library, Healthcare Support, Healthcare Practitioners & Technical, Sales & Related, Management, Arts Design Entertainment Sports & Media, Computer & Mathematical, Life Physical Social Science, Personal Care & Service, Community & Social Services, Office & Administrative Support, Construction & Extraction, Legal, Retired, Installation Maintenance & Repair, Transportation & Material Moving, Business & Financial, Protective Service, Food Preparation & Serving Related, Production Occupations, Building & Grounds Cleaning & Maintenance, Farming Fishing & Forestryincome: $37500 - $49999, $62500 - $74999, $12500 - $24999, $75000 - $87499, $50000 - $62499, $25000 - $37499, $100000 or More, $87500 - $99999, Less than $12500Bar: never, less1, 1~3, gt8,  nan4~8 (feature meaning: how many times do you go to a bar every month?)CoffeeHouse: never, less1, 4~8, 1~3, gt8,  nan (feature meaning: how many times do you go to a coffeehouse every month?)CarryAway:n4~8, 1~3, gt8, less1, never (feature meaning: how many times do you get take-away food every month?)RestaurantLessThan20: 4~8, 1~3, less1, gt8,  never (feature meaning: how many times do you go to a restaurant with an average expense per person of less than $20 every month?)Restaurant20To50: 1~3, less1, never, gt8, 4~8,  nan (feature meaning: how many times do you go to a restaurant with average expense per person of $20 - $50 every month?)toCoupon_GEQ15min:0,1 (feature meaning: driving distance to the restaurant/bar for using the coupon is greater than 15 minutes)toCoupon_GEQ25min:0, 1 (feature meaning: driving distance to the restaurant/bar for using the coupon is greater than 25 minutes)direction_same:0, 1 (feature meaning: whether the restaurant/bar is in the same direction as your current destination)direction_opp:1, 0 (feature meaning: whether the restaurant/bar is in the same direction as your current destination)Y:1, 0 (whether the coupon is accepted)"
Incident management process enriched event log,Incident management process enriched event log,This event log was extracted from data gathered from the audit system of an instance of the ServiceNow platform used by an IT company and enriched with data loaded from a relational database.,Incident+management+process+enriched+event+log,https://archive.ics.uci.edu/ml//machine-learning-databases/00498/,https://archive.ics.uci.edu/ml/datasets/Incident+management+process+enriched+event+log,"This is an event log of an incident management process extracted from data gathered from the audit system of an instance of the ServiceNowTM platform used by an IT company. The event log is enriched with data loaded from a relational database underlying a corresponding process-aware information system. Information was anonymized for privacy.Number of instances: 141,712 events (24,918 incidents)Number of attributes: 36 attributes (1 case identifier, 1 state identifier, 32 descriptive attributes, 2 dependent variables)The attributed Ã¢â‚¬Ëœclosed_atÃ¢â‚¬â„¢ is used to determine the dependent variable for the time completion prediction task. The attribute Ã¢â‚¬Ëœresolved_atÃ¢â‚¬â„¢ is highly correlated with Ã¢â‚¬Ëœclosed_atÃ¢â‚¬â„¢. In this event log, some rows may have the same values (they are equal) since not all attributes involved in the real-world process are present in the log.Attributes used to record textual information are not placed in this log.The missing values should be considered Ã¢â‚¬Ëœunknown informationÃ¢â‚¬â„¢.",Business,"1. number: incident identifier (24,918 different values);2. incident state: eight levels controlling the incident management process transitions from opening until closing the case;3. active: boolean attribute that shows whether the record is active or closed/canceled;4. reassignment_count: number of times the incident has the group or the support analysts changed;5. reopen_count: number of times the incident resolution was rejected by the caller;6. sys_mod_count: number of incident updates until that moment;7. made_sla: boolean attribute that shows whether the incident exceeded the target SLA;8. caller_id: identifier of the user affected;9. opened_by: identifier of the user who reported the incident;10. opened_at: incident user opening date and time;11. sys_created_by: identifier of the user who registered the incident;12. sys_created_at: incident system creation date and time;13. sys_updated_by: identifier of the user who updated the incident and generated the current log record;14. sys_updated_at: incident system update date and time;15. contact_type: categorical attribute that shows by what means the incident was reported;16. location: identifier of the location of the place affected;17. category: first-level description of the affected service;18. subcategory: second-level description of the affected service (related to the first level description, i.e., to category);19. u_symptom: description of the user perception about service availability;20. cmdb_ci: (confirmation item) identifier used to report the affected item (not mandatory);21. impact: description of the impact caused by the incident (values: 1Ã¢â‚¬â€œHigh; 2Ã¢â‚¬â€œMedium; 3Ã¢â‚¬â€œLow);22. urgency: description of the urgency informed by the user for the incident resolution (values: 1Ã¢â‚¬â€œHigh; 2Ã¢â‚¬â€œMedium; 3Ã¢â‚¬â€œLow);23. priority: calculated by the system based on 'impact' and 'urgency';24. assignment_group: identifier of the support group in charge of the incident;25. assigned_to: identifier of the user in charge of the incident;26. knowledge: boolean attribute that shows whether a knowledge base document was used to resolve the incident;27. u_priority_confirmation: boolean attribute that shows whether the priority field has been double-checked;28. notify: categorical attribute that shows whether notifications were generated for the incident;29. problem_id: identifier of the problem associated with the incident;30. rfc: (request for change) identifier of the change request associated with the incident;31. vendor: identifier of the vendor in charge of the incident;32. caused_by: identifier of the RFC responsible by the incident;33. close_code: identifier of the resolution of the incident;34. resolved_by: identifier of the user who resolved the incident;35. resolved_at: incident user resolution date and time (dependent variable);36. closed_at: incident user close date and time (dependent variable).","This event log was extracted from data gathered from the audit system of an instance of the ServiceNow platform used by an IT company and enriched with data loaded from a relational database.This is an event log of an incident management process extracted from data gathered from the audit system of an instance of the ServiceNowTM platform used by an IT company. The event log is enriched with data loaded from a relational database underlying a corresponding process-aware information system. Information was anonymized for privacy.Number of instances: 141,712 events (24,918 incidents)Number of attributes: 36 attributes (1 case identifier, 1 state identifier, 32 descriptive attributes, 2 dependent variables)The attributed Ã¢â‚¬Ëœclosed_atÃ¢â‚¬â„¢ is used to determine the dependent variable for the time completion prediction task. The attribute Ã¢â‚¬Ëœresolved_atÃ¢â‚¬â„¢ is highly correlated with Ã¢â‚¬Ëœclosed_atÃ¢â‚¬â„¢. In this event log, some rows may have the same values (they are equal) since not all attributes involved in the real-world process are present in the log.Attributes used to record textual information are not placed in this log.The missing values should be considered Ã¢â‚¬Ëœunknown informationÃ¢â‚¬â„¢.1. number: incident identifier (24,918 different values);2. incident state: eight levels controlling the incident management process transitions from opening until closing the case;3. active: boolean attribute that shows whether the record is active or closed/canceled;4. reassignment_count: number of times the incident has the group or the support analysts changed;5. reopen_count: number of times the incident resolution was rejected by the caller;6. sys_mod_count: number of incident updates until that moment;7. made_sla: boolean attribute that shows whether the incident exceeded the target SLA;8. caller_id: identifier of the user affected;9. opened_by: identifier of the user who reported the incident;10. opened_at: incident user opening date and time;11. sys_created_by: identifier of the user who registered the incident;12. sys_created_at: incident system creation date and time;13. sys_updated_by: identifier of the user who updated the incident and generated the current log record;14. sys_updated_at: incident system update date and time;15. contact_type: categorical attribute that shows by what means the incident was reported;16. location: identifier of the location of the place affected;17. category: first-level description of the affected service;18. subcategory: second-level description of the affected service (related to the first level description, i.e., to category);19. u_symptom: description of the user perception about service availability;20. cmdb_ci: (confirmation item) identifier used to report the affected item (not mandatory);21. impact: description of the impact caused by the incident (values: 1Ã¢â‚¬â€œHigh; 2Ã¢â‚¬â€œMedium; 3Ã¢â‚¬â€œLow);22. urgency: description of the urgency informed by the user for the incident resolution (values: 1Ã¢â‚¬â€œHigh; 2Ã¢â‚¬â€œMedium; 3Ã¢â‚¬â€œLow);23. priority: calculated by the system based on 'impact' and 'urgency';24. assignment_group: identifier of the support group in charge of the incident;25. assigned_to: identifier of the user in charge of the incident;26. knowledge: boolean attribute that shows whether a knowledge base document was used to resolve the incident;27. u_priority_confirmation: boolean attribute that shows whether the priority field has been double-checked;28. notify: categorical attribute that shows whether notifications were generated for the incident;29. problem_id: identifier of the problem associated with the incident;30. rfc: (request for change) identifier of the change request associated with the incident;31. vendor: identifier of the vendor in charge of the incident;32. caused_by: identifier of the RFC responsible by the incident;33. close_code: identifier of the resolution of the incident;34. resolved_by: identifier of the user who resolved the incident;35. resolved_at: incident user resolution date and time (dependent variable);36. closed_at: incident user close date and time (dependent variable)."
Dow Jones Index,Dow Jones Index,This dataset contains weekly data for the Dow Jones Industrial Index.  It has been used in computational investing research.,Dow+Jones+Index,https://archive.ics.uci.edu/ml//machine-learning-databases/00312/,https://archive.ics.uci.edu/ml/datasets/Dow+Jones+Index,"In predicting stock prices you collect data over some period of time - day, week, month, etc. But you cannot take advantage of data from a time period until the next increment of the time period. For example, assume you collect data daily.  When Monday is over you have all of the data for that day.  However you can invest on Monday, because you don't get the data until the end of the day.  You can use the data from Monday to invest on Tuesday.  In our research each record (row) is data for a week.  Each record also has the percentage of return that stock has in the following week (percent_change_next_weeks_price). Ideally, you want to determine which stock will produce the greatest rate of return in the following week.  This can help you train and test your algorithm.Some of these attributes might not be use used in your research.  They were originally added to our database to perform calculations.  (Brown, Pelosi & Dirska, 2013) used percent_change_price, percent_change_volume_over_last_wk, days_to_next_dividend, and percent_return_next_dividend.  We left the other attributes in the dataset	in case you wanted to use any of them. Of course what you want to maximize is percent_change_next_weeks_price.Training data vs Test data:In (Brown, Pelosi & Dirska, 2013) we used quarter 1 (Jan-Mar) data for training and quarter 2 (Apr-Jun) data for testing. Interesting data points:If you use quarter 2 data for testing, you will notice something interesting in the week ending 5/27/2011 every Dow Jones Index stock lost money.",Business,	quarter:  the yearly quarter (1 = Jan-Mar; 2 = Apr=Jun).	stock: the stock symbol (see above)	date: the last business day of the work (this is typically a Friday)	open: the price of the stock at the beginning of the week	high: the highest price of the stock during the week	low: the lowest price of the stock during the week	close: the price of the stock at the end of the week	volume: the number of shares of stock that traded hands in the week	percent_change_price: the percentage change in price throughout the week	percent_chagne_volume_over_last_wek: the percentage change in the number of shares of 		stock that traded hands for this week compared to the previous week	previous_weeks_volume: the number of shares of stock that traded hands in the previous week	next_weeks_open: the opening price of the stock in the following week	next_weeks_close: the closing price of the stock in the following week	percent_change_next_weeks_price: the percentage change in price of the stock in the 		following week days_to_next_dividend: the number of days until the next dividend	percent_return_next_dividend: the percentage of return on the next dividend,"This dataset contains weekly data for the Dow Jones Industrial Index.  It has been used in computational investing research.In predicting stock prices you collect data over some period of time - day, week, month, etc. But you cannot take advantage of data from a time period until the next increment of the time period. For example, assume you collect data daily.  When Monday is over you have all of the data for that day.  However you can invest on Monday, because you don't get the data until the end of the day.  You can use the data from Monday to invest on Tuesday.  In our research each record (row) is data for a week.  Each record also has the percentage of return that stock has in the following week (percent_change_next_weeks_price). Ideally, you want to determine which stock will produce the greatest rate of return in the following week.  This can help you train and test your algorithm.Some of these attributes might not be use used in your research.  They were originally added to our database to perform calculations.  (Brown, Pelosi & Dirska, 2013) used percent_change_price, percent_change_volume_over_last_wk, days_to_next_dividend, and percent_return_next_dividend.  We left the other attributes in the dataset	in case you wanted to use any of them. Of course what you want to maximize is percent_change_next_weeks_price.Training data vs Test data:In (Brown, Pelosi & Dirska, 2013) we used quarter 1 (Jan-Mar) data for training and quarter 2 (Apr-Jun) data for testing. Interesting data points:If you use quarter 2 data for testing, you will notice something interesting in the week ending 5/27/2011 every Dow Jones Index stock lost money.	quarter:  the yearly quarter (1 = Jan-Mar; 2 = Apr=Jun).	stock: the stock symbol (see above)	date: the last business day of the work (this is typically a Friday)	open: the price of the stock at the beginning of the week	high: the highest price of the stock during the week	low: the lowest price of the stock during the week	close: the price of the stock at the end of the week	volume: the number of shares of stock that traded hands in the week	percent_change_price: the percentage change in price throughout the week	percent_chagne_volume_over_last_wek: the percentage change in the number of shares of 		stock that traded hands for this week compared to the previous week	previous_weeks_volume: the number of shares of stock that traded hands in the previous week	next_weeks_open: the opening price of the stock in the following week	next_weeks_close: the closing price of the stock in the following week	percent_change_next_weeks_price: the percentage change in price of the stock in the 		following week days_to_next_dividend: the number of days until the next dividend	percent_return_next_dividend: the percentage of return on the next dividend"
Iranian Churn Dataset,Iranian Churn Dataset,This dataset is randomly collected from an Iranian telecom companyâ€™s database over a period of 12 months.,Iranian+Churn+Dataset,https://archive.ics.uci.edu/ml//machine-learning-databases/00563/,https://archive.ics.uci.edu/ml/datasets/Iranian+Churn+Dataset,"This dataset is randomly collected from an Iranian telecom companyÃ¢â‚¬â„¢s database over a period of 12 months. A total of 3150 rows of data, each representing a customer, bear information for 13 columns. The attributes that are in this datasetare call failures, frequency of SMS, number of complaints, number of distinct calls, subscription length, age group, the charge amount, type of service, seconds of use, status, frequency of use, and Customer Value.All of the attributes except for attribute churn is the aggregated data of the first 9 months. The churn labels are the state of the customers at the end of 12 months. The three months is the designated planning gap.",Business,"Anonymous Customer IDCall Failures: number of call failuresComplains: binary (0: No complaint, 1: complaint)Subscription Length: total months of subscriptionCharge Amount: Ordinal attribute (0: lowest amount, 9: highest amount)Seconds of Use: total seconds of callsFrequency of use: total number of callsFrequency of SMS: total number of text messagesDistinct Called Numbers: total number of distinct phone calls Age Group: ordinal attribute (1: younger age, 5: older age)Tariff Plan: binary (1: Pay as you go, 2: contractual)Status: binary (1: active, 2: non-active)Churn: binary (1: churn, 0: non-churn) - Class labelCustomer Value: The calculated value of customer","This dataset is randomly collected from an Iranian telecom companyâ€™s database over a period of 12 months.This dataset is randomly collected from an Iranian telecom companyÃ¢â‚¬â„¢s database over a period of 12 months. A total of 3150 rows of data, each representing a customer, bear information for 13 columns. The attributes that are in this datasetare call failures, frequency of SMS, number of complaints, number of distinct calls, subscription length, age group, the charge amount, type of service, seconds of use, status, frequency of use, and Customer Value.All of the attributes except for attribute churn is the aggregated data of the first 9 months. The churn labels are the state of the customers at the end of 12 months. The three months is the designated planning gap.Anonymous Customer IDCall Failures: number of call failuresComplains: binary (0: No complaint, 1: complaint)Subscription Length: total months of subscriptionCharge Amount: Ordinal attribute (0: lowest amount, 9: highest amount)Seconds of Use: total seconds of callsFrequency of use: total number of callsFrequency of SMS: total number of text messagesDistinct Called Numbers: total number of distinct phone calls Age Group: ordinal attribute (1: younger age, 5: older age)Tariff Plan: binary (1: Pay as you go, 2: contractual)Status: binary (1: active, 2: non-active)Churn: binary (1: churn, 0: non-churn) - Class labelCustomer Value: The calculated value of customer"
ISTANBUL STOCK EXCHANGE,ISTANBUL STOCK EXCHANGE,"Data sets includes returns of Istanbul Stock Exchange with seven other international index; SP, DAX, FTSE, NIKKEI, BOVESPA, MSCE_EU, MSCI_EM from Jun 5, 2009 to Feb 22, 2011.",ISTANBUL+STOCK+EXCHANGE,https://archive.ics.uci.edu/ml//machine-learning-databases/00247/,https://archive.ics.uci.edu/ml/datasets/ISTANBUL+STOCK+EXCHANGE,Data is collected from imkb.gov.tr and finance.yahoo.com. Data is organized with regard to working days in Istanbul Stock Exchange. ,Business,"Stock exchange returns. Istanbul stock exchange national 100 index, Standard & poorÃ¢â‚¬â„¢s 500 return index, Stock market return index of Germany, Stock market return index of UK, Stock market return index of Japan, Stock market return index of Brazil, MSCI European index, MSCI emerging markets index","Data sets includes returns of Istanbul Stock Exchange with seven other international index; SP, DAX, FTSE, NIKKEI, BOVESPA, MSCE_EU, MSCI_EM from Jun 5, 2009 to Feb 22, 2011.Data is collected from imkb.gov.tr and finance.yahoo.com. Data is organized with regard to working days in Istanbul Stock Exchange. Stock exchange returns. Istanbul stock exchange national 100 index, Standard & poorÃ¢â‚¬â„¢s 500 return index, Stock market return index of Germany, Stock market return index of UK, Stock market return index of Japan, Stock market return index of Brazil, MSCI European index, MSCI emerging markets index"
Japanese Credit Screening,Japanese Credit Screening,Includes domain theory (generated by talking to Japanese domain experts); data in Lisp,Japanese+Credit+Screening,https://archive.ics.uci.edu/ml//machine-learning-databases/credit-screening,https://archive.ics.uci.edu/ml/datasets/Japanese+Credit+Screening,Examples represent positive and negative instances of people who were and were not  granted credit.The theory was generated by talking to the individuals at a Japanese company that grants credit.,Business,,Includes domain theory (generated by talking to Japanese domain experts); data in LispExamples represent positive and negative instances of people who were and were not  granted credit.The theory was generated by talking to the individuals at a Japanese company that grants credit.nan
Machine Learning based ZZAlpha Ltd. Stock Recommendations 2012-2014,Machine Learning based ZZAlpha Ltd. Stock Recommendations 2012-2014,"The data here are the ZZAlphaÂ® machine learning recommendations made for various US traded stock portfolios the morning of each day during the 3 year period Jan 1, 2012 - Dec 31, 2014.  ",Machine+Learning+based+ZZAlpha+Ltd.+Stock+Recommendations+2012-2014,https://archive.ics.uci.edu/ml//machine-learning-databases/00337/,https://archive.ics.uci.edu/ml/datasets/Machine+Learning+based+ZZAlpha+Ltd.+Stock+Recommendations+2012-2014,"1. Title of Database: Machine Learning based ZZAlpha Stock Recommendations2. Sources:   (a) Original owners of data: ZZAlpha Ltd., 4729 E. Sunrise #109, Tucson AZ 85718 USA, info '@' zzalpha.com     (b) Donor of database: Kevin Pratt, Chief Scientist, ZZAlpha Ltd. on behalf of ZZAlpha Ltd.   (c) Date received: 6-Jun-2015 3. Past Usage:   (a) Pratt, Kevin.  Proof Protocol for a Machine Learning Technique Making Longitudinal Predictions in Dynamic Contexts. (ACM KDD 2015)   (b) Attribute predicted: for each stock in each portfolio, opening price change over 5 trading days    (c) Indication of study's results.  Significant predictions in multiple portfolios.  See publications.4. Relevant Information Paragraph:   The files were zipped (on a Windows machine) by year.   The data here are the ZZAlphaÃ‚Â® machine learning recommendations made for various US traded stock portfolios the morning of each day during the 3 year period Jan 1, 2012 - Dec 31, 2014.  They are deposited here in .txt form for easy accessibility (and as a convenience to users, have had results included for each recommendation).  A .pdf version of the original recommendations file was certified by Digistamp (.p7s) at time of creation each day for stringent auditability.  Please contact info '@' zzalpha.com if you desire to purchase the set of the certified .pdf, .p7s file pairs.  The certified set contains only the recommendations, not the results included in the deposited set here.For convenience, the data deposited includes calculated returns (outcomes) for each recommended transaction.  The returns obviously were not part of the original recommendations when made, but were appended later.  Returns were calculated several days after sale day.The date inside the file reflects the date for which morning trading recommendation was made.  The evaluation of the recommendations, as described in the KDD 2015 article mentioned above, involved comparison of the opening price of the day of recommendation to the opening price five market days later.  As mentioned in the article, evaluation must be adjusted by trading costs and constraints.A recommendation portfolio consists of a segment, a size (1,2,5,10,20), and a side (Long or Short),  and the ticker symbols of the companies recommended for price increase (or decrease in the case of Short) from the opening price to the opening price 5 trading days later.The stocks included must first pass a general screen of $3 recent price and 80,000 recent daily average share volume for inclusion.  Thus penny stocks and micro-caps are not present and even some large cap, but very low prices stocks are omitted.  All stocks must be traded on NYSE, NASDAQ or AMEX at the time of recommendation.The daily file contains all recommendations for all portfolios for the day.  Both long and short recommendations are included. Long entries have duplicates.These are the portfolios:  (Note other portfolios limited to ETFs (exchange traded funds) may be listed each day.  Due to data issues those are incomplete across the time period.) 5. Number of Instances: 755 market days, 41 portfolios, 5 sizes of portfolios, Long and Short6. Number of Attributes    The data set submitted does not include attributes used for prediction. This data is provided as a benchmark of machine learning results in a longitudinal 3 yr period. Here is a sample content of a line in the files:Jan 04 2005_006 Big_100_5_LONG_SHORT_F.pdf, L, AA 0.959 =25.97/27.09, AMAT 0.950 =14.70/15.46, EBAY 0.930 =53.33/57.31, PFE 0.995 =19.84/19.95, UPS 0.980 =71.72/73.16, Avg of 5 = 0.963The above indicates recommendations were made before market open on Jan 4, 2005.  This portfolio was limited to the biggest 100 cap stocks and was of size 5.  It was for 'L' or long recommendations.  The five stocks recommended are shown by ticker, result, price at sale divided by price at purchase.  The average for the five is shown.Note: The user of this data set must implement its own parser of these files.  The contributor does NOT provide one.Note: The prices used are adjusted prices based on data when results were calculated.  Back-calculation of the adjusted prices using newer data may give different prices, but the ratios will remain the same (+/- rounding errors).7. For Each Attribute: Not applicable8. Missing Attribute Values: On some days for a few portfolios, results may be missing.  These are tagged as 'missing'.9. Class Distribution: Distribution of positive and negative outcomes vary by portfolio, size, and day.",Business,See above,"The data here are the ZZAlphaÂ® machine learning recommendations made for various US traded stock portfolios the morning of each day during the 3 year period Jan 1, 2012 - Dec 31, 2014.  1. Title of Database: Machine Learning based ZZAlpha Stock Recommendations2. Sources:   (a) Original owners of data: ZZAlpha Ltd., 4729 E. Sunrise #109, Tucson AZ 85718 USA, info '@' zzalpha.com     (b) Donor of database: Kevin Pratt, Chief Scientist, ZZAlpha Ltd. on behalf of ZZAlpha Ltd.   (c) Date received: 6-Jun-2015 3. Past Usage:   (a) Pratt, Kevin.  Proof Protocol for a Machine Learning Technique Making Longitudinal Predictions in Dynamic Contexts. (ACM KDD 2015)   (b) Attribute predicted: for each stock in each portfolio, opening price change over 5 trading days    (c) Indication of study's results.  Significant predictions in multiple portfolios.  See publications.4. Relevant Information Paragraph:   The files were zipped (on a Windows machine) by year.   The data here are the ZZAlphaÃ‚Â® machine learning recommendations made for various US traded stock portfolios the morning of each day during the 3 year period Jan 1, 2012 - Dec 31, 2014.  They are deposited here in .txt form for easy accessibility (and as a convenience to users, have had results included for each recommendation).  A .pdf version of the original recommendations file was certified by Digistamp (.p7s) at time of creation each day for stringent auditability.  Please contact info '@' zzalpha.com if you desire to purchase the set of the certified .pdf, .p7s file pairs.  The certified set contains only the recommendations, not the results included in the deposited set here.For convenience, the data deposited includes calculated returns (outcomes) for each recommended transaction.  The returns obviously were not part of the original recommendations when made, but were appended later.  Returns were calculated several days after sale day.The date inside the file reflects the date for which morning trading recommendation was made.  The evaluation of the recommendations, as described in the KDD 2015 article mentioned above, involved comparison of the opening price of the day of recommendation to the opening price five market days later.  As mentioned in the article, evaluation must be adjusted by trading costs and constraints.A recommendation portfolio consists of a segment, a size (1,2,5,10,20), and a side (Long or Short),  and the ticker symbols of the companies recommended for price increase (or decrease in the case of Short) from the opening price to the opening price 5 trading days later.The stocks included must first pass a general screen of $3 recent price and 80,000 recent daily average share volume for inclusion.  Thus penny stocks and micro-caps are not present and even some large cap, but very low prices stocks are omitted.  All stocks must be traded on NYSE, NASDAQ or AMEX at the time of recommendation.The daily file contains all recommendations for all portfolios for the day.  Both long and short recommendations are included. Long entries have duplicates.These are the portfolios:  (Note other portfolios limited to ETFs (exchange traded funds) may be listed each day.  Due to data issues those are incomplete across the time period.) 5. Number of Instances: 755 market days, 41 portfolios, 5 sizes of portfolios, Long and Short6. Number of Attributes    The data set submitted does not include attributes used for prediction. This data is provided as a benchmark of machine learning results in a longitudinal 3 yr period. Here is a sample content of a line in the files:Jan 04 2005_006 Big_100_5_LONG_SHORT_F.pdf, L, AA 0.959 =25.97/27.09, AMAT 0.950 =14.70/15.46, EBAY 0.930 =53.33/57.31, PFE 0.995 =19.84/19.95, UPS 0.980 =71.72/73.16, Avg of 5 = 0.963The above indicates recommendations were made before market open on Jan 4, 2005.  This portfolio was limited to the biggest 100 cap stocks and was of size 5.  It was for 'L' or long recommendations.  The five stocks recommended are shown by ticker, result, price at sale divided by price at purchase.  The average for the five is shown.Note: The user of this data set must implement its own parser of these files.  The contributor does NOT provide one.Note: The prices used are adjusted prices based on data when results were calculated.  Back-calculation of the adjusted prices using newer data may give different prices, but the ratios will remain the same (+/- rounding errors).7. For Each Attribute: Not applicable8. Missing Attribute Values: On some days for a few portfolios, results may be missing.  These are tagged as 'missing'.9. Class Distribution: Distribution of positive and negative outcomes vary by portfolio, size, and day.See above"
default of credit card clients,default of credit card clients,This research aimed at the case of customersâ€™ default payments in Taiwan and compares the predictive accuracy of probability of default among six data mining methods.,default+of+credit+card+clients,https://archive.ics.uci.edu/ml//machine-learning-databases/00350/,https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients,"This research aimed at the case of customersÃ¢â‚¬â„¢ default payments in Taiwan and compares the predictive accuracy of probability of default among six data mining methods. From the perspective of risk management, the result of predictive accuracy of the estimated probability of default will be more valuable than the binary result of classification - credible or not credible clients. Because the real probability of default is unknown, this study presented the novel Ã¢â‚¬Å“Sorting Smoothing MethodÃ¢â‚¬Â� to estimate the real probability of default. With the real probability of default as the response variable (Y), and the predictive probability of default as the independent variable (X), the simple linear regression result (Y = A + BX) shows that the forecasting model produced by artificial neural network has the highest coefficient of determination; its regression intercept (A) is close to zero, and regression coefficient (B) to one. Therefore, among the six data mining techniques, artificial neural network is the only one that can accurately estimate the real probability of default.",Business,"This research employed a binary variable, default payment (Yes = 1, No = 0), as the response variable. This study reviewed the literature and used the following 23 variables as explanatory variables:X1: Amount of the given credit (NT dollar): it includes both the individual consumer credit and his/her family (supplementary) credit.X2: Gender (1 = male; 2 = female).X3: Education (1 = graduate school; 2 = university; 3 = high school; 4 = others).X4: Marital status (1 = married; 2 = single; 3 = others).X5: Age (year).X6 - X11: History of past payment. We tracked the past monthly payment records (from April to September, 2005) as follows: X6 = the repayment status in September, 2005; X7 = the repayment status in August, 2005; . . .;X11 = the repayment status in April, 2005. The measurement scale for the repayment status is: -1 = pay duly; 1 = payment delay for one month; 2 = payment delay for two months; . . .; 8 = payment delay for eight months; 9 = payment delay for nine months and above.X12-X17: Amount of bill statement (NT dollar). X12 = amount of bill statement in September, 2005; X13 = amount of bill statement in August, 2005; . . .; X17 = amount of bill statement in April, 2005. X18-X23: Amount of previous payment (NT dollar). X18 = amount paid in September, 2005; X19 = amount paid in August, 2005; . . .;X23 = amount paid in April, 2005.","This research aimed at the case of customersâ€™ default payments in Taiwan and compares the predictive accuracy of probability of default among six data mining methods.This research aimed at the case of customersÃ¢â‚¬â„¢ default payments in Taiwan and compares the predictive accuracy of probability of default among six data mining methods. From the perspective of risk management, the result of predictive accuracy of the estimated probability of default will be more valuable than the binary result of classification - credible or not credible clients. Because the real probability of default is unknown, this study presented the novel Ã¢â‚¬Å“Sorting Smoothing MethodÃ¢â‚¬Â� to estimate the real probability of default. With the real probability of default as the response variable (Y), and the predictive probability of default as the independent variable (X), the simple linear regression result (Y = A + BX) shows that the forecasting model produced by artificial neural network has the highest coefficient of determination; its regression intercept (A) is close to zero, and regression coefficient (B) to one. Therefore, among the six data mining techniques, artificial neural network is the only one that can accurately estimate the real probability of default.This research employed a binary variable, default payment (Yes = 1, No = 0), as the response variable. This study reviewed the literature and used the following 23 variables as explanatory variables:X1: Amount of the given credit (NT dollar): it includes both the individual consumer credit and his/her family (supplementary) credit.X2: Gender (1 = male; 2 = female).X3: Education (1 = graduate school; 2 = university; 3 = high school; 4 = others).X4: Marital status (1 = married; 2 = single; 3 = others).X5: Age (year).X6 - X11: History of past payment. We tracked the past monthly payment records (from April to September, 2005) as follows: X6 = the repayment status in September, 2005; X7 = the repayment status in August, 2005; . . .;X11 = the repayment status in April, 2005. The measurement scale for the repayment status is: -1 = pay duly; 1 = payment delay for one month; 2 = payment delay for two months; . . .; 8 = payment delay for eight months; 9 = payment delay for nine months and above.X12-X17: Amount of bill statement (NT dollar). X12 = amount of bill statement in September, 2005; X13 = amount of bill statement in August, 2005; . . .; X17 = amount of bill statement in April, 2005. X18-X23: Amount of previous payment (NT dollar). X18 = amount paid in September, 2005; X19 = amount paid in August, 2005; . . .;X23 = amount paid in April, 2005."
Daily Demand Forecasting Orders,Daily Demand Forecasting Orders,"The dataset was collected during 60 days, this is a real database of a brazilian logistics company.",Daily+Demand+Forecasting+Orders,https://archive.ics.uci.edu/ml//machine-learning-databases/00409/,https://archive.ics.uci.edu/ml/datasets/Daily+Demand+Forecasting+Orders,"The database was collected during 60 days, this is a real database of a Brazilian company of large logistics. Twelve predictive attributes and a target that is the total of orders for daily. treatment",Business,"The dataset was collected during 60 days, this is a real database of a brazilian logistics company. The dataset has twelve predictive attributes and a target that is the total of orders for daily treatment. The database was used in academic research at the Universidade Nove de Julho..arff header for Weka:@relation Daily_Demand_Forecasting_Orders@attribute Week_of_the_month {1.0, 2.0, 3.0, 4.0, 5.0}@attribute Day_of_the_week_(Monday_to_Friday) {2.0, 3.0, 4.0, 5.0, 6.0}@attribute Non_urgent_order integer@attribute Urgent_order integer@attribute Order_type_A integer@attribute Order_type_B integer@attribute Order_type_C integer@attribute Fiscal_sector_orders integer@attribute Orders_from_the_traffic_controller_sector integer@attribute Banking_orders_(1) integer@attribute Banking_orders_(2) integer@attribute Banking_orders_(3) integer@attribute Target_(Total_orders) integer@data","The dataset was collected during 60 days, this is a real database of a brazilian logistics company.The database was collected during 60 days, this is a real database of a Brazilian company of large logistics. Twelve predictive attributes and a target that is the total of orders for daily. treatmentThe dataset was collected during 60 days, this is a real database of a brazilian logistics company. The dataset has twelve predictive attributes and a target that is the total of orders for daily treatment. The database was used in academic research at the Universidade Nove de Julho..arff header for Weka:@relation Daily_Demand_Forecasting_Orders@attribute Week_of_the_month {1.0, 2.0, 3.0, 4.0, 5.0}@attribute Day_of_the_week_(Monday_to_Friday) {2.0, 3.0, 4.0, 5.0, 6.0}@attribute Non_urgent_order integer@attribute Urgent_order integer@attribute Order_type_A integer@attribute Order_type_B integer@attribute Order_type_C integer@attribute Fiscal_sector_orders integer@attribute Orders_from_the_traffic_controller_sector integer@attribute Banking_orders_(1) integer@attribute Banking_orders_(2) integer@attribute Banking_orders_(3) integer@attribute Target_(Total_orders) integer@data"
Credit Approval,Credit Approval,This data concerns credit card applications; good mix of attributes,Credit+Approval,https://archive.ics.uci.edu/ml//machine-learning-databases/credit-screening/,https://archive.ics.uci.edu/ml/datasets/Credit+Approval,"This file concerns credit card applications.  All attribute names and values have been changed to meaningless symbols to protect confidentiality of the data.  This dataset is interesting because there is a good mix of attributes -- continuous, nominal with small numbers of values, and nominal with larger numbers of values.  There are also a few missing values.",Business,"A1:	b, a.A2:	continuous.A3:	continuous.A4:	u, y, l, t.A5:	g, p, gg.A6:	c, d, cc, i, j, k, m, r, q, w, x, e, aa, ff.A7:	v, h, bb, j, n, z, dd, ff, o.A8:	continuous.A9:	t, f.A10:	t, f.A11:	continuous.A12:	t, f.A13:	g, p, s.A14:	continuous.A15:	continuous.A16: +,-         (class attribute)","This data concerns credit card applications; good mix of attributesThis file concerns credit card applications.  All attribute names and values have been changed to meaningless symbols to protect confidentiality of the data.  This dataset is interesting because there is a good mix of attributes -- continuous, nominal with small numbers of values, and nominal with larger numbers of values.  There are also a few missing values.A1:	b, a.A2:	continuous.A3:	continuous.A4:	u, y, l, t.A5:	g, p, gg.A6:	c, d, cc, i, j, k, m, r, q, w, x, e, aa, ff.A7:	v, h, bb, j, n, z, dd, ff, o.A8:	continuous.A9:	t, f.A10:	t, f.A11:	continuous.A12:	t, f.A13:	g, p, s.A14:	continuous.A15:	continuous.A16: +,-         (class attribute)"
Non verbal tourists data,Non verbal tourists data,This dataset contains the information about non-verbal preferences of tourists,Non+verbal+tourists+data,https://archive.ics.uci.edu/ml//machine-learning-databases/00620/,https://archive.ics.uci.edu/ml/datasets/Non+verbal+tourists+data,"A total of 73 customers, aged between 24 and 81 years old, were surveyed. Of the customers surveyed, 38 were returning customers, and 35 were new cus-tomers. The variables chosen are the essential ones that make up the non-verbal communication system. In addition to being the most feasible to evaluate in clients. The non-verbal system is made up of subsystems such as kinesic, paralanguage, proxemic, chronic, and others. In the design of the questionnaire, the indicators that make up these subsystems were taken into account to be explored as part of the client's communication preferences, as well as being feasible to evaluate in clients. The 22 variables analyzed were considered feasible to evaluate by the hotel's clientele.",Business,"Number	Name	Description 	        Admissible values1	Sex 	Sex of the client 	Male, Female, ?1  2	Age	Age of the client 	0-100, ?3	Country	Country of the client 	United Nations admitted countries, ?4	Returning 	If the client is returning	Yes, No, ?5	GImg1	Handshake 	Indifferent, likes, dislikes, ? 6	GImg2	Hug 	Indifferent, likes, dislikes, ?7	GImg3	Kiss 	Indifferent, likes, dislikes, ?8	PImg1	Consent posture	Indifferent, likes, dislikes, ? 9	PImg2	Interest posture	Indifferent, likes, dislikes, ? 10	PImg3	Neutral posture	Indifferent, likes, dislikes, ? 11	PImg4	Reflexive posture	Indifferent, likes, dislikes, ? 12	PImg5	Negative posture	Indifferent, likes, dislikes, ? 13	Tense - relaxed	Observed emotional clime. 	1-10, ? (1 is too tense, 10 is too relaxed)14	Authoritative -anarchic	Observed emotional clime	1-10, ? (1 is too authoritative, 10 is too anar-chic)15	Hostile - friendly	Observed emotional clime	1-10, ? (1 is too hostile, 10 is too friendly)16	TAudio1	Authoritative 	Indifferent, likes, dislikes, ?17	TAudio2	Sarcastic 	Indifferent, likes, dislikes, ?18	TAudio3	Friendly 	Indifferent, likes, dislikes, ?19	QAudio1	Spitting	Indifferent, likes, dislikes, ?20	QAudio2	Hum	Indifferent, likes, dislikes, ?21	QAudio3	Sigh	Indifferent, likes, dislikes, ?22	Proxemic 	Physical distance preferred for the client	A, B, C, D, ? (A. intimate: 15cm-45cm; B. per-sonal: 46cm-122cm; C. social: 123cm-360cm; D. public: > 360cm)23      Class           Type of client","This dataset contains the information about non-verbal preferences of touristsA total of 73 customers, aged between 24 and 81 years old, were surveyed. Of the customers surveyed, 38 were returning customers, and 35 were new cus-tomers. The variables chosen are the essential ones that make up the non-verbal communication system. In addition to being the most feasible to evaluate in clients. The non-verbal system is made up of subsystems such as kinesic, paralanguage, proxemic, chronic, and others. In the design of the questionnaire, the indicators that make up these subsystems were taken into account to be explored as part of the client's communication preferences, as well as being feasible to evaluate in clients. The 22 variables analyzed were considered feasible to evaluate by the hotel's clientele.Number	Name	Description 	        Admissible values1	Sex 	Sex of the client 	Male, Female, ?1  2	Age	Age of the client 	0-100, ?3	Country	Country of the client 	United Nations admitted countries, ?4	Returning 	If the client is returning	Yes, No, ?5	GImg1	Handshake 	Indifferent, likes, dislikes, ? 6	GImg2	Hug 	Indifferent, likes, dislikes, ?7	GImg3	Kiss 	Indifferent, likes, dislikes, ?8	PImg1	Consent posture	Indifferent, likes, dislikes, ? 9	PImg2	Interest posture	Indifferent, likes, dislikes, ? 10	PImg3	Neutral posture	Indifferent, likes, dislikes, ? 11	PImg4	Reflexive posture	Indifferent, likes, dislikes, ? 12	PImg5	Negative posture	Indifferent, likes, dislikes, ? 13	Tense - relaxed	Observed emotional clime. 	1-10, ? (1 is too tense, 10 is too relaxed)14	Authoritative -anarchic	Observed emotional clime	1-10, ? (1 is too authoritative, 10 is too anar-chic)15	Hostile - friendly	Observed emotional clime	1-10, ? (1 is too hostile, 10 is too friendly)16	TAudio1	Authoritative 	Indifferent, likes, dislikes, ?17	TAudio2	Sarcastic 	Indifferent, likes, dislikes, ?18	TAudio3	Friendly 	Indifferent, likes, dislikes, ?19	QAudio1	Spitting	Indifferent, likes, dislikes, ?20	QAudio2	Hum	Indifferent, likes, dislikes, ?21	QAudio3	Sigh	Indifferent, likes, dislikes, ?22	Proxemic 	Physical distance preferred for the client	A, B, C, D, ? (A. intimate: 15cm-45cm; B. per-sonal: 46cm-122cm; C. social: 123cm-360cm; D. public: > 360cm)23      Class           Type of client"
Online News Popularity,Online News Popularity,This dataset summarizes a heterogeneous set of features about articles published by Mashable in a period of two years. The goal is to predict the number of shares in social networks (popularity).,Online+News+Popularity,https://archive.ics.uci.edu/ml//machine-learning-databases/00332/,https://archive.ics.uci.edu/ml/datasets/Online+News+Popularity,"* The articles were published by Mashable (www.mashable.com) and their content as the rights to reproduce it belongs to them. Hence, this dataset does not share the original content but some statistics associated with it. The original content be publicly accessed and retrieved using the provided urls.* Acquisition date: January 8, 2015* The estimated relative performance values were estimated by the authors using a Random Forest classifier and a rolling windows as assessment method.  See their article for more details on how the relative performance values were set.",Business,"Number of Attributes: 61 (58 predictive attributes, 2 non-predictive, 1 goal field)Attribute Information:     0. url:                           URL of the article (non-predictive)     1. timedelta:                     Days between the article publication and the dataset acquisition (non-predictive)     2. n_tokens_title:                Number of words in the title     3. n_tokens_content:              Number of words in the content     4. n_unique_tokens:               Rate of unique words in the content     5. n_non_stop_words:              Rate of non-stop words in the content     6. n_non_stop_unique_tokens:      Rate of unique non-stop words in the content     7. num_hrefs:                     Number of links     8. num_self_hrefs:                Number of links to other articles published by Mashable     9. num_imgs:                      Number of images    10. num_videos:                    Number of videos    11. average_token_length:          Average length of the words in the content    12. num_keywords:                  Number of keywords in the metadata    13. data_channel_is_lifestyle:     Is data channel 'Lifestyle'?    14. data_channel_is_entertainment: Is data channel 'Entertainment'?    15. data_channel_is_bus:           Is data channel 'Business'?    16. data_channel_is_socmed:        Is data channel 'Social Media'?    17. data_channel_is_tech:          Is data channel 'Tech'?    18. data_channel_is_world:         Is data channel 'World'?    19. kw_min_min:                    Worst keyword (min. shares)    20. kw_max_min:                    Worst keyword (max. shares)    21. kw_avg_min:                    Worst keyword (avg. shares)    22. kw_min_max:                    Best keyword (min. shares)    23. kw_max_max:                    Best keyword (max. shares)    24. kw_avg_max:                    Best keyword (avg. shares)    25. kw_min_avg:                    Avg. keyword (min. shares)    26. kw_max_avg:                    Avg. keyword (max. shares)    27. kw_avg_avg:                    Avg. keyword (avg. shares)    28. self_reference_min_shares:     Min. shares of referenced articles in Mashable    29. self_reference_max_shares:     Max. shares of referenced articles in Mashable    30. self_reference_avg_sharess:    Avg. shares of referenced articles in Mashable    31. weekday_is_monday:             Was the article published on a Monday?    32. weekday_is_tuesday:            Was the article published on a Tuesday?    33. weekday_is_wednesday:          Was the article published on a Wednesday?    34. weekday_is_thursday:           Was the article published on a Thursday?    35. weekday_is_friday:             Was the article published on a Friday?    36. weekday_is_saturday:           Was the article published on a Saturday?    37. weekday_is_sunday:             Was the article published on a Sunday?    38. is_weekend:                    Was the article published on the weekend?    39. LDA_00:                        Closeness to LDA topic 0    40. LDA_01:                        Closeness to LDA topic 1    41. LDA_02:                        Closeness to LDA topic 2    42. LDA_03:                        Closeness to LDA topic 3    43. LDA_04:                        Closeness to LDA topic 4    44. global_subjectivity:           Text subjectivity    45. global_sentiment_polarity:     Text sentiment polarity    46. global_rate_positive_words:    Rate of positive words in the content    47. global_rate_negative_words:    Rate of negative words in the content    48. rate_positive_words:           Rate of positive words among non-neutral tokens    49. rate_negative_words:           Rate of negative words among non-neutral tokens    50. avg_positive_polarity:         Avg. polarity of positive words    51. min_positive_polarity:         Min. polarity of positive words    52. max_positive_polarity:         Max. polarity of positive words    53. avg_negative_polarity:         Avg. polarity of negative  words    54. min_negative_polarity:         Min. polarity of negative  words    55. max_negative_polarity:         Max. polarity of negative  words    56. title_subjectivity:            Title subjectivity    57. title_sentiment_polarity:      Title polarity    58. abs_title_subjectivity:        Absolute subjectivity level    59. abs_title_sentiment_polarity:  Absolute polarity level    60. shares:                        Number of shares (target)","This dataset summarizes a heterogeneous set of features about articles published by Mashable in a period of two years. The goal is to predict the number of shares in social networks (popularity).* The articles were published by Mashable (www.mashable.com) and their content as the rights to reproduce it belongs to them. Hence, this dataset does not share the original content but some statistics associated with it. The original content be publicly accessed and retrieved using the provided urls.* Acquisition date: January 8, 2015* The estimated relative performance values were estimated by the authors using a Random Forest classifier and a rolling windows as assessment method.  See their article for more details on how the relative performance values were set.Number of Attributes: 61 (58 predictive attributes, 2 non-predictive, 1 goal field)Attribute Information:     0. url:                           URL of the article (non-predictive)     1. timedelta:                     Days between the article publication and the dataset acquisition (non-predictive)     2. n_tokens_title:                Number of words in the title     3. n_tokens_content:              Number of words in the content     4. n_unique_tokens:               Rate of unique words in the content     5. n_non_stop_words:              Rate of non-stop words in the content     6. n_non_stop_unique_tokens:      Rate of unique non-stop words in the content     7. num_hrefs:                     Number of links     8. num_self_hrefs:                Number of links to other articles published by Mashable     9. num_imgs:                      Number of images    10. num_videos:                    Number of videos    11. average_token_length:          Average length of the words in the content    12. num_keywords:                  Number of keywords in the metadata    13. data_channel_is_lifestyle:     Is data channel 'Lifestyle'?    14. data_channel_is_entertainment: Is data channel 'Entertainment'?    15. data_channel_is_bus:           Is data channel 'Business'?    16. data_channel_is_socmed:        Is data channel 'Social Media'?    17. data_channel_is_tech:          Is data channel 'Tech'?    18. data_channel_is_world:         Is data channel 'World'?    19. kw_min_min:                    Worst keyword (min. shares)    20. kw_max_min:                    Worst keyword (max. shares)    21. kw_avg_min:                    Worst keyword (avg. shares)    22. kw_min_max:                    Best keyword (min. shares)    23. kw_max_max:                    Best keyword (max. shares)    24. kw_avg_max:                    Best keyword (avg. shares)    25. kw_min_avg:                    Avg. keyword (min. shares)    26. kw_max_avg:                    Avg. keyword (max. shares)    27. kw_avg_avg:                    Avg. keyword (avg. shares)    28. self_reference_min_shares:     Min. shares of referenced articles in Mashable    29. self_reference_max_shares:     Max. shares of referenced articles in Mashable    30. self_reference_avg_sharess:    Avg. shares of referenced articles in Mashable    31. weekday_is_monday:             Was the article published on a Monday?    32. weekday_is_tuesday:            Was the article published on a Tuesday?    33. weekday_is_wednesday:          Was the article published on a Wednesday?    34. weekday_is_thursday:           Was the article published on a Thursday?    35. weekday_is_friday:             Was the article published on a Friday?    36. weekday_is_saturday:           Was the article published on a Saturday?    37. weekday_is_sunday:             Was the article published on a Sunday?    38. is_weekend:                    Was the article published on the weekend?    39. LDA_00:                        Closeness to LDA topic 0    40. LDA_01:                        Closeness to LDA topic 1    41. LDA_02:                        Closeness to LDA topic 2    42. LDA_03:                        Closeness to LDA topic 3    43. LDA_04:                        Closeness to LDA topic 4    44. global_subjectivity:           Text subjectivity    45. global_sentiment_polarity:     Text sentiment polarity    46. global_rate_positive_words:    Rate of positive words in the content    47. global_rate_negative_words:    Rate of negative words in the content    48. rate_positive_words:           Rate of positive words among non-neutral tokens    49. rate_negative_words:           Rate of negative words among non-neutral tokens    50. avg_positive_polarity:         Avg. polarity of positive words    51. min_positive_polarity:         Min. polarity of positive words    52. max_positive_polarity:         Max. polarity of positive words    53. avg_negative_polarity:         Avg. polarity of negative  words    54. min_negative_polarity:         Min. polarity of negative  words    55. max_negative_polarity:         Max. polarity of negative  words    56. title_subjectivity:            Title subjectivity    57. title_sentiment_polarity:      Title polarity    58. abs_title_subjectivity:        Absolute subjectivity level    59. abs_title_sentiment_polarity:  Absolute polarity level    60. shares:                        Number of shares (target)"
Stock portfolio performance,Stock portfolio performance,The data set of performances of weighted scoring stock portfolios are obtained with mixture design from the US stock market historical database.,Stock+portfolio+performance,https://archive.ics.uci.edu/ml//machine-learning-databases/00390/,https://archive.ics.uci.edu/ml/datasets/Stock+portfolio+performance,"There are three disadvantages of weighted scoring stock selection models. First, they cannot identify the relations between weights of stock-picking concepts and performances of portfolios. Second, they cannot systematically discover the optimal combination for weights of concepts to optimize the performances. Third, they are unable to meet various investorsÃ¢â‚¬â„¢ preferences. This study aims to more efficiently construct weighted scoring stock selection models to overcome these disadvantages. Since the weights of stock-picking concepts in a weighted scoring stock selection model can be regarded as components in a mixture, we used the simplex centroid mixture design to obtain the experimental sets of weights. These sets of weights are simulated with US stock market historical data to obtain their performances. Performance prediction models were built with the simulated performance data set and artificial neural networks. Furthermore, the optimization models to reflect investorsÃ¢â‚¬â„¢ preferences were built up, and the performance prediction models were employed as the kernel of the optimization models so that the optimal solutions can now be solved with optimization techniques. The empirical values of the performances of the optimal weighting combinations generated by the optimization models showed that they can meet various investorsÃ¢â‚¬â„¢ preferences and outperform those of S&PÃ¢â‚¬â„¢s 500 not only during the training period but also during the testing period.",Business,The inputs are the weights of the stock-picking concepts as followsX1=the weight of the Large B/P conceptX2=the weight of the Large ROE conceptX3=the weight of the Large S/P conceptX4=the weight of the Large Return Rate in the last quarter conceptX5=the weight of the Large Market Value conceptX6=the weight of the Small systematic Risk conceptThe outputs are the investment performance indicators (normalized) as followsY1=Annual ReturnY2=Excess ReturnY3=Systematic RiskY4=Total RiskY5=Abs. Win RateY6=Rel. Win Rate,"The data set of performances of weighted scoring stock portfolios are obtained with mixture design from the US stock market historical database.There are three disadvantages of weighted scoring stock selection models. First, they cannot identify the relations between weights of stock-picking concepts and performances of portfolios. Second, they cannot systematically discover the optimal combination for weights of concepts to optimize the performances. Third, they are unable to meet various investorsÃ¢â‚¬â„¢ preferences. This study aims to more efficiently construct weighted scoring stock selection models to overcome these disadvantages. Since the weights of stock-picking concepts in a weighted scoring stock selection model can be regarded as components in a mixture, we used the simplex centroid mixture design to obtain the experimental sets of weights. These sets of weights are simulated with US stock market historical data to obtain their performances. Performance prediction models were built with the simulated performance data set and artificial neural networks. Furthermore, the optimization models to reflect investorsÃ¢â‚¬â„¢ preferences were built up, and the performance prediction models were employed as the kernel of the optimization models so that the optimal solutions can now be solved with optimization techniques. The empirical values of the performances of the optimal weighting combinations generated by the optimization models showed that they can meet various investorsÃ¢â‚¬â„¢ preferences and outperform those of S&PÃ¢â‚¬â„¢s 500 not only during the training period but also during the testing period.The inputs are the weights of the stock-picking concepts as followsX1=the weight of the Large B/P conceptX2=the weight of the Large ROE conceptX3=the weight of the Large S/P conceptX4=the weight of the Large Return Rate in the last quarter conceptX5=the weight of the Large Market Value conceptX6=the weight of the Small systematic Risk conceptThe outputs are the investment performance indicators (normalized) as followsY1=Annual ReturnY2=Excess ReturnY3=Systematic RiskY4=Total RiskY5=Abs. Win RateY6=Rel. Win Rate"
Taiwanese Bankruptcy Prediction,Taiwanese Bankruptcy Prediction,The data were collected from the Taiwan Economic Journal  for the years 1999 to 2009. Company bankruptcy was defined based on the business regulations of the Taiwan Stock Exchange.,Taiwanese+Bankruptcy+Prediction,https://archive.ics.uci.edu/ml//machine-learning-databases/00572/,https://archive.ics.uci.edu/ml/datasets/Taiwanese+Bankruptcy+Prediction,Provide all relevant information about your data set.,Business,The first attribute is the class lable.X1	Cost of Interest-bearing DebtX2	Cash Reinvestment RatioX3	Current RatioX4	Acid Test  X5	Interest Expenses/Total RevenueX6	Total Liability/Equity RatioX7	Liability/Total AssetsX8	Interest-bearing Debt/EquityX9	Contingent Liability/EquityX10	Operating Income/CapitalX11	Pretax Income/CapitalX12	Working Capital to Total AssetsX13	Quick Assets/Total assetsX14	Current Assets/Total AssetsX15	Cash/Total AssetsX16	Quick Assets/Current LiabilityX17	Cash/Current LiabilityX18	Current Liability to AssetsX19	Operating Funds to Liability X20	Inventory/Working CapitalX21	Inventory/Current LiabilityX22	Current Liabilities/LiabilityX23	Working Capital/EquityX24	Current Liabilities/EquityX25	Long-term Liability to Current AssetsX26	Current Liability to Current AssetsX27	One if Total Liability exceeds Total Assets;X28	Equity to LiabilityX29	Equity/Total AssetsX30	(Long-term Liability+Equity)/Fixed AssetsX31	Fixed Assets to AssetsX32	Current Liability to Liability X33	Current Liability to EquityX34	Equity to Long-term LiabilityX35	Liability to Equity X36	Degree of Financial LeverageX37	Interest Coverage RatioX38	Operating Expenses/Net SalesX39	(Research and Development Expenses)/Net SalesX40	Effective Tax RateX41	Book Value Per Share(B)X42	Book Value Per Share(A)X43	Book Value Per Share(C)X44	Cash Flow Per ShareX45	Sales Per ShareX46	Operating Income Per ShareX47	Sales Per EmployeeX48	Operation Income Per EmployeeX49	Fixed Assets Per EmployeeX50	total assets to GNP priceX51	Return On Total Assets(C)X52	Return On Total Assets(A)X53	Return On Total Assets(B)X54	Gross Profit /Net SalesX55	Realized Gross Profit/Net SalesX56	Operating Income /Net SalesX57	Pre-Tax Income/Net SalesX58	Net Income/Net SalesX59	Net Non-operating Income RatioX60	Net Income-Exclude Disposal Gain or Loss/Net SalesX61	EPS-Net IncomeX62	Pretax Income Per ShareX63	Retained Earnings to Total AssetsX64	Total Income to Total ExpensesX65	Total Expenses to AssetsX66	Net Income to Total AssetsX67	Gross Profit to SalesX68	Net Income to Stockholder's EquityX69	One if Net Income is Negative for the Last Two Years; Zero OtherwiseX70	(Inventory +Accounts Receivables) /EquityX71	Total Asset TurnoverX72	Accounts Receivable TurnoverX73	Days Receivable OutstandingX74	Inventory TurnoverX75	Fixed Asset TurnoverX76	Equity TurnoverX77	Current Assets to SalesX78	Quick Assets to SalesX79	Working Capital to SalesX80	Cash to SalesX81	Cash Flow to SalesX82	No-credit IntervalX83	Cash Flow from Operating/Current LiabilitiesX84	Cash Flow to Total AssetsX85	Cash Flow to LiabilityX86	CFO to AssetsX87	Cash Flow to EquityX88	Realized Gross Profit Growth RateX89	Operating Income GrowthX90	Net Income GrowthX91	Continuing Operating Income after Tax GrowthX92	Net Income-Excluding Disposal Gain or Loss GrowthX93	Total Asset GrowthX94	Total Equity GrowthX95	Return on Total Asset Growth,The data were collected from the Taiwan Economic Journal  for the years 1999 to 2009. Company bankruptcy was defined based on the business regulations of the Taiwan Stock Exchange.Provide all relevant information about your data set.The first attribute is the class lable.X1	Cost of Interest-bearing DebtX2	Cash Reinvestment RatioX3	Current RatioX4	Acid Test  X5	Interest Expenses/Total RevenueX6	Total Liability/Equity RatioX7	Liability/Total AssetsX8	Interest-bearing Debt/EquityX9	Contingent Liability/EquityX10	Operating Income/CapitalX11	Pretax Income/CapitalX12	Working Capital to Total AssetsX13	Quick Assets/Total assetsX14	Current Assets/Total AssetsX15	Cash/Total AssetsX16	Quick Assets/Current LiabilityX17	Cash/Current LiabilityX18	Current Liability to AssetsX19	Operating Funds to Liability X20	Inventory/Working CapitalX21	Inventory/Current LiabilityX22	Current Liabilities/LiabilityX23	Working Capital/EquityX24	Current Liabilities/EquityX25	Long-term Liability to Current AssetsX26	Current Liability to Current AssetsX27	One if Total Liability exceeds Total Assets;X28	Equity to LiabilityX29	Equity/Total AssetsX30	(Long-term Liability+Equity)/Fixed AssetsX31	Fixed Assets to AssetsX32	Current Liability to Liability X33	Current Liability to EquityX34	Equity to Long-term LiabilityX35	Liability to Equity X36	Degree of Financial LeverageX37	Interest Coverage RatioX38	Operating Expenses/Net SalesX39	(Research and Development Expenses)/Net SalesX40	Effective Tax RateX41	Book Value Per Share(B)X42	Book Value Per Share(A)X43	Book Value Per Share(C)X44	Cash Flow Per ShareX45	Sales Per ShareX46	Operating Income Per ShareX47	Sales Per EmployeeX48	Operation Income Per EmployeeX49	Fixed Assets Per EmployeeX50	total assets to GNP priceX51	Return On Total Assets(C)X52	Return On Total Assets(A)X53	Return On Total Assets(B)X54	Gross Profit /Net SalesX55	Realized Gross Profit/Net SalesX56	Operating Income /Net SalesX57	Pre-Tax Income/Net SalesX58	Net Income/Net SalesX59	Net Non-operating Income RatioX60	Net Income-Exclude Disposal Gain or Loss/Net SalesX61	EPS-Net IncomeX62	Pretax Income Per ShareX63	Retained Earnings to Total AssetsX64	Total Income to Total ExpensesX65	Total Expenses to AssetsX66	Net Income to Total AssetsX67	Gross Profit to SalesX68	Net Income to Stockholder's EquityX69	One if Net Income is Negative for the Last Two Years; Zero OtherwiseX70	(Inventory +Accounts Receivables) /EquityX71	Total Asset TurnoverX72	Accounts Receivable TurnoverX73	Days Receivable OutstandingX74	Inventory TurnoverX75	Fixed Asset TurnoverX76	Equity TurnoverX77	Current Assets to SalesX78	Quick Assets to SalesX79	Working Capital to SalesX80	Cash to SalesX81	Cash Flow to SalesX82	No-credit IntervalX83	Cash Flow from Operating/Current LiabilitiesX84	Cash Flow to Total AssetsX85	Cash Flow to LiabilityX86	CFO to AssetsX87	Cash Flow to EquityX88	Realized Gross Profit Growth RateX89	Operating Income GrowthX90	Net Income GrowthX91	Continuing Operating Income after Tax GrowthX92	Net Income-Excluding Disposal Gain or Loss GrowthX93	Total Asset GrowthX94	Total Equity GrowthX95	Return on Total Asset Growth
Farm Ads,Farm Ads,This data was collected from text ads found on twelve websites that deal with various farm animal related topics.  The binary labels are based on whether or not the content owner approves of the ad.,Farm+Ads,https://archive.ics.uci.edu/ml//machine-learning-databases/00218/,https://archive.ics.uci.edu/ml/datasets/Farm+Ads,"This data was collected from text ads found on twelve websites that deal with various farm animal related topics.  Information from the ad creative and the ad landing page is included.  The binary labels are based on whether or not the content owner approves of the ad.For each ad, we include the words on the ad creative and the words from the landing page.  Each word from the creative is given a prefixof 'ad-'.  Title and header HTML markups are noted in a similar way in the text of the landing page.  We have already performed stemming andstop word removal.  Each ad is on a single line.  The first word in the line is the label of the instance.  It is 1 for accepted ads and -1 for rejected ads.We have also included a straightforward bag-of-words representation of our data.  We use the SVMlight sparse vector format.  The first valueis the label followed by every nonzero attribute.  Each of these attributes is encoded as index:value.  This is the representation used for the relevant paper cited below.",Business,Text words in file farm-ads.  SVMlight format sparse vectors in file farm-ads-vect.,"This data was collected from text ads found on twelve websites that deal with various farm animal related topics.  The binary labels are based on whether or not the content owner approves of the ad.This data was collected from text ads found on twelve websites that deal with various farm animal related topics.  Information from the ad creative and the ad landing page is included.  The binary labels are based on whether or not the content owner approves of the ad.For each ad, we include the words on the ad creative and the words from the landing page.  Each word from the creative is given a prefixof 'ad-'.  Title and header HTML markups are noted in a similar way in the text of the landing page.  We have already performed stemming andstop word removal.  Each ad is on a single line.  The first word in the line is the label of the instance.  It is 1 for accepted ads and -1 for rejected ads.We have also included a straightforward bag-of-words representation of our data.  We use the SVMlight sparse vector format.  The first valueis the label followed by every nonzero attribute.  Each of these attributes is encoded as index:value.  This is the representation used for the relevant paper cited below.Text words in file farm-ads.  SVMlight format sparse vectors in file farm-ads-vect."
Vehicle routing and scheduling problems,Vehicle routing and scheduling problems,Data collection was conducted through notes taken during the distribution of orders in a courier company that operates in the region and in the city of SÃ£o Paulo (Brazil).,Vehicle+routing+and+scheduling+problems,https://archive.ics.uci.edu/ml//machine-learning-databases/00546/,https://archive.ics.uci.edu/ml/datasets/Vehicle+routing+and+scheduling+problems,"The attributes are the number of crew members, form of cargo stowage/transshipment (manual or mechanized/palletized), service difficulty (waiting time, identification of delivery person, etc.), distance from the depot in kilometers, average monthly cargo, average daily per point, average number of volumes transported per day, average vehicle occupation (%), and the type of vehicle used. The data set (Vehicle routing and scheduling problems) was used in academic research at the Universidade Nove de Julho - Postgraduate Program in Informatics and Knowledge Management.",Business,"1.	Number of crew members2.	Form of cargo stowage/transshipment (manual = 1 or mechanized/palletized = 2)3.	Service difficulty (waiting time, identification of delivery person, etc.) - (low service difficulty = 1; 2, 3 and 4 intermediate; high service difficulty = 5)4.	Distance from the depot in kilometers5.	Average monthly cargo6.	Average daily per point7.	Average number of volumes transported per day (box)8.	Average vehicle occupation (%)9.	Type of vehicle (Up to 0.7 tons of capacity = 1; Up to 1.5 tons of capacity; Up to 3 tons of capacity).","Data collection was conducted through notes taken during the distribution of orders in a courier company that operates in the region and in the city of SÃ£o Paulo (Brazil).The attributes are the number of crew members, form of cargo stowage/transshipment (manual or mechanized/palletized), service difficulty (waiting time, identification of delivery person, etc.), distance from the depot in kilometers, average monthly cargo, average daily per point, average number of volumes transported per day, average vehicle occupation (%), and the type of vehicle used. The data set (Vehicle routing and scheduling problems) was used in academic research at the Universidade Nove de Julho - Postgraduate Program in Informatics and Knowledge Management.1.	Number of crew members2.	Form of cargo stowage/transshipment (manual = 1 or mechanized/palletized = 2)3.	Service difficulty (waiting time, identification of delivery person, etc.) - (low service difficulty = 1; 2, 3 and 4 intermediate; high service difficulty = 5)4.	Distance from the depot in kilometers5.	Average monthly cargo6.	Average daily per point7.	Average number of volumes transported per day (box)8.	Average vehicle occupation (%)9.	Type of vehicle (Up to 0.7 tons of capacity = 1; Up to 1.5 tons of capacity; Up to 3 tons of capacity)."
Wholesale customers,Wholesale customers,The data set refers to clients of a wholesale distributor. It includes the annual spending in monetary units (m.u.) on diverse product categories,Wholesale+customers,https://archive.ics.uci.edu/ml//machine-learning-databases/00292/,https://archive.ics.uci.edu/ml/datasets/Wholesale+customers,Provide all relevant information about your data set.,Business,"1)	FRESH: annual spending (m.u.) on fresh products (Continuous);2)	MILK: annual spending (m.u.) on milk products (Continuous);3)	GROCERY: annual spending (m.u.)on grocery products (Continuous);4)	FROZEN: annual spending (m.u.)on frozen products (Continuous)5)	DETERGENTS_PAPER: annual spending (m.u.) on detergents and paper products (Continuous) 6)	DELICATESSEN: annual spending (m.u.)on and delicatessen products (Continuous); 7)	CHANNEL: customersÃ¢â‚¬â„¢ Channel - Horeca (Hotel/Restaurant/CafÃƒÂ©) or Retail channel (Nominal)8)	REGION: customersÃ¢â‚¬â„¢ Region Ã¢â‚¬â€œ Lisnon, Oporto or Other (Nominal)Descriptive Statistics:	(Minimum, Maximum, Mean, Std. Deviation)FRESH (	3, 112151, 12000.30, 12647.329)MILK	(55, 73498, 5796.27, 7380.377)GROCERY	(3, 92780, 7951.28, 9503.163)FROZEN	(25, 60869, 3071.93, 4854.673)DETERGENTS_PAPER (3, 40827, 2881.49, 4767.854)DELICATESSEN (3, 47943, 1524.87, 2820.106)REGION	FrequencyLisbon	77Oporto	47Other Region	316Total	440CHANNEL	FrequencyHoreca	298Retail	142Total	440","The data set refers to clients of a wholesale distributor. It includes the annual spending in monetary units (m.u.) on diverse product categoriesProvide all relevant information about your data set.1)	FRESH: annual spending (m.u.) on fresh products (Continuous);2)	MILK: annual spending (m.u.) on milk products (Continuous);3)	GROCERY: annual spending (m.u.)on grocery products (Continuous);4)	FROZEN: annual spending (m.u.)on frozen products (Continuous)5)	DETERGENTS_PAPER: annual spending (m.u.) on detergents and paper products (Continuous) 6)	DELICATESSEN: annual spending (m.u.)on and delicatessen products (Continuous); 7)	CHANNEL: customersÃ¢â‚¬â„¢ Channel - Horeca (Hotel/Restaurant/CafÃƒÂ©) or Retail channel (Nominal)8)	REGION: customersÃ¢â‚¬â„¢ Region Ã¢â‚¬â€œ Lisnon, Oporto or Other (Nominal)Descriptive Statistics:	(Minimum, Maximum, Mean, Std. Deviation)FRESH (	3, 112151, 12000.30, 12647.329)MILK	(55, 73498, 5796.27, 7380.377)GROCERY	(3, 92780, 7951.28, 9503.163)FROZEN	(25, 60869, 3071.93, 4854.673)DETERGENTS_PAPER (3, 40827, 2881.49, 4767.854)DELICATESSEN (3, 47943, 1524.87, 2820.106)REGION	FrequencyLisbon	77Oporto	47Other Region	316Total	440CHANNEL	FrequencyHoreca	298Retail	142Total	440"
Wine Quality,Wine Quality,"Two datasets are included, related to red and white vinho verde wine samples, from the north of Portugal. The goal is to model wine quality based on physicochemical tests (see [Cortez et al., 2009], http://www3.dsi.uminho.pt/pcortez/wine/).",Wine+Quality,https://archive.ics.uci.edu/ml//machine-learning-databases/wine-quality/,https://archive.ics.uci.edu/ml/datasets/Wine+Quality,"The two datasets are related to red and white variants of the Portuguese ""Vinho Verde"" wine. For more details, consult: [Web Link] or the reference [Cortez et al., 2009].  Due to privacy and logistic issues, only physicochemical (inputs) and sensory (the output) variables are available (e.g. there is no data about grape types, wine brand, wine selling price, etc.).These datasets can be viewed as classification or regression tasks.  The classes are ordered and not balanced (e.g. there are many more normal wines than excellent or poor ones). Outlier detection algorithms could be used to detect the few excellent or poor wines. Also, we are not sure if all input variables are relevant. So it could be interesting to test feature selection methods.",Business,"For more information, read [Cortez et al., 2009].Input variables (based on physicochemical tests):   1 - fixed acidity   2 - volatile acidity   3 - citric acid   4 - residual sugar   5 - chlorides   6 - free sulfur dioxide   7 - total sulfur dioxide   8 - density   9 - pH   10 - sulphates   11 - alcoholOutput variable (based on sensory data):    12 - quality (score between 0 and 10)","Two datasets are included, related to red and white vinho verde wine samples, from the north of Portugal. The goal is to model wine quality based on physicochemical tests (see [Cortez et al., 2009], http://www3.dsi.uminho.pt/pcortez/wine/).The two datasets are related to red and white variants of the Portuguese ""Vinho Verde"" wine. For more details, consult: [Web Link] or the reference [Cortez et al., 2009].  Due to privacy and logistic issues, only physicochemical (inputs) and sensory (the output) variables are available (e.g. there is no data about grape types, wine brand, wine selling price, etc.).These datasets can be viewed as classification or regression tasks.  The classes are ordered and not balanced (e.g. there are many more normal wines than excellent or poor ones). Outlier detection algorithms could be used to detect the few excellent or poor wines. Also, we are not sure if all input variables are relevant. So it could be interesting to test feature selection methods.For more information, read [Cortez et al., 2009].Input variables (based on physicochemical tests):   1 - fixed acidity   2 - volatile acidity   3 - citric acid   4 - residual sugar   5 - chlorides   6 - free sulfur dioxide   7 - total sulfur dioxide   8 - density   9 - pH   10 - sulphates   11 - alcoholOutput variable (based on sensory data):    12 - quality (score between 0 and 10)"
Amazon Access Samples,Amazon Access Samples,Amazon's InfoSec is getting smarter about the way Access data is leveraged. This is an anonymized sample of access provisioned within the company.,Amazon+Access+Samples,https://archive.ics.uci.edu/ml//machine-learning-databases/00216/,https://archive.ics.uci.edu/ml/datasets/Amazon+Access+Samples,"This is a sparse data set, less than 10% of the attributes are used for each sample. The link is to a '*.tgz' file which contains two files:[amzn-anon-access-samples-2.0.csv] this file contains the access for users[amzn-anon-access-samples-history-2.0.csv] this file contains the access history for a given user",Business,"__amzn-anon-access-samples-2.0.csv__This is a sparse data set containing users and their assigned access. The file contains 4 categories of attributes.1) [PERSON_{ATTRIBUTE}] This category describes the 'user' who was given access. The [PERSON_ID] column is the primary key column for the file. There is one row per user.PERSON_ID: id of the userPERSON_MGR_ID: id of the user's managerPERSON_ROLLUP_1: user grouping idPERSON_ROLLUP_2: user grouping idPERSON_ROLLUP_3: user grouping idPERSON_DEPTNAME: department desciption idPERSON_LOCATION: region idPERSON_BUSINESS_TITLE: title idPERSON_BUSINESS_TITLE_DETAIL: description idPERSON_JOB_CODE: job code idPERSON_COMPANY: company idPERSON_JOB_FAMILY: job family id2) [RESOURCE_{ID}] This category of attributes are the resources that a users can possibly have access to. A user will have a 1 in this column if the have access to it otherwise it will be 0.3) [GROUP_{ID}] - This category of attributes are the groups that a users can possibly have access to. A user will have a 1 in this column if the have access to it otherwise it will be 0.4) [SYSTEM_SUPPORT_{ID}] - This category of attributes are the system that a user can possibly be supporting. A user will have a 1 in this column if the have can possibly be supporting it, otherwise it will be 0.__amzn-anon-access-samples-history-2.0.csv__Permissions Time series data. Here is a short description of the columns:ACTION: either 'remove_access' or 'add_access'TARGET_NAME: either the {RESOURCE_ID} or {GROUP_ID}LOGIN: the id of the user that is obtaining or losing accessREQUEST_DATE: YYYY-MM-DD HH:MM:SSAUTHORIZATION_DATE: YYYY-MM-DD HH:MM:SS","Amazon's InfoSec is getting smarter about the way Access data is leveraged. This is an anonymized sample of access provisioned within the company.This is a sparse data set, less than 10% of the attributes are used for each sample. The link is to a '*.tgz' file which contains two files:[amzn-anon-access-samples-2.0.csv] this file contains the access for users[amzn-anon-access-samples-history-2.0.csv] this file contains the access history for a given user__amzn-anon-access-samples-2.0.csv__This is a sparse data set containing users and their assigned access. The file contains 4 categories of attributes.1) [PERSON_{ATTRIBUTE}] This category describes the 'user' who was given access. The [PERSON_ID] column is the primary key column for the file. There is one row per user.PERSON_ID: id of the userPERSON_MGR_ID: id of the user's managerPERSON_ROLLUP_1: user grouping idPERSON_ROLLUP_2: user grouping idPERSON_ROLLUP_3: user grouping idPERSON_DEPTNAME: department desciption idPERSON_LOCATION: region idPERSON_BUSINESS_TITLE: title idPERSON_BUSINESS_TITLE_DETAIL: description idPERSON_JOB_CODE: job code idPERSON_COMPANY: company idPERSON_JOB_FAMILY: job family id2) [RESOURCE_{ID}] This category of attributes are the resources that a users can possibly have access to. A user will have a 1 in this column if the have access to it otherwise it will be 0.3) [GROUP_{ID}] - This category of attributes are the groups that a users can possibly have access to. A user will have a 1 in this column if the have access to it otherwise it will be 0.4) [SYSTEM_SUPPORT_{ID}] - This category of attributes are the system that a user can possibly be supporting. A user will have a 1 in this column if the have can possibly be supporting it, otherwise it will be 0.__amzn-anon-access-samples-history-2.0.csv__Permissions Time series data. Here is a short description of the columns:ACTION: either 'remove_access' or 'add_access'TARGET_NAME: either the {RESOURCE_ID} or {GROUP_ID}LOGIN: the id of the user that is obtaining or losing accessREQUEST_DATE: YYYY-MM-DD HH:MM:SSAUTHORIZATION_DATE: YYYY-MM-DD HH:MM:SS"
Apartment for rent classified,Apartment for rent classified,"This is a dataset of classified for apartments for rent in USA.
",Apartment+for+rent+classified,https://archive.ics.uci.edu/ml//machine-learning-databases/00555/,https://archive.ics.uci.edu/ml/datasets/Apartment+for+rent+classified,"The dataset contains of 10'000 or 100'000 rows and of 22 columns The data has been cleaned in the way that column price and square_feet never is empty but the dataset is saved as it was created.Can be used for different machine learning tasks such as clustering, classification and also regression for the squares feet column",Business,"Provide information id = unique identifier of apartmentcategory = category of classifiedtitle = title text of apartmentbody = body text of apartmentamenities = like AC, basketball,cable, gym, internet access, pool, refrigerator etc.bathrooms = number of bathroomsbedrooms = number of bedroomscurrency = price in currentfee = feehas_photo = photo of apartmentpets_allowed = what pets are allowed dogs/cats etc.price = rental price of apartmentprice_display = price converted into display for readerprice_type = price in USDsquare_feet = size of the apartmentaddress =  where the apartment is locatedcityname =  where the apartment is locatedstate =  where the apartment is locatedlatitude = where the apartment is locatedlongitude = where the apartment is locatedsource = origin of classifiedtime = when classified was createdbout each attribute in your data set.","This is a dataset of classified for apartments for rent in USA.
The dataset contains of 10'000 or 100'000 rows and of 22 columns The data has been cleaned in the way that column price and square_feet never is empty but the dataset is saved as it was created.Can be used for different machine learning tasks such as clustering, classification and also regression for the squares feet columnProvide information id = unique identifier of apartmentcategory = category of classifiedtitle = title text of apartmentbody = body text of apartmentamenities = like AC, basketball,cable, gym, internet access, pool, refrigerator etc.bathrooms = number of bathroomsbedrooms = number of bedroomscurrency = price in currentfee = feehas_photo = photo of apartmentpets_allowed = what pets are allowed dogs/cats etc.price = rental price of apartmentprice_display = price converted into display for readerprice_type = price in USDsquare_feet = size of the apartmentaddress =  where the apartment is locatedcityname =  where the apartment is locatedstate =  where the apartment is locatedlatitude = where the apartment is locatedlongitude = where the apartment is locatedsource = origin of classifiedtime = when classified was createdbout each attribute in your data set."
Absenteeism at work,Absenteeism at work,The database was created with records of absenteeism at work from July 2007 to July 2010 at a courier company in Brazil.,Absenteeism+at+work,https://archive.ics.uci.edu/ml//machine-learning-databases/00445/,https://archive.ics.uci.edu/ml/datasets/Absenteeism+at+work,"The data set allows for several new combinations of attributes and attribute exclusions, or the modification of the attribute type (categorical, integer, or real) depending on the purpose of the research.The data set (Absenteeism at work - Part I) was used in academic research at the Universidade Nove de Julho - Postgraduate Program in Informatics and Knowledge Management.",Business,"1. Individual identification (ID)2. Reason for absence (ICD).Absences attested by the International Code of Diseases (ICD) stratified into 21 categories (I to XXI) as follows:I Certain infectious and parasitic diseases  II Neoplasms  III Diseases of the blood and blood-forming organs and certain disorders involving the immune mechanism  IV Endocrine, nutritional and metabolic diseases  V Mental and behavioural disorders  VI Diseases of the nervous system  VII Diseases of the eye and adnexa  VIII Diseases of the ear and mastoid process  IX Diseases of the circulatory system  X Diseases of the respiratory system  XI Diseases of the digestive system  XII Diseases of the skin and subcutaneous tissue  XIII Diseases of the musculoskeletal system and connective tissue  XIV Diseases of the genitourinary system  XV Pregnancy, childbirth and the puerperium  XVI Certain conditions originating in the perinatal period  XVII Congenital malformations, deformations and chromosomal abnormalities  XVIII Symptoms, signs and abnormal clinical and laboratory findings, not elsewhere classified  XIX Injury, poisoning and certain other consequences of external causes  XX External causes of morbidity and mortality  XXI Factors influencing health status and contact with health services.And 7 categories without (CID) patient follow-up (22), medical consultation (23), blood donation (24), laboratory examination (25), unjustified absence (26), physiotherapy (27), dental consultation (28).3. Month of absence4. Day of the week (Monday (2), Tuesday (3), Wednesday (4), Thursday (5), Friday (6))5. Seasons (summer (1), autumn (2), winter (3), spring (4))6. Transportation expense7. Distance from Residence to Work (kilometers)8. Service time9. Age10. Work load Average/day 11. Hit target12. Disciplinary failure (yes=1; no=0)13. Education (high school (1), graduate (2), postgraduate (3), master and doctor (4))14. Son (number of children)15. Social drinker (yes=1; no=0)16. Social smoker (yes=1; no=0)17. Pet (number of pet)18. Weight19. Height20. Body mass index21. Absenteeism time in hours (target).arff header for Weka: @relation Absenteeism_at_work@attribute ID {31.0, 27.0, 19.0, 30.0, 7.0, 20.0, 24.0, 32.0, 3.0, 33.0, 26.0, 29.0, 18.0, 25.0, 17.0, 14.0, 16.0, 23.0, 2.0, 21.0, 36.0, 15.0, 22.0, 5.0, 12.0, 9.0, 6.0, 34.0, 10.0, 28.0, 13.0, 11.0, 1.0, 4.0, 8.0, 35.0}@attribute Reason_for_absence {17.0, 3.0, 15.0, 4.0, 21.0, 2.0, 9.0, 24.0, 18.0, 1.0, 12.0, 5.0, 16.0, 7.0, 27.0, 25.0, 8.0, 10.0, 26.0, 19.0, 28.0, 6.0, 23.0, 22.0, 13.0, 14.0, 11.0, 0.0}@attribute Month_of_absence REAL@attribute Day_of_the_week {5.0, 2.0, 3.0, 4.0, 6.0}@attribute Seasons {4.0, 1.0, 2.0, 3.0}@attribute Transportation_expense REAL@attribute Distance_from_Residence_to_Work REAL@attribute Service_time INTEGER@attribute Age INTEGER@attribute Work_load_Average/day_ REAL@attribute Hit_target REAL@attribute Disciplinary_failure {1.0, 0.0}@attribute Education REAL@attribute Son REAL@attribute Social_drinker {1.0, 0.0}@attribute Social_smoker {1.0, 0.0}@attribute Pet REAL@attribute Weight REAL@attribute Height REAL@attribute Body_mass_index REAL@attribute Absenteeism_time_in_hours REAL","The database was created with records of absenteeism at work from July 2007 to July 2010 at a courier company in Brazil.The data set allows for several new combinations of attributes and attribute exclusions, or the modification of the attribute type (categorical, integer, or real) depending on the purpose of the research.The data set (Absenteeism at work - Part I) was used in academic research at the Universidade Nove de Julho - Postgraduate Program in Informatics and Knowledge Management.1. Individual identification (ID)2. Reason for absence (ICD).Absences attested by the International Code of Diseases (ICD) stratified into 21 categories (I to XXI) as follows:I Certain infectious and parasitic diseases  II Neoplasms  III Diseases of the blood and blood-forming organs and certain disorders involving the immune mechanism  IV Endocrine, nutritional and metabolic diseases  V Mental and behavioural disorders  VI Diseases of the nervous system  VII Diseases of the eye and adnexa  VIII Diseases of the ear and mastoid process  IX Diseases of the circulatory system  X Diseases of the respiratory system  XI Diseases of the digestive system  XII Diseases of the skin and subcutaneous tissue  XIII Diseases of the musculoskeletal system and connective tissue  XIV Diseases of the genitourinary system  XV Pregnancy, childbirth and the puerperium  XVI Certain conditions originating in the perinatal period  XVII Congenital malformations, deformations and chromosomal abnormalities  XVIII Symptoms, signs and abnormal clinical and laboratory findings, not elsewhere classified  XIX Injury, poisoning and certain other consequences of external causes  XX External causes of morbidity and mortality  XXI Factors influencing health status and contact with health services.And 7 categories without (CID) patient follow-up (22), medical consultation (23), blood donation (24), laboratory examination (25), unjustified absence (26), physiotherapy (27), dental consultation (28).3. Month of absence4. Day of the week (Monday (2), Tuesday (3), Wednesday (4), Thursday (5), Friday (6))5. Seasons (summer (1), autumn (2), winter (3), spring (4))6. Transportation expense7. Distance from Residence to Work (kilometers)8. Service time9. Age10. Work load Average/day 11. Hit target12. Disciplinary failure (yes=1; no=0)13. Education (high school (1), graduate (2), postgraduate (3), master and doctor (4))14. Son (number of children)15. Social drinker (yes=1; no=0)16. Social smoker (yes=1; no=0)17. Pet (number of pet)18. Weight19. Height20. Body mass index21. Absenteeism time in hours (target).arff header for Weka: @relation Absenteeism_at_work@attribute ID {31.0, 27.0, 19.0, 30.0, 7.0, 20.0, 24.0, 32.0, 3.0, 33.0, 26.0, 29.0, 18.0, 25.0, 17.0, 14.0, 16.0, 23.0, 2.0, 21.0, 36.0, 15.0, 22.0, 5.0, 12.0, 9.0, 6.0, 34.0, 10.0, 28.0, 13.0, 11.0, 1.0, 4.0, 8.0, 35.0}@attribute Reason_for_absence {17.0, 3.0, 15.0, 4.0, 21.0, 2.0, 9.0, 24.0, 18.0, 1.0, 12.0, 5.0, 16.0, 7.0, 27.0, 25.0, 8.0, 10.0, 26.0, 19.0, 28.0, 6.0, 23.0, 22.0, 13.0, 14.0, 11.0, 0.0}@attribute Month_of_absence REAL@attribute Day_of_the_week {5.0, 2.0, 3.0, 4.0, 6.0}@attribute Seasons {4.0, 1.0, 2.0, 3.0}@attribute Transportation_expense REAL@attribute Distance_from_Residence_to_Work REAL@attribute Service_time INTEGER@attribute Age INTEGER@attribute Work_load_Average/day_ REAL@attribute Hit_target REAL@attribute Disciplinary_failure {1.0, 0.0}@attribute Education REAL@attribute Son REAL@attribute Social_drinker {1.0, 0.0}@attribute Social_smoker {1.0, 0.0}@attribute Pet REAL@attribute Weight REAL@attribute Height REAL@attribute Body_mass_index REAL@attribute Absenteeism_time_in_hours REAL"
Miskolc IIS Hybrid IPS,Miskolc IIS Hybrid IPS,"The dataset was created for the comparison and evaluation of hybrid indoor positioning methods. The dataset presented contains data from W-LAN and Bluetooth interfaces, and Magnetometer. ",Miskolc+IIS+Hybrid+IPS,https://archive.ics.uci.edu/ml//machine-learning-databases/00375/,https://archive.ics.uci.edu/ml/datasets/Miskolc+IIS+Hybrid+IPS,"The measurements were created to ease the development, comparison and evaluation of fingerprinting based hybrid indoor positioning methods. The measurements were recorded by the same kind of Android devices in order to reduce the effect of the variety of the hardware. The recording was preformed at weekend to reduce the noise of the environment. The measurements were performed in a three-story building and cover about 50% of it. ",Computer,"#Measurement Info1) 	Measurement Id - Java UUID2) 	Timestamp - YYYY-MM-dd hh:mm:ss #Position Info3-5) 	Coordinates of the absolute position (x,y,z)6-7) 	Symbolic position - UUID and name of the position#Measruement Values8-10) 	Magnetometer values x,y,z, real11-42) 	WiFi RSSI values, negative integeres [-255,0]43-65) 	Bluetooth devices {0,1} - 1 if the given devices was sensed in during the measurement.","The dataset was created for the comparison and evaluation of hybrid indoor positioning methods. The dataset presented contains data from W-LAN and Bluetooth interfaces, and Magnetometer. The measurements were created to ease the development, comparison and evaluation of fingerprinting based hybrid indoor positioning methods. The measurements were recorded by the same kind of Android devices in order to reduce the effect of the variety of the hardware. The recording was preformed at weekend to reduce the noise of the environment. The measurements were performed in a three-story building and cover about 50% of it. #Measurement Info1) 	Measurement Id - Java UUID2) 	Timestamp - YYYY-MM-dd hh:mm:ss #Position Info3-5) 	Coordinates of the absolute position (x,y,z)6-7) 	Symbolic position - UUID and name of the position#Measruement Values8-10) 	Magnetometer values x,y,z, real11-42) 	WiFi RSSI values, negative integeres [-255,0]43-65) 	Bluetooth devices {0,1} - 1 if the given devices was sensed in during the measurement."
microblogPCU,microblogPCU,MicroblogPCU data is crawled from sina weibo microblog[http://weibo.com/]. This data can be used to study machine learning methods  as well as do some social network research. ,microblogPCU,https://archive.ics.uci.edu/ml//machine-learning-databases/00323/,https://archive.ics.uci.edu/ml/datasets/microblogPCU,Our dataset is used by us to explore spammers in microblog and you can access our demo system at [Web Link]Please add :8080 after the domain name as port. The repository webpage fails to parse the weblink when it's added in the source. (under inspection),Computer,"weibo_user.csv has the following attributes:-user_id: account ID in sina weibo;-user_name: account nicknameÃ¯Â¼â€º-gender:account registration gender including maleÃ¯Â¼Å’ female and otherÃ¯Â¼â€º-class:account level given by sina weibo;-message:account registration location or other personal information;-post_num: the number of posts of this account up to now;-follower_num: the number of followers of this account;-followee_num: the number of followee of this account;-follow ratio: followee_num/follower_num;-is_spammer: manually annotated label, 1 means spammer and -1 means non-spammer;user_post.csv has the following attributes:-post_id:user post ID given by sina weibo;-post_time:the time when a post is posted;-poster_id: the user ID who posted this post;-repost_num:the number of retweet by others;-commnet_num: the number of comment by others;followe-followee.csv has the following attributes:-follower: the nickname of follower;-follower_id: the user ID of follower;-followee: the nickname of followee;-followee_id: the user ID of followee;post.csv is almost the as user_post.csv and the post in it are retrievalled by a certain key word related to a topic;-content: the post text(mostly in Chinese, please set your Microsoft Office to make it readable)","MicroblogPCU data is crawled from sina weibo microblog[http://weibo.com/]. This data can be used to study machine learning methods  as well as do some social network research. Our dataset is used by us to explore spammers in microblog and you can access our demo system at [Web Link]Please add :8080 after the domain name as port. The repository webpage fails to parse the weblink when it's added in the source. (under inspection)weibo_user.csv has the following attributes:-user_id: account ID in sina weibo;-user_name: account nicknameÃ¯Â¼â€º-gender:account registration gender including maleÃ¯Â¼Å’ female and otherÃ¯Â¼â€º-class:account level given by sina weibo;-message:account registration location or other personal information;-post_num: the number of posts of this account up to now;-follower_num: the number of followers of this account;-followee_num: the number of followee of this account;-follow ratio: followee_num/follower_num;-is_spammer: manually annotated label, 1 means spammer and -1 means non-spammer;user_post.csv has the following attributes:-post_id:user post ID given by sina weibo;-post_time:the time when a post is posted;-poster_id: the user ID who posted this post;-repost_num:the number of retweet by others;-commnet_num: the number of comment by others;followe-followee.csv has the following attributes:-follower: the nickname of follower;-follower_id: the user ID of follower;-followee: the nickname of followee;-followee_id: the user ID of followee;post.csv is almost the as user_post.csv and the post in it are retrievalled by a certain key word related to a topic;-content: the post text(mostly in Chinese, please set your Microsoft Office to make it readable)"
WESAD (Wearable Stress and Affect Detection),WESAD (Wearable Stress and Affect Detection),"WESAD (Wearable Stress and Affect Detection) contains data of 15 subjects during a stress-affect lab study, while wearing physiological and motion sensors.",WESAD+%28Wearable+Stress+and+Affect+Detection%29,https://archive.ics.uci.edu/ml//machine-learning-databases/00465/,https://archive.ics.uci.edu/ml/datasets/WESAD+%28Wearable+Stress+and+Affect+Detection%29,"WESAD is a publicly available dataset for wearable stress and affect detection. This multimodal dataset features physiological and motion data, recorded from both a wrist- and a chest-worn device, of 15 subjects during a lab study. The following sensor modalities are included: blood volume pulse, electrocardiogram, electrodermal activity, electromyogram, respiration, body temperature, and three-axis acceleration. Moreover, the dataset bridges the gap between previous lab studies on stress and emotions, by containing three different affective states (neutral, stress, amusement). In addition, self-reports of the subjects, which were obtained using several established questionnaires, are contained in the dataset. Details can be found in the dataset's readme-file, as well as in [1].",Computer,"Raw sensor data was recorded with two devices: a chest-worn device (RespiBAN) and a wrist-worn device (Empatica E4).The RespiBAN device provides the following sensor data: electrocardiogram (ECG), electrodermal activity (EDA), electromyogram (EMG), respiration, body temperature, and three-axis acceleration. All signals are sampled at 700 Hz.The Empatica E4 device provides the following sensor data: blood volume pulse (BVP, 64 Hz), electrodermal activity (EDA, 4 Hz), body temperature (4 Hz), and three-axis acceleration (32 Hz).The dataset's readme-file contains all further details with respect to the dataset structure, data format (RespiBAN device, Empatica E4 device, synchronised data), study protocol, and the self-report questionnaires.","WESAD (Wearable Stress and Affect Detection) contains data of 15 subjects during a stress-affect lab study, while wearing physiological and motion sensors.WESAD is a publicly available dataset for wearable stress and affect detection. This multimodal dataset features physiological and motion data, recorded from both a wrist- and a chest-worn device, of 15 subjects during a lab study. The following sensor modalities are included: blood volume pulse, electrocardiogram, electrodermal activity, electromyogram, respiration, body temperature, and three-axis acceleration. Moreover, the dataset bridges the gap between previous lab studies on stress and emotions, by containing three different affective states (neutral, stress, amusement). In addition, self-reports of the subjects, which were obtained using several established questionnaires, are contained in the dataset. Details can be found in the dataset's readme-file, as well as in [1].Raw sensor data was recorded with two devices: a chest-worn device (RespiBAN) and a wrist-worn device (Empatica E4).The RespiBAN device provides the following sensor data: electrocardiogram (ECG), electrodermal activity (EDA), electromyogram (EMG), respiration, body temperature, and three-axis acceleration. All signals are sampled at 700 Hz.The Empatica E4 device provides the following sensor data: blood volume pulse (BVP, 64 Hz), electrodermal activity (EDA, 4 Hz), body temperature (4 Hz), and three-axis acceleration (32 Hz).The dataset's readme-file contains all further details with respect to the dataset structure, data format (RespiBAN device, Empatica E4 device, synchronised data), study protocol, and the self-report questionnaires."
MHEALTH Dataset,MHEALTH Dataset,The MHEALTH (Mobile Health) dataset is devised to benchmark techniques dealing with human behavior analysis based on multimodal body sensing.,MHEALTH+Dataset,https://archive.ics.uci.edu/ml//machine-learning-databases/00319/,https://archive.ics.uci.edu/ml/datasets/MHEALTH+Dataset,"The MHEALTH (Mobile HEALTH) dataset comprises body motion and vital signs recordings for ten volunteers of diverse profile while performing several physical activities. Sensors placed on the subject's chest, right wrist and left ankle are used to measure the motion experienced by diverse body parts, namely, acceleration, rate of turn and magnetic field orientation. The sensor positioned on the chest also provides 2-lead ECG measurements, which can be potentially used for basic heart monitoring, checking for various arrhythmias or looking at the effects of exercise on the ECG.----------------------------------------------------------------------------------------------------------------------DATASET SUMMARY:#Activities: 12 #Sensor devices: 3#Subjects: 10----------------------------------------------------------------------------------------------------------------------EXPERIMENTAL SETUPThe collected dataset comprises body motion and vital signs recordings for ten volunteers of diverse profile while performing 12 physical activities (Table 1). Shimmer2 [BUR10] wearable sensors were used for the recordings. The sensors were respectively placed on the subject's chest, right wrist and left ankle and attached by using elastic straps (as shown in the figure in attachment). The use of multiple sensors permits us to measure the motion experienced by diverse body parts, namely, the acceleration, the rate of turn and the magnetic field orientation, thus better capturing the body dynamics. The sensor positioned on the chest also provides 2-lead ECG measurements which are not used for the development of the recognition model but rather collected for future work purposes. This information can be used, for example, for basic heart monitoring, checking for various arrhythmias or looking at the effects of exercise on the ECG. All sensing modalities are recorded at a sampling rate of 50 Hz, which is considered sufficient for capturing human activity. Each session was recorded using a video camera. This dataset is found to generalize to common activities of the daily living, given the diversity of body parts involved in each one (e.g., frontal elevation of arms vs. knees bending), the intensity of the actions (e.g., cycling vs. sitting and relaxing) and their execution speed or dynamicity (e.g., running vs. standing still). The activities were collected in an out-of-lab environment with no constraints on the way these must be executed, with the exception that the subject should try their best when executing them.ACTIVITY SETThe activity set is listed in the following:L1: Standing still (1 min) L2: Sitting and relaxing (1 min) L3: Lying down (1 min) L4: Walking (1 min) L5: Climbing stairs (1 min) L6: Waist bends forward (20x) L7: Frontal elevation of arms (20x)L8: Knees bending (crouching) (20x)L9: Cycling (1 min)L10: Jogging (1 min)L11: Running (1 min)L12: Jump front & back (20x)NOTE: In brackets are the number of repetitions (Nx) or the duration of the exercises (min).A complete and illustrated description (including table of activities, sensor setup, etc.) of the dataset is provided in the papers presented in the section Ã¢â‚¬Å“Citation RequestsÃ¢â‚¬Â�.",Computer,"The data collected for each subject is stored in a different log file: 'mHealth_subject.log'. Each file contains the samples (by rows) recorded for all sensors (by columns). The labels used to identify the activities are similar to the abovementioned (e.g., the label for walking is '4').The meaning of each column is detailed next:Column 1: acceleration from the chest sensor (X axis)Column 2: acceleration from the chest sensor (Y axis)Column 3: acceleration from the chest sensor (Z axis)Column 4: electrocardiogram signal (lead 1) Column 5: electrocardiogram signal (lead 2)Column 6: acceleration from the left-ankle sensor (X axis)Column 7: acceleration from the left-ankle sensor (Y axis)Column 8: acceleration from the left-ankle sensor (Z axis)Column 9: gyro from the left-ankle sensor (X axis)Column 10: gyro from the left-ankle sensor (Y axis)Column 11: gyro from the left-ankle sensor (Z axis)Column 13: magnetometer from the left-ankle sensor (X axis)Column 13: magnetometer from the left-ankle sensor (Y axis)Column 14: magnetometer from the left-ankle sensor (Z axis)Column 15: acceleration from the right-lower-arm sensor (X axis)Column 16: acceleration from the right-lower-arm sensor (Y axis)Column 17: acceleration from the right-lower-arm sensor (Z axis)Column 18: gyro from the right-lower-arm sensor (X axis)Column 19: gyro from the right-lower-arm sensor (Y axis)Column 20: gyro from the right-lower-arm sensor (Z axis)Column 21: magnetometer from the right-lower-arm sensor (X axis)Column 22: magnetometer from the right-lower-arm sensor (Y axis)Column 23: magnetometer from the right-lower-arm sensor (Z axis)Column 24: Label (0 for the null class)*Units: Acceleration (m/s^2), gyroscope (deg/s), magnetic field (local), ecg (mV)","The MHEALTH (Mobile Health) dataset is devised to benchmark techniques dealing with human behavior analysis based on multimodal body sensing.The MHEALTH (Mobile HEALTH) dataset comprises body motion and vital signs recordings for ten volunteers of diverse profile while performing several physical activities. Sensors placed on the subject's chest, right wrist and left ankle are used to measure the motion experienced by diverse body parts, namely, acceleration, rate of turn and magnetic field orientation. The sensor positioned on the chest also provides 2-lead ECG measurements, which can be potentially used for basic heart monitoring, checking for various arrhythmias or looking at the effects of exercise on the ECG.----------------------------------------------------------------------------------------------------------------------DATASET SUMMARY:#Activities: 12 #Sensor devices: 3#Subjects: 10----------------------------------------------------------------------------------------------------------------------EXPERIMENTAL SETUPThe collected dataset comprises body motion and vital signs recordings for ten volunteers of diverse profile while performing 12 physical activities (Table 1). Shimmer2 [BUR10] wearable sensors were used for the recordings. The sensors were respectively placed on the subject's chest, right wrist and left ankle and attached by using elastic straps (as shown in the figure in attachment). The use of multiple sensors permits us to measure the motion experienced by diverse body parts, namely, the acceleration, the rate of turn and the magnetic field orientation, thus better capturing the body dynamics. The sensor positioned on the chest also provides 2-lead ECG measurements which are not used for the development of the recognition model but rather collected for future work purposes. This information can be used, for example, for basic heart monitoring, checking for various arrhythmias or looking at the effects of exercise on the ECG. All sensing modalities are recorded at a sampling rate of 50 Hz, which is considered sufficient for capturing human activity. Each session was recorded using a video camera. This dataset is found to generalize to common activities of the daily living, given the diversity of body parts involved in each one (e.g., frontal elevation of arms vs. knees bending), the intensity of the actions (e.g., cycling vs. sitting and relaxing) and their execution speed or dynamicity (e.g., running vs. standing still). The activities were collected in an out-of-lab environment with no constraints on the way these must be executed, with the exception that the subject should try their best when executing them.ACTIVITY SETThe activity set is listed in the following:L1: Standing still (1 min) L2: Sitting and relaxing (1 min) L3: Lying down (1 min) L4: Walking (1 min) L5: Climbing stairs (1 min) L6: Waist bends forward (20x) L7: Frontal elevation of arms (20x)L8: Knees bending (crouching) (20x)L9: Cycling (1 min)L10: Jogging (1 min)L11: Running (1 min)L12: Jump front & back (20x)NOTE: In brackets are the number of repetitions (Nx) or the duration of the exercises (min).A complete and illustrated description (including table of activities, sensor setup, etc.) of the dataset is provided in the papers presented in the section Ã¢â‚¬Å“Citation RequestsÃ¢â‚¬Â�.The data collected for each subject is stored in a different log file: 'mHealth_subject.log'. Each file contains the samples (by rows) recorded for all sensors (by columns). The labels used to identify the activities are similar to the abovementioned (e.g., the label for walking is '4').The meaning of each column is detailed next:Column 1: acceleration from the chest sensor (X axis)Column 2: acceleration from the chest sensor (Y axis)Column 3: acceleration from the chest sensor (Z axis)Column 4: electrocardiogram signal (lead 1) Column 5: electrocardiogram signal (lead 2)Column 6: acceleration from the left-ankle sensor (X axis)Column 7: acceleration from the left-ankle sensor (Y axis)Column 8: acceleration from the left-ankle sensor (Z axis)Column 9: gyro from the left-ankle sensor (X axis)Column 10: gyro from the left-ankle sensor (Y axis)Column 11: gyro from the left-ankle sensor (Z axis)Column 13: magnetometer from the left-ankle sensor (X axis)Column 13: magnetometer from the left-ankle sensor (Y axis)Column 14: magnetometer from the left-ankle sensor (Z axis)Column 15: acceleration from the right-lower-arm sensor (X axis)Column 16: acceleration from the right-lower-arm sensor (Y axis)Column 17: acceleration from the right-lower-arm sensor (Z axis)Column 18: gyro from the right-lower-arm sensor (X axis)Column 19: gyro from the right-lower-arm sensor (Y axis)Column 20: gyro from the right-lower-arm sensor (Z axis)Column 21: magnetometer from the right-lower-arm sensor (X axis)Column 22: magnetometer from the right-lower-arm sensor (Y axis)Column 23: magnetometer from the right-lower-arm sensor (Z axis)Column 24: Label (0 for the null class)*Units: Acceleration (m/s^2), gyroscope (deg/s), magnetic field (local), ecg (mV)"
MEx,MEx,"The MEx Multi-modal Exercise dataset contains data of 7 different
physiotherapy exercises, performed by 30 subjects recorded with 2 accelerometers,
a pressure mat and a depth camera.",MEx,https://archive.ics.uci.edu/ml//machine-learning-databases/00500/,https://archive.ics.uci.edu/ml/datasets/MEx,"The MEx Multi-modal Exercise dataset contains data of 7 different physiotherapyexercises, performed by 30 subjects recorded four sensor modalities.**Application**The dataset can be used for exercise recognition, exercise quality assessment andexercise counting, by developing algorithms for pre-processing, feature extraction,multi-modal sensor fusion, segmentation and classification.** Data collection method **Each subject was given a sheet of 7 exercises with instructions to perform theexercise at the beginning of the session. At the beginning of each exercise theresearcher demonstrated the exercise to the subject, then the subject performed theexercise for maximum 60 seconds while being recorded with four sensors. Duringthe recording, the researcher did not give any advice or kept count or time to enforcea rhythm.** Sensors**Obbrec Astra Depth Camera- sampling frequency - 15HzÂ - frame size - 240x320Sensing Tex Pressure Mat- sampling frequency - 15Hz- frame size - 32*16Axivity AX3 3-Axis Logging Accelerometer- sampling frequency - 100Hz- range - 8g** Sensor Placement**All the exercises were performed lying down on the mat while the subject wearingtwo accelerometers on the wrist and the thigh. The depth camera was placed abovethe subject facing down-words recording an aerial view. Top of the depth cameraframe was aligned with the top of the pressure mat frame and the subjectÃ¢â‚¬â„¢sshoulders such that the face will not be included in the depth camera video.** Data folder **MEx folder has four folders, one for each sensor. Inside each sensor folder,30 folders can be found, one for each subject. In each subject folder, 8 files can befound for each exercise with 2 files for exercise 4 as it is performed on two sides.(The user 22 will only have 7 files as they performed the exercise 4 on only oneside.) One line in the data files correspond to one timestamped and sensory data.",Computer,The 4 columns in the act and acw files is organized as follows:1 - timestamp2 - x value3 - y value4 - z valueMin value = -8Max value = +8The 513 columns in the pm file is organized as follows:1 - timestamp2-513 pressure mat data frame (32x16)Min value - 0Max value - 1The 193 columns in the dc file is organized as follows:1 - timestamp2-193 depth camera data frame (12x16)dc data frame is scaled down from 240x320 to 12x16 using the OpenCV resizealgorithmMin value - 0Max value - 1,"The MEx Multi-modal Exercise dataset contains data of 7 different
physiotherapy exercises, performed by 30 subjects recorded with 2 accelerometers,
a pressure mat and a depth camera.The MEx Multi-modal Exercise dataset contains data of 7 different physiotherapyexercises, performed by 30 subjects recorded four sensor modalities.**Application**The dataset can be used for exercise recognition, exercise quality assessment andexercise counting, by developing algorithms for pre-processing, feature extraction,multi-modal sensor fusion, segmentation and classification.** Data collection method **Each subject was given a sheet of 7 exercises with instructions to perform theexercise at the beginning of the session. At the beginning of each exercise theresearcher demonstrated the exercise to the subject, then the subject performed theexercise for maximum 60 seconds while being recorded with four sensors. Duringthe recording, the researcher did not give any advice or kept count or time to enforcea rhythm.** Sensors**Obbrec Astra Depth Camera- sampling frequency - 15HzÂ - frame size - 240x320Sensing Tex Pressure Mat- sampling frequency - 15Hz- frame size - 32*16Axivity AX3 3-Axis Logging Accelerometer- sampling frequency - 100Hz- range - 8g** Sensor Placement**All the exercises were performed lying down on the mat while the subject wearingtwo accelerometers on the wrist and the thigh. The depth camera was placed abovethe subject facing down-words recording an aerial view. Top of the depth cameraframe was aligned with the top of the pressure mat frame and the subjectÃ¢â‚¬â„¢sshoulders such that the face will not be included in the depth camera video.** Data folder **MEx folder has four folders, one for each sensor. Inside each sensor folder,30 folders can be found, one for each subject. In each subject folder, 8 files can befound for each exercise with 2 files for exercise 4 as it is performed on two sides.(The user 22 will only have 7 files as they performed the exercise 4 on only oneside.) One line in the data files correspond to one timestamped and sensory data.The 4 columns in the act and acw files is organized as follows:1 - timestamp2 - x value3 - y value4 - z valueMin value = -8Max value = +8The 513 columns in the pm file is organized as follows:1 - timestamp2-513 pressure mat data frame (32x16)Min value - 0Max value - 1The 193 columns in the dc file is organized as follows:1 - timestamp2-193 depth camera data frame (12x16)dc data frame is scaled down from 240x320 to 12x16 using the OpenCV resizealgorithmMin value - 0Max value - 1"
MEU-Mobile KSD,MEU-Mobile KSD,"This dataset contains keystroke dynamics data collected on a touch mobile device (Nexus 7). The dataset contains 2856 records, 51 records per subject for 56 subjects. ",MEU-Mobile+KSD,https://archive.ics.uci.edu/ml//machine-learning-databases/00399/,https://archive.ics.uci.edu/ml/datasets/MEU-Mobile+KSD,"The dataset is used in the evaluation of EER, FRR and FAR metrics using a new anomaly detector model (Med-Min-Diff). The typed text in the experiment is the password '.tie5Roanl'.",Computer,"The measured features (attributes) are Hold (H), Up-Down (UD), Down-Down (DD), Pressure (P), Finger-Area (A), Averages of Hold (AH), Pressure (AP) and Finger Area (AFA). There are 71 features because each feature has a set of feature elements corresponding to the typed characters.  ","This dataset contains keystroke dynamics data collected on a touch mobile device (Nexus 7). The dataset contains 2856 records, 51 records per subject for 56 subjects. The dataset is used in the evaluation of EER, FRR and FAR metrics using a new anomaly detector model (Med-Min-Diff). The typed text in the experiment is the password '.tie5Roanl'.The measured features (attributes) are Hold (H), Up-Down (UD), Down-Down (DD), Pressure (P), Finger-Area (A), Averages of Hold (AH), Pressure (AP) and Finger Area (AFA). There are 71 features because each feature has a set of feature elements corresponding to the typed characters.  "
Malware static and dynamic features VxHeaven and Virus Total,Malware static and dynamic features VxHeaven and Virus Total,"3 datasets: staDynBenignLab.csv, features extracted from 595 files (Win 7 and 8); staDynVxHeaven2698Lab.csv, from 2698 files of VxHeaven and staDynVt2955Lab.csv,from 2955 files of Virus Total.",Malware+static+and+dynamic+features+VxHeaven+and+Virus+Total,https://archive.ics.uci.edu/ml//machine-learning-databases/00541/,https://archive.ics.uci.edu/ml/datasets/Malware+static+and+dynamic+features+VxHeaven+and+Virus+Total,"- staDynBenignLab.csv: 1086 features extracted from 595 files on MS Windows 7 and 8, obtained Program Files directory.- staDynVxHeaven2698Lab.csv: 1087 features extracted from 2698 files of VxHeaven dataset.- staDynVt2955Lab.csv: 1087 features extracted from 2955 provided by Virus Total in 2018.",Computer,"Static features: ASM, Hex dump and PE Header (discreate, continuous)Dynamic features: extracted from a Cuckoo sandbox","3 datasets: staDynBenignLab.csv, features extracted from 595 files (Win 7 and 8); staDynVxHeaven2698Lab.csv, from 2698 files of VxHeaven and staDynVt2955Lab.csv,from 2955 files of Virus Total.- staDynBenignLab.csv: 1086 features extracted from 595 files on MS Windows 7 and 8, obtained Program Files directory.- staDynVxHeaven2698Lab.csv: 1087 features extracted from 2698 files of VxHeaven dataset.- staDynVt2955Lab.csv: 1087 features extracted from 2955 provided by Virus Total in 2018.Static features: ASM, Hex dump and PE Header (discreate, continuous)Dynamic features: extracted from a Cuckoo sandbox"
Mobile Robots,Mobile Robots,Learning concepts from sensor data of a mobile robot; set of data sets,Mobile+Robots,https://archive.ics.uci.edu/ml//machine-learning-databases/mobile-robots/,https://archive.ics.uci.edu/ml/datasets/Mobile+Robots,Please view the associated .names file,Computer,"   Tr (Trace)           (integer)   T (Time)             (integer)   S (Sensor)           (integer 0-23)   Or (Orientation)     (real 0-360)   Sa (S-Orientation)   (real 0-360)   Gr (Gradient)        (real)   Dist (Distance)      (real)   Sx,Sy   (Sensor-coordinates) (real)   Obj (Object)         (integer)   E (Edge)             (integer)   S_C (Sensorclass)    (set of front_side,right_side,back_side,left_side ...)   Mv (Movement)        (set of parallel, diagonal)   MD (MoveDirection)   (set of forward, backward, right, left)   PD (PerceptionDir.)  (set of front, rear, right, left)   Perc (perceptual features)","Learning concepts from sensor data of a mobile robot; set of data setsPlease view the associated .names file   Tr (Trace)           (integer)   T (Time)             (integer)   S (Sensor)           (integer 0-23)   Or (Orientation)     (real 0-360)   Sa (S-Orientation)   (real 0-360)   Gr (Gradient)        (real)   Dist (Distance)      (real)   Sx,Sy   (Sensor-coordinates) (real)   Obj (Object)         (integer)   E (Edge)             (integer)   S_C (Sensorclass)    (set of front_side,right_side,back_side,left_side ...)   Mv (Movement)        (set of parallel, diagonal)   MD (MoveDirection)   (set of forward, backward, right, left)   PD (PerceptionDir.)  (set of front, rear, right, left)   Perc (perceptual features)"
Logic Theorist,Logic Theorist,All code for Logic Theorist,Logic+Theorist,https://archive.ics.uci.edu/ml//machine-learning-databases/logic-theorist/,https://archive.ics.uci.edu/ml/datasets/Logic+Theorist,,Computer,,All code for Logic Theoristnannan
Letter Recognition,Letter Recognition,Database of character image features; try to identify the letter,Letter+Recognition,https://archive.ics.uci.edu/ml//machine-learning-databases/letter-recognition/,https://archive.ics.uci.edu/ml/datasets/Letter+Recognition,"The objective is to identify each of a large number of black-and-white rectangular pixel displays as one of the 26 capital letters in the English alphabet.  The character images were based on 20 different fonts and each letter within these 20 fonts was randomly distorted to produce a file of 20,000 unique stimuli.  Each stimulus was converted into 16 primitive numerical attributes (statistical moments and edge counts) which were then scaled to fit into a range of integer values from 0 through 15.  We typically train on the first 16000 items and then use the resulting model to predict the letter category for the remaining 4000.  See the article cited above for more details.",Computer,	 1.	lettr	capital letter	(26 values from A to Z)	 2.	x-box	horizontal position of box	(integer)	 3.	y-box	vertical position of box	(integer)	 4.	width	width of box			(integer)	 5.	high 	height of box			(integer)	 6.	onpix	total # on pixels		(integer)	 7.	x-bar	mean x of on pixels in box	(integer)	 8.	y-bar	mean y of on pixels in box	(integer)	 9.	x2bar	mean x variance			(integer)	10.	y2bar	mean y variance			(integer)	11.	xybar	mean x y correlation		(integer)	12.	x2ybr	mean of x * x * y		(integer)	13.	xy2br	mean of x * y * y		(integer)	14.	x-ege	mean edge count left to right	(integer)	15.	xegvy	correlation of x-ege with y	(integer)	16.	y-ege	mean edge count bottom to top	(integer)	17.	yegvx	correlation of y-ege with x	(integer),"Database of character image features; try to identify the letterThe objective is to identify each of a large number of black-and-white rectangular pixel displays as one of the 26 capital letters in the English alphabet.  The character images were based on 20 different fonts and each letter within these 20 fonts was randomly distorted to produce a file of 20,000 unique stimuli.  Each stimulus was converted into 16 primitive numerical attributes (statistical moments and edge counts) which were then scaled to fit into a range of integer values from 0 through 15.  We typically train on the first 16000 items and then use the resulting model to predict the letter category for the remaining 4000.  See the article cited above for more details.	 1.	lettr	capital letter	(26 values from A to Z)	 2.	x-box	horizontal position of box	(integer)	 3.	y-box	vertical position of box	(integer)	 4.	width	width of box			(integer)	 5.	high 	height of box			(integer)	 6.	onpix	total # on pixels		(integer)	 7.	x-bar	mean x of on pixels in box	(integer)	 8.	y-bar	mean y of on pixels in box	(integer)	 9.	x2bar	mean x variance			(integer)	10.	y2bar	mean y variance			(integer)	11.	xybar	mean x y correlation		(integer)	12.	x2ybr	mean of x * x * y		(integer)	13.	xy2br	mean of x * y * y		(integer)	14.	x-ege	mean edge count left to right	(integer)	15.	xegvy	correlation of x-ege with y	(integer)	16.	y-ege	mean edge count bottom to top	(integer)	17.	yegvx	correlation of y-ege with x	(integer)"
LED Display Domain,LED Display Domain,From Classification and Regression Trees book; We provide here 2 C programs for generating sample databases,LED+Display+Domain,https://archive.ics.uci.edu/ml//machine-learning-databases/led-display-creator/,https://archive.ics.uci.edu/ml/datasets/LED+Display+Domain,"This simple domain contains 7 Boolean attributes and 10 concepts, the set of decimal digits.  Recall that LED displays contain 7 light-emitting diodes -- hence the reason for 7 attributes.  The problem would be easy if not for the introduction of noise.  In this case, each attribute value has the 10% probability of having its value inverted.  It's valuable to know the optimal Bayes rate for these databases. In this case, the misclassification rate is 26% (74% classification accuracy).",Computer,"   -- All attribute values are either 0 or 1, according to whether the corresponding light is on or not for the decimal digit.   -- Each attribute (excluding the class attribute, which is an integer ranging between 0 and 9 inclusive) has a 10% percent chance of being inverted.","From Classification and Regression Trees book; We provide here 2 C programs for generating sample databasesThis simple domain contains 7 Boolean attributes and 10 concepts, the set of decimal digits.  Recall that LED displays contain 7 light-emitting diodes -- hence the reason for 7 attributes.  The problem would be easy if not for the introduction of noise.  In this case, each attribute value has the 10% probability of having its value inverted.  It's valuable to know the optimal Bayes rate for these databases. In this case, the misclassification rate is 26% (74% classification accuracy).   -- All attribute values are either 0 or 1, according to whether the corresponding light is on or not for the decimal digit.   -- Each attribute (excluding the class attribute, which is an integer ranging between 0 and 9 inclusive) has a 10% percent chance of being inverted."
Leaf,Leaf,This dataset consists in a collection of shape and texture features extracted from digital images of leaf specimens originating from a total of 40 different plant species.,Leaf,https://archive.ics.uci.edu/ml//machine-learning-databases/00288/,https://archive.ics.uci.edu/ml/datasets/Leaf,"For further details on this dataset and/or its attributes, please read the 'ReadMe.pdf' file included and/or consult the Master's Thesis 'Development of a System for Automatic Plant Species Recognition' available at [Web Link].",Computer,1. Class (Species)2. Specimen Number3. Eccentricity4. Aspect Ratio5. Elongation6. Solidity7. Stochastic Convexity8. Isoperimetric Factor9. Maximal Indentation Depth10. Lobedness11. Average Intensity12. Average Contrast13. Smoothness14. Third moment15. Uniformity16. Entropy,"This dataset consists in a collection of shape and texture features extracted from digital images of leaf specimens originating from a total of 40 different plant species.For further details on this dataset and/or its attributes, please read the 'ReadMe.pdf' file included and/or consult the Master's Thesis 'Development of a System for Automatic Plant Species Recognition' available at [Web Link].1. Class (Species)2. Specimen Number3. Eccentricity4. Aspect Ratio5. Elongation6. Solidity7. Stochastic Convexity8. Isoperimetric Factor9. Maximal Indentation Depth10. Lobedness11. Average Intensity12. Average Contrast13. Smoothness14. Third moment15. Uniformity16. Entropy"
Labeled Text Forum Threads Dataset,Labeled Text Forum Threads Dataset,"The dataset is a collection of text forum threads with class labels reflects the reply quality to the Initial-Post, 3 for complete relevant, 2 for partially relevant, and 1 for irrelevant",Labeled+Text+Forum+Threads+Dataset,https://archive.ics.uci.edu/ml//machine-learning-databases/00584/,https://archive.ics.uci.edu/ml/datasets/Labeled+Text+Forum+Threads+Dataset,"This document describes the datasets used in the following paper:Akram Osman, Naomie Salim and Faisal Saeed. Quality Dimensions Features for Identifying High-Quality User Replies in Text Forum Threads using Classification Methods, journal PLOS ONE, 10.1371/journal.pone.0215516	.The authors downloaded the Forum Thread Retrieval Dataset from the following url, [Web Link], the dataset is avilable free online and authorized to be used.The authors conducted a survey on crowdsourcing platform community  ([Web Link]) to judge the quality of each reply in the thread to the initial post. This platform was used to assign class labels (1,2, or 3) to each posted reply, as follows: Score 3 has been assined to High-quality Replies, 2 for Low-quality Replies, and 1 for Non-quality Replies.",Computer,"60974_588_2410400Question on Hotel Military DiscountBflo_girl4014 December 2008, 2:41     I need some advice and hope someone can help me out. Last August I made hotel reservations online at a Homewood Suites for Christmas week. I requested the military rate. Today, more than 5 months later and a week before check-in I received a letter from the hotel stating that I will have to show ';gov't issued work orders specifying dates and location of gov't agency where work will be performed';. There is no official business as this is just a vacation and most hotels offer a military rate, just like a AAA or AARP rate. At this late date all the hotel rates are jacked up or unavailable. Their website states that the military rate requires ';valid ID or travel orders required at check-in';. What should I do?    Thanks.    buffalonian15 December 2008, 17:423     Since the letter is from the hotel directly, I get the impression that they plan to enforce the intention of the policy. My thoughts have always been that these discounts were for folks traveling on gov't business..not a just a deal for gov't employees. AAA, AARP dicounts rarely top 10% whereas gov't and military can be as deep as 30-50% off the rack rate.     You could just play dumb and take your chances....   Bflo_girl4016 December 2008, 4:172     Thank you for your response. I have been asking for and getting the military discount going on 20 years at various hotels and have never been asked for this documentation. The discount I received was only about $18 less a nite than the AAA rate. What makes me upset is that I made these reservations in August and I just got the letter!    Lady_Dee16 December 2008, 8:442     Can you find the hotel chain's policy in writing, like on the website?   buffalonian16 December 2008, 23:292     Interesting...    I do think it is odd that they would ask for this so far after the initial reservation was posted... I would contact the hotel for an explanation. What sort of Id have most the hotels required in the past...I am wondering now if I qualify as a government employee...I would love to tap into those rates.....   Bflo_girl4019 December 2008, 3:323     One of the perks of being in the military are the discounts - all you need to show is your id card. (except in this instance). I contacted Hilton Customer Assistance regarding this matter and they were very professional and helpful about my concerns. The manager of the Buffalo-Amherst property contacted me and offered me a discount off of the rack rate, but will not honor the reservation rate. Hilton corporate stated that each property can make up their own policies regarding rates. This is a very bad business practice if they change the terms of the reservation.    ","The dataset is a collection of text forum threads with class labels reflects the reply quality to the Initial-Post, 3 for complete relevant, 2 for partially relevant, and 1 for irrelevantThis document describes the datasets used in the following paper:Akram Osman, Naomie Salim and Faisal Saeed. Quality Dimensions Features for Identifying High-Quality User Replies in Text Forum Threads using Classification Methods, journal PLOS ONE, 10.1371/journal.pone.0215516	.The authors downloaded the Forum Thread Retrieval Dataset from the following url, [Web Link], the dataset is avilable free online and authorized to be used.The authors conducted a survey on crowdsourcing platform community  ([Web Link]) to judge the quality of each reply in the thread to the initial post. This platform was used to assign class labels (1,2, or 3) to each posted reply, as follows: Score 3 has been assined to High-quality Replies, 2 for Low-quality Replies, and 1 for Non-quality Replies.60974_588_2410400Question on Hotel Military DiscountBflo_girl4014 December 2008, 2:41     I need some advice and hope someone can help me out. Last August I made hotel reservations online at a Homewood Suites for Christmas week. I requested the military rate. Today, more than 5 months later and a week before check-in I received a letter from the hotel stating that I will have to show ';gov't issued work orders specifying dates and location of gov't agency where work will be performed';. There is no official business as this is just a vacation and most hotels offer a military rate, just like a AAA or AARP rate. At this late date all the hotel rates are jacked up or unavailable. Their website states that the military rate requires ';valid ID or travel orders required at check-in';. What should I do?    Thanks.    buffalonian15 December 2008, 17:423     Since the letter is from the hotel directly, I get the impression that they plan to enforce the intention of the policy. My thoughts have always been that these discounts were for folks traveling on gov't business..not a just a deal for gov't employees. AAA, AARP dicounts rarely top 10% whereas gov't and military can be as deep as 30-50% off the rack rate.     You could just play dumb and take your chances....   Bflo_girl4016 December 2008, 4:172     Thank you for your response. I have been asking for and getting the military discount going on 20 years at various hotels and have never been asked for this documentation. The discount I received was only about $18 less a nite than the AAA rate. What makes me upset is that I made these reservations in August and I just got the letter!    Lady_Dee16 December 2008, 8:442     Can you find the hotel chain's policy in writing, like on the website?   buffalonian16 December 2008, 23:292     Interesting...    I do think it is odd that they would ask for this so far after the initial reservation was posted... I would contact the hotel for an explanation. What sort of Id have most the hotels required in the past...I am wondering now if I qualify as a government employee...I would love to tap into those rates.....   Bflo_girl4019 December 2008, 3:323     One of the perks of being in the military are the discounts - all you need to show is your id card. (except in this instance). I contacted Hilton Customer Assistance regarding this matter and they were very professional and helpful about my concerns. The manager of the Buffalo-Amherst property contacted me and offered me a discount off of the rack rate, but will not honor the reservation rate. Hilton corporate stated that each property can make up their own policies regarding rates. This is a very bad business practice if they change the terms of the reservation.    "
Mechanical Analysis,Mechanical Analysis,Fault diagnosis problem of electromechanical devices; also PUMPS DATA SET is newer version with domain theory and results,Mechanical+Analysis,https://archive.ics.uci.edu/ml//machine-learning-databases/mechanical-analysis/,https://archive.ics.uci.edu/ml/datasets/Mechanical+Analysis,"F. Bergadano supplied this database.  Each instance contains many components, each of which has 8 attributes.  Different instances in this database have different numbers of components.   It was impossible to put one instance on one line.  He originally had one instance per file, but this makes it difficult to ftp them (imagine ftp'ing 222 or so files!).  I bundled the set of 209 instances into a single data file, prefixing each with the line:                ===== Instance number 1: =====where ""n"" is a number in [1,221].  However, they are NOT, repeat NOT in sequential order.  Twelve (12) of the instances are missing.  Bergadano supplied these additional 12 instances (numbers 8,12,32,33,66,69,73,152,167,194,203,208) in a ""notused"" sub-directory.  I bundled these up with the same format in the ""notused-instances"" file.A quick scan of their file didn't reveal what the purpose is for these twelve instances.",Computer,"   0 - dummy (always 1) - used for numbering - ignore   1 - class - classification (1..6, the same for components of one example)   2 - # - component number (integer)   3 - sup - support in the machine where measure was taken (1..4)   4 - cpm - frequency of the measure (integer)   5 - mis - measure  (real)   6 - misr - earlier measure (real)   7 - dir - filter, type of the measure and direction:		       {vo=,			va=,			vv=,			ao=,			aa=,			av=,			io=,			ia=,			iv=}   8 - omega - rpm of the machine (integer, the same for components of one example)","Fault diagnosis problem of electromechanical devices; also PUMPS DATA SET is newer version with domain theory and resultsF. Bergadano supplied this database.  Each instance contains many components, each of which has 8 attributes.  Different instances in this database have different numbers of components.   It was impossible to put one instance on one line.  He originally had one instance per file, but this makes it difficult to ftp them (imagine ftp'ing 222 or so files!).  I bundled the set of 209 instances into a single data file, prefixing each with the line:                ===== Instance number 1: =====where ""n"" is a number in [1,221].  However, they are NOT, repeat NOT in sequential order.  Twelve (12) of the instances are missing.  Bergadano supplied these additional 12 instances (numbers 8,12,32,33,66,69,73,152,167,194,203,208) in a ""notused"" sub-directory.  I bundled these up with the same format in the ""notused-instances"" file.A quick scan of their file didn't reveal what the purpose is for these twelve instances.   0 - dummy (always 1) - used for numbering - ignore   1 - class - classification (1..6, the same for components of one example)   2 - # - component number (integer)   3 - sup - support in the machine where measure was taken (1..4)   4 - cpm - frequency of the measure (integer)   5 - mis - measure  (real)   6 - misr - earlier measure (real)   7 - dir - filter, type of the measure and direction:		       {vo=,			va=,			vv=,			ao=,			aa=,			av=,			io=,			ia=,			iv=}   8 - omega - rpm of the machine (integer, the same for components of one example)"
MoCap Hand Postures,MoCap Hand Postures,"5 types of hand postures from 12 users were recorded using unlabeled markers attached to fingers of a glove in a motion capture environment. Due to resolution and occlusion, missing values are common.",MoCap+Hand+Postures,https://archive.ics.uci.edu/ml//machine-learning-databases/00391/,https://archive.ics.uci.edu/ml/datasets/MoCap+Hand+Postures,"A Vicon motion capture camera system was used to record 12 users performing 5 hand postures with markers attached to a left-handed glove. A rigid pattern of markers on the back of the glove was used to establish a local coordinate system for the hand, and 11 other markers were attached to the thumb and fingers of the glove. 3 markers were attached to the thumb with one above the thumbnail and the other two on the knuckles. 2 markers were attached to each finger with one above the fingernail and the other on the joint between the proximal and middle phalanx.The 11 markers not part of the rigid pattern were unlabeled; their positions were not explicitly tracked. Consequently, there is no a priori correspondence between the markers of two given records. In addition, due to the resolution of the capture volume and self-occlusion due to the orientation and configuration of the hand and fingers, many records have missing markers. Extraneous markers were also possible due to artifacts in the Vicon software's marker reconstruction/recording process and other objects in the capture volume. As a result, the number of visible markers in a record varied considerably.The data presented here is already partially preprocessed. First, all markers were transformed to the local coordinate system of the record containing them. Second, each transformed marker with a norm greater than 200 millimeters was pruned. Finally, any record that contained fewer than 3 markers was removed. The processed data has at most 12 markers per record and at least 3. For more information, see 'Attribute Information'.Due to the manner in which data was captured, it is likely that for a given record and user there exists a near duplicate record originating from the same user. We recommend therefore to evaluate classification algorithms on a leave-one-user-out basis wherein each user is iteratively left out from training and used as a test set. One then tests the generalization of the algorithm to new users. A 'User' attribute is provided to accomodate this strategy. This dataset may be used for a variety of tasks, the most obvious of which is posture recognition via classification. One may also attempt user identification. Alternatively, one may perform clustering (constrained or unconstrained) to discover marker distributions either as an attempt to predict marker identities or obtain statistical descriptions/visualizations of the postures.In previous work, we randomly sampled without replacement a constant number (e.g. 75) of records per class per user in order to balance classes.",Computer,"Data is provided as a CSV file. A header provides the name of each attribute. An initial dummy record composed entirely of 0s should be ignored. A question mark '?' is used to indicate a missing value. A record corresponds to a single instant or frame as recorded by the camera system.'Class' - Integer. The class ID of the given record. Ranges from 1 to 5 with 1=Fist(with thumb out), 2=Stop(hand flat), 3=Point1(point with pointer finger), 4=Point2(point with pointer and middle fingers), 5=Grab(fingers curled as if to grab).'User' - Integer. The ID of the user that contributed the record. No meaning other than as an identifier.'Xi' - Real. The x-coordinate of the i-th unlabeled marker position. 'i' ranges from 0 to 11.'Yi' - Real. The y-coordinate of the i-th unlabeled marker position. 'i' ranges from 0 to 11.'Zi' - Real. The z-coordinate of the i-th unlabeled marker position. 'i' ranges from 0 to 11.Each record is a set. The i-th marker of a given record does not necessarily correspond to the i-th marker of a different record. One may randomly permute the visible (not missing) markers of a given record without changing the set that the record represents. For the sake of convenience, all visible markers of a given record are given a lower index than any missing marker. A class is not guaranteed to have even a single record with all markers visible.","5 types of hand postures from 12 users were recorded using unlabeled markers attached to fingers of a glove in a motion capture environment. Due to resolution and occlusion, missing values are common.A Vicon motion capture camera system was used to record 12 users performing 5 hand postures with markers attached to a left-handed glove. A rigid pattern of markers on the back of the glove was used to establish a local coordinate system for the hand, and 11 other markers were attached to the thumb and fingers of the glove. 3 markers were attached to the thumb with one above the thumbnail and the other two on the knuckles. 2 markers were attached to each finger with one above the fingernail and the other on the joint between the proximal and middle phalanx.The 11 markers not part of the rigid pattern were unlabeled; their positions were not explicitly tracked. Consequently, there is no a priori correspondence between the markers of two given records. In addition, due to the resolution of the capture volume and self-occlusion due to the orientation and configuration of the hand and fingers, many records have missing markers. Extraneous markers were also possible due to artifacts in the Vicon software's marker reconstruction/recording process and other objects in the capture volume. As a result, the number of visible markers in a record varied considerably.The data presented here is already partially preprocessed. First, all markers were transformed to the local coordinate system of the record containing them. Second, each transformed marker with a norm greater than 200 millimeters was pruned. Finally, any record that contained fewer than 3 markers was removed. The processed data has at most 12 markers per record and at least 3. For more information, see 'Attribute Information'.Due to the manner in which data was captured, it is likely that for a given record and user there exists a near duplicate record originating from the same user. We recommend therefore to evaluate classification algorithms on a leave-one-user-out basis wherein each user is iteratively left out from training and used as a test set. One then tests the generalization of the algorithm to new users. A 'User' attribute is provided to accomodate this strategy. This dataset may be used for a variety of tasks, the most obvious of which is posture recognition via classification. One may also attempt user identification. Alternatively, one may perform clustering (constrained or unconstrained) to discover marker distributions either as an attempt to predict marker identities or obtain statistical descriptions/visualizations of the postures.In previous work, we randomly sampled without replacement a constant number (e.g. 75) of records per class per user in order to balance classes.Data is provided as a CSV file. A header provides the name of each attribute. An initial dummy record composed entirely of 0s should be ignored. A question mark '?' is used to indicate a missing value. A record corresponds to a single instant or frame as recorded by the camera system.'Class' - Integer. The class ID of the given record. Ranges from 1 to 5 with 1=Fist(with thumb out), 2=Stop(hand flat), 3=Point1(point with pointer finger), 4=Point2(point with pointer and middle fingers), 5=Grab(fingers curled as if to grab).'User' - Integer. The ID of the user that contributed the record. No meaning other than as an identifier.'Xi' - Real. The x-coordinate of the i-th unlabeled marker position. 'i' ranges from 0 to 11.'Yi' - Real. The y-coordinate of the i-th unlabeled marker position. 'i' ranges from 0 to 11.'Zi' - Real. The z-coordinate of the i-th unlabeled marker position. 'i' ranges from 0 to 11.Each record is a set. The i-th marker of a given record does not necessarily correspond to the i-th marker of a different record. One may randomly permute the visible (not missing) markers of a given record without changing the set that the record represents. For the sake of convenience, all visible markers of a given record are given a lower index than any missing marker. A class is not guaranteed to have even a single record with all markers visible."
Monolithic Columns in Troad and Mysia Region,Monolithic Columns in Troad and Mysia Region,These data have been constituted to clarify the distribution in Northwestern Anatolia of the monolithic columns produced in the ancient granite quarries located in Troad and Mysia Regions. ,Monolithic+Columns+in+Troad+and+Mysia+Region,https://archive.ics.uci.edu/ml//machine-learning-databases/00558/,https://archive.ics.uci.edu/ml/datasets/Monolithic+Columns+in+Troad+and+Mysia+Region,"These data have been obtained from the qualitative mineralogical-petrographic and geochemical analyses results of three geological samples and eight archaeological samples considered with 19 attributes to clarify the distribution in Northwestern Anatolia of the monolithic columns produced in the ancient granite quarries located in Troad and Mysia Regions. The geological samples have been taken from KoÃƒÂ§ali-AkÃƒÂ§akeÃƒÂ§ili ancient quarries in Troad Region and Kozak ancient quarry in Mysia Region while the archaeological samples have been taken from Smintheion (Smintheion 1, Smintheion 2), Pergamon Red Hall/Serapeion, Smyrna Agora (Smyrna Agora 1, Smyrna Agora 2), Tlos Stadium, Tlos Theatre, and Side Theatre.The studies in which the raw data is obtained was supported by the Office of Scientific Research Projects Coordination at Ãƒâ€¡anakkale Onsekiz Mart University, Grant number: SYL-2015-521. The studies in which the raw data is processed was supported by the Office of Scientific Research Projects Coordination at Tokat GaziosmanpaÃ…Å¸a University, Grant numbers: 2009-72 and 2010/89.",Computer,The data have been composed of one matrix shown the geochemical analyses results of the eleven samples and of five matrices which are indicated their the qualitative mineralogical-petrographic analysis results for each of the five main components. ,"These data have been constituted to clarify the distribution in Northwestern Anatolia of the monolithic columns produced in the ancient granite quarries located in Troad and Mysia Regions. These data have been obtained from the qualitative mineralogical-petrographic and geochemical analyses results of three geological samples and eight archaeological samples considered with 19 attributes to clarify the distribution in Northwestern Anatolia of the monolithic columns produced in the ancient granite quarries located in Troad and Mysia Regions. The geological samples have been taken from KoÃƒÂ§ali-AkÃƒÂ§akeÃƒÂ§ili ancient quarries in Troad Region and Kozak ancient quarry in Mysia Region while the archaeological samples have been taken from Smintheion (Smintheion 1, Smintheion 2), Pergamon Red Hall/Serapeion, Smyrna Agora (Smyrna Agora 1, Smyrna Agora 2), Tlos Stadium, Tlos Theatre, and Side Theatre.The studies in which the raw data is obtained was supported by the Office of Scientific Research Projects Coordination at Ãƒâ€¡anakkale Onsekiz Mart University, Grant number: SYL-2015-521. The studies in which the raw data is processed was supported by the Office of Scientific Research Projects Coordination at Tokat GaziosmanpaÃ…Å¸a University, Grant numbers: 2009-72 and 2010/89.The data have been composed of one matrix shown the geochemical analyses results of the eleven samples and of five matrices which are indicated their the qualitative mineralogical-petrographic analysis results for each of the five main components. "
Moral Reasoner,Moral Reasoner,Horn-clause model that qualitatively simulates moral reasoning; Theory includes negated literals,Moral+Reasoner,https://archive.ics.uci.edu/ml//machine-learning-databases/moral-reasoner/,https://archive.ics.uci.edu/ml/datasets/Moral+Reasoner,"This is a rule-based model that qualitatively simulates moral reasoning. The model was intended to simulate how an ordinary person, down to about age five, reasons about harm-doing.The horn-clause theory and the 202 instances are the same as were used in (Wogulis, 1994).  The top-level predicate to predict is guilty/1. For more information, e.g. on the generation of instances, see (Wogulis, 1994).",Computer,,"Horn-clause model that qualitatively simulates moral reasoning; Theory includes negated literalsThis is a rule-based model that qualitatively simulates moral reasoning. The model was intended to simulate how an ordinary person, down to about age five, reasons about harm-doing.The horn-clause theory and the 202 instances are the same as were used in (Wogulis, 1994).  The top-level predicate to predict is guilty/1. For more information, e.g. on the generation of instances, see (Wogulis, 1994).nan"
Wall-Following Robot Navigation Data,Wall-Following Robot Navigation Data,"The data were collected as the SCITOS G5 robot navigates through the room following the wall in a clockwise direction, for 4 rounds, using 24 ultrasound sensors arranged circularly around its 'waist'.",Wall-Following+Robot+Navigation+Data,https://archive.ics.uci.edu/ml//machine-learning-databases/00194/,https://archive.ics.uci.edu/ml/datasets/Wall-Following+Robot+Navigation+Data,"The provided files comprise three different data sets. The first one contains the raw values of the measurements of all 24 ultrasound sensors and the corresponding class label (see Section 7). Sensor readings are sampled at a rate of 9 samples per second.The second one contains four sensor readings named 'simplified distances' and the corresponding class label (see Section 7). These simplified distances are referred to as the 'front distance', 'left distance', 'right distance' and 'back distance'. They consist, respectively, of the minimum sensor readings among those within 60 degree arcs located at the front, left, right and back parts of the robot.The third one contains only the front and left simplified distances and the corresponding class label.It is worth mentioning that the 24 ultrasound readings and the simplified distances were collected at the same time step, so each file has the same number of rows (one for each sampling time step).The wall-following task and data gathering were designed to test the hypothesis that this apparently simple navigation task is indeed a non-linearly separable classification task. Thus, linear classifiers, such as the Perceptron network, are not able to learn the task and command the robot around the room without collisions. Nonlinear neural classifiers, such as the MLP network, are able to learn the task and command the robot successfully without collisions. If some kind of short-term memory mechanism is provided to the neural classifiers, their performances are improved in general. For example, if past inputs are provided together with current sensor readings, even the Perceptron becomes able to learn the task and command the robot succesfully. If a recurrent neural network, such as the Elman network, is used to learn the task, the resulting dynamical classifier is able to learn the task using less hidden neurons than the MLP network.Files with different number of sensor readings were built in order to evaluate the performance of the classifiers with respect to the number of inputs.",Computer,Number of Attributes    -- sensor_readings_24.data: 24 numeric attributes and the class.   -- sensor_readings_4.data:   4 numeric attributes and the class.   -- sensor_readings_2.data:   2 numeric attributes and the class.For Each Attribute:    -- File sensor_readings_24.data:	1. US1: ultrasound sensor at the front of the robot (reference angle: 180Ã‚Â°) - (numeric: real)	2. US2: ultrasound reading (reference angle: -165Ã‚Â°) - (numeric: real)	3. US3: ultrasound reading (reference angle: -150Ã‚Â°) - (numeric: real)	4. US4: ultrasound reading (reference angle: -135Ã‚Â°) - (numeric: real)	5. US5: ultrasound reading (reference angle: -120Ã‚Â°) - (numeric: real)	6. US6: ultrasound reading (reference angle: -105Ã‚Â°) - (numeric: real)	7. US7: ultrasound reading (reference angle: -90Ã‚Â°) - (numeric: real)	8. US8: ultrasound reading (reference angle: -75Ã‚Â°) - (numeric: real)	9. US9: ultrasound reading (reference angle: -60Ã‚Â°) - (numeric: real)	10. US10: ultrasound reading (reference angle: -45Ã‚Â°) - (numeric: real)	11. US11: ultrasound reading (reference angle: -30Ã‚Â°) - (numeric: real)	12. US12: ultrasound reading (reference angle: -15Ã‚Â°) - (numeric: real)	13. US13: reading of ultrasound sensor situated at the back of the robot (reference angle: 0Ã‚Â°) - (numeric: real)	14. US14: ultrasound reading (reference angle: 15Ã‚Â°) - (numeric: real)	15. US15: ultrasound reading (reference angle: 30Ã‚Â°) - (numeric: real)	16. US16: ultrasound reading (reference angle: 45Ã‚Â°) - (numeric: real)	17. US17: ultrasound reading (reference angle: 60Ã‚Â°) - (numeric: real)	18. US18: ultrasound reading (reference angle: 75Ã‚Â°) - (numeric: real)	19. US19: ultrasound reading (reference angle: 90Ã‚Â°) - (numeric: real)	20. US20: ultrasound reading (reference angle: 105Ã‚Â°) - (numeric: real)	21. US21: ultrasound reading (reference angle: 120Ã‚Â°) - (numeric: real)	22. US22: ultrasound reading (reference angle: 135Ã‚Â°) - (numeric: real)	23. US23: ultrasound reading (reference angle: 150Ã‚Â°) - (numeric: real)	24. US24: ultrasound reading (reference angle: 165Ã‚Â°) - (numeric: real)   	25. Class:       		-- Move-Forward      		-- Slight-Right-Turn      		-- Sharp-Right-Turn      		-- Slight-Left-Turn   -- File sensor_readings_4.data:	1. SD_front: minimum sensor reading within a 60 degree arc located at the front of the robot - (numeric: real)	2. SD_left:  minimum sensor reading within a 60 degree arc located at the left of the robot  - (numeric: real)	3. SD_right: minimum sensor reading within a 60 degree arc located at the right of the robot - (numeric: real)	4. SD_back:  minimum sensor reading within a 60 degree arc located at the back of the robot - (numeric: real)   	5. Class:       		-- Move-Forward      		-- Slight-Right-Turn      		-- Sharp-Right-Turn      		-- Slight-Left-Turn   -- File sensor_readings_2.data:	1. SD_front: minimum sensor reading within a 60 degree arc located at the front of the robot - (numeric: real)	2. SD_left:  minimum sensor reading within a 60 degree arc located at the left of the robot - (numeric: real)   	3. Class:       		-- Move-Forward      		-- Slight-Right-Turn      		-- Sharp-Right-Turn      		-- Slight-Left-Turn,"The data were collected as the SCITOS G5 robot navigates through the room following the wall in a clockwise direction, for 4 rounds, using 24 ultrasound sensors arranged circularly around its 'waist'.The provided files comprise three different data sets. The first one contains the raw values of the measurements of all 24 ultrasound sensors and the corresponding class label (see Section 7). Sensor readings are sampled at a rate of 9 samples per second.The second one contains four sensor readings named 'simplified distances' and the corresponding class label (see Section 7). These simplified distances are referred to as the 'front distance', 'left distance', 'right distance' and 'back distance'. They consist, respectively, of the minimum sensor readings among those within 60 degree arcs located at the front, left, right and back parts of the robot.The third one contains only the front and left simplified distances and the corresponding class label.It is worth mentioning that the 24 ultrasound readings and the simplified distances were collected at the same time step, so each file has the same number of rows (one for each sampling time step).The wall-following task and data gathering were designed to test the hypothesis that this apparently simple navigation task is indeed a non-linearly separable classification task. Thus, linear classifiers, such as the Perceptron network, are not able to learn the task and command the robot around the room without collisions. Nonlinear neural classifiers, such as the MLP network, are able to learn the task and command the robot successfully without collisions. If some kind of short-term memory mechanism is provided to the neural classifiers, their performances are improved in general. For example, if past inputs are provided together with current sensor readings, even the Perceptron becomes able to learn the task and command the robot succesfully. If a recurrent neural network, such as the Elman network, is used to learn the task, the resulting dynamical classifier is able to learn the task using less hidden neurons than the MLP network.Files with different number of sensor readings were built in order to evaluate the performance of the classifiers with respect to the number of inputs.Number of Attributes    -- sensor_readings_24.data: 24 numeric attributes and the class.   -- sensor_readings_4.data:   4 numeric attributes and the class.   -- sensor_readings_2.data:   2 numeric attributes and the class.For Each Attribute:    -- File sensor_readings_24.data:	1. US1: ultrasound sensor at the front of the robot (reference angle: 180Ã‚Â°) - (numeric: real)	2. US2: ultrasound reading (reference angle: -165Ã‚Â°) - (numeric: real)	3. US3: ultrasound reading (reference angle: -150Ã‚Â°) - (numeric: real)	4. US4: ultrasound reading (reference angle: -135Ã‚Â°) - (numeric: real)	5. US5: ultrasound reading (reference angle: -120Ã‚Â°) - (numeric: real)	6. US6: ultrasound reading (reference angle: -105Ã‚Â°) - (numeric: real)	7. US7: ultrasound reading (reference angle: -90Ã‚Â°) - (numeric: real)	8. US8: ultrasound reading (reference angle: -75Ã‚Â°) - (numeric: real)	9. US9: ultrasound reading (reference angle: -60Ã‚Â°) - (numeric: real)	10. US10: ultrasound reading (reference angle: -45Ã‚Â°) - (numeric: real)	11. US11: ultrasound reading (reference angle: -30Ã‚Â°) - (numeric: real)	12. US12: ultrasound reading (reference angle: -15Ã‚Â°) - (numeric: real)	13. US13: reading of ultrasound sensor situated at the back of the robot (reference angle: 0Ã‚Â°) - (numeric: real)	14. US14: ultrasound reading (reference angle: 15Ã‚Â°) - (numeric: real)	15. US15: ultrasound reading (reference angle: 30Ã‚Â°) - (numeric: real)	16. US16: ultrasound reading (reference angle: 45Ã‚Â°) - (numeric: real)	17. US17: ultrasound reading (reference angle: 60Ã‚Â°) - (numeric: real)	18. US18: ultrasound reading (reference angle: 75Ã‚Â°) - (numeric: real)	19. US19: ultrasound reading (reference angle: 90Ã‚Â°) - (numeric: real)	20. US20: ultrasound reading (reference angle: 105Ã‚Â°) - (numeric: real)	21. US21: ultrasound reading (reference angle: 120Ã‚Â°) - (numeric: real)	22. US22: ultrasound reading (reference angle: 135Ã‚Â°) - (numeric: real)	23. US23: ultrasound reading (reference angle: 150Ã‚Â°) - (numeric: real)	24. US24: ultrasound reading (reference angle: 165Ã‚Â°) - (numeric: real)   	25. Class:       		-- Move-Forward      		-- Slight-Right-Turn      		-- Sharp-Right-Turn      		-- Slight-Left-Turn   -- File sensor_readings_4.data:	1. SD_front: minimum sensor reading within a 60 degree arc located at the front of the robot - (numeric: real)	2. SD_left:  minimum sensor reading within a 60 degree arc located at the left of the robot  - (numeric: real)	3. SD_right: minimum sensor reading within a 60 degree arc located at the right of the robot - (numeric: real)	4. SD_back:  minimum sensor reading within a 60 degree arc located at the back of the robot - (numeric: real)   	5. Class:       		-- Move-Forward      		-- Slight-Right-Turn      		-- Sharp-Right-Turn      		-- Slight-Left-Turn   -- File sensor_readings_2.data:	1. SD_front: minimum sensor reading within a 60 degree arc located at the front of the robot - (numeric: real)	2. SD_left:  minimum sensor reading within a 60 degree arc located at the left of the robot - (numeric: real)   	3. Class:       		-- Move-Forward      		-- Slight-Right-Turn      		-- Sharp-Right-Turn      		-- Slight-Left-Turn"
Water Quality Prediction,Water Quality Prediction,The goal is to predict the spatio-temporal water quality in terms of the â€œpower of hydrogen (pH)â€� value for the next day based on the historical data of water measurement indices.,Water+Quality+Prediction,https://archive.ics.uci.edu/ml//machine-learning-databases/00629/,https://archive.ics.uci.edu/ml/datasets/Water+Quality+Prediction,"Here we want to forecast the spatio-temporal water quality in terms of the Ã¢â‚¬Å“power of hydrogen (pH)Ã¢â‚¬Â� value for the next day based on the input data, which is the historical data of other water measurement indices. The input data consists of daily samples for 36 sites, providing measurements related to pH values in Georgia, USA. The input features consist of 11 common indices including volume of dissolved oxygen, temperature, and specific conductance (see details in dataset). The output to predict is the measurement of 'pH, water, unfiltered, field, standard units (Median)'.There are two major water systems to consider: one is centered on the city of Atlanta while the other is centered on the eastern coast of Georgia. This information indicates spatial dependency among different locations which are important to the forecast.For details of the data description, please refer to the file named README.docx.",Computer,"'Specific conductance, water, unfiltered, microsiemens per centimeter at 25 degrees Celsius (Maximum)'	'pH, water, unfiltered, field, standard units (Maximum)'	'pH, water, unfiltered, field, standard units (Minimum)'	'Specific conductance, water, unfiltered, microsiemens per centimeter at 25 degrees Celsius (Minimum)'	'Specific conductance, water, unfiltered, microsiemens per centimeter at 25 degrees Celsius (Mean)'	'Dissolved oxygen, water, unfiltered, milligrams per liter (Maximum)'	'Dissolved oxygen, water, unfiltered, milligrams per liter (Mean)'	'Dissolved oxygen, water, unfiltered, milligrams per liter (Minimum)'	'Temperature, water, degrees Celsius (Mean)'	'Temperature, water, degrees Celsius (Minimum)'	'Temperature, water, degrees Celsius (Maximum)'","The goal is to predict the spatio-temporal water quality in terms of the â€œpower of hydrogen (pH)â€� value for the next day based on the historical data of water measurement indices.Here we want to forecast the spatio-temporal water quality in terms of the Ã¢â‚¬Å“power of hydrogen (pH)Ã¢â‚¬Â� value for the next day based on the input data, which is the historical data of other water measurement indices. The input data consists of daily samples for 36 sites, providing measurements related to pH values in Georgia, USA. The input features consist of 11 common indices including volume of dissolved oxygen, temperature, and specific conductance (see details in dataset). The output to predict is the measurement of 'pH, water, unfiltered, field, standard units (Median)'.There are two major water systems to consider: one is centered on the city of Atlanta while the other is centered on the eastern coast of Georgia. This information indicates spatial dependency among different locations which are important to the forecast.For details of the data description, please refer to the file named README.docx.'Specific conductance, water, unfiltered, microsiemens per centimeter at 25 degrees Celsius (Maximum)'	'pH, water, unfiltered, field, standard units (Maximum)'	'pH, water, unfiltered, field, standard units (Minimum)'	'Specific conductance, water, unfiltered, microsiemens per centimeter at 25 degrees Celsius (Minimum)'	'Specific conductance, water, unfiltered, microsiemens per centimeter at 25 degrees Celsius (Mean)'	'Dissolved oxygen, water, unfiltered, milligrams per liter (Maximum)'	'Dissolved oxygen, water, unfiltered, milligrams per liter (Mean)'	'Dissolved oxygen, water, unfiltered, milligrams per liter (Minimum)'	'Temperature, water, degrees Celsius (Mean)'	'Temperature, water, degrees Celsius (Minimum)'	'Temperature, water, degrees Celsius (Maximum)'"
Online Handwritten Assamese Characters Dataset,Online Handwritten Assamese Characters Dataset,This is a dataset of 8235 online handwritten assamese characters. The â€œonlineâ€� process involves capturing of data as text is written on a digitizing tablet with an electronic pen.,Online+Handwritten+Assamese+Characters+Dataset,https://archive.ics.uci.edu/ml//machine-learning-databases/00208/,https://archive.ics.uci.edu/ml/datasets/Online+Handwritten+Assamese+Characters+Dataset,"A dataset of online handwritten assamese characters by collecting samples from 45 writers is created. Each writer contributed 52 basic characters, 10 numerals and 121 assamese conjunct consonants. The total number of entries corresponding to each writer is 183 (= 52 characters + 10 numerals + 121 conjunct consonants). The total number of samples in the dataset is 8235 ( = 45 Ãƒâ€” 183 ).The handwriting samples were collected on an iball 8060U external digitizing tablet connected to a laptop using its cordless digital stylus pen. The data acquisition program consists of a GUI which shows a box on the screen along with other controls. The writers are instructed to write only inside the acquisition box. The acquisition program records the handwriting as a stream of (X, Y) coordinate points using the appropriate pen position sensor along with the pen-up/pen-down switching. No pressure level was recorded. The distribution of the dataset consists of 45 folders (one for each writer) and a Ã¢â‚¬Å“Data_Table.pdfÃ¢â‚¬Â� file. This file contains information about the character id (ID), character name (Label) and actual shape of the character (Char).  Each folder contains 183 text files corresponding to the 183 characters written by a single writer. Each file is named based on the pair (M, N). The text file Ã¢â‚¬Å“M.N.txtÃ¢â‚¬Â� represents the character with ID Ã¢â‚¬Å“MÃ¢â‚¬Â� written by the writer with ID Ã¢â‚¬Å“NÃ¢â‚¬Â�. For instance the file Ã¢â‚¬Å“132.10.txtÃ¢â‚¬Â� represents the character with ID Ã¢â‚¬Å“132Ã¢â‚¬Â� written by the writer with ID Ã¢â‚¬Å“10Ã¢â‚¬Â�.  ",Computer,"1.	Character Name: The first line of each sample is Ã¢â‚¬Å“CHARACTER_NAME: CharacterÃ¢â‚¬Â�. The Ã¢â‚¬Å“CharacterÃ¢â‚¬Â� is the Name of any one of the 183 characters listed below: Here Ã¢â‚¬Å“ID [i]Ã¢â‚¬Â� represents the name of the character with the ID Ã¢â‚¬Å“iÃ¢â‚¬Â�.ID [1]     = Ã¢â‚¬Å“AÃ¢â‚¬Â�ID [2]     = Ã¢â‚¬Å“AAÃ¢â‚¬Â�ID [3]     = Ã¢â‚¬Å“EÃ¢â‚¬Â�ID [4]     = Ã¢â‚¬Å“EEÃ¢â‚¬Â�ID [5]     = Ã¢â‚¬Å“UÃ¢â‚¬Â�ID [6]     = Ã¢â‚¬Å“UUÃ¢â‚¬Â�ID [7]     = Ã¢â‚¬Å“REEÃ¢â‚¬Â�ID [8]     = Ã¢â‚¬Å“AEÃ¢â‚¬Â�ID [9]     = Ã¢â‚¬Å“OIÃ¢â‚¬Â�ID [10]   = Ã¢â‚¬Å“OÃ¢â‚¬Â�ID [11]   = Ã¢â‚¬Å“OUÃ¢â‚¬Â�ID [12]   = Ã¢â‚¬Å“KAÃ¢â‚¬Â�ID [13]   = Ã¢â‚¬Å“KHAÃ¢â‚¬Â�ID [14]   = Ã¢â‚¬Å“GAÃ¢â‚¬Â�ID [15]   = Ã¢â‚¬Å“GHAÃ¢â‚¬Â�ID [16]   = Ã¢â‚¬Å“NGÃ¢â‚¬Â�ID [17]   = Ã¢â‚¬Å“CAÃ¢â‚¬Â�ID [18]   = Ã¢â‚¬Å“CCAÃ¢â‚¬Â�ID [19]   = Ã¢â‚¬Å“JAÃ¢â‚¬Â�ID [20]   = Ã¢â‚¬Å“JHAÃ¢â‚¬Â�ID [21]   = Ã¢â‚¬Å“NIYAÃ¢â‚¬Â�ID [22]   = Ã¢â‚¬Å“MTAÃ¢â‚¬Â�ID [23]   = Ã¢â‚¬Å“MTHAÃ¢â‚¬Â�ID [24]   = Ã¢â‚¬Å“MDAÃ¢â‚¬Â�ID [25]   = Ã¢â‚¬Å“MDHAÃ¢â‚¬Â�ID [26]   = Ã¢â‚¬Å“MNAÃ¢â‚¬Â�ID [27]   = Ã¢â‚¬Å“TAÃ¢â‚¬Â�ID [28]   = Ã¢â‚¬Å“THAÃ¢â‚¬Â�ID [29]   = Ã¢â‚¬Å“DAÃ¢â‚¬Â�ID [30]   = Ã¢â‚¬Å“DHAÃ¢â‚¬Â�ID [31]   = Ã¢â‚¬Å“NAÃ¢â‚¬Â�ID [32]   = Ã¢â‚¬Å“PAÃ¢â‚¬Â�ID [33]   = Ã¢â‚¬Å“PHAÃ¢â‚¬Â�ID [34]   = Ã¢â‚¬Å“BAÃ¢â‚¬Â�ID [35]   = Ã¢â‚¬Å“BHAÃ¢â‚¬Â�ID [36]   = Ã¢â‚¬Å“MAÃ¢â‚¬Â�ID [37]   = Ã¢â‚¬Å“AJAÃ¢â‚¬Â�ID [38]   = Ã¢â‚¬Å“RAÃ¢â‚¬Â�ID [39]   = Ã¢â‚¬Å“LAÃ¢â‚¬Â�ID [40]   = Ã¢â‚¬Å“WAÃ¢â‚¬Â�ID [41]   = Ã¢â‚¬Å“TXAÃ¢â‚¬Â�ID [42]   = Ã¢â‚¬Å“MXAÃ¢â‚¬Â�ID [43]   = Ã¢â‚¬Å“DXAÃ¢â‚¬Â�ID [44]   = Ã¢â‚¬Å“HAÃ¢â‚¬Â�ID [45]   = Ã¢â‚¬Å“KHYAÃ¢â‚¬Â�ID [46]   = Ã¢â‚¬Å“AYAÃ¢â‚¬Â�ID [47]   = Ã¢â‚¬Å“DRAÃ¢â‚¬Â�ID [48]   = Ã¢â‚¬Å“DHRAÃ¢â‚¬Â�ID [49]   = Ã¢â‚¬Å“KTAÃ¢â‚¬Â�ID [50]   = Ã¢â‚¬Å“ANSRÃ¢â‚¬Â�ID [51]   = Ã¢â‚¬Å“BXGÃ¢â‚¬Â�ID [52]   = Ã¢â‚¬Å“CBNÃ¢â‚¬Â�ID [53]   = Ã¢â‚¬Å“KKÃ¢â‚¬Â�ID [54]   = Ã¢â‚¬Å“KTÃ¢â‚¬Â�ID [55]   = Ã¢â‚¬Å“KTTÃ¢â‚¬Â�ID [56]   = Ã¢â‚¬Å“KSÃ¢â‚¬Â�ID [57]   = Ã¢â‚¬Å“KLÃ¢â‚¬Â�ID [58]   = Ã¢â‚¬Å“KMÃ¢â‚¬Â�ID [59]   = Ã¢â‚¬Å“GLÃ¢â‚¬Â�ID [60]   = Ã¢â‚¬Å“CCÃ¢â‚¬Â�ID [61]   = Ã¢â‚¬Å“CCCÃ¢â‚¬Â�ID [62]   = Ã¢â‚¬Å“JJÃ¢â‚¬Â�ID [63]   = Ã¢â‚¬Å“JBÃ¢â‚¬Â�ID [64]   = Ã¢â‚¬Å“BJÃ¢â‚¬Â�ID [65]   = Ã¢â‚¬Å“GNÃ¢â‚¬Â�ID [66]   = Ã¢â‚¬Å“TNÃ¢â‚¬Â�ID [67]   = Ã¢â‚¬Å“JJBÃ¢â‚¬Â�ID [68]   = Ã¢â‚¬Å“LGÃ¢â‚¬Â�ID [69]   = Ã¢â‚¬Å“TTÃ¢â‚¬Â�ID [70]   = Ã¢â‚¬Å“GDHÃ¢â‚¬Â�ID [71]   = Ã¢â‚¬Å“GMÃ¢â‚¬Â�ID [72]   = Ã¢â‚¬Å“GHNÃ¢â‚¬Â�ID [73]   = Ã¢â‚¬Å“MDDÃ¢â‚¬Â�ID [74]   = Ã¢â‚¬Å“NTÃ¢â‚¬Â�ID [75]   = Ã¢â‚¬Å“NNÃ¢â‚¬Â�ID [76]   = Ã¢â‚¬Å“NMMÃ¢â‚¬Â�ID [77]   = Ã¢â‚¬Å“TTTÃ¢â‚¬Â�ID [78]   = Ã¢â‚¬Å“TTBÃ¢â‚¬Â�ID [79]   = Ã¢â‚¬Å“TMÃ¢â‚¬Â�ID [80]   = Ã¢â‚¬Å“TRÃ¢â‚¬Â�ID [81]   = Ã¢â‚¬Å“NTTÃ¢â‚¬Â�ID [82]   = Ã¢â‚¬Å“RRGÃ¢â‚¬Â�ID [83]   = Ã¢â‚¬Å“NDDÃ¢â‚¬Â�ID [84]   = Ã¢â‚¬Å“NTHÃ¢â‚¬Â�ID [85]   = Ã¢â‚¬Å“NDHÃ¢â‚¬Â�ID [86]   = Ã¢â‚¬Å“NNNÃ¢â‚¬Â�ID [87]   = Ã¢â‚¬Å“NBÃ¢â‚¬Â�ID [88]   = Ã¢â‚¬Å“NSÃ¢â‚¬Â�ID [89]   = Ã¢â‚¬Å“NMÃ¢â‚¬Â�ID [90]   = Ã¢â‚¬Å“DBÃ¢â‚¬Â�ID [91]   = Ã¢â‚¬Å“QJÃ¢â‚¬Â�ID [92]   = Ã¢â‚¬Å“PTTÃ¢â‚¬Â�ID [93]   = Ã¢â‚¬Å“PLÃ¢â‚¬Â�ID [94]   = Ã¢â‚¬Å“DVÃ¢â‚¬Â�ID [95]   = Ã¢â‚¬Å“BLÃ¢â‚¬Â�ID [96]   = Ã¢â‚¬Å“BDÃ¢â‚¬Â�ID [97]   = Ã¢â‚¬Å“TBÃ¢â‚¬Â�ID [98]   = Ã¢â‚¬Å“MMÃ¢â‚¬Â�ID [99]   = Ã¢â‚¬Å“MVÃ¢â‚¬Â�ID [100] = Ã¢â‚¬Å“MPÃ¢â‚¬Â�ID [101] = Ã¢â‚¬Å“MNÃ¢â‚¬Â�ID [102] = Ã¢â‚¬Å“NTRÃ¢â‚¬Â�ID [103] = Ã¢â‚¬Å“MBÃ¢â‚¬Â�ID [104] = Ã¢â‚¬Å“LKÃ¢â‚¬Â�ID [105] = Ã¢â‚¬Å“MNDÃ¢â‚¬Â�ID [106] = Ã¢â‚¬Å“FKÃ¢â‚¬Â�ID [107] = Ã¢â‚¬Å“LDÃ¢â‚¬Â�ID [108] = Ã¢â‚¬Å“LLÃ¢â‚¬Â�ID [109] = Ã¢â‚¬Å“LPÃ¢â‚¬Â�ID [110] = Ã¢â‚¬Å“LTÃ¢â‚¬Â�ID [111] = Ã¢â‚¬Å“SNÃ¢â‚¬Â�ID [112] = Ã¢â‚¬Å“SCÃ¢â‚¬Â�ID [113] = Ã¢â‚¬Å“SMÃ¢â‚¬Â�ID [114] = Ã¢â‚¬Å“SBÃ¢â‚¬Â�ID [115] = Ã¢â‚¬Å“FNÃ¢â‚¬Â�ID [116] = Ã¢â‚¬Å“FTÃ¢â‚¬Â�ID [117] = Ã¢â‚¬Å“SKÃ¢â‚¬Â�ID [118] = Ã¢â‚¬Å“SSTHÃ¢â‚¬Â�ID [119] = Ã¢â‚¬Å“SSMÃ¢â‚¬Â�ID [120] = Ã¢â‚¬Å“SSNÃ¢â‚¬Â�ID [121] = Ã¢â‚¬Å“SSBÃ¢â‚¬Â�ID [122] = Ã¢â‚¬Å“STÃ¢â‚¬Â�ID [123] = Ã¢â‚¬Å“SPÃ¢â‚¬Â�ID [124] = Ã¢â‚¬Å“SPHÃ¢â‚¬Â�ID [125] = Ã¢â‚¬Å“STHÃ¢â‚¬Â�ID [126] = Ã¢â‚¬Å“SKHÃ¢â‚¬Â�ID [127] = Ã¢â‚¬Å“NGGÃ¢â‚¬Â�ID [128] = Ã¢â‚¬Å“NGCÃ¢â‚¬Â�ID [129] = Ã¢â‚¬Å“FPÃ¢â‚¬Â�ID [130] = Ã¢â‚¬Å“NGNÃ¢â‚¬Â�ID [131] = Ã¢â‚¬Å“XMÃ¢â‚¬Â�ID [132] = Ã¢â‚¬Å“NGJÃ¢â‚¬Â�ID [133] = Ã¢â‚¬Å“MNTHÃ¢â‚¬Â�ID [134] = Ã¢â‚¬Å“NGKÃ¢â‚¬Â�ID [135] = Ã¢â‚¬Å“KRÃ¢â‚¬Â�ID [136] = Ã¢â‚¬Å“TRUÃ¢â‚¬Â�ID [137] = Ã¢â‚¬Å“BHRÃ¢â‚¬Â�ID [138] = Ã¢â‚¬Å“THBÃ¢â‚¬Â�ID [139] = Ã¢â‚¬Å“DGÃ¢â‚¬Â�ID [140] = Ã¢â‚¬Å“DGHÃ¢â‚¬Â�ID [141] = Ã¢â‚¬Å“DDÃ¢â‚¬Â�ID [142] = Ã¢â‚¬Å“DDHÃ¢â‚¬Â�ID [143] = Ã¢â‚¬Å“HRÃ¢â‚¬Â�ID [144] = Ã¢â‚¬Å“GGUÃ¢â‚¬Â�ID [145] = Ã¢â‚¬Å“GGNÃ¢â‚¬Â�ID [146] = Ã¢â‚¬Å“NKHÃ¢â‚¬Â�ID [147] = Ã¢â‚¬Å“NGHÃ¢â‚¬Â�ID [148] = Ã¢â‚¬Å“NGKHÃ¢â‚¬Â�ID [149] = Ã¢â‚¬Å“TTHÃ¢â‚¬Â�ID [150] = Ã¢â‚¬Å“PNÃ¢â‚¬Â�ID [151] = Ã¢â‚¬Å“HNÃ¢â‚¬Â�ID [152] = Ã¢â‚¬Å“XNÃ¢â‚¬Â�ID [153] = Ã¢â‚¬Å“MFÃ¢â‚¬Â�ID [154] = Ã¢â‚¬Å“BBÃ¢â‚¬Â�ID [155] = Ã¢â‚¬Å“LBÃ¢â‚¬Â�ID [156] = Ã¢â‚¬Å“LMÃ¢â‚¬Â�ID [157] = Ã¢â‚¬Å“BHMÃ¢â‚¬Â�ID [158] = Ã¢â‚¬Å“MLÃ¢â‚¬Â�ID [159] = Ã¢â‚¬Å“SLÃ¢â‚¬Â�ID [160] = Ã¢â‚¬Å“PSÃ¢â‚¬Â�ID [161] = Ã¢â‚¬Å“KHRÃ¢â‚¬Â�ID [162] = Ã¢â‚¬Å“GRÃ¢â‚¬Â�ID [163] = Ã¢â‚¬Å“GHRÃ¢â‚¬Â�ID [164] = Ã¢â‚¬Å“JRÃ¢â‚¬Â�ID [165] = Ã¢â‚¬Å“TRRÃ¢â‚¬Â�ID [166] = Ã¢â‚¬Å“DRRÃ¢â‚¬Â�ID [167] = Ã¢â‚¬Å“DHRRÃ¢â‚¬Â�ID [168] = Ã¢â‚¬Å“PRRÃ¢â‚¬Â�ID [169] = Ã¢â‚¬Å“BRRÃ¢â‚¬Â�ID [170] = Ã¢â‚¬Å“MRRÃ¢â‚¬Â�ID [171] = Ã¢â‚¬Å“TSRÃ¢â‚¬Â�ID [172] = Ã¢â‚¬Å“DSRÃ¢â‚¬Â�ID [173] = Ã¢â‚¬Å“HRRÃ¢â‚¬Â�ID [174] = Ã¢â‚¬Å“SUNYAÃ¢â‚¬Â�ID [175] = Ã¢â‚¬Å“EKÃ¢â‚¬Â�ID [176] = Ã¢â‚¬Å“DUIÃ¢â‚¬Â�ID [177] = Ã¢â‚¬Å“TINIÃ¢â‚¬Â�ID [178] = Ã¢â‚¬Å“CARIÃ¢â‚¬Â�ID [179] = Ã¢â‚¬Å“PACÃ¢â‚¬Â�ID [180] = Ã¢â‚¬Å“CAYÃ¢â‚¬Â�ID [181] = Ã¢â‚¬Å“XATÃ¢â‚¬Â�ID [182] = Ã¢â‚¬Å“ATHÃ¢â‚¬Â�ID [183] = Ã¢â‚¬Å“NAAÃ¢â‚¬Â� 2.	The total number of strokes in the sample: The total number of strokes used to write a character is represented by the line Ã¢â‚¬Å“STROKE_COUNT: NumberÃ¢â‚¬Â�, where Ã¢â‚¬Å“NumberÃ¢â‚¬Â� is an integer value.3.	Sequence of Strokes: Each stroke begins with the Ã¢â‚¬Å“PEN_DOWNÃ¢â‚¬Â� information and there is a Ã¢â‚¬Å“PEN_UPÃ¢â‚¬Â� information followed by the Ã¢â‚¬Å“PEN_DOWNÃ¢â‚¬Â� information between two consecutive strokes. The end of a sample is represented by the Ã¢â‚¬Å“PEN_UPÃ¢â‚¬Â� information followed by the Ã¢â‚¬Å“END_CHARACTER: CharacterÃ¢â‚¬Â� information. Each stroke consists of a sequence of X and Y coordinates values which are given in the first and the second columns respectively. Corresponding to each pair of values of X and Y coordinates, there are Ã¢â‚¬Å“STYLUS_STATEÃ¢â‚¬Â� and Ã¢â‚¬Å“STROKEÃ¢â‚¬Â� information given in the third and the fourth columns respectively. Ã¢â‚¬Å“STYLUS_STATEÃ¢â‚¬Â� is either 1 or 0. Corresponding to each recorded (X, Y) point, Ã¢â‚¬Å“STYLUS_STATEÃ¢â‚¬Â� is 1 and corresponding to the Ã¢â‚¬Å“PEN_UPÃ¢â‚¬Â� information Ã¢â‚¬Å“STYLUS_STATEÃ¢â‚¬Â� is 0. Ã¢â‚¬Å“STYLUS_STATEÃ¢â‚¬Â� is kept blank corresponding to each Ã¢â‚¬Å“PEN_DOWNÃ¢â‚¬Â� information. The Ã¢â‚¬Å“STROKEÃ¢â‚¬Â� information represents the serial number of a constituent stroke of a sample. The value of X grows left-to-right and that of Y grows downwards. Coordinates are integer numbers ranging from 0 to 4392 for X and 0 to 4868 for Y respectively. ","This is a dataset of 8235 online handwritten assamese characters. The â€œonlineâ€� process involves capturing of data as text is written on a digitizing tablet with an electronic pen.A dataset of online handwritten assamese characters by collecting samples from 45 writers is created. Each writer contributed 52 basic characters, 10 numerals and 121 assamese conjunct consonants. The total number of entries corresponding to each writer is 183 (= 52 characters + 10 numerals + 121 conjunct consonants). The total number of samples in the dataset is 8235 ( = 45 Ãƒâ€” 183 ).The handwriting samples were collected on an iball 8060U external digitizing tablet connected to a laptop using its cordless digital stylus pen. The data acquisition program consists of a GUI which shows a box on the screen along with other controls. The writers are instructed to write only inside the acquisition box. The acquisition program records the handwriting as a stream of (X, Y) coordinate points using the appropriate pen position sensor along with the pen-up/pen-down switching. No pressure level was recorded. The distribution of the dataset consists of 45 folders (one for each writer) and a Ã¢â‚¬Å“Data_Table.pdfÃ¢â‚¬Â� file. This file contains information about the character id (ID), character name (Label) and actual shape of the character (Char).  Each folder contains 183 text files corresponding to the 183 characters written by a single writer. Each file is named based on the pair (M, N). The text file Ã¢â‚¬Å“M.N.txtÃ¢â‚¬Â� represents the character with ID Ã¢â‚¬Å“MÃ¢â‚¬Â� written by the writer with ID Ã¢â‚¬Å“NÃ¢â‚¬Â�. For instance the file Ã¢â‚¬Å“132.10.txtÃ¢â‚¬Â� represents the character with ID Ã¢â‚¬Å“132Ã¢â‚¬Â� written by the writer with ID Ã¢â‚¬Å“10Ã¢â‚¬Â�.  1.	Character Name: The first line of each sample is Ã¢â‚¬Å“CHARACTER_NAME: CharacterÃ¢â‚¬Â�. The Ã¢â‚¬Å“CharacterÃ¢â‚¬Â� is the Name of any one of the 183 characters listed below: Here Ã¢â‚¬Å“ID [i]Ã¢â‚¬Â� represents the name of the character with the ID Ã¢â‚¬Å“iÃ¢â‚¬Â�.ID [1]     = Ã¢â‚¬Å“AÃ¢â‚¬Â�ID [2]     = Ã¢â‚¬Å“AAÃ¢â‚¬Â�ID [3]     = Ã¢â‚¬Å“EÃ¢â‚¬Â�ID [4]     = Ã¢â‚¬Å“EEÃ¢â‚¬Â�ID [5]     = Ã¢â‚¬Å“UÃ¢â‚¬Â�ID [6]     = Ã¢â‚¬Å“UUÃ¢â‚¬Â�ID [7]     = Ã¢â‚¬Å“REEÃ¢â‚¬Â�ID [8]     = Ã¢â‚¬Å“AEÃ¢â‚¬Â�ID [9]     = Ã¢â‚¬Å“OIÃ¢â‚¬Â�ID [10]   = Ã¢â‚¬Å“OÃ¢â‚¬Â�ID [11]   = Ã¢â‚¬Å“OUÃ¢â‚¬Â�ID [12]   = Ã¢â‚¬Å“KAÃ¢â‚¬Â�ID [13]   = Ã¢â‚¬Å“KHAÃ¢â‚¬Â�ID [14]   = Ã¢â‚¬Å“GAÃ¢â‚¬Â�ID [15]   = Ã¢â‚¬Å“GHAÃ¢â‚¬Â�ID [16]   = Ã¢â‚¬Å“NGÃ¢â‚¬Â�ID [17]   = Ã¢â‚¬Å“CAÃ¢â‚¬Â�ID [18]   = Ã¢â‚¬Å“CCAÃ¢â‚¬Â�ID [19]   = Ã¢â‚¬Å“JAÃ¢â‚¬Â�ID [20]   = Ã¢â‚¬Å“JHAÃ¢â‚¬Â�ID [21]   = Ã¢â‚¬Å“NIYAÃ¢â‚¬Â�ID [22]   = Ã¢â‚¬Å“MTAÃ¢â‚¬Â�ID [23]   = Ã¢â‚¬Å“MTHAÃ¢â‚¬Â�ID [24]   = Ã¢â‚¬Å“MDAÃ¢â‚¬Â�ID [25]   = Ã¢â‚¬Å“MDHAÃ¢â‚¬Â�ID [26]   = Ã¢â‚¬Å“MNAÃ¢â‚¬Â�ID [27]   = Ã¢â‚¬Å“TAÃ¢â‚¬Â�ID [28]   = Ã¢â‚¬Å“THAÃ¢â‚¬Â�ID [29]   = Ã¢â‚¬Å“DAÃ¢â‚¬Â�ID [30]   = Ã¢â‚¬Å“DHAÃ¢â‚¬Â�ID [31]   = Ã¢â‚¬Å“NAÃ¢â‚¬Â�ID [32]   = Ã¢â‚¬Å“PAÃ¢â‚¬Â�ID [33]   = Ã¢â‚¬Å“PHAÃ¢â‚¬Â�ID [34]   = Ã¢â‚¬Å“BAÃ¢â‚¬Â�ID [35]   = Ã¢â‚¬Å“BHAÃ¢â‚¬Â�ID [36]   = Ã¢â‚¬Å“MAÃ¢â‚¬Â�ID [37]   = Ã¢â‚¬Å“AJAÃ¢â‚¬Â�ID [38]   = Ã¢â‚¬Å“RAÃ¢â‚¬Â�ID [39]   = Ã¢â‚¬Å“LAÃ¢â‚¬Â�ID [40]   = Ã¢â‚¬Å“WAÃ¢â‚¬Â�ID [41]   = Ã¢â‚¬Å“TXAÃ¢â‚¬Â�ID [42]   = Ã¢â‚¬Å“MXAÃ¢â‚¬Â�ID [43]   = Ã¢â‚¬Å“DXAÃ¢â‚¬Â�ID [44]   = Ã¢â‚¬Å“HAÃ¢â‚¬Â�ID [45]   = Ã¢â‚¬Å“KHYAÃ¢â‚¬Â�ID [46]   = Ã¢â‚¬Å“AYAÃ¢â‚¬Â�ID [47]   = Ã¢â‚¬Å“DRAÃ¢â‚¬Â�ID [48]   = Ã¢â‚¬Å“DHRAÃ¢â‚¬Â�ID [49]   = Ã¢â‚¬Å“KTAÃ¢â‚¬Â�ID [50]   = Ã¢â‚¬Å“ANSRÃ¢â‚¬Â�ID [51]   = Ã¢â‚¬Å“BXGÃ¢â‚¬Â�ID [52]   = Ã¢â‚¬Å“CBNÃ¢â‚¬Â�ID [53]   = Ã¢â‚¬Å“KKÃ¢â‚¬Â�ID [54]   = Ã¢â‚¬Å“KTÃ¢â‚¬Â�ID [55]   = Ã¢â‚¬Å“KTTÃ¢â‚¬Â�ID [56]   = Ã¢â‚¬Å“KSÃ¢â‚¬Â�ID [57]   = Ã¢â‚¬Å“KLÃ¢â‚¬Â�ID [58]   = Ã¢â‚¬Å“KMÃ¢â‚¬Â�ID [59]   = Ã¢â‚¬Å“GLÃ¢â‚¬Â�ID [60]   = Ã¢â‚¬Å“CCÃ¢â‚¬Â�ID [61]   = Ã¢â‚¬Å“CCCÃ¢â‚¬Â�ID [62]   = Ã¢â‚¬Å“JJÃ¢â‚¬Â�ID [63]   = Ã¢â‚¬Å“JBÃ¢â‚¬Â�ID [64]   = Ã¢â‚¬Å“BJÃ¢â‚¬Â�ID [65]   = Ã¢â‚¬Å“GNÃ¢â‚¬Â�ID [66]   = Ã¢â‚¬Å“TNÃ¢â‚¬Â�ID [67]   = Ã¢â‚¬Å“JJBÃ¢â‚¬Â�ID [68]   = Ã¢â‚¬Å“LGÃ¢â‚¬Â�ID [69]   = Ã¢â‚¬Å“TTÃ¢â‚¬Â�ID [70]   = Ã¢â‚¬Å“GDHÃ¢â‚¬Â�ID [71]   = Ã¢â‚¬Å“GMÃ¢â‚¬Â�ID [72]   = Ã¢â‚¬Å“GHNÃ¢â‚¬Â�ID [73]   = Ã¢â‚¬Å“MDDÃ¢â‚¬Â�ID [74]   = Ã¢â‚¬Å“NTÃ¢â‚¬Â�ID [75]   = Ã¢â‚¬Å“NNÃ¢â‚¬Â�ID [76]   = Ã¢â‚¬Å“NMMÃ¢â‚¬Â�ID [77]   = Ã¢â‚¬Å“TTTÃ¢â‚¬Â�ID [78]   = Ã¢â‚¬Å“TTBÃ¢â‚¬Â�ID [79]   = Ã¢â‚¬Å“TMÃ¢â‚¬Â�ID [80]   = Ã¢â‚¬Å“TRÃ¢â‚¬Â�ID [81]   = Ã¢â‚¬Å“NTTÃ¢â‚¬Â�ID [82]   = Ã¢â‚¬Å“RRGÃ¢â‚¬Â�ID [83]   = Ã¢â‚¬Å“NDDÃ¢â‚¬Â�ID [84]   = Ã¢â‚¬Å“NTHÃ¢â‚¬Â�ID [85]   = Ã¢â‚¬Å“NDHÃ¢â‚¬Â�ID [86]   = Ã¢â‚¬Å“NNNÃ¢â‚¬Â�ID [87]   = Ã¢â‚¬Å“NBÃ¢â‚¬Â�ID [88]   = Ã¢â‚¬Å“NSÃ¢â‚¬Â�ID [89]   = Ã¢â‚¬Å“NMÃ¢â‚¬Â�ID [90]   = Ã¢â‚¬Å“DBÃ¢â‚¬Â�ID [91]   = Ã¢â‚¬Å“QJÃ¢â‚¬Â�ID [92]   = Ã¢â‚¬Å“PTTÃ¢â‚¬Â�ID [93]   = Ã¢â‚¬Å“PLÃ¢â‚¬Â�ID [94]   = Ã¢â‚¬Å“DVÃ¢â‚¬Â�ID [95]   = Ã¢â‚¬Å“BLÃ¢â‚¬Â�ID [96]   = Ã¢â‚¬Å“BDÃ¢â‚¬Â�ID [97]   = Ã¢â‚¬Å“TBÃ¢â‚¬Â�ID [98]   = Ã¢â‚¬Å“MMÃ¢â‚¬Â�ID [99]   = Ã¢â‚¬Å“MVÃ¢â‚¬Â�ID [100] = Ã¢â‚¬Å“MPÃ¢â‚¬Â�ID [101] = Ã¢â‚¬Å“MNÃ¢â‚¬Â�ID [102] = Ã¢â‚¬Å“NTRÃ¢â‚¬Â�ID [103] = Ã¢â‚¬Å“MBÃ¢â‚¬Â�ID [104] = Ã¢â‚¬Å“LKÃ¢â‚¬Â�ID [105] = Ã¢â‚¬Å“MNDÃ¢â‚¬Â�ID [106] = Ã¢â‚¬Å“FKÃ¢â‚¬Â�ID [107] = Ã¢â‚¬Å“LDÃ¢â‚¬Â�ID [108] = Ã¢â‚¬Å“LLÃ¢â‚¬Â�ID [109] = Ã¢â‚¬Å“LPÃ¢â‚¬Â�ID [110] = Ã¢â‚¬Å“LTÃ¢â‚¬Â�ID [111] = Ã¢â‚¬Å“SNÃ¢â‚¬Â�ID [112] = Ã¢â‚¬Å“SCÃ¢â‚¬Â�ID [113] = Ã¢â‚¬Å“SMÃ¢â‚¬Â�ID [114] = Ã¢â‚¬Å“SBÃ¢â‚¬Â�ID [115] = Ã¢â‚¬Å“FNÃ¢â‚¬Â�ID [116] = Ã¢â‚¬Å“FTÃ¢â‚¬Â�ID [117] = Ã¢â‚¬Å“SKÃ¢â‚¬Â�ID [118] = Ã¢â‚¬Å“SSTHÃ¢â‚¬Â�ID [119] = Ã¢â‚¬Å“SSMÃ¢â‚¬Â�ID [120] = Ã¢â‚¬Å“SSNÃ¢â‚¬Â�ID [121] = Ã¢â‚¬Å“SSBÃ¢â‚¬Â�ID [122] = Ã¢â‚¬Å“STÃ¢â‚¬Â�ID [123] = Ã¢â‚¬Å“SPÃ¢â‚¬Â�ID [124] = Ã¢â‚¬Å“SPHÃ¢â‚¬Â�ID [125] = Ã¢â‚¬Å“STHÃ¢â‚¬Â�ID [126] = Ã¢â‚¬Å“SKHÃ¢â‚¬Â�ID [127] = Ã¢â‚¬Å“NGGÃ¢â‚¬Â�ID [128] = Ã¢â‚¬Å“NGCÃ¢â‚¬Â�ID [129] = Ã¢â‚¬Å“FPÃ¢â‚¬Â�ID [130] = Ã¢â‚¬Å“NGNÃ¢â‚¬Â�ID [131] = Ã¢â‚¬Å“XMÃ¢â‚¬Â�ID [132] = Ã¢â‚¬Å“NGJÃ¢â‚¬Â�ID [133] = Ã¢â‚¬Å“MNTHÃ¢â‚¬Â�ID [134] = Ã¢â‚¬Å“NGKÃ¢â‚¬Â�ID [135] = Ã¢â‚¬Å“KRÃ¢â‚¬Â�ID [136] = Ã¢â‚¬Å“TRUÃ¢â‚¬Â�ID [137] = Ã¢â‚¬Å“BHRÃ¢â‚¬Â�ID [138] = Ã¢â‚¬Å“THBÃ¢â‚¬Â�ID [139] = Ã¢â‚¬Å“DGÃ¢â‚¬Â�ID [140] = Ã¢â‚¬Å“DGHÃ¢â‚¬Â�ID [141] = Ã¢â‚¬Å“DDÃ¢â‚¬Â�ID [142] = Ã¢â‚¬Å“DDHÃ¢â‚¬Â�ID [143] = Ã¢â‚¬Å“HRÃ¢â‚¬Â�ID [144] = Ã¢â‚¬Å“GGUÃ¢â‚¬Â�ID [145] = Ã¢â‚¬Å“GGNÃ¢â‚¬Â�ID [146] = Ã¢â‚¬Å“NKHÃ¢â‚¬Â�ID [147] = Ã¢â‚¬Å“NGHÃ¢â‚¬Â�ID [148] = Ã¢â‚¬Å“NGKHÃ¢â‚¬Â�ID [149] = Ã¢â‚¬Å“TTHÃ¢â‚¬Â�ID [150] = Ã¢â‚¬Å“PNÃ¢â‚¬Â�ID [151] = Ã¢â‚¬Å“HNÃ¢â‚¬Â�ID [152] = Ã¢â‚¬Å“XNÃ¢â‚¬Â�ID [153] = Ã¢â‚¬Å“MFÃ¢â‚¬Â�ID [154] = Ã¢â‚¬Å“BBÃ¢â‚¬Â�ID [155] = Ã¢â‚¬Å“LBÃ¢â‚¬Â�ID [156] = Ã¢â‚¬Å“LMÃ¢â‚¬Â�ID [157] = Ã¢â‚¬Å“BHMÃ¢â‚¬Â�ID [158] = Ã¢â‚¬Å“MLÃ¢â‚¬Â�ID [159] = Ã¢â‚¬Å“SLÃ¢â‚¬Â�ID [160] = Ã¢â‚¬Å“PSÃ¢â‚¬Â�ID [161] = Ã¢â‚¬Å“KHRÃ¢â‚¬Â�ID [162] = Ã¢â‚¬Å“GRÃ¢â‚¬Â�ID [163] = Ã¢â‚¬Å“GHRÃ¢â‚¬Â�ID [164] = Ã¢â‚¬Å“JRÃ¢â‚¬Â�ID [165] = Ã¢â‚¬Å“TRRÃ¢â‚¬Â�ID [166] = Ã¢â‚¬Å“DRRÃ¢â‚¬Â�ID [167] = Ã¢â‚¬Å“DHRRÃ¢â‚¬Â�ID [168] = Ã¢â‚¬Å“PRRÃ¢â‚¬Â�ID [169] = Ã¢â‚¬Å“BRRÃ¢â‚¬Â�ID [170] = Ã¢â‚¬Å“MRRÃ¢â‚¬Â�ID [171] = Ã¢â‚¬Å“TSRÃ¢â‚¬Â�ID [172] = Ã¢â‚¬Å“DSRÃ¢â‚¬Â�ID [173] = Ã¢â‚¬Å“HRRÃ¢â‚¬Â�ID [174] = Ã¢â‚¬Å“SUNYAÃ¢â‚¬Â�ID [175] = Ã¢â‚¬Å“EKÃ¢â‚¬Â�ID [176] = Ã¢â‚¬Å“DUIÃ¢â‚¬Â�ID [177] = Ã¢â‚¬Å“TINIÃ¢â‚¬Â�ID [178] = Ã¢â‚¬Å“CARIÃ¢â‚¬Â�ID [179] = Ã¢â‚¬Å“PACÃ¢â‚¬Â�ID [180] = Ã¢â‚¬Å“CAYÃ¢â‚¬Â�ID [181] = Ã¢â‚¬Å“XATÃ¢â‚¬Â�ID [182] = Ã¢â‚¬Å“ATHÃ¢â‚¬Â�ID [183] = Ã¢â‚¬Å“NAAÃ¢â‚¬Â� 2.	The total number of strokes in the sample: The total number of strokes used to write a character is represented by the line Ã¢â‚¬Å“STROKE_COUNT: NumberÃ¢â‚¬Â�, where Ã¢â‚¬Å“NumberÃ¢â‚¬Â� is an integer value.3.	Sequence of Strokes: Each stroke begins with the Ã¢â‚¬Å“PEN_DOWNÃ¢â‚¬Â� information and there is a Ã¢â‚¬Å“PEN_UPÃ¢â‚¬Â� information followed by the Ã¢â‚¬Å“PEN_DOWNÃ¢â‚¬Â� information between two consecutive strokes. The end of a sample is represented by the Ã¢â‚¬Å“PEN_UPÃ¢â‚¬Â� information followed by the Ã¢â‚¬Å“END_CHARACTER: CharacterÃ¢â‚¬Â� information. Each stroke consists of a sequence of X and Y coordinates values which are given in the first and the second columns respectively. Corresponding to each pair of values of X and Y coordinates, there are Ã¢â‚¬Å“STYLUS_STATEÃ¢â‚¬Â� and Ã¢â‚¬Å“STROKEÃ¢â‚¬Â� information given in the third and the fourth columns respectively. Ã¢â‚¬Å“STYLUS_STATEÃ¢â‚¬Â� is either 1 or 0. Corresponding to each recorded (X, Y) point, Ã¢â‚¬Å“STYLUS_STATEÃ¢â‚¬Â� is 1 and corresponding to the Ã¢â‚¬Å“PEN_UPÃ¢â‚¬Â� information Ã¢â‚¬Å“STYLUS_STATEÃ¢â‚¬Â� is 0. Ã¢â‚¬Å“STYLUS_STATEÃ¢â‚¬Â� is kept blank corresponding to each Ã¢â‚¬Å“PEN_DOWNÃ¢â‚¬Â� information. The Ã¢â‚¬Å“STROKEÃ¢â‚¬Â� information represents the serial number of a constituent stroke of a sample. The value of X grows left-to-right and that of Y grows downwards. Coordinates are integer numbers ranging from 0 to 4392 for X and 0 to 4868 for Y respectively. "
OCT data &amp; Color Fundus Images of Left &amp; Right Eyes,OCT data &amp; Color Fundus Images of Left &amp; Right Eyes,This dataset contains OCT data (in mat format) and color fundus data (in jpg format) of left & right eyes of 50 healthy persons.,OCT+data+%26+Color+Fundus+Images+of+Left+%26+Right+Eyes,https://archive.ics.uci.edu/ml//machine-learning-databases/00430/,https://archive.ics.uci.edu/ml/datasets/OCT+data+%26+Color+Fundus+Images+of+Left+%26+Right+Eyes,OCT data & Color Fundus Images of Left & Right Eyes : This dataset contains OCT data (in mat format) and color fundus data (in jpg format) of left & right eyes of 50 healthy persons. Each volunteer's folder includes color fundus images (.jpg) and OCT data (.mat) of the right and left eyes.,Computer,OCT data & Color Fundus Images of Left & Right Eyes : This dataset contains OCT data (in mat format) and color fundus data (in jpg format) of left & right eyes of 50 healthy persons. Each volunteer's folder includes color fundus images (.jpg) and OCT data (.mat) of the right and left eyes.,This dataset contains OCT data (in mat format) and color fundus data (in jpg format) of left & right eyes of 50 healthy persons.OCT data & Color Fundus Images of Left & Right Eyes : This dataset contains OCT data (in mat format) and color fundus data (in jpg format) of left & right eyes of 50 healthy persons. Each volunteer's folder includes color fundus images (.jpg) and OCT data (.mat) of the right and left eyes.OCT data & Color Fundus Images of Left & Right Eyes : This dataset contains OCT data (in mat format) and color fundus data (in jpg format) of left & right eyes of 50 healthy persons. Each volunteer's folder includes color fundus images (.jpg) and OCT data (.mat) of the right and left eyes.
Occupancy Detection ,Occupancy Detection ,"Experimental data used for binary classification (room occupancy) from Temperature,Humidity,Light and CO2. Ground-truth occupancy was obtained from time stamped pictures that were taken every minute.",Occupancy+Detection+,https://archive.ics.uci.edu/ml//machine-learning-databases/00357/,https://archive.ics.uci.edu/ml/datasets/Occupancy+Detection+,"Three data sets are submitted, for training and testing. Ground-truth occupancy was obtained from time stamped pictures that were taken every minute.For the journal publication, the processing R scripts can be found in:[Web Link]",Computer,"date time year-month-day hour:minute:secondTemperature, in CelsiusRelative Humidity, %Light, in Lux CO2, in ppmHumidity Ratio, Derived quantity from temperature and relative humidity, in kgwater-vapor/kg-airOccupancy, 0 or 1, 0 for not occupied, 1 for occupied status","Experimental data used for binary classification (room occupancy) from Temperature,Humidity,Light and CO2. Ground-truth occupancy was obtained from time stamped pictures that were taken every minute.Three data sets are submitted, for training and testing. Ground-truth occupancy was obtained from time stamped pictures that were taken every minute.For the journal publication, the processing R scripts can be found in:[Web Link]date time year-month-day hour:minute:secondTemperature, in CelsiusRelative Humidity, %Light, in Lux CO2, in ppmHumidity Ratio, Derived quantity from temperature and relative humidity, in kgwater-vapor/kg-airOccupancy, 0 or 1, 0 for not occupied, 1 for occupied status"
Northix,Northix,Northix is designed to be a schema matching benchmark problem for data integration of two entity relationship databases. ,Northix,https://archive.ics.uci.edu/ml//machine-learning-databases/00237/,https://archive.ics.uci.edu/ml/datasets/Northix,"Northix is designed to be a schema matching benchmark problem for data integration of two entity relationship databases. Northix is the resulting schema matching of two demonstration databases namely Northwind and Sakila. Some unnecessary database entities (columns) such as multimedia were deleted. It was desired to have at least around 200 tuples per database entity; therefore, tuples were randomly injected, respecting the existing pattern, if the number of tuples was low. The schema matching was done manually. The ideal entities matching are grouped into classes. In total, there are 115 input database entities stored respectively as '.dat' from the first database and as '.txt' if from the second database. The file naming pattern is attributeName@ColumnName@Database. After schema matching, the files are grouped into 34 classes (folders). 33 classes are ideal matchings whereas the class 'UNCLASSED' groups all the attributes that are unique and donÃ¢â‚¬â„¢t have another similar attribute. The attributes are of different data types such as texts, integers, real numbers, dates, and alphanumeric data types. In total, there are 21805 tokens. A token is separated by spaces and other non alphanumeric characters such as Ã¢â‚¬Å“/-,Ã¢â‚¬Â�.[1]	Microsoft. Northwind. [Online] 2005. [Cited: 06 28, 2009.] [Web Link].[2]	MySQL. Sakila. [Online] 2005. [Cited: 06 28, 2009.] [Web Link].",Computer,"In total, there are 115 input database entities stored respectively as '.dat' from the first database and as '.txt' if from the second database. The file naming pattern is attributeName@ColumnName@Database. After schema matching, the files are grouped into 34 classes (folders). 33 classes are ideal matchings whereas the class 'UNCLASSED' groups all the attributes that are unique and donÃ¢â‚¬â„¢t have another similar attribute.","Northix is designed to be a schema matching benchmark problem for data integration of two entity relationship databases. Northix is designed to be a schema matching benchmark problem for data integration of two entity relationship databases. Northix is the resulting schema matching of two demonstration databases namely Northwind and Sakila. Some unnecessary database entities (columns) such as multimedia were deleted. It was desired to have at least around 200 tuples per database entity; therefore, tuples were randomly injected, respecting the existing pattern, if the number of tuples was low. The schema matching was done manually. The ideal entities matching are grouped into classes. In total, there are 115 input database entities stored respectively as '.dat' from the first database and as '.txt' if from the second database. The file naming pattern is attributeName@ColumnName@Database. After schema matching, the files are grouped into 34 classes (folders). 33 classes are ideal matchings whereas the class 'UNCLASSED' groups all the attributes that are unique and donÃ¢â‚¬â„¢t have another similar attribute. The attributes are of different data types such as texts, integers, real numbers, dates, and alphanumeric data types. In total, there are 21805 tokens. A token is separated by spaces and other non alphanumeric characters such as Ã¢â‚¬Å“/-,Ã¢â‚¬Â�.[1]	Microsoft. Northwind. [Online] 2005. [Cited: 06 28, 2009.] [Web Link].[2]	MySQL. Sakila. [Online] 2005. [Cited: 06 28, 2009.] [Web Link].In total, there are 115 input database entities stored respectively as '.dat' from the first database and as '.txt' if from the second database. The file naming pattern is attributeName@ColumnName@Database. After schema matching, the files are grouped into 34 classes (folders). 33 classes are ideal matchings whereas the class 'UNCLASSED' groups all the attributes that are unique and donÃ¢â‚¬â„¢t have another similar attribute."
Wave Energy Converters,Wave Energy Converters,This data set consists of positions and absorbed power outputs of wave energy converters (WECs) in four real wave scenarios from the southern coast of Australia.,Wave+Energy+Converters,https://archive.ics.uci.edu/ml//machine-learning-databases/00494/,https://archive.ics.uci.edu/ml/datasets/Wave+Energy+Converters,"This data set consists of positions and absorbed power outputs of wave energy converters (WECs) in four real wave scenarios from the southern coast of Australia (Sydney, Adelaide, Perth and Tasmania). The applied converter model is a fully submerged three-tether converter called CETO [1]. 16 WECs locations are placed and optimized in a size-constrained environment. In terms of optimization, the problem is categorised as an expensive optimization problem that each farm evaluation takes several minutes. The results are derived from several popular and successful Evolutionary optimization methods that are published in [2,3].  The source code of the applied hydrodynamic simulator [4] is available by the below link: [Web Link]This work was supported with supercomputing resources provided by the Phoenix HPC service at the University of Adelaide.",Computer,"Attribute: Attribute Range 1. WECs position {X1, X2, Ã¢â‚¬Â¦, X16; Y1, Y2,Ã¢â‚¬Â¦, Y16} continuous from 0 to 566 (m). 2. WECs absorbed power: {P1, P2, Ã¢â‚¬Â¦, P16} 3. Total power output of the farm: Powerall","This data set consists of positions and absorbed power outputs of wave energy converters (WECs) in four real wave scenarios from the southern coast of Australia.This data set consists of positions and absorbed power outputs of wave energy converters (WECs) in four real wave scenarios from the southern coast of Australia (Sydney, Adelaide, Perth and Tasmania). The applied converter model is a fully submerged three-tether converter called CETO [1]. 16 WECs locations are placed and optimized in a size-constrained environment. In terms of optimization, the problem is categorised as an expensive optimization problem that each farm evaluation takes several minutes. The results are derived from several popular and successful Evolutionary optimization methods that are published in [2,3].  The source code of the applied hydrodynamic simulator [4] is available by the below link: [Web Link]This work was supported with supercomputing resources provided by the Phoenix HPC service at the University of Adelaide.Attribute: Attribute Range 1. WECs position {X1, X2, Ã¢â‚¬Â¦, X16; Y1, Y2,Ã¢â‚¬Â¦, Y16} continuous from 0 to 566 (m). 2. WECs absorbed power: {P1, P2, Ã¢â‚¬Â¦, P16} 3. Total power output of the farm: Powerall"
Nomao,Nomao,"Nomao collects data about places (name, phone, localization...) from many sources.
Deduplication consists in detecting what data refer to the same place.
Instances in the dataset compare 2 spots.",Nomao,https://archive.ics.uci.edu/ml//machine-learning-databases/00227/,https://archive.ics.uci.edu/ml/datasets/Nomao,The dataset has been enriched during the Nomao Challenge:[Web Link]organized along with the ALRA workshop (Active Learning in Real-world Applications):[Web Link]held at the ECML-PKDD 2012 conference.,Computer,"120 attributes: 89 continuous, 31 nominal (including the attributes 'label' and 'id').","Nomao collects data about places (name, phone, localization...) from many sources.
Deduplication consists in detecting what data refer to the same place.
Instances in the dataset compare 2 spots.The dataset has been enriched during the Nomao Challenge:[Web Link]organized along with the ALRA workshop (Active Learning in Real-world Applications):[Web Link]held at the ECML-PKDD 2012 conference.120 attributes: 89 continuous, 31 nominal (including the attributes 'label' and 'id')."
Kitsune Network Attack Dataset,Kitsune Network Attack Dataset,"A cybersecurity dataset containing nine different network attacks on a commercial IP-based surveillance system and an IoT network. The dataset includes reconnaissance, MitM, DoS, and botnet attacks.",Kitsune+Network+Attack+Dataset,https://archive.ics.uci.edu/ml//machine-learning-databases/00516/,https://archive.ics.uci.edu/ml/datasets/Kitsune+Network+Attack+Dataset,"==== Overview ====The are 9 network capture datasets in total, listed below. Viol. is the security violation (Confidentiality, Integrity, and Authenticity). Attack Type	Attack Name	Tool		Viol.	Description: The attackerRecon.		   -1		OS Scan		Nmap		C	scans the network for hosts, and their operating systems, to reveal possible vulnerabilities.   -2		Fuzzing		SFuzz		C	searches for vulnerabilities in the camera's web servers by sending random commands to their cgis.Man in the Middle	   -3		Video Injection	Video Jack	C,I	injects a recorded video clip into a live video stream.   -4		ARP MitM	Ettercap	C	intercepts all LAN traffic via an ARP poisoning attack.   -5		Active Wiretap	R.PI 3B		C	intercepts all LAN traffic via active wiretap (network bridge) covertly installed on an exposed cable.Denial of Service	   -6		SSDP Flood	Saddam		A	overloads the DVR by causing cameras to spam the server with UPnP advertisements.   -7		SYN DoS		Hping3		A	disables a camera's video stream by overloading its web server.   -8		SSL Reneg.	THC		A	disables a camera's video stream by sending many SSL renegotiation packets to the camera.Botnet Malware	   -9		Mirai		Telnet		C,I	infects IoT with the Mirai malware by exploiting default credentials, and then scans for new vulnerable victims network.-For more details on the attacks themselves, please refer to our paper. ==== Data Organization ====For each attack (network capture) above we provide (1) a csv of the features used in our paper where each row is a network packet, (2) the corresponding labels [benign, malicious], and (3) the original network capture in truncated pcap format.-Each attack dataset is located in a separate directory-Each directory contains three files:	_pcap.pcapng	:	A raw pcap capture of the original N packets. The packets have been truncated to 200 bytes for privacy reasons.	_dataset.csv	:	An N-by-M matrix of M-sized feature vectors, each describing the packet and the context of that packet's channel (see our paper for details).	_labels.csv	:	An N-by-1 vector of 0-1 values which indicate whether each packet in _pcap.pcapng (and _dataset.csv) is malicious ('1') or not ('0'). For the Man-in-middle-Attacks, all packets which have passed through the MitM are marked as '1'.-Every attack dataset begins with benign traffic, and then at some point (1) the attacker connects to the network and (2) initiates the given attack.",Computer,"=== The features in the csv files ===Each row in the csv is a packet captured (chronologically). More a deep explanation, please see our paper. In general, each row (feature vector) are recent (temporal) statistics which describes the context of the packet's channel and its communicating parties:Whenever a packet arrives, we extract a behavioral snapshot of the hosts and protocols which communicated the given packet. The snapshot consists of 115 traffic statistics capturing a small temporal window into: (1) the packet's sender in general, and (2) the traffic between the packet's sender and receiver.Specifically, the statistics summarize all of the traffic...	 ...originating from this packet's source MAC and IP address (denoted SrcMAC-IP).	 ...originating from this packet's source IP (denoted SrcIP).	 ...sent between this packet's source and destination IPs (denoted Channel). 		 ...sent between this packet's source and destination TCP/UDP Socket (denoted Socket).A total of 23 features (capturing the above) can be extracted from a single time window ÃŽÂ» (see Table II). The FE extracts the same set of features from a total of five time damped windows of approximately: 100ms, 500ms, 1.5sec, 10sec, and 1min into the past (ÃŽÂ» = 5, 3, 1, 0.1, 0.01), thus totaling 115 features.We note that not every packet applies to every channel type (e.g., there is no socket if the packet does not contain a TCP or UDP datagram). In these cases, these features are zeroed. Thus, the final feature vector ~x, which the FE passes to theFM, is always a member of R^n, where n = 115.The feature extraction code (pcap to csv) is available at: [Web Link] ","A cybersecurity dataset containing nine different network attacks on a commercial IP-based surveillance system and an IoT network. The dataset includes reconnaissance, MitM, DoS, and botnet attacks.==== Overview ====The are 9 network capture datasets in total, listed below. Viol. is the security violation (Confidentiality, Integrity, and Authenticity). Attack Type	Attack Name	Tool		Viol.	Description: The attackerRecon.		   -1		OS Scan		Nmap		C	scans the network for hosts, and their operating systems, to reveal possible vulnerabilities.   -2		Fuzzing		SFuzz		C	searches for vulnerabilities in the camera's web servers by sending random commands to their cgis.Man in the Middle	   -3		Video Injection	Video Jack	C,I	injects a recorded video clip into a live video stream.   -4		ARP MitM	Ettercap	C	intercepts all LAN traffic via an ARP poisoning attack.   -5		Active Wiretap	R.PI 3B		C	intercepts all LAN traffic via active wiretap (network bridge) covertly installed on an exposed cable.Denial of Service	   -6		SSDP Flood	Saddam		A	overloads the DVR by causing cameras to spam the server with UPnP advertisements.   -7		SYN DoS		Hping3		A	disables a camera's video stream by overloading its web server.   -8		SSL Reneg.	THC		A	disables a camera's video stream by sending many SSL renegotiation packets to the camera.Botnet Malware	   -9		Mirai		Telnet		C,I	infects IoT with the Mirai malware by exploiting default credentials, and then scans for new vulnerable victims network.-For more details on the attacks themselves, please refer to our paper. ==== Data Organization ====For each attack (network capture) above we provide (1) a csv of the features used in our paper where each row is a network packet, (2) the corresponding labels [benign, malicious], and (3) the original network capture in truncated pcap format.-Each attack dataset is located in a separate directory-Each directory contains three files:	_pcap.pcapng	:	A raw pcap capture of the original N packets. The packets have been truncated to 200 bytes for privacy reasons.	_dataset.csv	:	An N-by-M matrix of M-sized feature vectors, each describing the packet and the context of that packet's channel (see our paper for details).	_labels.csv	:	An N-by-1 vector of 0-1 values which indicate whether each packet in _pcap.pcapng (and _dataset.csv) is malicious ('1') or not ('0'). For the Man-in-middle-Attacks, all packets which have passed through the MitM are marked as '1'.-Every attack dataset begins with benign traffic, and then at some point (1) the attacker connects to the network and (2) initiates the given attack.=== The features in the csv files ===Each row in the csv is a packet captured (chronologically). More a deep explanation, please see our paper. In general, each row (feature vector) are recent (temporal) statistics which describes the context of the packet's channel and its communicating parties:Whenever a packet arrives, we extract a behavioral snapshot of the hosts and protocols which communicated the given packet. The snapshot consists of 115 traffic statistics capturing a small temporal window into: (1) the packet's sender in general, and (2) the traffic between the packet's sender and receiver.Specifically, the statistics summarize all of the traffic...	 ...originating from this packet's source MAC and IP address (denoted SrcMAC-IP).	 ...originating from this packet's source IP (denoted SrcIP).	 ...sent between this packet's source and destination IPs (denoted Channel). 		 ...sent between this packet's source and destination TCP/UDP Socket (denoted Socket).A total of 23 features (capturing the above) can be extracted from a single time window ÃŽÂ» (see Table II). The FE extracts the same set of features from a total of five time damped windows of approximately: 100ms, 500ms, 1.5sec, 10sec, and 1min into the past (ÃŽÂ» = 5, 3, 1, 0.1, 0.01), thus totaling 115 features.We note that not every packet applies to every channel type (e.g., there is no socket if the packet does not contain a TCP or UDP datagram). In these cases, these features are zeroed. Thus, the final feature vector ~x, which the FE passes to theFM, is always a member of R^n, where n = 115.The feature extraction code (pcap to csv) is available at: [Web Link] "
NoisyOffice,NoisyOffice,Corpus intended to do cleaning (or binarization) and enhancement of noisy grayscale printed text images using supervised learning methods. Noisy images and their corresponding ground truth provided.,NoisyOffice,https://archive.ics.uci.edu/ml//machine-learning-databases/00318/,https://archive.ics.uci.edu/ml/datasets/NoisyOffice,"AIMS AND PURPOSESThis corpus is intended to do cleaning (or binarization) and enhancement of noisy grayscale printed text images using supervised learning methods. To this end, noisy images and their corresponding cleaned or binarized ground truth are provided. Double resolution ground truth images are also provided in order to test superresolution methods.CORPUS DIRECTORIES STRUCTURESimulatedNoisyOffice folder has been prepared for training, validation and test of supervised methods. RealNoisyOffice folder is provided for subjective evaluation..|-- RealNoisyOffice|   |-- real_noisy_images_grayscale|   `-- real_noisy_images_grayscale_doubleresolution`-- SimulatedNoisyOffice    |-- clean_images_binaryscale    |-- clean_images_grayscale    |-- clean_images_grayscale_doubleresolution    `-- simulated_noisy_images_grayscaleRealNoisyOffice- real_noisy_images_grayscale: 72 grayscale images of scanned 'noisy' images.- real_noisy_images_grayscale_doubleresolution: idem, double resolution.SimulatedNoisyOffice- simulated_noisy_images_grayscale: 72 grayscale images of scanned 'simulated noisy' images for training, validation and test.- clean_images_grayscale_doubleresolution: Grayscale ground truth of the images with double resolution.- clean_images_grayscale: Grayscale ground truth of the images with smoothing on the borders (normal resolution).- clean_images_binary: Binary ground truth of the images (normal resolution).DESCRIPTIONEvery file is a printed text image following the pattern FontABC_NoiseD_EE.png:A) Size of the font: footnote size (f), normal size (n) o large size (L).B) Font type: typewriter (t), sans serif (s) or roman (r). C) Yes/no emphasized font (e/m).D) Type of noise: folded sheets (Noise f), wrinkled sheets (Noise w), coffee stains (Noise c), and footprints (Noise p).E) Data set partition: training (TR), validation (VA), test (TE), real (RE).For each type of font, one type of Noise: 17 files * 4 types of noise = 72 images.OTHER INFORMATION200 ppi => normal resolution400 ppi => double resolution",Computer,"The format of each file is the following: Grayscale PNG files ([Web Link]). The ground truth is also provided as grayscale PNG files, and for the binary version the values are saturated to 0 and 255.","Corpus intended to do cleaning (or binarization) and enhancement of noisy grayscale printed text images using supervised learning methods. Noisy images and their corresponding ground truth provided.AIMS AND PURPOSESThis corpus is intended to do cleaning (or binarization) and enhancement of noisy grayscale printed text images using supervised learning methods. To this end, noisy images and their corresponding cleaned or binarized ground truth are provided. Double resolution ground truth images are also provided in order to test superresolution methods.CORPUS DIRECTORIES STRUCTURESimulatedNoisyOffice folder has been prepared for training, validation and test of supervised methods. RealNoisyOffice folder is provided for subjective evaluation..|-- RealNoisyOffice|   |-- real_noisy_images_grayscale|   `-- real_noisy_images_grayscale_doubleresolution`-- SimulatedNoisyOffice    |-- clean_images_binaryscale    |-- clean_images_grayscale    |-- clean_images_grayscale_doubleresolution    `-- simulated_noisy_images_grayscaleRealNoisyOffice- real_noisy_images_grayscale: 72 grayscale images of scanned 'noisy' images.- real_noisy_images_grayscale_doubleresolution: idem, double resolution.SimulatedNoisyOffice- simulated_noisy_images_grayscale: 72 grayscale images of scanned 'simulated noisy' images for training, validation and test.- clean_images_grayscale_doubleresolution: Grayscale ground truth of the images with double resolution.- clean_images_grayscale: Grayscale ground truth of the images with smoothing on the borders (normal resolution).- clean_images_binary: Binary ground truth of the images (normal resolution).DESCRIPTIONEvery file is a printed text image following the pattern FontABC_NoiseD_EE.png:A) Size of the font: footnote size (f), normal size (n) o large size (L).B) Font type: typewriter (t), sans serif (s) or roman (r). C) Yes/no emphasized font (e/m).D) Type of noise: folded sheets (Noise f), wrinkled sheets (Noise w), coffee stains (Noise c), and footprints (Noise p).E) Data set partition: training (TR), validation (VA), test (TE), real (RE).For each type of font, one type of Noise: 17 files * 4 types of noise = 72 images.OTHER INFORMATION200 ppi => normal resolution400 ppi => double resolutionThe format of each file is the following: Grayscale PNG files ([Web Link]). The ground truth is also provided as grayscale PNG files, and for the binary version the values are saturated to 0 and 255."
NIPS Conference Papers 1987-2015,NIPS Conference Papers 1987-2015,This data set contains the distribution of words in the full text of the NIPS conference papers published from 1987 to 2015.,NIPS+Conference+Papers+1987-2015,https://archive.ics.uci.edu/ml//machine-learning-databases/00371/,https://archive.ics.uci.edu/ml/datasets/NIPS+Conference+Papers+1987-2015,"The dataset is in the form of a 11463 x 5812 matrix of word counts, containing 11463 words and 5811 NIPS conference papers (the first column contains the list of words). Each column contains the number of times each word appears in the corresponding document. The names of the columns give information about each document and its timestamp in the following format: Xyear_paperID. The matrix of word counts was obtained using the R package 'tmÃ¢â‚¬Â� to process the raw .txt files of the full text of the NIPS conference papers published between 1987 and 2015. The document-term matrix was constructed after tokenization, removal of stopwords and truncation of the vocabulary by only keeping words occurring more than 50 times.",Computer,Column 1: 'X' (list of words)Columns 2-5812: 'Xyear_ID' (timestamp and paper ID),"This data set contains the distribution of words in the full text of the NIPS conference papers published from 1987 to 2015.The dataset is in the form of a 11463 x 5812 matrix of word counts, containing 11463 words and 5811 NIPS conference papers (the first column contains the list of words). Each column contains the number of times each word appears in the corresponding document. The names of the columns give information about each document and its timestamp in the following format: Xyear_paperID. The matrix of word counts was obtained using the R package 'tmÃ¢â‚¬Â� to process the raw .txt files of the full text of the NIPS conference papers published between 1987 and 2015. The document-term matrix was constructed after tokenization, removal of stopwords and truncation of the vocabulary by only keeping words occurring more than 50 times.Column 1: 'X' (list of words)Columns 2-5812: 'Xyear_ID' (timestamp and paper ID)"
Newspaper and magazine images segmentation dataset,Newspaper and magazine images segmentation dataset,Dataset is well suited for segmentation tasks. It contains 101 scanned pages from different newspapers and magazines in Russian with ground truth pixel-based masks.,Newspaper+and+magazine+images+segmentation+dataset,https://archive.ics.uci.edu/ml//machine-learning-databases/00306/,https://archive.ics.uci.edu/ml/datasets/Newspaper+and+magazine+images+segmentation+dataset,"This dataset was collected for training and validation of machine learning algorithm for classification regions of documents on text, picture and background areas. It contains 101 scanned images of various newspapers and magazines in Russian. Most of the images have resolution 300 dpi and size A4, about 2400x3500 pixels. For all images ground truth pixel-based masks were manually created. The ground truth masks named like original images with postfix _mÂ�. There are three classes: text area, picture area, background. Pixels on the mask with color 255, 0, 0 (rgb, red color) correspond to picture area, pixels with color 0, 0, 255 (rgb, blue color) correspond to text area, all other pixels correspond to background. Images with background of different colors are in the dataset. ",Computer," There are three classes: text area, picture area, background. Pixels on the mask with color 255, 0, 0 (rgb, red color) correspond to picture area, pixels with color 0, 0, 255 (rgb, blue color) correspond to text area, all other pixels correspond to background.","Dataset is well suited for segmentation tasks. It contains 101 scanned pages from different newspapers and magazines in Russian with ground truth pixel-based masks.This dataset was collected for training and validation of machine learning algorithm for classification regions of documents on text, picture and background areas. It contains 101 scanned images of various newspapers and magazines in Russian. Most of the images have resolution 300 dpi and size A4, about 2400x3500 pixels. For all images ground truth pixel-based masks were manually created. The ground truth masks named like original images with postfix _mÂ�. There are three classes: text area, picture area, background. Pixels on the mask with color 255, 0, 0 (rgb, red color) correspond to picture area, pixels with color 0, 0, 255 (rgb, blue color) correspond to text area, all other pixels correspond to background. Images with background of different colors are in the dataset.  There are three classes: text area, picture area, background. Pixels on the mask with color 255, 0, 0 (rgb, red color) correspond to picture area, pixels with color 0, 0, 255 (rgb, blue color) correspond to text area, all other pixels correspond to background."
News Popularity in Multiple Social Media Platforms,News Popularity in Multiple Social Media Platforms,"Large data set of news items and their respective social feedback on multiple platforms: Facebook, Google+ and LinkedIn.",News+Popularity+in+Multiple+Social+Media+Platforms,https://archive.ics.uci.edu/ml//machine-learning-databases/00432/,https://archive.ics.uci.edu/ml/datasets/News+Popularity+in+Multiple+Social+Media+Platforms,"This is a large data set of news items and their respective social feedback on multiple platforms: Facebook, Google+ and LinkedIn. The collected data relates to a period of 8 months, between November 2015 and July 2016, accounting for about 100,000 news items on four different topics: economy, microsoft, obama and palestine. This data set is tailored for evaluative comparisons in predictive analytics tasks, although allowing for tasks in other research areas such as topic detection and tracking, sentiment analysis in short text, first story detection or news recommendation.Further details on the process of building the data set are provided in the article mentioned in the 'Relevant Papers' section.An .R file is provided to provide a simple introduction to handling the data set.",Computer,######################## VARIABLES OF NEWS DATA ########################IDLink (numeric): Unique identifier of news itemsTitle (string): Title of the news item according to the official media sourcesHeadline (string): Headline of the news item according to the official media sourcesSource (string): Original news outlet that published the news itemTopic (string): Query topic used to obtain the items in the official media sourcesPublishDate (timestamp): Date and time of the news items' publicationSentimentTitle (numeric): Sentiment score of the text in the news items' titleSentimentHeadline (numeric): Sentiment score of the text in the news items' headlineFacebook (numeric): Final value of the news items' popularity according to the social media source FacebookGooglePlus (numeric): Final value of the news items' popularity according to the social media source Google+LinkedIn (numeric): Final value of the news items' popularity according to the social media source LinkedIn################################## VARIABLES OF SOCIAL FEEDBACK DATA ##################################IDLink (numeric): Unique identifier of news itemsTS1 (numeric): Level of popularity in time slice 1 (0-20 minutes upon publication)TS2 (numeric): Level of popularity in time slice 2 (20-40 minutes upon publication)TS... (numeric): Level of popularity in time slice ...TS144 (numeric): Final level of popularity after 2 days upon publication,"Large data set of news items and their respective social feedback on multiple platforms: Facebook, Google+ and LinkedIn.This is a large data set of news items and their respective social feedback on multiple platforms: Facebook, Google+ and LinkedIn. The collected data relates to a period of 8 months, between November 2015 and July 2016, accounting for about 100,000 news items on four different topics: economy, microsoft, obama and palestine. This data set is tailored for evaluative comparisons in predictive analytics tasks, although allowing for tasks in other research areas such as topic detection and tracking, sentiment analysis in short text, first story detection or news recommendation.Further details on the process of building the data set are provided in the article mentioned in the 'Relevant Papers' section.An .R file is provided to provide a simple introduction to handling the data set.######################## VARIABLES OF NEWS DATA ########################IDLink (numeric): Unique identifier of news itemsTitle (string): Title of the news item according to the official media sourcesHeadline (string): Headline of the news item according to the official media sourcesSource (string): Original news outlet that published the news itemTopic (string): Query topic used to obtain the items in the official media sourcesPublishDate (timestamp): Date and time of the news items' publicationSentimentTitle (numeric): Sentiment score of the text in the news items' titleSentimentHeadline (numeric): Sentiment score of the text in the news items' headlineFacebook (numeric): Final value of the news items' popularity according to the social media source FacebookGooglePlus (numeric): Final value of the news items' popularity according to the social media source Google+LinkedIn (numeric): Final value of the news items' popularity according to the social media source LinkedIn################################## VARIABLES OF SOCIAL FEEDBACK DATA ##################################IDLink (numeric): Unique identifier of news itemsTS1 (numeric): Level of popularity in time slice 1 (0-20 minutes upon publication)TS2 (numeric): Level of popularity in time slice 2 (20-40 minutes upon publication)TS... (numeric): Level of popularity in time slice ...TS144 (numeric): Final level of popularity after 2 days upon publication"
Multiple Features,Multiple Features,This dataset consists of features of handwritten numerals (`0'--`9') extracted from a collection of Dutch utility maps,Multiple+Features,https://archive.ics.uci.edu/ml//machine-learning-databases/mfeat/,https://archive.ics.uci.edu/ml/datasets/Multiple+Features,"This dataset consists of features of handwritten numerals (`0'--`9') extracted from a collection of Dutch utility maps. 200 patterns per class (for a total of 2,000 patterns) have been digitized in  binary images. These digits are represented in terms of the following six feature sets (files): 1. mfeat-fou: 76 Fourier coefficients of the character shapes; 2. mfeat-fac: 216 profile correlations; 3. mfeat-kar: 64 Karhunen-Love coefficients; 4. mfeat-pix: 240 pixel averages in 2 x 3 windows; 5. mfeat-zer: 47 Zernike moments; 6. mfeat-mor: 6 morphological features. In each file the 2000 patterns are stored in ASCI on 2000 lines. The first 200 patterns are of class `0', followed by sets of 200 patterns for each of the classes `1' - `9'. Corresponding patterns in different feature sets (files) correspond to the same original character.The source image dataset is lost. Using the pixel-dataset (mfeat-pix) sampled versions of the original images may be obtained (15 x 16 pixels).",Computer,6 Files:1. mfeat-fou: 76 Fourier coefficients of the character shapes; 2. mfeat-fac: 216 profile correlations; 3. mfeat-kar: 64 Karhunen-Love coefficients; 4. mfeat-pix: 240 pixel averages in 2 x 3 windows; 5. mfeat-zer: 47 Zernike moments; 6. mfeat-mor: 6 morphological features. ,"This dataset consists of features of handwritten numerals (`0'--`9') extracted from a collection of Dutch utility mapsThis dataset consists of features of handwritten numerals (`0'--`9') extracted from a collection of Dutch utility maps. 200 patterns per class (for a total of 2,000 patterns) have been digitized in  binary images. These digits are represented in terms of the following six feature sets (files): 1. mfeat-fou: 76 Fourier coefficients of the character shapes; 2. mfeat-fac: 216 profile correlations; 3. mfeat-kar: 64 Karhunen-Love coefficients; 4. mfeat-pix: 240 pixel averages in 2 x 3 windows; 5. mfeat-zer: 47 Zernike moments; 6. mfeat-mor: 6 morphological features. In each file the 2000 patterns are stored in ASCI on 2000 lines. The first 200 patterns are of class `0', followed by sets of 200 patterns for each of the classes `1' - `9'. Corresponding patterns in different feature sets (files) correspond to the same original character.The source image dataset is lost. Using the pixel-dataset (mfeat-pix) sampled versions of the original images may be obtained (15 x 16 pixels).6 Files:1. mfeat-fou: 76 Fourier coefficients of the character shapes; 2. mfeat-fac: 216 profile correlations; 3. mfeat-kar: 64 Karhunen-Love coefficients; 4. mfeat-pix: 240 pixel averages in 2 x 3 windows; 5. mfeat-zer: 47 Zernike moments; 6. mfeat-mor: 6 morphological features. "
Mturk User-Perceived Clusters over Images,Mturk User-Perceived Clusters over Images,"This dataset was collected by Shan-Hung Wu and DataLab members at NTHU, Taiwan. There're 325 user-perceived clusters from 100 users and their corresponding descriptions.",Mturk+User-Perceived+Clusters+over+Images,https://archive.ics.uci.edu/ml//machine-learning-databases/00416/,https://archive.ics.uci.edu/ml/datasets/Mturk+User-Perceived+Clusters+over+Images,"This dataset was collected by Shan-Hung Wu and DataLab members at National Tsing Hua University, Taiwan. It random sampled 180 images from the NUS-WIDE image database.  Each image has 500 features consisting of the bag of words based on SIFT descriptions. With a series of experiments on the Amazon Mechanical Turk platform, there are 325 user-perceived clusters from 100 users and their corresponding descriptions.Dataset spec 1:- #Image: 180 - #Cluster: 325 (may be created by different users)- #User: 100 - |Vocabulary of supervision|: 108- cluster_data.csv : 325 clusters x 180 images	- 'cluster_data.csv' is an indicator matrix. M_(i,j) = 1 if image_j belongs to cluster_i. Note: Clusters may be created by different users.		- cluster_userIndex.csv : 325 clusters x 1 userIndex(0-99)	- 'cluster_userIndex.csv' is an vector where V_i = k if cluster_i is grouped by user_k.	- data_feature.csv : 180 images x 500 features	- Each row is 500 features vector consisting of the bag of words based on SIFT descriptions. All 180 images are sampled from NUS-WIDE dataset.	- Reference: [Web Link]	- supervision_cluster_matrix.csv : 108 bag of words x 183 clusters	- We parse the raw supervisions and merge similar words into 108 dimensions. Each row is a description of corresponding cluster.	- perception_words.csv : 108 perception words	- Vocabulary of perception words .		Dataset spec 2(Raw data):- cluster_list.csv:	-FileName: ['UserId'], ['ImageId Cluster'], ['Description']	-['UserId']: Specify the user who created the cluster.	-['ImageId Cluster']: Image ids in the cluster which are separated by ';'.	-['Description']: A sentence or some keywords describe the images in the cluster by user.	- 325 records(clusters) in total.		",Computer,As the above.,"This dataset was collected by Shan-Hung Wu and DataLab members at NTHU, Taiwan. There're 325 user-perceived clusters from 100 users and their corresponding descriptions.This dataset was collected by Shan-Hung Wu and DataLab members at National Tsing Hua University, Taiwan. It random sampled 180 images from the NUS-WIDE image database.  Each image has 500 features consisting of the bag of words based on SIFT descriptions. With a series of experiments on the Amazon Mechanical Turk platform, there are 325 user-perceived clusters from 100 users and their corresponding descriptions.Dataset spec 1:- #Image: 180 - #Cluster: 325 (may be created by different users)- #User: 100 - |Vocabulary of supervision|: 108- cluster_data.csv : 325 clusters x 180 images	- 'cluster_data.csv' is an indicator matrix. M_(i,j) = 1 if image_j belongs to cluster_i. Note: Clusters may be created by different users.		- cluster_userIndex.csv : 325 clusters x 1 userIndex(0-99)	- 'cluster_userIndex.csv' is an vector where V_i = k if cluster_i is grouped by user_k.	- data_feature.csv : 180 images x 500 features	- Each row is 500 features vector consisting of the bag of words based on SIFT descriptions. All 180 images are sampled from NUS-WIDE dataset.	- Reference: [Web Link]	- supervision_cluster_matrix.csv : 108 bag of words x 183 clusters	- We parse the raw supervisions and merge similar words into 108 dimensions. Each row is a description of corresponding cluster.	- perception_words.csv : 108 perception words	- Vocabulary of perception words .		Dataset spec 2(Raw data):- cluster_list.csv:	-FileName: ['UserId'], ['ImageId Cluster'], ['Description']	-['UserId']: Specify the user who created the cluster.	-['ImageId Cluster']: Image ids in the cluster which are separated by ';'.	-['Description']: A sentence or some keywords describe the images in the cluster by user.	- 325 records(clusters) in total.		As the above."
MSNBC.com Anonymous Web Data,MSNBC.com Anonymous Web Data,"This data describes the page visits of users who visited msnbc.com on September 28, 1999. Visits are recorded at the level of URL category (see description) and are recorded in time order.",MSNBC.com+Anonymous+Web+Data,https://archive.ics.uci.edu/ml//machine-learning-databases/msnbc-mld/,https://archive.ics.uci.edu/ml/datasets/MSNBC.com+Anonymous+Web+Data,"The data comes from Internet Information Server (IIS) logs for msnbc.com and news-related portions of msn.com for the entire day of September, 28, 1999 (Pacific Standard Time). Each sequence in the dataset corresponds to page views of a user during that twenty-four hour period. Each event in the sequence corresponds to a user's request for a page. Requests are not recorded at the finest level of detail---that is, at the level of URL, but rather, they are recorded at the level of page category (as determined by a site administrator). The categories are ""frontpage"", ""news"", ""tech"", ""local"", ""opinion"", ""on-air"", ""misc"", ""weather"", ""health"", ""living"", ""business"", ""sports"", ""summary"", ""bbs"" (bulletin board service), ""travel"", ""msn-news"", and ""msn-sports"". Any page requests served via a caching mechanism were not recorded in the server logs and, hence, not present in the data.Other Relevant Information:    * Number of users: 989818    * Average number of vitis per user: 5.7    * Number of URLs per category: 10 to 5000",Computer,"Each category is associated--in order--with an integer starting with ""1"". For example, ""frontpage"" is associated with 1, ""news"" with 2, and ""tech"" with 3. Each row below ""% Sequences:"" describes the hits--in order--of a single user. For example, the first user hits ""frontpage"" twice, and the second user hits ""news"" once.","This data describes the page visits of users who visited msnbc.com on September 28, 1999. Visits are recorded at the level of URL category (see description) and are recorded in time order.The data comes from Internet Information Server (IIS) logs for msnbc.com and news-related portions of msn.com for the entire day of September, 28, 1999 (Pacific Standard Time). Each sequence in the dataset corresponds to page views of a user during that twenty-four hour period. Each event in the sequence corresponds to a user's request for a page. Requests are not recorded at the finest level of detail---that is, at the level of URL, but rather, they are recorded at the level of page category (as determined by a site administrator). The categories are ""frontpage"", ""news"", ""tech"", ""local"", ""opinion"", ""on-air"", ""misc"", ""weather"", ""health"", ""living"", ""business"", ""sports"", ""summary"", ""bbs"" (bulletin board service), ""travel"", ""msn-news"", and ""msn-sports"". Any page requests served via a caching mechanism were not recorded in the server logs and, hence, not present in the data.Other Relevant Information:    * Number of users: 989818    * Average number of vitis per user: 5.7    * Number of URLs per category: 10 to 5000Each category is associated--in order--with an integer starting with ""1"". For example, ""frontpage"" is associated with 1, ""news"" with 2, and ""tech"" with 3. Each row below ""% Sequences:"" describes the hits--in order--of a single user. For example, the first user hits ""frontpage"" twice, and the second user hits ""news"" once."
Motion Capture Hand Postures,Motion Capture Hand Postures,"5 types of hand postures from 12 users were recorded using unlabeled markers on fingers of a glove in a motion capture environment. Due to resolution and occlusion, missing values are common.",Motion+Capture+Hand+Postures,https://archive.ics.uci.edu/ml//machine-learning-databases/00405/,https://archive.ics.uci.edu/ml/datasets/Motion+Capture+Hand+Postures,"A Vicon motion capture camera system was used to record 12 users performing 5 hand postures with markers attached to a left-handed glove. A rigid pattern of markers on the back of the glove was used to establish a local coordinate system for the hand, and 11 other markers were attached to the thumb and fingers of the glove. 3 markers were attached to the thumb with one above the thumbnail and the other two on the knuckles. 2 markers were attached to each finger with one above the fingernail and the other on the joint between the proximal and middle phalanx.The 11 markers not part of the rigid pattern were unlabeled; their positions were not explicitly tracked. Consequently, there is no a priori correspondence between the markers of two given records. In addition, due to the resolution of the capture volume and self-occlusion due to the orientation and configuration of the hand and fingers, many records have missing markers. Extraneous markers were also possible due to artifacts in the Vicon software's marker reconstruction/recording process and other objects in the capture volume. As a result, the number of visible markers in a record varied considerably.The data presented here is already partially preprocessed. First, all markers were transformed to the local coordinate system of the record containing them. Second, each transformed marker with a norm greater than 200 millimeters was pruned. Finally, any record that contained fewer than 3 markers was removed. The processed data has at most 12 markers per record and at least 3. For more information, see 'Attribute Information'.Due to the manner in which data was captured, it is likely that for a given record and user there exists a near duplicate record originating from the same user. We recommend therefore to evaluate classification algorithms on a leave-one-user-out basis wherein each user is iteratively left out from training and used as a test set. One then tests the generalization of the algorithm to new users. A 'User' attribute is provided to accomodate this strategy. This dataset may be used for a variety of tasks, the most obvious of which is posture recognition via classification. One may also attempt user identification. Alternatively, one may perform clustering (constrained or unconstrained) to discover marker distributions either as an attempt to predict marker identities or obtain statistical descriptions/visualizations of the postures.In previous work, we randomly sampled without replacement a constant number (e.g. 75) of records per class per user in order to balance classes.A mirror of the dataset may currently be obtained at [Web Link] by following the Postures link.",Computer,"Data is provided as a CSV file. A header provides the name of each attribute. An initial dummy record composed entirely of 0s should be ignored. A question mark '?' is used to indicate a missing value. A record corresponds to a single instant or frame as recorded by the camera system.'Class' - Integer. The class ID of the given record. Ranges from 1 to 5 with 1=Fist(with thumb out), 2=Stop(hand flat), 3=Point1(point with pointer finger), 4=Point2(point with pointer and middle fingers), 5=Grab(fingers curled as if to grab).'User' - Integer. The ID of the user that contributed the record. No meaning other than as an identifier.'Xi' - Real. The x-coordinate of the i-th unlabeled marker position. 'i' ranges from 0 to 11.'Yi' - Real. The y-coordinate of the i-th unlabeled marker position. 'i' ranges from 0 to 11.'Zi' - Real. The z-coordinate of the i-th unlabeled marker position. 'i' ranges from 0 to 11.Each record is a set. The i-th marker of a given record does not necessarily correspond to the i-th marker of a different record. One may randomly permute the visible (i.e. not missing) markers of a given record without changing the set that the record represents. For the sake of convenience, all visible markers of a given record are given a lower index than any missing marker. A class is not guaranteed to have even a single record with all markers visible.","5 types of hand postures from 12 users were recorded using unlabeled markers on fingers of a glove in a motion capture environment. Due to resolution and occlusion, missing values are common.A Vicon motion capture camera system was used to record 12 users performing 5 hand postures with markers attached to a left-handed glove. A rigid pattern of markers on the back of the glove was used to establish a local coordinate system for the hand, and 11 other markers were attached to the thumb and fingers of the glove. 3 markers were attached to the thumb with one above the thumbnail and the other two on the knuckles. 2 markers were attached to each finger with one above the fingernail and the other on the joint between the proximal and middle phalanx.The 11 markers not part of the rigid pattern were unlabeled; their positions were not explicitly tracked. Consequently, there is no a priori correspondence between the markers of two given records. In addition, due to the resolution of the capture volume and self-occlusion due to the orientation and configuration of the hand and fingers, many records have missing markers. Extraneous markers were also possible due to artifacts in the Vicon software's marker reconstruction/recording process and other objects in the capture volume. As a result, the number of visible markers in a record varied considerably.The data presented here is already partially preprocessed. First, all markers were transformed to the local coordinate system of the record containing them. Second, each transformed marker with a norm greater than 200 millimeters was pruned. Finally, any record that contained fewer than 3 markers was removed. The processed data has at most 12 markers per record and at least 3. For more information, see 'Attribute Information'.Due to the manner in which data was captured, it is likely that for a given record and user there exists a near duplicate record originating from the same user. We recommend therefore to evaluate classification algorithms on a leave-one-user-out basis wherein each user is iteratively left out from training and used as a test set. One then tests the generalization of the algorithm to new users. A 'User' attribute is provided to accomodate this strategy. This dataset may be used for a variety of tasks, the most obvious of which is posture recognition via classification. One may also attempt user identification. Alternatively, one may perform clustering (constrained or unconstrained) to discover marker distributions either as an attempt to predict marker identities or obtain statistical descriptions/visualizations of the postures.In previous work, we randomly sampled without replacement a constant number (e.g. 75) of records per class per user in order to balance classes.A mirror of the dataset may currently be obtained at [Web Link] by following the Postures link.Data is provided as a CSV file. A header provides the name of each attribute. An initial dummy record composed entirely of 0s should be ignored. A question mark '?' is used to indicate a missing value. A record corresponds to a single instant or frame as recorded by the camera system.'Class' - Integer. The class ID of the given record. Ranges from 1 to 5 with 1=Fist(with thumb out), 2=Stop(hand flat), 3=Point1(point with pointer finger), 4=Point2(point with pointer and middle fingers), 5=Grab(fingers curled as if to grab).'User' - Integer. The ID of the user that contributed the record. No meaning other than as an identifier.'Xi' - Real. The x-coordinate of the i-th unlabeled marker position. 'i' ranges from 0 to 11.'Yi' - Real. The y-coordinate of the i-th unlabeled marker position. 'i' ranges from 0 to 11.'Zi' - Real. The z-coordinate of the i-th unlabeled marker position. 'i' ranges from 0 to 11.Each record is a set. The i-th marker of a given record does not necessarily correspond to the i-th marker of a different record. One may randomly permute the visible (i.e. not missing) markers of a given record without changing the set that the record represents. For the sake of convenience, all visible markers of a given record are given a lower index than any missing marker. A class is not guaranteed to have even a single record with all markers visible."
Website Phishing,Website Phishing,"

",Website+Phishing,https://archive.ics.uci.edu/ml//machine-learning-databases/00379/,https://archive.ics.uci.edu/ml/datasets/Website+Phishing,"The phishing problem is considered a vital issue in Ã¢â‚¬Å“.COMÃ¢â‚¬Â� industry especially e-banking and e-commerce taking the number of online transactions involving payments. We have identified different features related to legitimate and phishy websites and collected 1353 different websites from difference sources.Phishing websites were collected from Phishtank data archive (www.phishtank.com), which is a free community site where users can submit, verify, track and share phishing data. The legitimate websites were collected from Yahoo and starting point directories using a web script developed in PHP. The PHP script was plugged with a browser and we collected 548 legitimate websites out of 1353 websites. There is 702 phishing URLs, and 103 suspicious URLs.  When a website is considered SUSPICIOUS that means it can be either phishy or legitimate, meaning the website held some legit and phishy features. ",Computer,"URL Anchor	Request URL	SFH	URL Length	Having Ã¢â‚¬â„¢@Ã¢â‚¬â„¢	Prefix/Suffix	IP	Sub Domain	Web traffic	Domain age	Class collected features hold the categorical values , Ã¢â‚¬Å“LegitimateÃ¢â‚¬Â�, Ã¢â‚¬Â�SuspiciousÃ¢â‚¬Â� and Ã¢â‚¬Å“PhishyÃ¢â‚¬Â�, these values have been replaced with numerical values 1,0 and -1 respectively.details of each feature are mentioned in the research paper mentioned below","

The phishing problem is considered a vital issue in Ã¢â‚¬Å“.COMÃ¢â‚¬Â� industry especially e-banking and e-commerce taking the number of online transactions involving payments. We have identified different features related to legitimate and phishy websites and collected 1353 different websites from difference sources.Phishing websites were collected from Phishtank data archive (www.phishtank.com), which is a free community site where users can submit, verify, track and share phishing data. The legitimate websites were collected from Yahoo and starting point directories using a web script developed in PHP. The PHP script was plugged with a browser and we collected 548 legitimate websites out of 1353 websites. There is 702 phishing URLs, and 103 suspicious URLs.  When a website is considered SUSPICIOUS that means it can be either phishy or legitimate, meaning the website held some legit and phishy features. URL Anchor	Request URL	SFH	URL Length	Having Ã¢â‚¬â„¢@Ã¢â‚¬â„¢	Prefix/Suffix	IP	Sub Domain	Web traffic	Domain age	Class collected features hold the categorical values , Ã¢â‚¬Å“LegitimateÃ¢â‚¬Â�, Ã¢â‚¬Â�SuspiciousÃ¢â‚¬Â� and Ã¢â‚¬Å“PhishyÃ¢â‚¬Â�, these values have been replaced with numerical values 1,0 and -1 respectively.details of each feature are mentioned in the research paper mentioned below"
Wearable Computing: Classification of Body Postures and Movements (PUC-Rio),Wearable Computing: Classification of Body Postures and Movements (PUC-Rio),"A dataset with 5 classes (sitting-down, standing-up, standing, walking, and sitting) collected on 8 hours of activities of 4 healthy subjects. We also established a baseline performance index.",Wearable+Computing%3A+Classification+of+Body+Postures+and+Movements+%28PUC-Rio%29,https://archive.ics.uci.edu/ml//machine-learning-databases/00250/,https://archive.ics.uci.edu/ml/datasets/Wearable+Computing%3A+Classification+of+Body+Postures+and+Movements+%28PUC-Rio%29,"IMPORTANT: we have lower performance on 'leave-one-subject-out' tests. The performance baseline index we established is for 10-fold cross-validation tests. Therefore, there's much more space for optimization in subject independent tests. If you need more information, please send us an e-mail.Licensing: You are free to use this dataset for any purpose. This dataset is licensed under the Creative Commons license (CC BY-SA). The CC BY-SA license means you can remix, tweak, and build upon this work even for commercial purposes, as long as you credit the authors of the original work and you license your new creations under the identical terms we are licensing to you. This license is often compared to 'copyleft' free and open source software licenses. All new works based on this dataset will carry the same license, so any derivatives will also allow commercial use.",Computer,"Detailed information in: [Web Link]user (text)gender (text) age (integer)how_tall_in_meters (real) weight	(int) body_mass_index	(real)x1 (type int, contains the read value of the axis 'x' of the 1st accelerometer, mounted on waist)y1 (type int, contains the read value of the axis 'y' of the 1st accelerometer, mounted on waist)z1 (type int, contains the read value of the axis 'z' of the 1st accelerometer, mounted on waist)x2 (type int, contains the read value of the axis 'x' of the 2nd accelerometer, mounted on the left thigh)	y2 (type int, contains the read value of the axis 'y' of the 2nd accelerometer, mounted on the left thigh)		z2 (type int, contains the read value of the axis 'z' of the 2nd accelerometer, mounted on the left thigh)	x3 (type int, contains the read value of the axis 'x' of the 3rd accelerometer, mounted on the right ankle)	y3 (type int, contains the read value of the axis 'y' of the 3rd accelerometer, mounted on the right ankle)		z3 (type int, contains the read value of the axis 'z' of the 3rd accelerometer, mounted on the right ankle)	x4 (type int, contains the read value of the axis 'x' of the 4th accelerometer, mounted on the right upper-arm)		y4 (type int, contains the read value of the axis 'y' of the 4th accelerometer, mounted on the right upper-arm)			z4 (type int, contains the read value of the axis 'z' of the 4th accelerometer, mounted on the right upper-arm)		","A dataset with 5 classes (sitting-down, standing-up, standing, walking, and sitting) collected on 8 hours of activities of 4 healthy subjects. We also established a baseline performance index.IMPORTANT: we have lower performance on 'leave-one-subject-out' tests. The performance baseline index we established is for 10-fold cross-validation tests. Therefore, there's much more space for optimization in subject independent tests. If you need more information, please send us an e-mail.Licensing: You are free to use this dataset for any purpose. This dataset is licensed under the Creative Commons license (CC BY-SA). The CC BY-SA license means you can remix, tweak, and build upon this work even for commercial purposes, as long as you credit the authors of the original work and you license your new creations under the identical terms we are licensing to you. This license is often compared to 'copyleft' free and open source software licenses. All new works based on this dataset will carry the same license, so any derivatives will also allow commercial use.Detailed information in: [Web Link]user (text)gender (text) age (integer)how_tall_in_meters (real) weight	(int) body_mass_index	(real)x1 (type int, contains the read value of the axis 'x' of the 1st accelerometer, mounted on waist)y1 (type int, contains the read value of the axis 'y' of the 1st accelerometer, mounted on waist)z1 (type int, contains the read value of the axis 'z' of the 1st accelerometer, mounted on waist)x2 (type int, contains the read value of the axis 'x' of the 2nd accelerometer, mounted on the left thigh)	y2 (type int, contains the read value of the axis 'y' of the 2nd accelerometer, mounted on the left thigh)		z2 (type int, contains the read value of the axis 'z' of the 2nd accelerometer, mounted on the left thigh)	x3 (type int, contains the read value of the axis 'x' of the 3rd accelerometer, mounted on the right ankle)	y3 (type int, contains the read value of the axis 'y' of the 3rd accelerometer, mounted on the right ankle)		z3 (type int, contains the read value of the axis 'z' of the 3rd accelerometer, mounted on the right ankle)	x4 (type int, contains the read value of the axis 'x' of the 4th accelerometer, mounted on the right upper-arm)		y4 (type int, contains the read value of the axis 'y' of the 4th accelerometer, mounted on the right upper-arm)			z4 (type int, contains the read value of the axis 'z' of the 4th accelerometer, mounted on the right upper-arm)		"
KDD Cup 1999 Data,KDD Cup 1999 Data,"This is the data set used for The Third International Knowledge Discovery and Data Mining Tools Competition, which was held in conjunction with KDD-99",KDD+Cup+1999+Data,https://archive.ics.uci.edu/ml//machine-learning-databases/kddcup99-mld/,https://archive.ics.uci.edu/ml/datasets/KDD+Cup+1999+Data,Please see task description.,Computer,,"This is the data set used for The Third International Knowledge Discovery and Data Mining Tools Competition, which was held in conjunction with KDD-99Please see task description.nan"
TUANDROMD ( Tezpur University Android Malware Dataset),TUANDROMD ( Tezpur University Android Malware Dataset),TUNADROMD dataset contains 4465  instances and 241 attributes. The target attribute for classification is a category (malware vs goodware). (N.B. This is the preprocessed version of TUANDROMD),TUANDROMD+%28+Tezpur+University+Android+Malware+Dataset%29,https://archive.ics.uci.edu/ml//machine-learning-databases/00622/,https://archive.ics.uci.edu/ml/datasets/TUANDROMD+%28+Tezpur+University+Android+Malware+Dataset%29,Provide all relevant information about your data set.,Computer,1-214: Permission-based features215-241: API based featuresClass: 1) Malware 2) Goodware,TUNADROMD dataset contains 4465  instances and 241 attributes. The target attribute for classification is a category (malware vs goodware). (N.B. This is the preprocessed version of TUANDROMD)Provide all relevant information about your data set.1-214: Permission-based features215-241: API based featuresClass: 1) Malware 2) Goodware
Victorian Era Authorship Attribution,Victorian Era Authorship Attribution,"To create the largest authorship attribution dataset, we extracted works of 50 well-known authors. To have a non-exhaustive learning, in training there are 45 authors whereas, in the testing, it's 50",Victorian+Era+Authorship+Attribution,https://archive.ics.uci.edu/ml//machine-learning-databases/00454/,https://archive.ics.uci.edu/ml/datasets/Victorian+Era+Authorship+Attribution,"To decrease the bias and create a reliable authorship attribution dataset the following criteria have been chosen to filter out authors in Gdelt database: English language writing authors, authors that have enough books available (at least 5), 19th century authors. With these criteria 50 authors have been selected and their books were queried through Big Query Gdelt database. The next task has been cleaning the dataset due to OCR reading problems in the original raw form. To achieve that, firstly all books have been scanned through to get the overall number of unique words and each words frequencies. While scanning the texts, the first 500 words and the last 500 words have been removed to take out specific features such as the name of the author, the name of the book and other word specific features that could make the classification task easier. After this step, we have chosen top 10,000 words that occurred in the whole 50 authors text data corpus. The words that are not in top 10,000 words were removed while keeping the rest of the sentence structure intact. The entire book is split into text fragments with 1000 words each. We separately maintained author and book identification number for each one of them in different arrays. Text segments with less than 1000 words were filled with zeros to keep them in the dataset as well. 1000 words make approximately 2 pages of writing, which is long enough to extract a variety of features from the document. Each instance in the training set consists of a text piece of 1000 words and an author id attached. In the testing set, there is only the text piece of 1000 words to do authorship attribution. Training data consists of 45 authors and testing data has 50 information. %34 of testing data is the percentile of unknown authors in the testing set.  ",Computer,"Each instance consists of 1000 word sequences that are divided from the works of every author's book. In the training, the author id is also provided.  ","To create the largest authorship attribution dataset, we extracted works of 50 well-known authors. To have a non-exhaustive learning, in training there are 45 authors whereas, in the testing, it's 50To decrease the bias and create a reliable authorship attribution dataset the following criteria have been chosen to filter out authors in Gdelt database: English language writing authors, authors that have enough books available (at least 5), 19th century authors. With these criteria 50 authors have been selected and their books were queried through Big Query Gdelt database. The next task has been cleaning the dataset due to OCR reading problems in the original raw form. To achieve that, firstly all books have been scanned through to get the overall number of unique words and each words frequencies. While scanning the texts, the first 500 words and the last 500 words have been removed to take out specific features such as the name of the author, the name of the book and other word specific features that could make the classification task easier. After this step, we have chosen top 10,000 words that occurred in the whole 50 authors text data corpus. The words that are not in top 10,000 words were removed while keeping the rest of the sentence structure intact. The entire book is split into text fragments with 1000 words each. We separately maintained author and book identification number for each one of them in different arrays. Text segments with less than 1000 words were filled with zeros to keep them in the dataset as well. 1000 words make approximately 2 pages of writing, which is long enough to extract a variety of features from the document. Each instance in the training set consists of a text piece of 1000 words and an author id attached. In the testing set, there is only the text piece of 1000 words to do authorship attribution. Training data consists of 45 authors and testing data has 50 information. %34 of testing data is the percentile of unknown authors in the testing set.  Each instance consists of 1000 word sequences that are divided from the works of every author's book. In the training, the author id is also provided.  "
GNFUV Unmanned Surface Vehicles Sensor Data,GNFUV Unmanned Surface Vehicles Sensor Data,"The data-set contains four (4) sets of mobile sensor readings data (humidity, temperature) corresponding to a swarm of four (4) Unmanned Surface Vehicles (USVs) in a test-bed in Athens (Greece). ",GNFUV+Unmanned+Surface+Vehicles+Sensor+Data,https://archive.ics.uci.edu/ml//machine-learning-databases/00452/,https://archive.ics.uci.edu/ml/datasets/GNFUV+Unmanned+Surface+Vehicles+Sensor+Data,"The data-set comprises (4) sets of mobile sensor readings data (humidity, temperature) corresponding to a swarm of four (4) Unmanned Surface Vehicles (USVs). Each USV set contains records of the format: {'USV-ID'; 'humidity-value'; 'temperature-value'; 'experiment-id';'sensing-time'}The swarm of the USVs is moving according to a GPS pre-defined trajectory, whose relative way-points are specified in the README.pdf file. The USVs are floating over the sea surface in a coastal area of Athens (Greece). More information on the project: [Web Link]",Computer,Attributes:'device' = USV ID (String)'humidity' = sensed humidity value from the USV sensor (real value)'temperature' = sensed temperature value from the USV sensor (real value)'experiment' = 1 (constant real value)'time' = the sensing and reporting time (real value),"The data-set contains four (4) sets of mobile sensor readings data (humidity, temperature) corresponding to a swarm of four (4) Unmanned Surface Vehicles (USVs) in a test-bed in Athens (Greece). The data-set comprises (4) sets of mobile sensor readings data (humidity, temperature) corresponding to a swarm of four (4) Unmanned Surface Vehicles (USVs). Each USV set contains records of the format: {'USV-ID'; 'humidity-value'; 'temperature-value'; 'experiment-id';'sensing-time'}The swarm of the USVs is moving according to a GPS pre-defined trajectory, whose relative way-points are specified in the README.pdf file. The USVs are floating over the sea surface in a coastal area of Athens (Greece). More information on the project: [Web Link]Attributes:'device' = USV ID (String)'humidity' = sensed humidity value from the USV sensor (real value)'temperature' = sensed temperature value from the USV sensor (real value)'experiment' = 1 (constant real value)'time' = the sensing and reporting time (real value)"
Gisette,Gisette,"GISETTE is a handwritten digit recognition problem. The problem is to separate the highly confusible digits '4' and '9'. This dataset is one of five datasets of the NIPS 2003 feature selection challenge.
",Gisette,https://archive.ics.uci.edu/ml//machine-learning-databases/gisette/,https://archive.ics.uci.edu/ml/datasets/Gisette,"The digits have been size-normalized and centered in a fixed-size image of dimension 28x28. The original data were modified for the purpose of the feature selection challenge. In particular, pixels were samples at random in the middle top part of the feature containing the information necessary to disambiguate 4 from 9 and higher order features were created as products of these pixels to plunge the problem in a higher dimensional feature space. We also added a number of distractor features called 'probes' having no predictive power. The order of the features and patterns were randomized. GISETTE -- Positive ex. -- Negative ex. -- TotalTraining set -- 3000 -- 3000 -- 6000Validation set -- 500 -- 500 -- 1000Test set -- 3250 -- 3250 -- 6500All -- 6750 -- 6750 -- 13500Number of variables/features/attributes:Real: 2500Probes: 2500Total: 5000This dataset is one of five datasets used in the NIPS 2003 feature selection challenge. Our website [Web Link] is still open for post-challenge submissions. Information about other related challenges are found at: [Web Link]. The CLOP package includes sample code to process these data: [Web Link].All details about the preparation of the data are found in our technical report: Design of experiments for the NIPS 2003 variable selection benchmark, Isabelle Guyon, July 2003, [Web Link] (also included in the dataset archive). Such information was made available only after the end of the challenge.The data are split into training, validation, and test set. Target values are provided only for the 2 first sets. Test set performance results are obtained by submitting prediction results to: [Web Link].The data are in the following format:dataname.param: Parameters and statistics about the datadataname.feat: Identities of the features (withheld, to avoid biasing feature selection).dataname_train.data: Training set (a coma delimited regular matrix, patterns in lines, features in columns).dataname_valid.data: Validation set.dataname_test.data: Test set.dataname_train.labels: Labels (truth values of the classes) for training examples.dataname_valid.labels: Validation set labels (withheld during the benchmark, but provided now).dataname_test.labels: Test set labels (withheld, so the data can still be use as a benchmark). ",Computer,We do not provide attribute information to avoid biasing the feature selection process. ,"GISETTE is a handwritten digit recognition problem. The problem is to separate the highly confusible digits '4' and '9'. This dataset is one of five datasets of the NIPS 2003 feature selection challenge.
The digits have been size-normalized and centered in a fixed-size image of dimension 28x28. The original data were modified for the purpose of the feature selection challenge. In particular, pixels were samples at random in the middle top part of the feature containing the information necessary to disambiguate 4 from 9 and higher order features were created as products of these pixels to plunge the problem in a higher dimensional feature space. We also added a number of distractor features called 'probes' having no predictive power. The order of the features and patterns were randomized. GISETTE -- Positive ex. -- Negative ex. -- TotalTraining set -- 3000 -- 3000 -- 6000Validation set -- 500 -- 500 -- 1000Test set -- 3250 -- 3250 -- 6500All -- 6750 -- 6750 -- 13500Number of variables/features/attributes:Real: 2500Probes: 2500Total: 5000This dataset is one of five datasets used in the NIPS 2003 feature selection challenge. Our website [Web Link] is still open for post-challenge submissions. Information about other related challenges are found at: [Web Link]. The CLOP package includes sample code to process these data: [Web Link].All details about the preparation of the data are found in our technical report: Design of experiments for the NIPS 2003 variable selection benchmark, Isabelle Guyon, July 2003, [Web Link] (also included in the dataset archive). Such information was made available only after the end of the challenge.The data are split into training, validation, and test set. Target values are provided only for the 2 first sets. Test set performance results are obtained by submitting prediction results to: [Web Link].The data are in the following format:dataname.param: Parameters and statistics about the datadataname.feat: Identities of the features (withheld, to avoid biasing feature selection).dataname_train.data: Training set (a coma delimited regular matrix, patterns in lines, features in columns).dataname_valid.data: Validation set.dataname_test.data: Test set.dataname_train.labels: Labels (truth values of the classes) for training examples.dataname_valid.labels: Validation set labels (withheld during the benchmark, but provided now).dataname_test.labels: Test set labels (withheld, so the data can still be use as a benchmark). We do not provide attribute information to avoid biasing the feature selection process. "
Geo-Magnetic field and WLAN dataset for indoor localisation from wristband and smartphone,Geo-Magnetic field and WLAN dataset for indoor localisation from wristband and smartphone,A multisource and multivariate dataset for indoor localisation methods based on WLAN and Geo-Magnetic ï¬�eld ï¬�ngerprinting,Geo-Magnetic+field+and+WLAN+dataset+for+indoor+localisation+from+wristband+and+smartphone,https://archive.ics.uci.edu/ml//machine-learning-databases/00377/,https://archive.ics.uci.edu/ml/datasets/Geo-Magnetic+field+and+WLAN+dataset+for+indoor+localisation+from+wristband+and+smartphone,"Indoor localisation is a key topic for the Ambient Intelligence (AmI) research community. In this scenarios, recent advancements in wearable technologies, particularly smartwatches with built-in sensors, and personal devices, such as smartphones, are being seen as the breakthrough for making concrete the envisioned Smart Environment (SE) paradigm. In particular, scenarios devoted to indoor localization represent a key challenge to be addressed. Many works try to solve the indoor localization issue, but the lack of a common dataset or frameworks to compare and evaluate solutions represent a big barrier to be overcome in the Ã¯Â¬Â�eld. The unavailability and uncertainty of public datasets hinders the  possibility to compare different indoor localization algorithms. This constitutes the main motivation of the proposed dataset described herein. We collected Wi-Fi and geo-magnetic Ã¯Â¬Â�eld Ã¯Â¬Â�ngerprints, together with inertial sensor data during two campaigns performed in the same environment. Retrieving syncronized data from a smartwatch and a smartphone worn by users at the purpose of create and present a public available dataset is the goal of this work. ",Computer,"Pointsmapping.ods: 	A three column spreadsheet (ID,X,Y) which points mapping in local coordinates. 	Each ID represents an unique place on the map. The X-Y coordinates represents the local coordinates.For each measure:measure1(2)_timestamp_id.csv:		Timestamp (Unixtime) of arrival on placeID, timestamp (Unixtime) of departure by placeID, Place ID identifier (0-324)measure1(2)_smartphone_sens.csv:		According to measure1(2)_timestamp_id.csv, this csv contains the data sensors retrieved by the smartphone. 	Timestamp, AccelerationX, AccelerationY, AccelerationZ, MagneticFieldX, MagneticFieldY, MagneticFieldZ, Z-AxisAgle(Azimuth), X-AxisAngle(Pitch), Y-AxisAngle(Roll), GyroX, GyroY, GyroZ	measure1(2)_smartwatch_sens.csv:		According to measure1(2)_timestamp_id.csv, this csv contains the data sensors retrieved by the smartwatch. 	Timestamp, AccelerationX, AccelerationY, AccelerationZ, MagneticFieldX, MagneticFieldY, MagneticFieldZ, Z-AxisAgle(Azimuth), X-AxisAngle(Pitch), Y-AxisAngle(Roll), GyroX, GyroY, GyroZmeasure1(2)_smartphone_wifi.csv:		Each rows contains PlaceId (ascending order) and 127 column, with RSSI level for each different	WAPs retrieved during the campaign. Not all the WAPs are detected in each scan.	For these WAPs, the articial RSSI value is -100 (dbm).","A multisource and multivariate dataset for indoor localisation methods based on WLAN and Geo-Magnetic ï¬�eld ï¬�ngerprintingIndoor localisation is a key topic for the Ambient Intelligence (AmI) research community. In this scenarios, recent advancements in wearable technologies, particularly smartwatches with built-in sensors, and personal devices, such as smartphones, are being seen as the breakthrough for making concrete the envisioned Smart Environment (SE) paradigm. In particular, scenarios devoted to indoor localization represent a key challenge to be addressed. Many works try to solve the indoor localization issue, but the lack of a common dataset or frameworks to compare and evaluate solutions represent a big barrier to be overcome in the Ã¯Â¬Â�eld. The unavailability and uncertainty of public datasets hinders the  possibility to compare different indoor localization algorithms. This constitutes the main motivation of the proposed dataset described herein. We collected Wi-Fi and geo-magnetic Ã¯Â¬Â�eld Ã¯Â¬Â�ngerprints, together with inertial sensor data during two campaigns performed in the same environment. Retrieving syncronized data from a smartwatch and a smartphone worn by users at the purpose of create and present a public available dataset is the goal of this work. Pointsmapping.ods: 	A three column spreadsheet (ID,X,Y) which points mapping in local coordinates. 	Each ID represents an unique place on the map. The X-Y coordinates represents the local coordinates.For each measure:measure1(2)_timestamp_id.csv:		Timestamp (Unixtime) of arrival on placeID, timestamp (Unixtime) of departure by placeID, Place ID identifier (0-324)measure1(2)_smartphone_sens.csv:		According to measure1(2)_timestamp_id.csv, this csv contains the data sensors retrieved by the smartphone. 	Timestamp, AccelerationX, AccelerationY, AccelerationZ, MagneticFieldX, MagneticFieldY, MagneticFieldZ, Z-AxisAgle(Azimuth), X-AxisAngle(Pitch), Y-AxisAngle(Roll), GyroX, GyroY, GyroZ	measure1(2)_smartwatch_sens.csv:		According to measure1(2)_timestamp_id.csv, this csv contains the data sensors retrieved by the smartwatch. 	Timestamp, AccelerationX, AccelerationY, AccelerationZ, MagneticFieldX, MagneticFieldY, MagneticFieldZ, Z-AxisAgle(Azimuth), X-AxisAngle(Pitch), Y-AxisAngle(Roll), GyroX, GyroY, GyroZmeasure1(2)_smartphone_wifi.csv:		Each rows contains PlaceId (ascending order) and 127 column, with RSSI level for each different	WAPs retrieved during the campaign. Not all the WAPs are detected in each scan.	For these WAPs, the articial RSSI value is -100 (dbm)."
Gastrointestinal Lesions in Regular Colonoscopy,Gastrointestinal Lesions in Regular Colonoscopy,"This dataset contains features extracted from colonoscopy videos used to detect gastrointestinal lesions. It contains 76 lesions: 15 serrated adenomas, 21 hyperplastic lesions and 40 adenoma. ",Gastrointestinal+Lesions+in+Regular+Colonoscopy,https://archive.ics.uci.edu/ml//machine-learning-databases/00408/,https://archive.ics.uci.edu/ml/datasets/Gastrointestinal+Lesions+in+Regular+Colonoscopy,"This dataset contains the features extracted from a database of colonoscopic videos showing gastrointestinal lesions. It also contains the ground truth collected from both expert image inspection and histology (in an xlsx file). There are features vectors for 76 lesions, and there are 3 types of lesion: hyperplasic, adenoma and serrated adenoma. It is possible to consider this classification problem as a binary one by combining adenoma and serrated adenoma in the same class. According to this, hyperplasic lesions would belong to the class 'benign' while the other two types of gastrointestinal lesions would go to the 'malignant' class. The first line/row of the dataset corresponds to the lesion name (text label). Every lesion appears twice because it has been recorded using two types of lights: white light (WL) and narrow band imaging (NBI). The second line/row represents the type of lesion (3 for adenoma, 1 for hyperplasic, and 2 for serrated). And, finally, the third line/row is the type of light used (1 for WL and 2 for NBI). All other rows are the raw features (without any kind of preprocessing):422 2D TEXTURAL FEATURES- First 166 features: AHT: Autocorrelation Homogeneous Texture (Invariant Gabor Texture)- Next 256: Rotational Invariant LBP76 2D COLOR FEATURES- 16 Color Naming- 13 Discriminative Color- 7 Hue- 7 Opponent- 33 color gray-level co-occurrence matrix200 3D SHAPE FEATURES- 100 shapeDNA- 100 KPCAThe main objective of this dataset is to study how good computers can be at diagnosing gastrointestinal lesions from regular colonoscopic videos. In order to compare the performance of machine learning methods with the one offered by humans, we provide the file ground_truth.xlsx that includes the ground truth after histopathology and the opinion of 7 clinicians (4 experts and 3 beginners). An automatic tissue classification approach could save clinician's time by avoiding chromoendoscopy, a time-consuming staining procedure using indigo carmine, as well as could help to assess the severity of individual lesions in patients with many polyps, so that the gastroenterologist would directly focus on those requiring polypectomy. A possible way of proceeding with the classification is to concatenate the information from the two types of light for each lesion, i.e. create a single vector of 1396 elements per lesion.The technical goal is to maximize accuracy while minimizing false positives (lesions that do not need resection but that are classified as if they do) and false negatives (lesions that do need resection but that are classified as if they do not need it). In particular, we are specially interested on maximizing accuracy while reducing false negatives, i.e. minimizing the number of adenoma and serrated adenoma that are classified as hyperplasic. The opposite case is not that serious: the resection of a hyperplasic polyp considering it as an adenoma or serrated adenoma. Another interesting experiment would consist on compare the performance of the best machine learning method we can get with the one provided by human operators (experts and beginners).The best results obtained so far, in the binary case, using leave-one-out and Random Forest with 1000 trees (using color+texture+3D with NBI), corresponded to an accuracy of ~89,5%, sensitivity ~94,5% and specificity ~76% (considering as positive condition the resection). This is the best confusion matrix found so far:                     Classified as		Resection	No-ResectionResection       52			3No-Resection	5			16The best results obtained in the multi-class case, using leave-one-out and Random Subspace of SVMs (color+texture+3D using WL), were as follows:                   Classified as	Hyp.	       Ser.     	Ade.Hyp.	18		0		3Ser.	2		9		4Ade.	7		4		29Overall Accuracy : 0.7368 Acc Hyp.  	0.84Acc Ser.	0.87Acc Ade.	0.76Sen Hyp.	0.86	Sen Ser.	0.6Sen Ade.	0.725Spe Hyp.	0.84Spe Ser.	0.93Spe Ade.	0.81",Computer,First 422 attributes: 2D TEXTURAL FEATURES- 166 features: AHT: Autocorrelation Homogeneous Texture (Invariant Gabor Texture)- Next 256: Rotational Invariant LBPNext 76 attributes: 2D COLOR FEATURES- 16 Color Naming- 13 Discriminative Color- 7 Hue- 7 Opponent- 33 color gray-level co-occurrence matrixLast 200 attributes: 3D SHAPE FEATURES- 100 shapeDNA- 100 KPCA,"This dataset contains features extracted from colonoscopy videos used to detect gastrointestinal lesions. It contains 76 lesions: 15 serrated adenomas, 21 hyperplastic lesions and 40 adenoma. This dataset contains the features extracted from a database of colonoscopic videos showing gastrointestinal lesions. It also contains the ground truth collected from both expert image inspection and histology (in an xlsx file). There are features vectors for 76 lesions, and there are 3 types of lesion: hyperplasic, adenoma and serrated adenoma. It is possible to consider this classification problem as a binary one by combining adenoma and serrated adenoma in the same class. According to this, hyperplasic lesions would belong to the class 'benign' while the other two types of gastrointestinal lesions would go to the 'malignant' class. The first line/row of the dataset corresponds to the lesion name (text label). Every lesion appears twice because it has been recorded using two types of lights: white light (WL) and narrow band imaging (NBI). The second line/row represents the type of lesion (3 for adenoma, 1 for hyperplasic, and 2 for serrated). And, finally, the third line/row is the type of light used (1 for WL and 2 for NBI). All other rows are the raw features (without any kind of preprocessing):422 2D TEXTURAL FEATURES- First 166 features: AHT: Autocorrelation Homogeneous Texture (Invariant Gabor Texture)- Next 256: Rotational Invariant LBP76 2D COLOR FEATURES- 16 Color Naming- 13 Discriminative Color- 7 Hue- 7 Opponent- 33 color gray-level co-occurrence matrix200 3D SHAPE FEATURES- 100 shapeDNA- 100 KPCAThe main objective of this dataset is to study how good computers can be at diagnosing gastrointestinal lesions from regular colonoscopic videos. In order to compare the performance of machine learning methods with the one offered by humans, we provide the file ground_truth.xlsx that includes the ground truth after histopathology and the opinion of 7 clinicians (4 experts and 3 beginners). An automatic tissue classification approach could save clinician's time by avoiding chromoendoscopy, a time-consuming staining procedure using indigo carmine, as well as could help to assess the severity of individual lesions in patients with many polyps, so that the gastroenterologist would directly focus on those requiring polypectomy. A possible way of proceeding with the classification is to concatenate the information from the two types of light for each lesion, i.e. create a single vector of 1396 elements per lesion.The technical goal is to maximize accuracy while minimizing false positives (lesions that do not need resection but that are classified as if they do) and false negatives (lesions that do need resection but that are classified as if they do not need it). In particular, we are specially interested on maximizing accuracy while reducing false negatives, i.e. minimizing the number of adenoma and serrated adenoma that are classified as hyperplasic. The opposite case is not that serious: the resection of a hyperplasic polyp considering it as an adenoma or serrated adenoma. Another interesting experiment would consist on compare the performance of the best machine learning method we can get with the one provided by human operators (experts and beginners).The best results obtained so far, in the binary case, using leave-one-out and Random Forest with 1000 trees (using color+texture+3D with NBI), corresponded to an accuracy of ~89,5%, sensitivity ~94,5% and specificity ~76% (considering as positive condition the resection). This is the best confusion matrix found so far:                     Classified as		Resection	No-ResectionResection       52			3No-Resection	5			16The best results obtained in the multi-class case, using leave-one-out and Random Subspace of SVMs (color+texture+3D using WL), were as follows:                   Classified as	Hyp.	       Ser.     	Ade.Hyp.	18		0		3Ser.	2		9		4Ade.	7		4		29Overall Accuracy : 0.7368 Acc Hyp.  	0.84Acc Ser.	0.87Acc Ade.	0.76Sen Hyp.	0.86	Sen Ser.	0.6Sen Ade.	0.725Spe Hyp.	0.84Spe Ser.	0.93Spe Ade.	0.81First 422 attributes: 2D TEXTURAL FEATURES- 166 features: AHT: Autocorrelation Homogeneous Texture (Invariant Gabor Texture)- Next 256: Rotational Invariant LBPNext 76 attributes: 2D COLOR FEATURES- 16 Color Naming- 13 Discriminative Color- 7 Hue- 7 Opponent- 33 color gray-level co-occurrence matrixLast 200 attributes: 3D SHAPE FEATURES- 100 shapeDNA- 100 KPCA"
Gas Turbine CO and NOx Emission Data Set,Gas Turbine CO and NOx Emission Data Set,"The dataset contains 36733 instances of 11 sensor measures aggregated over one hour, from a gas turbine located in Turkey for the purpose of studying flue gas emissions, namely CO and NOx.",Gas+Turbine+CO+and+NOx+Emission+Data+Set,https://archive.ics.uci.edu/ml//machine-learning-databases/00551/,https://archive.ics.uci.edu/ml/datasets/Gas+Turbine+CO+and+NOx+Emission+Data+Set,"The dataset contains 36733 instances of 11 sensor measures aggregated over one hour (by means of average or sum) from a gas turbine located in Turkey's north western region for the purpose of studying flue gas emissions, namely CO and NOx (NO + NO2). The data comes from the same power plant as the dataset ([Web Link]) used for predicting hourly net energy yield. By contrast, this data is collected in another data range (01.01.2011 - 31.12.2015), includes gas turbine parameters (such as Turbine Inlet Temperature and Compressor Discharge pressure) in addition to the ambient variables. Note that the dates are not given in the instances but the data are sorted in chronological order. See the attribute information and relevant paper for details. Kindly follow the protocol mentioned in the paper (using the first three years' data for training/ cross-validation and the last two for testing) for reproducibility and comparability of works. The dataset can be well used for predicting turbine energy yield (TEY) using ambient variables as features.",Computer,The explanations of sensor measurements and their brief statistics are given below. Variable (Abbr.) Unit Min Max MeanAmbient temperature (AT) C Ã¢â‚¬â€œ6.23 37.10 17.71Ambient pressure (AP) mbar 985.85 1036.56 1013.07Ambient humidity (AH) (%) 24.08 100.20 77.87Air filter difference pressure (AFDP) mbar 2.09 7.61 3.93Gas turbine exhaust pressure (GTEP) mbar 17.70 40.72 25.56Turbine inlet temperature (TIT) C 1000.85 1100.89 1081.43Turbine after temperature (TAT) C 511.04 550.61 546.16Compressor discharge pressure (CDP) mbar 9.85 15.16 12.06Turbine energy yield (TEY) MWH 100.02 179.50 133.51Carbon monoxide (CO) mg/m3 0.00 44.10 2.37Nitrogen oxides (NOx) mg/m3 25.90 119.91 65.29,"The dataset contains 36733 instances of 11 sensor measures aggregated over one hour, from a gas turbine located in Turkey for the purpose of studying flue gas emissions, namely CO and NOx.The dataset contains 36733 instances of 11 sensor measures aggregated over one hour (by means of average or sum) from a gas turbine located in Turkey's north western region for the purpose of studying flue gas emissions, namely CO and NOx (NO + NO2). The data comes from the same power plant as the dataset ([Web Link]) used for predicting hourly net energy yield. By contrast, this data is collected in another data range (01.01.2011 - 31.12.2015), includes gas turbine parameters (such as Turbine Inlet Temperature and Compressor Discharge pressure) in addition to the ambient variables. Note that the dates are not given in the instances but the data are sorted in chronological order. See the attribute information and relevant paper for details. Kindly follow the protocol mentioned in the paper (using the first three years' data for training/ cross-validation and the last two for testing) for reproducibility and comparability of works. The dataset can be well used for predicting turbine energy yield (TEY) using ambient variables as features.The explanations of sensor measurements and their brief statistics are given below. Variable (Abbr.) Unit Min Max MeanAmbient temperature (AT) C Ã¢â‚¬â€œ6.23 37.10 17.71Ambient pressure (AP) mbar 985.85 1036.56 1013.07Ambient humidity (AH) (%) 24.08 100.20 77.87Air filter difference pressure (AFDP) mbar 2.09 7.61 3.93Gas turbine exhaust pressure (GTEP) mbar 17.70 40.72 25.56Turbine inlet temperature (TIT) C 1000.85 1100.89 1081.43Turbine after temperature (TAT) C 511.04 550.61 546.16Compressor discharge pressure (CDP) mbar 9.85 15.16 12.06Turbine energy yield (TEY) MWH 100.02 179.50 133.51Carbon monoxide (CO) mg/m3 0.00 44.10 2.37Nitrogen oxides (NOx) mg/m3 25.90 119.91 65.29"
Gas sensors for home activity monitoring,Gas sensors for home activity monitoring,"100 recordings of a sensor array under different conditions in a home setting: background, wine and banana presentations. The array includes 8 MOX gas sensors, and humidity and temperature sensors.
",Gas+sensors+for+home+activity+monitoring,https://archive.ics.uci.edu/ml//machine-learning-databases/00362/,https://archive.ics.uci.edu/ml/datasets/Gas+sensors+for+home+activity+monitoring,"This dataset has recordings of a gas sensor array composed of 8 MOX gas sensors, and a temperature and humidity sensor. This sensor array was exposed to background home activity while subject to two different stimuli: wine and banana. The responses to banana and wine stimuli were recorded by placing the stimulus close to the sensors. The duration of each stimulation varied from 7min to 2h, with an average duration of 42min. This dataset contains a set of time series from three different conditions: wine, banana and background activity. There are 36 inductions with wine, 33 with banana and 31 recordings of background activity. One possible application is to discriminate among background, wine and banana.This dataset is composed of two files: HT_sensor_dataset.dat (zipped), where the actual time series are stored, and the HT_Sensor_metadata.dat, where metadata for each induction is stored. Each induction is uniquely identified by an id in both files. Thus, metadata for a particular induction can be easily found by matching columns id from each file. We also made available python scripts to exemplify how to import, organize and plot our data. The scripts are available on GitHub:[Web Link]For each induction, we include one hour of background activity prior to and after the stimulus presentation. Time series were recorded at one sample per second, with minor variations at some data points due to issues in the wireless communication. For details on which sensors were used and how the time series is organized, see Attribute Information below.The metadata stored in file HT_Sensor_metadata.dat is divided in the following columns:* id: identification of the induction, to be matched with id in file HT_Sensor_dataset.dat;* date: day, month and year when this induction was recorded;* class: what was used to generate this induction (wine, banana or background);* t0: time in hours in which the induction started (represents the time zero in file HT_Sensor_dataset.dat);* dt: interval that this induction lasted.",Computer,"The dataset is composed of 100 snippets of time series, each being a single induction or background activity. On total, there are 919438 points. For each induction, the time when the stimulus was presented is set to zero. For the actual time, see column t0 of the metadata file. In file HT_Sensor_dataset.dat, each column has a title according to the following * id: identification of the induction, to be matched with id in file HT_Sensor_metadata.dat;* time: time in hours, where zero is the start of the induction;* R1 Ã¢â‚¬â€œ R8: value of each of the 8 MOX sensors resistance at that time;* Temp.: measurement of temperature in Celsius at that time;* Humidity: measurement of humidity in percent at that time.Temperature and humidity were measured using the Sensirion SHT75. The 8 MOX sensors are commercially available from Figaro, and are detailed below:R1: TGS2611R2: TGS2612R3: TGS2610R4: TGS2600R5: TGS2602R6: TGS2602R7: TGS2620R8: TGS2620","100 recordings of a sensor array under different conditions in a home setting: background, wine and banana presentations. The array includes 8 MOX gas sensors, and humidity and temperature sensors.
This dataset has recordings of a gas sensor array composed of 8 MOX gas sensors, and a temperature and humidity sensor. This sensor array was exposed to background home activity while subject to two different stimuli: wine and banana. The responses to banana and wine stimuli were recorded by placing the stimulus close to the sensors. The duration of each stimulation varied from 7min to 2h, with an average duration of 42min. This dataset contains a set of time series from three different conditions: wine, banana and background activity. There are 36 inductions with wine, 33 with banana and 31 recordings of background activity. One possible application is to discriminate among background, wine and banana.This dataset is composed of two files: HT_sensor_dataset.dat (zipped), where the actual time series are stored, and the HT_Sensor_metadata.dat, where metadata for each induction is stored. Each induction is uniquely identified by an id in both files. Thus, metadata for a particular induction can be easily found by matching columns id from each file. We also made available python scripts to exemplify how to import, organize and plot our data. The scripts are available on GitHub:[Web Link]For each induction, we include one hour of background activity prior to and after the stimulus presentation. Time series were recorded at one sample per second, with minor variations at some data points due to issues in the wireless communication. For details on which sensors were used and how the time series is organized, see Attribute Information below.The metadata stored in file HT_Sensor_metadata.dat is divided in the following columns:* id: identification of the induction, to be matched with id in file HT_Sensor_dataset.dat;* date: day, month and year when this induction was recorded;* class: what was used to generate this induction (wine, banana or background);* t0: time in hours in which the induction started (represents the time zero in file HT_Sensor_dataset.dat);* dt: interval that this induction lasted.The dataset is composed of 100 snippets of time series, each being a single induction or background activity. On total, there are 919438 points. For each induction, the time when the stimulus was presented is set to zero. For the actual time, see column t0 of the metadata file. In file HT_Sensor_dataset.dat, each column has a title according to the following * id: identification of the induction, to be matched with id in file HT_Sensor_metadata.dat;* time: time in hours, where zero is the start of the induction;* R1 Ã¢â‚¬â€œ R8: value of each of the 8 MOX sensors resistance at that time;* Temp.: measurement of temperature in Celsius at that time;* Humidity: measurement of humidity in percent at that time.Temperature and humidity were measured using the Sensirion SHT75. The 8 MOX sensors are commercially available from Figaro, and are detailed below:R1: TGS2611R2: TGS2612R3: TGS2610R4: TGS2600R5: TGS2602R6: TGS2602R7: TGS2620R8: TGS2620"
Gas sensor arrays in open sampling settings,Gas sensor arrays in open sampling settings,The dataset contains 18000 time-series recordings from a chemical detection platform at six different locations in a wind tunnel facility in response to ten high-priority chemical gaseous substances,Gas+sensor+arrays+in+open+sampling+settings,https://archive.ics.uci.edu/ml//machine-learning-databases/00251/,https://archive.ics.uci.edu/ml/datasets/Gas+sensor+arrays+in+open+sampling+settings,"Number of instances:18000 times-series measurements recorded from a 72 metal-oxide gas sensor array-based chemical detection platform.Number of attributes (features):Every measurement contains 72 time-series recorded during 260 seconds, each collected at a sample rate of 100 Hz (samples per second).The dataset also contains time, temperature, and relative humidity information.The resulting dataset ultimately includes 75-time series composed of 26000 points.This archive contains 18000 time-series measurement recordings collected from an array of 72 metal-oxide gas sensors composing our sensing platform utilized in the detection and identification of potentially-dangerous chemical gaseous substances under complex environmental conditions, as reported in the related manuscript below. Our primary purpose is to make our dataset freely accessible on-line to the chemo-sensing research and machine-learning communities, as well as other interested communities, to develop alternative competitive solutions relevant to gas-sensing discrimination tasks in open sampling settings, such as the one pursued here, and/or navigation. The dataset can be used exclusively for research purposes. Commercial purposes are fully excluded.The dataset was gathered from December 2010 to April 2012 (16 months) in a 2.5 m Ãƒâ€” 1.2 m Ãƒâ€” 0.4 m wind tunnel research test-bed facility situated at the BioCircuits Institute, University of California San Diego. Specifically, our customized research facility, endowed with a computer-supervised mass flow controller-based continuous flow gas delivery system, operates in a propulsion open-cycle mode, by continuously drawing external turbulent air into and throughout the tunnel and exhausting it back to the outside, thereby creating a relatively less-turbulent airflow moving downstream towards the end of the test field, which is particularly suitable for applications pursued here that require injecting chemical poisonous agents or explosive mixtures because it prevents saturation. Being operated by a fully computerized environment Ã¢â‚¬â€�controlled by a player/stage robot server software programmed on C++ on a PC fitted with the appropriate serial cardsÃ¢â‚¬â€� and with minimum human intervention, the designed wind tunnel test-bed facility provides versatility for releasing the chemical substances of interest at the desired concentrations with high accuracy and in a highly reproducible manner during the entire experiment and simultaneously in preserving the appropriate environmental conditions to generate chemical gas plumes exhibiting turbulent patterns. A graphical illustration of the designed wind tunnel test-bed facility considered in this study along with the characteristics of the geometry of the problem as well as the exact locations of the chemical analyte source and chemo-sensory platform is presented in Figure 2 of the manuscript cited below. Actual pictures of the designed wind tunnel are also presented in the Supplementary Material, Figure S.1 of the accompanying manuscript.The resulting dataset induces a ten-class gas discrimination problem, comprising recordings from ten distinct pure chemical gases, namely Acetone, Acetaldehyde, Ammonia, Butanol, Ethylene, Methane, Methanol, Carbon Monoxide, Benzene, and Toluene. The goal is to identify and discriminate the mentioned chemical hazards at relevant concentrations regardless of the location of the sensory system platform within the annotated wind tunnel research facility as well as the environmental and parametric conditions induced in the setting (Please see manuscript for more details). See Table 1 on Vergara et a. 2013 (manuscript below) for specifics on the identity of chemical analyte hazards as well as their nominal concentration values at the outlet of the gas source in parts-per-million by volume (ppmv). Please refer to the manuscript below for a more details of the wind tunnel test-bed facility as well as for specifics on the collection procedure followed and the operating and environmental parameters utilized during the creation of the aforementioned dataset.",Computer,"The response of the sensor platform is read-out in the form of the resistance across the active sensitive film of each of the 72 gas sensors integrating the sensor array; hence, each measurement produced a 72-channel time series, each of which represented by a 260-second time series collected at a sample rate of 100 samples per second (Hz), reflecting all the environmental changes in the evaluated scenario. For a more detailed analysis and discussion on the processing of the time series as well as a graphical illustration of them please refer to Sections 2 and 3 and Figure 4, respectively, of the manuscript below.For manipulation purposes, the data is organized into eleven folders, each containing the number of measurements per chemical class identity and nominal concentration indicated above and described in the Table 2 of the manuscript. For example the folder named Ã¢â‚¬Å“Toluene_200Ã¢â‚¬Â� means the name of the gas identity is Toluene, which has been dosed at 200 ppmv. Each folder contains 6 folders, each representing the line location within the test area of the wind tunnel (location 1, L1, to location 6, L6, being L1 the closest point to the gas source) from which the set of time-series were recorded. In each of these folders there are 300 files, each of which corresponding to the number of measurements recorded at each location in the tunnel. The name of each file contains the exact log information of each of the measurements performed during the entire experiment, which is organized as follows. The first 12 digits of the file name (e.g., 201106060617) indicate the date and time at which each specific measurement was collected, starting from the year, month, day, and time. The last 4 digits in the following 19 characters of the name file, (e.g., board_setPoint_500V), indicate the fixed operating temperature value, represented by a voltage value applied to the embedded heating element in the chemical sensor, applied to the entire sensing platform, which can adopt nominal values from 4 to 6 V with an resolution value of 0.5 V. Note that the value 500V in the example is a graphical representation of the 5V value applied to the sensorÃ¢â‚¬â„¢s heater. For more details on the operating principles of the chemical sensors utilized in our platform please refer to Section 2 of the manuscript. The last 3 digits in the following 16 characters of the file name (e.g., fan_setPoint_060) indicates the set-point value of the nominal rotational speeds of the multiple-step motor-driven exhaust fan utilized to induce the distinct artificial airflows speed in the wind tunnel. Only three values were adopted in this condition: the value Ã¢â‚¬Å“000Ã¢â‚¬Â� in the file name, which indicates the slowest rotational speed (1500 rpm), the value Ã¢â‚¬Å“060Ã¢â‚¬Â�, indicating the mid-point rotational speed value of the fan (3900rpm), and the value Ã¢â‚¬Å“100Ã¢â‚¬Â�, which refers to the fastest induced speed of the fan, 5500 rpm. The last 14 characters of the following string of 27 characters (e.g., mfc_setPoint_Toluene_200ppm) describe the analyte identity and concentration value for each particular measurement. Thus, the just mentioned example represents the class corresponding to the chemical analyte identity Ã¢â‚¬Å“TolueneÃ¢â‚¬Â� dosed at the nominal concentration value of 200 ppm. Finally, the last 2 or 3 digits in the name (e.g., Ã¢â‚¬Å“p7Ã¢â‚¬Â�) describe the line point location at which the chemo-sensory platform was located in the wind tunnel. Note that there is a shift of two numbers in the value of this position, i.e., the value p7 in actuality represents the line location 4 illustrated in Figure 2 of the cited manuscript. For example, in201106060617_board_setPoint_500V_fan_setPoint_060_mfc_setPoint_Toluene_200ppm_p7the entire text line stands for a stand-alone measurement of the chemo-sensory platform located at the line location L4 and in response to 200 ppm of Toluene collected on June 06 of 2011, at 06:17 am (PST), with an operating voltage applied to the heater of 5V and a nominal rotational speed of the exhaust fan of 3900 rpm.Having described the naming configuration adopted in the generated dataset, we describe the organization of the information in each of the attached files of the dataset. The data format encloses information relevant to each measurement file, containing all the time series indicated above (9 portable modules Ãƒâ€” 8 sensors, temperature and humidity values (oC and %, respectively), exhaust fan set-point and reading values, mass flow controller set-point and actual reading values (%), and reading time (ms)), which is organized as follows:Reading time (ms) fan_set_point fan_reading* mcf1_setpoint mcf2_setpoint mcf3_setpoint mcf1_read mcf2_read mcf3_read T RH 1 board1(Ãƒâ€” 8 chemical sensors) 1 board2(Ãƒâ€” 8 chemical sensors) 1 .... 1 board9(Ãƒâ€” 8 chemical sensors)where: Ã¢â‚¬Å“Reading time (ms)Ã¢â‚¬Â� is the time step for each recording (in ms, at a sample rate of 100 Hz), Ã¢â‚¬Å“fan_set_pointÃ¢â‚¬Â� and Ã¢â‚¬Å“fan_readingÃ¢â‚¬Â�, is the set-point and actual reading of the exhaust fan, respectively, Ã¢â‚¬Å“mcf1_setpointÃ¢â‚¬Â� to Ã¢â‚¬Å“mcf3_setpointÃ¢â‚¬Â� are the opening degree set-point values given to the mass flow controllers 1 to 3 during the experiment, respectively, Ã¢â‚¬Å“mcf1_readÃ¢â‚¬Â� to Ã¢â‚¬Å“mcf1_readÃ¢â‚¬Â� are the measured opening degree of mass flow controllers 1 to 3, respectively, Ã¢â‚¬Å“TÃ¢â‚¬Â� and Ã¢â‚¬Å“RÃ¢â‚¬Â� are the temperature and relative humidity values (in oC and %, respectively) during the entire experiment, and Ã¢â‚¬Å“board1(Ãƒâ€” 8 chemical sensors)Ã¢â‚¬Â� to Ã¢â‚¬Å“board9(Ãƒâ€” 8 chemical sensors)Ã¢â‚¬Â� are the 72 time series collected as a function of time from the 8 gas sensors (in KÃŽÂ©) integrating modules 1 to 9 in each location, respectively, each separated by the number Ã¢â‚¬Å“1Ã¢â‚¬Â� that stands as indicator label, forming thus the 72 time-series chemical sensor responses that is fetched to the classifier for training as described in the study. Note that there is a blank space between and among each column in the dataset.Thus, for example, inline1:22250    0    0    100    100    100    103    103    105    22.22    63.43    1    476    555    803    497    775    885    873    843    1    346    545    635    616    571    552    773    745    1    397    509    660    638    755    744    745    657    1    420    510    525    531    504    650    719    715    1    2201    449    652    1228    847    654    850    737    1    370    459    650    445    756    773    847    803    1    345    457    587    554    757    704    769    818    1    354    407    499    696    786    686    757    733    1    339    418    547    567    653    573    773    84The number Ã¢â‚¬Å“22250Ã¢â‚¬Â� stands for the recording made at time 22.25s, the following two numbers stand for the set-point and measured value of the fan speed, the following 6 numbers indicate the set-point (in this case, 100) and actual measured values of the MFC (103, 103, 105), the numbers Ã¢â‚¬Å“22.22Ã¢â‚¬Â� and Ã¢â‚¬Å“63.43Ã¢â‚¬Â� stand for the temperature and humidity values at that specific time recording, whereas the remaining 80 columns list the actual time series values for each measurement recording organized as described above, and in which the number Ã¢â‚¬Å“1Ã¢â‚¬Â� indicates the boundary between each sensor module board. The first and ninth boards correspond to the positions closer to the walls, whereas the board 5 is located in the main line orthogonal to the gas plume. For the exact location of each board, please refer to Figure 2 of the mentioned Journal article.*: we found out that the exhaust fan actual reading value registered on each file is not completely accurate, showing a Ã¢â‚¬Å“0Ã¢â‚¬Â� or other random values for some of the measurement recordings. Please discard this information value and utilize only the set point information for processing purposes; The value is accurate.Finally, to make the results presented in the associated article reproducible for the user of this read-me file, please use the hyper-parameter values described in the manuscript for the training task.","The dataset contains 18000 time-series recordings from a chemical detection platform at six different locations in a wind tunnel facility in response to ten high-priority chemical gaseous substancesNumber of instances:18000 times-series measurements recorded from a 72 metal-oxide gas sensor array-based chemical detection platform.Number of attributes (features):Every measurement contains 72 time-series recorded during 260 seconds, each collected at a sample rate of 100 Hz (samples per second).The dataset also contains time, temperature, and relative humidity information.The resulting dataset ultimately includes 75-time series composed of 26000 points.This archive contains 18000 time-series measurement recordings collected from an array of 72 metal-oxide gas sensors composing our sensing platform utilized in the detection and identification of potentially-dangerous chemical gaseous substances under complex environmental conditions, as reported in the related manuscript below. Our primary purpose is to make our dataset freely accessible on-line to the chemo-sensing research and machine-learning communities, as well as other interested communities, to develop alternative competitive solutions relevant to gas-sensing discrimination tasks in open sampling settings, such as the one pursued here, and/or navigation. The dataset can be used exclusively for research purposes. Commercial purposes are fully excluded.The dataset was gathered from December 2010 to April 2012 (16 months) in a 2.5 m Ãƒâ€” 1.2 m Ãƒâ€” 0.4 m wind tunnel research test-bed facility situated at the BioCircuits Institute, University of California San Diego. Specifically, our customized research facility, endowed with a computer-supervised mass flow controller-based continuous flow gas delivery system, operates in a propulsion open-cycle mode, by continuously drawing external turbulent air into and throughout the tunnel and exhausting it back to the outside, thereby creating a relatively less-turbulent airflow moving downstream towards the end of the test field, which is particularly suitable for applications pursued here that require injecting chemical poisonous agents or explosive mixtures because it prevents saturation. Being operated by a fully computerized environment Ã¢â‚¬â€�controlled by a player/stage robot server software programmed on C++ on a PC fitted with the appropriate serial cardsÃ¢â‚¬â€� and with minimum human intervention, the designed wind tunnel test-bed facility provides versatility for releasing the chemical substances of interest at the desired concentrations with high accuracy and in a highly reproducible manner during the entire experiment and simultaneously in preserving the appropriate environmental conditions to generate chemical gas plumes exhibiting turbulent patterns. A graphical illustration of the designed wind tunnel test-bed facility considered in this study along with the characteristics of the geometry of the problem as well as the exact locations of the chemical analyte source and chemo-sensory platform is presented in Figure 2 of the manuscript cited below. Actual pictures of the designed wind tunnel are also presented in the Supplementary Material, Figure S.1 of the accompanying manuscript.The resulting dataset induces a ten-class gas discrimination problem, comprising recordings from ten distinct pure chemical gases, namely Acetone, Acetaldehyde, Ammonia, Butanol, Ethylene, Methane, Methanol, Carbon Monoxide, Benzene, and Toluene. The goal is to identify and discriminate the mentioned chemical hazards at relevant concentrations regardless of the location of the sensory system platform within the annotated wind tunnel research facility as well as the environmental and parametric conditions induced in the setting (Please see manuscript for more details). See Table 1 on Vergara et a. 2013 (manuscript below) for specifics on the identity of chemical analyte hazards as well as their nominal concentration values at the outlet of the gas source in parts-per-million by volume (ppmv). Please refer to the manuscript below for a more details of the wind tunnel test-bed facility as well as for specifics on the collection procedure followed and the operating and environmental parameters utilized during the creation of the aforementioned dataset.The response of the sensor platform is read-out in the form of the resistance across the active sensitive film of each of the 72 gas sensors integrating the sensor array; hence, each measurement produced a 72-channel time series, each of which represented by a 260-second time series collected at a sample rate of 100 samples per second (Hz), reflecting all the environmental changes in the evaluated scenario. For a more detailed analysis and discussion on the processing of the time series as well as a graphical illustration of them please refer to Sections 2 and 3 and Figure 4, respectively, of the manuscript below.For manipulation purposes, the data is organized into eleven folders, each containing the number of measurements per chemical class identity and nominal concentration indicated above and described in the Table 2 of the manuscript. For example the folder named Ã¢â‚¬Å“Toluene_200Ã¢â‚¬Â� means the name of the gas identity is Toluene, which has been dosed at 200 ppmv. Each folder contains 6 folders, each representing the line location within the test area of the wind tunnel (location 1, L1, to location 6, L6, being L1 the closest point to the gas source) from which the set of time-series were recorded. In each of these folders there are 300 files, each of which corresponding to the number of measurements recorded at each location in the tunnel. The name of each file contains the exact log information of each of the measurements performed during the entire experiment, which is organized as follows. The first 12 digits of the file name (e.g., 201106060617) indicate the date and time at which each specific measurement was collected, starting from the year, month, day, and time. The last 4 digits in the following 19 characters of the name file, (e.g., board_setPoint_500V), indicate the fixed operating temperature value, represented by a voltage value applied to the embedded heating element in the chemical sensor, applied to the entire sensing platform, which can adopt nominal values from 4 to 6 V with an resolution value of 0.5 V. Note that the value 500V in the example is a graphical representation of the 5V value applied to the sensorÃ¢â‚¬â„¢s heater. For more details on the operating principles of the chemical sensors utilized in our platform please refer to Section 2 of the manuscript. The last 3 digits in the following 16 characters of the file name (e.g., fan_setPoint_060) indicates the set-point value of the nominal rotational speeds of the multiple-step motor-driven exhaust fan utilized to induce the distinct artificial airflows speed in the wind tunnel. Only three values were adopted in this condition: the value Ã¢â‚¬Å“000Ã¢â‚¬Â� in the file name, which indicates the slowest rotational speed (1500 rpm), the value Ã¢â‚¬Å“060Ã¢â‚¬Â�, indicating the mid-point rotational speed value of the fan (3900rpm), and the value Ã¢â‚¬Å“100Ã¢â‚¬Â�, which refers to the fastest induced speed of the fan, 5500 rpm. The last 14 characters of the following string of 27 characters (e.g., mfc_setPoint_Toluene_200ppm) describe the analyte identity and concentration value for each particular measurement. Thus, the just mentioned example represents the class corresponding to the chemical analyte identity Ã¢â‚¬Å“TolueneÃ¢â‚¬Â� dosed at the nominal concentration value of 200 ppm. Finally, the last 2 or 3 digits in the name (e.g., Ã¢â‚¬Å“p7Ã¢â‚¬Â�) describe the line point location at which the chemo-sensory platform was located in the wind tunnel. Note that there is a shift of two numbers in the value of this position, i.e., the value p7 in actuality represents the line location 4 illustrated in Figure 2 of the cited manuscript. For example, in201106060617_board_setPoint_500V_fan_setPoint_060_mfc_setPoint_Toluene_200ppm_p7the entire text line stands for a stand-alone measurement of the chemo-sensory platform located at the line location L4 and in response to 200 ppm of Toluene collected on June 06 of 2011, at 06:17 am (PST), with an operating voltage applied to the heater of 5V and a nominal rotational speed of the exhaust fan of 3900 rpm.Having described the naming configuration adopted in the generated dataset, we describe the organization of the information in each of the attached files of the dataset. The data format encloses information relevant to each measurement file, containing all the time series indicated above (9 portable modules Ãƒâ€” 8 sensors, temperature and humidity values (oC and %, respectively), exhaust fan set-point and reading values, mass flow controller set-point and actual reading values (%), and reading time (ms)), which is organized as follows:Reading time (ms) fan_set_point fan_reading* mcf1_setpoint mcf2_setpoint mcf3_setpoint mcf1_read mcf2_read mcf3_read T RH 1 board1(Ãƒâ€” 8 chemical sensors) 1 board2(Ãƒâ€” 8 chemical sensors) 1 .... 1 board9(Ãƒâ€” 8 chemical sensors)where: Ã¢â‚¬Å“Reading time (ms)Ã¢â‚¬Â� is the time step for each recording (in ms, at a sample rate of 100 Hz), Ã¢â‚¬Å“fan_set_pointÃ¢â‚¬Â� and Ã¢â‚¬Å“fan_readingÃ¢â‚¬Â�, is the set-point and actual reading of the exhaust fan, respectively, Ã¢â‚¬Å“mcf1_setpointÃ¢â‚¬Â� to Ã¢â‚¬Å“mcf3_setpointÃ¢â‚¬Â� are the opening degree set-point values given to the mass flow controllers 1 to 3 during the experiment, respectively, Ã¢â‚¬Å“mcf1_readÃ¢â‚¬Â� to Ã¢â‚¬Å“mcf1_readÃ¢â‚¬Â� are the measured opening degree of mass flow controllers 1 to 3, respectively, Ã¢â‚¬Å“TÃ¢â‚¬Â� and Ã¢â‚¬Å“RÃ¢â‚¬Â� are the temperature and relative humidity values (in oC and %, respectively) during the entire experiment, and Ã¢â‚¬Å“board1(Ãƒâ€” 8 chemical sensors)Ã¢â‚¬Â� to Ã¢â‚¬Å“board9(Ãƒâ€” 8 chemical sensors)Ã¢â‚¬Â� are the 72 time series collected as a function of time from the 8 gas sensors (in KÃŽÂ©) integrating modules 1 to 9 in each location, respectively, each separated by the number Ã¢â‚¬Å“1Ã¢â‚¬Â� that stands as indicator label, forming thus the 72 time-series chemical sensor responses that is fetched to the classifier for training as described in the study. Note that there is a blank space between and among each column in the dataset.Thus, for example, inline1:22250    0    0    100    100    100    103    103    105    22.22    63.43    1    476    555    803    497    775    885    873    843    1    346    545    635    616    571    552    773    745    1    397    509    660    638    755    744    745    657    1    420    510    525    531    504    650    719    715    1    2201    449    652    1228    847    654    850    737    1    370    459    650    445    756    773    847    803    1    345    457    587    554    757    704    769    818    1    354    407    499    696    786    686    757    733    1    339    418    547    567    653    573    773    84The number Ã¢â‚¬Å“22250Ã¢â‚¬Â� stands for the recording made at time 22.25s, the following two numbers stand for the set-point and measured value of the fan speed, the following 6 numbers indicate the set-point (in this case, 100) and actual measured values of the MFC (103, 103, 105), the numbers Ã¢â‚¬Å“22.22Ã¢â‚¬Â� and Ã¢â‚¬Å“63.43Ã¢â‚¬Â� stand for the temperature and humidity values at that specific time recording, whereas the remaining 80 columns list the actual time series values for each measurement recording organized as described above, and in which the number Ã¢â‚¬Å“1Ã¢â‚¬Â� indicates the boundary between each sensor module board. The first and ninth boards correspond to the positions closer to the walls, whereas the board 5 is located in the main line orthogonal to the gas plume. For the exact location of each board, please refer to Figure 2 of the mentioned Journal article.*: we found out that the exhaust fan actual reading value registered on each file is not completely accurate, showing a Ã¢â‚¬Å“0Ã¢â‚¬Â� or other random values for some of the measurement recordings. Please discard this information value and utilize only the set point information for processing purposes; The value is accurate.Finally, to make the results presented in the associated article reproducible for the user of this read-me file, please use the hyper-parameter values described in the manuscript for the training task."
Gas sensor array under flow modulation,Gas sensor array under flow modulation,The data set contains 58 time series acquired from 16 chemical sensors under gas flow modulation conditions. The sensors were exposed to different gaseous binary mixtures of acetone and ethanol.,Gas+sensor+array+under+flow+modulation,https://archive.ics.uci.edu/ml//machine-learning-databases/00308/,https://archive.ics.uci.edu/ml/datasets/Gas+sensor+array+under+flow+modulation,"The measured data was collected using a chemical sensing system based on an array of 16 metal-oxide gas sensors and an external mechanical ventilator to simulate the biological respiration cycle. The tested gas classes (12 in total) formed a relatively broad combination of two analytes, acetone and ethanol, in binary mixtures. Both, raw data set and feature data set, are available. In particular, two sets of low-frequency and high-frequency features are provided for a comparison study.The primary data analysis is supposed to be a multivariate regression with multiple responses (two responses), where the predictors were the features extracted from the sensor signals and the responses were the concentrations of two analytes, acetone and ethanol. This task is also known as a mixture quantification problem of two analytes. Please see the article (Ziyatdinov et al., 2014, Section 3.2) for such regression analysis based on partial least squares (PLS). A classification task is also possible given that a small number of samples per class is available, if all the 12 classes are used. Another classification problem can be stated to distinguish two pure analytes and mixtures of them.Three concentrations doses 0.1, 0.3 and 1 vol.% were used to prepare the dilutions in water for the pure analytes. The same dilutions were used to generate gas mixtures. The gas classes included samples of pure ethanol ('lab' attribute eth-0.1, eth-0.3 and eth-1), samples of pure acetone (ace-0.1, ace-0.3 and ace-1), samples of binary mixtures of ethanol and acetone (ace-0.1-eth-0.1, ace-0.1-eth-0.3, ace-0.3-eth-0.1, ace-0.1-eth-1 and ace-1-eth-0.1) and samples of water dilutions without any analyte (air) giving a total number of 12 classes. The choice of these analytes and concentrations was not affected by any particular application constraint, except that the sensors of selected models show consistent and diverse responses among the gas classes. The statistics on class distribution among 58 samples:eth-0.1: 6eth-0.3: 4eth-1: 5ace-0.1: 6ace-0.3: 6ace-1: 3ace-0.1-eth-0.1: 4ace-0.1-eth-0.3: 5ace-0.3-eth-0.1: 5ace-0.1-eth-1: 3ace-1-eth-0.1: 3air: 8The measurements were split into 5 batches ('batch' attribute), where each batch contained records approximately for all gas classes given in a random order. All the batches were collected in a time period of 4 days to minimize the effect of the long-term internal and environmental noise in the system. The statistics on batch distribution among 58 samples:day-1-morning: 19day-2-afternoon: 10day-2-morning: 10day-3-morning: 11day-4-afternoon: 8The array was composed of 16 metal-oxide gas sensors of 5 different TGS models from Figaro Inc. The sensors were configured for 10 different sensor conditioning profiles based on the combination of 5 TGS models and 2 sensor operating temperatures. The circuit board with the gas sensor array was placed in a 70 ml inner volume chamber connected to the mechanical ventilator. The device of the mechanical ventilator was made commercially available from Harvard Apparatus (Harvard Apparatus, Harvard Inspira Advanced Safety Ventilator Manual, Tech. rep., 2003). The mechanical ventilator includes a cylinder of volume 63.44 cm3 and a mechanical pump that takes air from the outlet 'Source' and pushes the air sample through the outlet 'To Animal'. The system also receives the sample again in the outlet 'From Animal' to close the loop, control the air pressure decay, and collect the exhaled air. The cylinder of the ventilator was fixed to a frequency of 5 breaths per minute, approximately equivalent to 0.08 Hz for all the measurements. See the article (Ziyatdinov et al., 2014, Section 2.1) for a detailed description of the experimental set up.The measurement protocol was the following: using a micropipette we delivered 10 ÃŽÂ¼l of the corresponding dilution to the vessel, which in turn was connected to the apparatus 'Source' channel to expose the sensor array to the generated gas sample. After 3 min of exposition, the source of the gas vapour was removed from the vessel to start the recovery phase. During the recovery phase, the system was sampling room air for 2 additional minutes to record the decay in the sensors signals. The recorded time-series signal for each sensor was acquired at the sampling frequency of 25 Hz during 5 min, resulting in 7500 data points per time-series of a single sensor. Note that 2 minutes of recovery phase was not sufficient to recover the sensors baseline and re-establish again the initial conditions in the gas chamber. Hence, although we acquired 2 minutes of recovery phase, the system was pumping air until the sensors recovered the baseline and the whole gas sample was exhausted from the gas chamber.The readout data was the output voltage of the sensor stored as resistance values according to the voltage-divider scheme and using the value of the load resistor. Hence, each data point in the array described the resistance of a sensor R(t) at a certain time of measurement t. The resistancevalues in the data set were normalized by subtracting the baseline value R0 = R(t0) at thestarting point of the measurement t0 and scaling by factor R0, (R(t) Ã¢Ë†â€™ R0)/R0. Note that such format of the measured raw data allows for comparison of responses among different sensors.Previously to computing the low-frequency and high-frequency features, the raw data were pre-processed by a set of digital filters. A median filter was used to remove the spikes in the signals. Then we employed two Butterworth filters of 3rd order: a low-pass filter (cut-off frequency 0.01 Hz) and a high-pass filter (pass-frequency 0.07 Hz) to generate the low/high frequency signals, respectively. Note that these low/high frequency signals (output of the two Butterworth filters) are not distributed within the data set.For feature extraction, both low-frequency and high-frequency sensor signals were divided by respiratory cycles, where each cycle was processed independently. Thus, a feature is referred to as a feature by respiratory cycle. Since high-frequency signals showed oscillatory behavior similar to a sine wave curve, we decided to follow a straightforward strategy for feature extraction in this case. We used amplitude of the high-frequency signal (oscillation) at every respiratory cycle as a feature. Low-frequency trajectories had a monotonic behaviour, and we used the magnitude of the low-frequency signal as a feature at every respiratory cycle. The magnitude value was taken at the same time of oscillation, where the amplitude of the high-frequency signal was measured. Note that the low-frequency and high-frequency features were computed only for the first 13 respiration cycles.In addition to the low/high frequency features, we also introduced a cycle-independent feature persingle measurement, defined as the maximum of the low-frequency signal over the course ofthe measurement.The first data analysis of the data set was presented in (Ziyatdinov et al., 2014), and the results reported there should be considered as a reference. The study aimed to characterize and explore the sensor signals in response to the modulated gas flow at a fixed respiration frequency. It was expected to confirm a superior performance of the proposed system under the gas flow modulation on the early detection scenario. The acquired modulated signals were decomposed into low-frequency and high-frequency components, and the resulted feature sets were compared in terms of the discrimination performance. Note that it was assumed that the low-frequency part of the modulated signals approximate the signals that would be measured under the standard constant flow rate mode (such assumption was empirically confirmed by observing the transient dynamics).The strategy in signal- and data-processing applied in (Ziyatdinov et al., 2014) was straightforward, and the analysis can be improved in a number of ways, on the stages of feature extraction and/or pattern recognition. Hence, the raw data stored in 'rawdata.csv.gz' file is intended for testing feature extraction methods, while the features computed in (Ziyatdinov et al., 2014) and stored in 'features.csv' can be readily used in testing pattern recognition methods.Additional links:1. Data vizualization of time series in the data set: [Web Link].2. Code repository for reproducible analysis applied to the data set: [Web Link].",Computer,"The data set is organized in two 'csv' files, 'rawdata.csv.gz' (4.5 MB) and 'features.csv' (200 kB). The raw data are stored in the first file 'rawdata.csv.gz', where each line represents a single measurement per sensor. Consequently, one needs to read specific 16 consecutive lines to get a single measurement from 16 sensors. The features extracted in (Ziyatdinov et al., 2014) are provided in the second file 'features.csv', where each line represents features extracted from all 16 time-series of the sensors (a single measurement).Raw data of each sample contains 16 time-series (one time-series per sensor). Each time-series was recorded during 5 min at a sample rate of 25 Hz (samples per second), providing 7500 data points per time-series. The total number of attributes per sample in raw data is 120000.Feature data set includes three types of features extracted from each time-series. Each time-series (one time-series per sensor) is associated with 1 maximum features, 13 high-frequency features and 13 low-frequency features (the features correspond to the first 13 respiration cycles, respectively). The total number of attributes per sample in feature data set is 432.Both tables of the raw data and features have common attributes:'exp': integer (range 100-181); represents the experiment number registered in the laboratory.'batch': string (5 values); represents the batch identificator of the measurements;'ace_conc': float (range 0-1); the concentration of the acetone analyte given in vol.%;'eth_conc': float (range 0-1); the concentration of the ethanol analyte given in vol.%;'lab': string (12 values); the class label of the gas;'gas': string (4 values); another class label that encodes either pure analytes, mixture or air;'col': string (12 values); the color code for better plotting among the class labels.The table of the raw data has specific attributes:'sensor': integer (range 1-16); the sensor number;'sample': integer (range 1-58); the sample number;'dR_t': float; represents the value of the time series for a given sensor and for a given sample, which were measured at the time instant , where  takes the value from 1 to 7500.The table of the features has specific attributes:'S_max': float; represents the value of the maximum feature extracted from the time-series of sensor ;'S_r_Alf': float; represents the low-frequency feature extracted from the time-series of sensor  at the respiration , where  takes the value from 1 to 16,  takes the value from 1 to 13;'S_r_Ahf': float; represents the high-frequency feature extracted from the time-series of sensor  at the respiration , where  takes the value from 1 to 16,  takes the value from 1 to 13.","The data set contains 58 time series acquired from 16 chemical sensors under gas flow modulation conditions. The sensors were exposed to different gaseous binary mixtures of acetone and ethanol.The measured data was collected using a chemical sensing system based on an array of 16 metal-oxide gas sensors and an external mechanical ventilator to simulate the biological respiration cycle. The tested gas classes (12 in total) formed a relatively broad combination of two analytes, acetone and ethanol, in binary mixtures. Both, raw data set and feature data set, are available. In particular, two sets of low-frequency and high-frequency features are provided for a comparison study.The primary data analysis is supposed to be a multivariate regression with multiple responses (two responses), where the predictors were the features extracted from the sensor signals and the responses were the concentrations of two analytes, acetone and ethanol. This task is also known as a mixture quantification problem of two analytes. Please see the article (Ziyatdinov et al., 2014, Section 3.2) for such regression analysis based on partial least squares (PLS). A classification task is also possible given that a small number of samples per class is available, if all the 12 classes are used. Another classification problem can be stated to distinguish two pure analytes and mixtures of them.Three concentrations doses 0.1, 0.3 and 1 vol.% were used to prepare the dilutions in water for the pure analytes. The same dilutions were used to generate gas mixtures. The gas classes included samples of pure ethanol ('lab' attribute eth-0.1, eth-0.3 and eth-1), samples of pure acetone (ace-0.1, ace-0.3 and ace-1), samples of binary mixtures of ethanol and acetone (ace-0.1-eth-0.1, ace-0.1-eth-0.3, ace-0.3-eth-0.1, ace-0.1-eth-1 and ace-1-eth-0.1) and samples of water dilutions without any analyte (air) giving a total number of 12 classes. The choice of these analytes and concentrations was not affected by any particular application constraint, except that the sensors of selected models show consistent and diverse responses among the gas classes. The statistics on class distribution among 58 samples:eth-0.1: 6eth-0.3: 4eth-1: 5ace-0.1: 6ace-0.3: 6ace-1: 3ace-0.1-eth-0.1: 4ace-0.1-eth-0.3: 5ace-0.3-eth-0.1: 5ace-0.1-eth-1: 3ace-1-eth-0.1: 3air: 8The measurements were split into 5 batches ('batch' attribute), where each batch contained records approximately for all gas classes given in a random order. All the batches were collected in a time period of 4 days to minimize the effect of the long-term internal and environmental noise in the system. The statistics on batch distribution among 58 samples:day-1-morning: 19day-2-afternoon: 10day-2-morning: 10day-3-morning: 11day-4-afternoon: 8The array was composed of 16 metal-oxide gas sensors of 5 different TGS models from Figaro Inc. The sensors were configured for 10 different sensor conditioning profiles based on the combination of 5 TGS models and 2 sensor operating temperatures. The circuit board with the gas sensor array was placed in a 70 ml inner volume chamber connected to the mechanical ventilator. The device of the mechanical ventilator was made commercially available from Harvard Apparatus (Harvard Apparatus, Harvard Inspira Advanced Safety Ventilator Manual, Tech. rep., 2003). The mechanical ventilator includes a cylinder of volume 63.44 cm3 and a mechanical pump that takes air from the outlet 'Source' and pushes the air sample through the outlet 'To Animal'. The system also receives the sample again in the outlet 'From Animal' to close the loop, control the air pressure decay, and collect the exhaled air. The cylinder of the ventilator was fixed to a frequency of 5 breaths per minute, approximately equivalent to 0.08 Hz for all the measurements. See the article (Ziyatdinov et al., 2014, Section 2.1) for a detailed description of the experimental set up.The measurement protocol was the following: using a micropipette we delivered 10 ÃŽÂ¼l of the corresponding dilution to the vessel, which in turn was connected to the apparatus 'Source' channel to expose the sensor array to the generated gas sample. After 3 min of exposition, the source of the gas vapour was removed from the vessel to start the recovery phase. During the recovery phase, the system was sampling room air for 2 additional minutes to record the decay in the sensors signals. The recorded time-series signal for each sensor was acquired at the sampling frequency of 25 Hz during 5 min, resulting in 7500 data points per time-series of a single sensor. Note that 2 minutes of recovery phase was not sufficient to recover the sensors baseline and re-establish again the initial conditions in the gas chamber. Hence, although we acquired 2 minutes of recovery phase, the system was pumping air until the sensors recovered the baseline and the whole gas sample was exhausted from the gas chamber.The readout data was the output voltage of the sensor stored as resistance values according to the voltage-divider scheme and using the value of the load resistor. Hence, each data point in the array described the resistance of a sensor R(t) at a certain time of measurement t. The resistancevalues in the data set were normalized by subtracting the baseline value R0 = R(t0) at thestarting point of the measurement t0 and scaling by factor R0, (R(t) Ã¢Ë†â€™ R0)/R0. Note that such format of the measured raw data allows for comparison of responses among different sensors.Previously to computing the low-frequency and high-frequency features, the raw data were pre-processed by a set of digital filters. A median filter was used to remove the spikes in the signals. Then we employed two Butterworth filters of 3rd order: a low-pass filter (cut-off frequency 0.01 Hz) and a high-pass filter (pass-frequency 0.07 Hz) to generate the low/high frequency signals, respectively. Note that these low/high frequency signals (output of the two Butterworth filters) are not distributed within the data set.For feature extraction, both low-frequency and high-frequency sensor signals were divided by respiratory cycles, where each cycle was processed independently. Thus, a feature is referred to as a feature by respiratory cycle. Since high-frequency signals showed oscillatory behavior similar to a sine wave curve, we decided to follow a straightforward strategy for feature extraction in this case. We used amplitude of the high-frequency signal (oscillation) at every respiratory cycle as a feature. Low-frequency trajectories had a monotonic behaviour, and we used the magnitude of the low-frequency signal as a feature at every respiratory cycle. The magnitude value was taken at the same time of oscillation, where the amplitude of the high-frequency signal was measured. Note that the low-frequency and high-frequency features were computed only for the first 13 respiration cycles.In addition to the low/high frequency features, we also introduced a cycle-independent feature persingle measurement, defined as the maximum of the low-frequency signal over the course ofthe measurement.The first data analysis of the data set was presented in (Ziyatdinov et al., 2014), and the results reported there should be considered as a reference. The study aimed to characterize and explore the sensor signals in response to the modulated gas flow at a fixed respiration frequency. It was expected to confirm a superior performance of the proposed system under the gas flow modulation on the early detection scenario. The acquired modulated signals were decomposed into low-frequency and high-frequency components, and the resulted feature sets were compared in terms of the discrimination performance. Note that it was assumed that the low-frequency part of the modulated signals approximate the signals that would be measured under the standard constant flow rate mode (such assumption was empirically confirmed by observing the transient dynamics).The strategy in signal- and data-processing applied in (Ziyatdinov et al., 2014) was straightforward, and the analysis can be improved in a number of ways, on the stages of feature extraction and/or pattern recognition. Hence, the raw data stored in 'rawdata.csv.gz' file is intended for testing feature extraction methods, while the features computed in (Ziyatdinov et al., 2014) and stored in 'features.csv' can be readily used in testing pattern recognition methods.Additional links:1. Data vizualization of time series in the data set: [Web Link].2. Code repository for reproducible analysis applied to the data set: [Web Link].The data set is organized in two 'csv' files, 'rawdata.csv.gz' (4.5 MB) and 'features.csv' (200 kB). The raw data are stored in the first file 'rawdata.csv.gz', where each line represents a single measurement per sensor. Consequently, one needs to read specific 16 consecutive lines to get a single measurement from 16 sensors. The features extracted in (Ziyatdinov et al., 2014) are provided in the second file 'features.csv', where each line represents features extracted from all 16 time-series of the sensors (a single measurement).Raw data of each sample contains 16 time-series (one time-series per sensor). Each time-series was recorded during 5 min at a sample rate of 25 Hz (samples per second), providing 7500 data points per time-series. The total number of attributes per sample in raw data is 120000.Feature data set includes three types of features extracted from each time-series. Each time-series (one time-series per sensor) is associated with 1 maximum features, 13 high-frequency features and 13 low-frequency features (the features correspond to the first 13 respiration cycles, respectively). The total number of attributes per sample in feature data set is 432.Both tables of the raw data and features have common attributes:'exp': integer (range 100-181); represents the experiment number registered in the laboratory.'batch': string (5 values); represents the batch identificator of the measurements;'ace_conc': float (range 0-1); the concentration of the acetone analyte given in vol.%;'eth_conc': float (range 0-1); the concentration of the ethanol analyte given in vol.%;'lab': string (12 values); the class label of the gas;'gas': string (4 values); another class label that encodes either pure analytes, mixture or air;'col': string (12 values); the color code for better plotting among the class labels.The table of the raw data has specific attributes:'sensor': integer (range 1-16); the sensor number;'sample': integer (range 1-58); the sample number;'dR_t': float; represents the value of the time series for a given sensor and for a given sample, which were measured at the time instant , where  takes the value from 1 to 7500.The table of the features has specific attributes:'S_max': float; represents the value of the maximum feature extracted from the time-series of sensor ;'S_r_Alf': float; represents the low-frequency feature extracted from the time-series of sensor  at the respiration , where  takes the value from 1 to 16,  takes the value from 1 to 13;'S_r_Ahf': float; represents the high-frequency feature extracted from the time-series of sensor  at the respiration , where  takes the value from 1 to 16,  takes the value from 1 to 13."
Gas sensor array under dynamic gas mixtures,Gas sensor array under dynamic gas mixtures,"The data set contains the recordings of 16 chemical sensors exposed to two dynamic gas mixtures at varying concentrations. For each mixture, signals were acquired continuously during 12 hours.",Gas+sensor+array+under+dynamic+gas+mixtures,https://archive.ics.uci.edu/ml//machine-learning-databases/00322/,https://archive.ics.uci.edu/ml/datasets/Gas+sensor+array+under+dynamic+gas+mixtures,"This data set contains the acquired time series from 16 chemical sensors exposed to gas mixtures at varying concentration levels. In particular, we generated two gas mixtures: Ethylene and Methane in air, and Ethylene and CO in air. Each measurement was constructed by the continuous acquisition of the 16-sensor array signals for a duration of about 12 hours without interruption. The data set was collected in a gas delivery platform facility at the ChemoSignals Laboratory in the BioCircuits Institute, University of California San Diego. The measurement system platform provides versatility for obtaining the desired concentrations of the chemical substances of interest with high accuracy and in a highly reproducible manner. The sensor array included 16 chemical sensors (Figaro Inc., US) of 4 different types: TGS-2600, TGS-2602, TGS-2610, TGS-2620 (4 units of each type). The sensors were integrated with customized signal conditioning and control electronics. The operating voltage of the sensors, which controls the sensorsÃ¢â‚¬â„¢ operating temperature, was kept constant at 5 V for the whole duration of the experiments. The sensorsÃ¢â‚¬â„¢ conductivities were acquired continuously at a sampling frequency of 100 Hz. The sensor array was placed in a 60 ml measurement chamber, where the gas sample was injected at a constant flow of 300 ml/min.Each measurement was constructed by the continuous acquisition of the 16-sensor array signals while concentration levels changed randomly. For each measurement (each gas mixture), the signals were acquired continuously for about 12 hours without interruption. The concentration transitions were set at random times (in the interval 80-120s) and to random concentration levels. The data set was constructed such that all possible transitions are present: increasing, decreasing, or setting to zero the concentration of one volatile while the concentration of the other volatile is kept constant (either at a fixed or at zero concentration level). At the beginning, ending, and approximately every 10,000 s, we inserted additional predefined concentration patterns with pure gas mixtures.The concentration ranges for Ethylene, Methane, and CO were selected such that the induced magnitudes of the sensor responses were similar. Moreover, for gas mixtures, lower concentration levels were favored. Therefore, the multivariate response of the sensors to the presented set of stimuli is challenging since none of the configurations (singlegas or mixture presentation) can be easily identified from the magnitude of sensorsÃ¢â‚¬â„¢ responses. In particular Ethylene concentration ranges from 0-20 ppm; 0-600 ppm for CO; and 0-300 ppm for Methane.The primary purpose of making this data set freely accessible on-line is to provide extensive and continuous time series acquired from chemical sensors to the sensor and artificial intelligence research communities to develop and test strategies to solve a wide variety of tasks. In particular, the data set may be useful to develop algorithms for continuous monitoring or improve response time of sensory systems. Also, the repetition of the same type of sensors in the array will allow further investigation on sensor variability (reproducibility of sensors of the same kind). Other interesting topics may include sensor failure (to what extent system predictions degrade when sensors start failing) or calibration transfer (whether the model for one sensor can be extended to other sensors).More information on the generated data set can be found in Fonollosa et al. 'Reservoir Computing compensates slow response of chemosensor arrays exposed to fast varying gas concentrations in continuous monitoring'; Sensors and Actuators B, 2015. The data set can be used exclusively for research purposes. Commercial purposes are fully excluded. ",Computer,"The data is presented in two different files: Each file contains the data from one mixture. The file ethylene_CO.txt contains the recordings from the sensors when exposed to mixtures of Ethylene and CO in air. The file ethylene_methane.txt contains the acquired time series induced by the mixture of Methane and Ethylene in air.The structure of the files is the same: Data is distributed in 19 columns. First column represents time (in seconds), second column represents Methane (or CO) concentration set point (in ppm), third column details Ethylene concentration set point (in ppm), and the following 16 columns show the recordings of the sensor array. Files include a header (one line) with the information of each column:Time (seconds), Methane conc (ppm), Ethylene conc (ppm), sensor readings (16 channels)The order of the sensors in the files is as follows:TGS2602; TGS2602; TGS2600; TGS2600; TGS2610; TGS2610; TGS2620; TGS2620; TGS2602; TGS2602; TGS2600; TGS2600; TGS2610; TGS2610; TGS2620; TGS2620Sensors' readings can be converted to KOhms by 40.000/S_i, where S_i is the value provided in the text files.","The data set contains the recordings of 16 chemical sensors exposed to two dynamic gas mixtures at varying concentrations. For each mixture, signals were acquired continuously during 12 hours.This data set contains the acquired time series from 16 chemical sensors exposed to gas mixtures at varying concentration levels. In particular, we generated two gas mixtures: Ethylene and Methane in air, and Ethylene and CO in air. Each measurement was constructed by the continuous acquisition of the 16-sensor array signals for a duration of about 12 hours without interruption. The data set was collected in a gas delivery platform facility at the ChemoSignals Laboratory in the BioCircuits Institute, University of California San Diego. The measurement system platform provides versatility for obtaining the desired concentrations of the chemical substances of interest with high accuracy and in a highly reproducible manner. The sensor array included 16 chemical sensors (Figaro Inc., US) of 4 different types: TGS-2600, TGS-2602, TGS-2610, TGS-2620 (4 units of each type). The sensors were integrated with customized signal conditioning and control electronics. The operating voltage of the sensors, which controls the sensorsÃ¢â‚¬â„¢ operating temperature, was kept constant at 5 V for the whole duration of the experiments. The sensorsÃ¢â‚¬â„¢ conductivities were acquired continuously at a sampling frequency of 100 Hz. The sensor array was placed in a 60 ml measurement chamber, where the gas sample was injected at a constant flow of 300 ml/min.Each measurement was constructed by the continuous acquisition of the 16-sensor array signals while concentration levels changed randomly. For each measurement (each gas mixture), the signals were acquired continuously for about 12 hours without interruption. The concentration transitions were set at random times (in the interval 80-120s) and to random concentration levels. The data set was constructed such that all possible transitions are present: increasing, decreasing, or setting to zero the concentration of one volatile while the concentration of the other volatile is kept constant (either at a fixed or at zero concentration level). At the beginning, ending, and approximately every 10,000 s, we inserted additional predefined concentration patterns with pure gas mixtures.The concentration ranges for Ethylene, Methane, and CO were selected such that the induced magnitudes of the sensor responses were similar. Moreover, for gas mixtures, lower concentration levels were favored. Therefore, the multivariate response of the sensors to the presented set of stimuli is challenging since none of the configurations (singlegas or mixture presentation) can be easily identified from the magnitude of sensorsÃ¢â‚¬â„¢ responses. In particular Ethylene concentration ranges from 0-20 ppm; 0-600 ppm for CO; and 0-300 ppm for Methane.The primary purpose of making this data set freely accessible on-line is to provide extensive and continuous time series acquired from chemical sensors to the sensor and artificial intelligence research communities to develop and test strategies to solve a wide variety of tasks. In particular, the data set may be useful to develop algorithms for continuous monitoring or improve response time of sensory systems. Also, the repetition of the same type of sensors in the array will allow further investigation on sensor variability (reproducibility of sensors of the same kind). Other interesting topics may include sensor failure (to what extent system predictions degrade when sensors start failing) or calibration transfer (whether the model for one sensor can be extended to other sensors).More information on the generated data set can be found in Fonollosa et al. 'Reservoir Computing compensates slow response of chemosensor arrays exposed to fast varying gas concentrations in continuous monitoring'; Sensors and Actuators B, 2015. The data set can be used exclusively for research purposes. Commercial purposes are fully excluded. The data is presented in two different files: Each file contains the data from one mixture. The file ethylene_CO.txt contains the recordings from the sensors when exposed to mixtures of Ethylene and CO in air. The file ethylene_methane.txt contains the acquired time series induced by the mixture of Methane and Ethylene in air.The structure of the files is the same: Data is distributed in 19 columns. First column represents time (in seconds), second column represents Methane (or CO) concentration set point (in ppm), third column details Ethylene concentration set point (in ppm), and the following 16 columns show the recordings of the sensor array. Files include a header (one line) with the information of each column:Time (seconds), Methane conc (ppm), Ethylene conc (ppm), sensor readings (16 channels)The order of the sensors in the files is as follows:TGS2602; TGS2602; TGS2600; TGS2600; TGS2610; TGS2610; TGS2620; TGS2620; TGS2602; TGS2602; TGS2600; TGS2600; TGS2610; TGS2610; TGS2620; TGS2620Sensors' readings can be converted to KOhms by 40.000/S_i, where S_i is the value provided in the text files."
Gas sensor array temperature modulation,Gas sensor array temperature modulation,"A chemical detection platform composed of 14 temperature-modulated metal oxide (MOX) gas sensors was exposed during 3 weeks to mixtures of carbon monoxide and humid synthetic air in a gas chamber.
",Gas+sensor+array+temperature+modulation,https://archive.ics.uci.edu/ml//machine-learning-databases/00487/,https://archive.ics.uci.edu/ml/datasets/Gas+sensor+array+temperature+modulation,"A chemical detection platform composed of 14 temperature-modulated metal oxide semiconductor (MOX) gas sensors was exposed to dynamic mixtures of carbon monoxide (CO) and humid synthetic air in a gas chamber. The acquired time series of the sensors and the measured values of CO concentration, humidity and temperature inside the gas chamber are provided. a) Chemical detection platform: The chemical detection platform was composed of 14 MOX gas sensors that generate a time-dependent multivariate response to the different gas stimuli. The utilized sensors were made commercially available by Figaro Engineering (7 units of TGS 3870-A04) and FIS (7 units of SB-500-12).The operating temperature of the sensors was controlled by the built-in heater, which voltage was modulated in the range 0.2-0.9 V in cycles of 20 and 25 s, following the manufacturer recommendations (0.9 V for 5s, 0.2 V for 20s, 0.9 V for 5 s, 0.2 V for 25 s, ...). The sensors were pre-heated for one week before starting the experiments.The MOX read-out circuits consisted of voltage dividers with 1 MOhm load resistors and powered at 5V.The output voltage of the sensors was sampled at 3.5 Hz using an Agilent HP34970A/34901A DAQ configured at 15 bits of precision and input impedance greater than 10 GOhm.b) Generator of dynamic gas mixturesDynamic mixtures of CO and humid synthetic air were delivered from high purity gases in cylinders to a small-sized polytetrafluoroethylene (PTFE) test chamber (250 cm3 internal volume), by means of a piping system and mass flow controllers (MFCs).Gas mixing was performed using mass flow controllers (MFC),which controlled three different gas streams (CO, wet air and dry air). These streams were delivered from high quality pressurizedgases in cylinders. The selected MFCs (EL-FLOW Select, Bronkhorst) had full scale flow rates of 1000 mln/min for the dry and wet air streams and 3 mln/min for the CO channel. The CO bottle contained 1600 ppm of CO diluted in synthetic air with 21 Ã‚Â± 1% O2. The relative uncertainty in the generated CO concentration was below 5.5%.The wet and dry air streams were both delivered from a synthetic air bottle with 99.995% purity and 21 Ã‚Â± 1% O2. Humidification of the wet stream was based on the saturation method using a glass bubbler (Drechsler bottles). c)  Temperature/humidity valuesA temperature/humidity sensor (SHT75, from Sensirion) provided reference humidity and temperature values inside the test chamber with tolerance below 1.8% r.h. and 0.5 Ã‚ÂºC, respectively, every 5 s.The temperature variations inside the gas chamber, for each experiment, were below 3 Ã‚ÂºC. d) Experimental protocol: Each experiment consisted on 100 measurements: 10 experimental concentrations uniformly distributed in the range 0-20 ppm and 10 replicates per concentration. Each replicate had a relative humidity randomly chosen from a uniform distribution between 15% and 75% r.h. At the beginning of each experiment, the gas chamber was cleaned for 15 min using a stream of synthetic air at a flow rate of 240 mln/min. After that, the gas mixtures were released in random order at a constant flow rate of 240 mln/min for 15 min each. A single experiment lasted 25 hours (100 samples x 15 minutes/sample) and was replicated on 13 working days spanning a natural period of 17 days.",Computer,"The dataset is presented in 13 text files, where each file corresponds to a different measurement day. The filenames indicate the timestamp (yyyymmdd_HHMMSS) of the start of the measurements.Each file includes the acquired time series, presented in 20 columns: Time (s), CO concentration (ppm), Humidity (%r.h.), Temperature (Ã‚ÂºC), Flow rate (mL/min), Heater voltage (V), and the resistance of the 14 gas sensors: R1 (MOhm),R2 (MOhm),R3 (MOhm),R4 (MOhm),R5 (MOhm),R6 (MOhm),R7 (MOhm),R8 (MOhm),R9 (MOhm),R10 (MOhm),R11 (MOhm),R12 (MOhm),R13 (MOhm),R14 (MOhm)Resistance values R1-R7 correspond to FIGARO TGS 3870 A-04 sensors, whereas R8-R14 correspond to FIS SB-500-12 units.The time series are sampled at 3.5 Hz.","A chemical detection platform composed of 14 temperature-modulated metal oxide (MOX) gas sensors was exposed during 3 weeks to mixtures of carbon monoxide and humid synthetic air in a gas chamber.
A chemical detection platform composed of 14 temperature-modulated metal oxide semiconductor (MOX) gas sensors was exposed to dynamic mixtures of carbon monoxide (CO) and humid synthetic air in a gas chamber. The acquired time series of the sensors and the measured values of CO concentration, humidity and temperature inside the gas chamber are provided. a) Chemical detection platform: The chemical detection platform was composed of 14 MOX gas sensors that generate a time-dependent multivariate response to the different gas stimuli. The utilized sensors were made commercially available by Figaro Engineering (7 units of TGS 3870-A04) and FIS (7 units of SB-500-12).The operating temperature of the sensors was controlled by the built-in heater, which voltage was modulated in the range 0.2-0.9 V in cycles of 20 and 25 s, following the manufacturer recommendations (0.9 V for 5s, 0.2 V for 20s, 0.9 V for 5 s, 0.2 V for 25 s, ...). The sensors were pre-heated for one week before starting the experiments.The MOX read-out circuits consisted of voltage dividers with 1 MOhm load resistors and powered at 5V.The output voltage of the sensors was sampled at 3.5 Hz using an Agilent HP34970A/34901A DAQ configured at 15 bits of precision and input impedance greater than 10 GOhm.b) Generator of dynamic gas mixturesDynamic mixtures of CO and humid synthetic air were delivered from high purity gases in cylinders to a small-sized polytetrafluoroethylene (PTFE) test chamber (250 cm3 internal volume), by means of a piping system and mass flow controllers (MFCs).Gas mixing was performed using mass flow controllers (MFC),which controlled three different gas streams (CO, wet air and dry air). These streams were delivered from high quality pressurizedgases in cylinders. The selected MFCs (EL-FLOW Select, Bronkhorst) had full scale flow rates of 1000 mln/min for the dry and wet air streams and 3 mln/min for the CO channel. The CO bottle contained 1600 ppm of CO diluted in synthetic air with 21 Ã‚Â± 1% O2. The relative uncertainty in the generated CO concentration was below 5.5%.The wet and dry air streams were both delivered from a synthetic air bottle with 99.995% purity and 21 Ã‚Â± 1% O2. Humidification of the wet stream was based on the saturation method using a glass bubbler (Drechsler bottles). c)  Temperature/humidity valuesA temperature/humidity sensor (SHT75, from Sensirion) provided reference humidity and temperature values inside the test chamber with tolerance below 1.8% r.h. and 0.5 Ã‚ÂºC, respectively, every 5 s.The temperature variations inside the gas chamber, for each experiment, were below 3 Ã‚ÂºC. d) Experimental protocol: Each experiment consisted on 100 measurements: 10 experimental concentrations uniformly distributed in the range 0-20 ppm and 10 replicates per concentration. Each replicate had a relative humidity randomly chosen from a uniform distribution between 15% and 75% r.h. At the beginning of each experiment, the gas chamber was cleaned for 15 min using a stream of synthetic air at a flow rate of 240 mln/min. After that, the gas mixtures were released in random order at a constant flow rate of 240 mln/min for 15 min each. A single experiment lasted 25 hours (100 samples x 15 minutes/sample) and was replicated on 13 working days spanning a natural period of 17 days.The dataset is presented in 13 text files, where each file corresponds to a different measurement day. The filenames indicate the timestamp (yyyymmdd_HHMMSS) of the start of the measurements.Each file includes the acquired time series, presented in 20 columns: Time (s), CO concentration (ppm), Humidity (%r.h.), Temperature (Ã‚ÂºC), Flow rate (mL/min), Heater voltage (V), and the resistance of the 14 gas sensors: R1 (MOhm),R2 (MOhm),R3 (MOhm),R4 (MOhm),R5 (MOhm),R6 (MOhm),R7 (MOhm),R8 (MOhm),R9 (MOhm),R10 (MOhm),R11 (MOhm),R12 (MOhm),R13 (MOhm),R14 (MOhm)Resistance values R1-R7 correspond to FIGARO TGS 3870 A-04 sensors, whereas R8-R14 correspond to FIS SB-500-12 units.The time series are sampled at 3.5 Hz."
Gas sensor array exposed to turbulent gas mixtures,Gas sensor array exposed to turbulent gas mixtures,A chemical detection platform composed of 8 chemoresistive gas sensors was exposed to turbulent gas mixtures generated naturally in a wind tunnel. The acquired time series of the sensors are provided.,Gas+sensor+array+exposed+to+turbulent+gas+mixtures,https://archive.ics.uci.edu/ml//machine-learning-databases/00309/,https://archive.ics.uci.edu/ml/datasets/Gas+sensor+array+exposed+to+turbulent+gas+mixtures,"A chemical detection platform composed of 8 chemo-resistive gas sensors was exposed to turbulent gas mixtures generated naturally in a wind tunnel. The acquired time series of the sensors are provided.The experimental setup was designed to test gas sensors in realistic environments. Traditionally, chemical detection systems based on chemo-resistive sensors include a gas chamber to control the sample air flow and minimize turbulence. Instead, we utilized a wind tunnel with two independent gas sources that generate two gas plumes. The plumes get naturally mixed along a turbulent flow and reproduce the gas concentration fluctuations observed in natural environments. Hence, the gas sensors can capture the spatio-temporal information contained in the gas plumes.a) Chemical detection platform:The chemical detection platform was composed of 8 MOX gas sensors that generate a time-dependent multivariate response to the different gas stimuli. The utilized sensors were made commercially available by Figaro (TGS2611, TGS2612, TGS2610, TGS2600, TGS2602 TGS2620). The operating temperature of the sensors was controlled by the built-in heater, which was kept at a constant voltage of 5V. The detection platform also includes Temperature and Relative Humidity sensors. The generated sensors' responses were acquired at a sampling rate of 20 ms for the whole duration of the experiment.b) Wind tunnel:In order to generate two independent gas plumes in an open environment, we built a 2.5 m x 1.2 m x 0.4 m wind tunnel facility with two gas sources (labeled as source1 and source2). Each source was controlled independently to release the selected volatiles at different flow rates, which generated different concentration levels in the sensors' position. The wind generator created a turbulent flow that constantly displaced the introduced volatiles towards the exhaust outlet.c) Experimental protocol:We exposed the detection unit to mixtures of Ethylene with Methane or Carbon Monoxide. The mixtures were originated releasing Ethylene at source1 and releasing Methane / Carbon Monoxide at source2.Each volatile was released at four different flows (zero z, low l, medium m, and high h), providing up to 30 different mixture configurations: 15 mixtures of Ethylene with CO (h+h, h+m, h+l, Ã¢â‚¬Â¦, z+h, z+m, z+l) and 15 mixtures of Ethylene with Methane. Each configuration was repeated 6 times. Hence, the complete dataset was composed of 180 measurements, which were performed in a random order. By means of a GCMS system, the mean concentration levels at the sensors' location were estimated: Ethylene (l: 31 ppm, m: 46 ppm, h: 96 ppm), CO (l: 270 ppm, m: 397 ppm, h: 460 ppm), Methane (l: 51 ppm, m: 115 ppm, h: 131 ppm). It is worth noting that GC-MS systems only provide the mean value of the concentration and are not sensitive to concentration fluctuations.Each measurement, which had a total duration of 300 seconds, was performed as follows: Initially no gas was released and clean air flowed along the wind tunnel. 60 seconds after, both sources started to release the corresponding volatile at the specified flow rate. The duration of the gas release was 180 s. Finally, the system acquired the recovery to the baseline for another 60 s. ",Computer,"The dataset is presented in 180 text files, where each file corresponds to a different measurement. The filenames identify the measurements as follows: The first 3 characters of the filename are a local identifier, which is not related to the order of the measurements; characters 5-8 indicate the concentration level of Ethylene released at source2 (n: zero, L: Low, M: Medium, H: High); the last 4 characters indicate the gas released at source1 (Me: Methane, CO: Carbon Monoxide) and the concentration level. For example, file 007_Et_L_Me_H contains time series acquired when Ethylene was released at Low concentration (31 ppm, mean concentration) and Methane at High concentration (131 ppm, mean concentration). Each file includes the acquired time series, presented in 11 columns: Time (s), Temperature (oC), Relative Humidity (%), and the readings of the 8 gas sensors: TGS2600, TGS2602, TGS2602, TGS2620, TGS2612, TGS2620, TGS2611, TGS2610. The readings can be converted to sensor resistance by Rs(KOhm)=10*(3110-A)/A, where A is the acquired value.The raw acquired time series are provided, and also time series down sampled at 100 ms.","A chemical detection platform composed of 8 chemoresistive gas sensors was exposed to turbulent gas mixtures generated naturally in a wind tunnel. The acquired time series of the sensors are provided.A chemical detection platform composed of 8 chemo-resistive gas sensors was exposed to turbulent gas mixtures generated naturally in a wind tunnel. The acquired time series of the sensors are provided.The experimental setup was designed to test gas sensors in realistic environments. Traditionally, chemical detection systems based on chemo-resistive sensors include a gas chamber to control the sample air flow and minimize turbulence. Instead, we utilized a wind tunnel with two independent gas sources that generate two gas plumes. The plumes get naturally mixed along a turbulent flow and reproduce the gas concentration fluctuations observed in natural environments. Hence, the gas sensors can capture the spatio-temporal information contained in the gas plumes.a) Chemical detection platform:The chemical detection platform was composed of 8 MOX gas sensors that generate a time-dependent multivariate response to the different gas stimuli. The utilized sensors were made commercially available by Figaro (TGS2611, TGS2612, TGS2610, TGS2600, TGS2602 TGS2620). The operating temperature of the sensors was controlled by the built-in heater, which was kept at a constant voltage of 5V. The detection platform also includes Temperature and Relative Humidity sensors. The generated sensors' responses were acquired at a sampling rate of 20 ms for the whole duration of the experiment.b) Wind tunnel:In order to generate two independent gas plumes in an open environment, we built a 2.5 m x 1.2 m x 0.4 m wind tunnel facility with two gas sources (labeled as source1 and source2). Each source was controlled independently to release the selected volatiles at different flow rates, which generated different concentration levels in the sensors' position. The wind generator created a turbulent flow that constantly displaced the introduced volatiles towards the exhaust outlet.c) Experimental protocol:We exposed the detection unit to mixtures of Ethylene with Methane or Carbon Monoxide. The mixtures were originated releasing Ethylene at source1 and releasing Methane / Carbon Monoxide at source2.Each volatile was released at four different flows (zero z, low l, medium m, and high h), providing up to 30 different mixture configurations: 15 mixtures of Ethylene with CO (h+h, h+m, h+l, Ã¢â‚¬Â¦, z+h, z+m, z+l) and 15 mixtures of Ethylene with Methane. Each configuration was repeated 6 times. Hence, the complete dataset was composed of 180 measurements, which were performed in a random order. By means of a GCMS system, the mean concentration levels at the sensors' location were estimated: Ethylene (l: 31 ppm, m: 46 ppm, h: 96 ppm), CO (l: 270 ppm, m: 397 ppm, h: 460 ppm), Methane (l: 51 ppm, m: 115 ppm, h: 131 ppm). It is worth noting that GC-MS systems only provide the mean value of the concentration and are not sensitive to concentration fluctuations.Each measurement, which had a total duration of 300 seconds, was performed as follows: Initially no gas was released and clean air flowed along the wind tunnel. 60 seconds after, both sources started to release the corresponding volatile at the specified flow rate. The duration of the gas release was 180 s. Finally, the system acquired the recovery to the baseline for another 60 s. The dataset is presented in 180 text files, where each file corresponds to a different measurement. The filenames identify the measurements as follows: The first 3 characters of the filename are a local identifier, which is not related to the order of the measurements; characters 5-8 indicate the concentration level of Ethylene released at source2 (n: zero, L: Low, M: Medium, H: High); the last 4 characters indicate the gas released at source1 (Me: Methane, CO: Carbon Monoxide) and the concentration level. For example, file 007_Et_L_Me_H contains time series acquired when Ethylene was released at Low concentration (31 ppm, mean concentration) and Methane at High concentration (131 ppm, mean concentration). Each file includes the acquired time series, presented in 11 columns: Time (s), Temperature (oC), Relative Humidity (%), and the readings of the 8 gas sensors: TGS2600, TGS2602, TGS2602, TGS2620, TGS2612, TGS2620, TGS2611, TGS2610. The readings can be converted to sensor resistance by Rs(KOhm)=10*(3110-A)/A, where A is the acquired value.The raw acquired time series are provided, and also time series down sampled at 100 ms."
Gas Sensor Array Drift Dataset at Different Concentrations,Gas Sensor Array Drift Dataset at Different Concentrations,This archive contains 13910 measurements from 16 chemical sensors exposed to 6 different gases at various concentration levels.,Gas+Sensor+Array+Drift+Dataset+at+Different+Concentrations,https://archive.ics.uci.edu/ml//machine-learning-databases/00270/,https://archive.ics.uci.edu/ml/datasets/Gas+Sensor+Array+Drift+Dataset+at+Different+Concentrations,"This data set contains 13,910 measurements from 16 chemical sensors exposed to 6 gases at different concentration levels. This dataset is an extension of the Gas Sensor Array Drift Dataset ([Web Link]), providing now the information about the concentration level at which the sensors were exposed for each measurement. The primary purpose of making this dataset freely accessible on-line is to provide an extensive dataset to the sensor and artificial intelligence research communities to develop and test strategies to solve a wide variety of tasks, including sensor drift, classification, regression, among others. The dataset can be used exclusively for research purposes. Commercial purposes are fully excluded. Citation of both Vergara et al. 'Chemical gas sensor drift compensation using classifier ensembles' and Rodriguez-Lujan et al. Ã¢â‚¬Å“On the calibration of sensor arrays for pattern recognition using the minimal number of experimentsÃ¢â‚¬Â� is required (see below).The dataset was gathered during the period of January 2008 to February 2011 (36 months) in a gas delivery platform facility situated at the ChemoSignals Laboratory in the BioCircuits Institute, University of California San Diego. The measurement system platform provides versatility for obtaining the desired concentrations of the chemical substances of interest with high accuracy and in a highly reproducible manner, minimizing thereby the common mistakes caused by human intervention and making it possible to exclusively concentrate on the chemical sensors. See reference 1 for more details on the experimental setup. The resulting dataset comprises recordings from six distinct pure gaseous substances, namely Ammonia, Acetaldehyde, Acetone, Ethylene, Ethanol, and Toluene, dosed at a wide variety of concentration levels in the intervals (50,1000), (5,500), (12,1000), (10,300), (10,600), and (10,100) ppmv, respectively.",Computer,"The responses of the said sensors are read in the form of the resistance across the active layer of each sensor; hence, each measurement produced a 16-channel time series, each  represented by an aggregate of features reflecting the dynamic processes occurring at the sensor surface in reaction to the chemical substance being evaluated. In particular, two distinct types of features were considered in the creation of this dataset: (i) the so-called steady-state feature (DR), defined as the maximal resistance change with respect to the baseline and its DR normalized version (DR divided by the acquired value when the chemical vapor is present in the test chamber). And (ii), an aggregate of features reflecting the sensor dynamics of the increasing/decaying transient portion of the sensor response during the entire measurement. This aggregate of features is a transformation, borrowed from the field of econometrics and originally introduced to the chemo-sensing community by Muezzinoglu et al. (2009), that converts the transient portion of the sensor response into a real scalar by estimating the maximum/minimum value y[k] for the rising/decaying portion of the exponential moving average of the sensor response:y[k] = (1-Alfa) y[k-1]+Alfa(R[k]-R[k-1])where R[k] is the sensor resistance measured at time k and Alfa is a scalar smoothing parameter between 0 and 1.In particular, three different values for Alfa=0.1, 0.01, 0.001 were set to obtain three different feature values from the rising portion of the sensor response and three additional features with the same Alfa values for the decaying portion of the sensor response, covering thus the entire sensor response dynamics. Thus, each feature vector contains the 8 features extracted from each particular sensor, resulting in a 128-dimensional feature vector (8 features x 16 sensors) containing all the features and organized as follows:DR_1, |DR|_1, EMAi0.001_1, EMAi0.01_1, EMAi0.1_1, EMAd0.001_1, EMAd0.01_1, EMAd0.1_1, DR_2, |DR|_2, EMAi0.001_2, EMAi0.01_2, EMAi0.1_2, EMAd0.001_2, EMAd0.01_2, EMAd0.1_2,..., DR_16, |DR|_16, EMAi0.001_16, EMAi0.01_16, EMAi0.1_16, EMAd0.001_16, EMAd0.01_16, EMAd0.1_16where: DR_j and |DR|_j are the R and the normalized R features, respectively. EMAi0.001_j, EMAi0.01_j, and EMAi0.1_j, are the emaR of the rising transient portion of the sensor response for Alfa 0.001, 0.01, and 0.1, respectively. EMAd0.001_j, EMAd0.01_j, and EMAd0.1_j, are emaR of the decaying transient portion of the sensor response for Alfa 0.001, 0.01, and 0.1, respectively. The index j=1Ã¢â‚¬Â¦16 represents the number of the sensor, forming thus the 128-dimensional feature vector. For processing purposes, the dataset is organized into ten batches, each containing the number of measurements per class and month indicated in the tables below. This reorganization of data was done to ensure having a sufficient and as uniformly distributed as possible number of experiments in each batch. Batch ID	Month IDs Batch 1	 Months 1 and 2 Batch 2	 Months 3, 4, 8, 9 and 10 Batch 3	 Months 11, 12, and 13 Batch 4	 Months 14 and 15 Batch 5	 Month 16 Batch 6	 Months 17, 18, 19, and 20 Batch 7	 Month 21 Batch 8	 Months 22 and 23 Batch 9	 Months 24 and 30 Batch 10 Month 36 Batch ID: Ethanol, Ethylene, Ammonia, Acetaldehyde, Acetone, TolueneBatch 1: 83, 30, 70, 98, 90, 74Batch 2: 100, 109, 532, 334, 164, 5Batch 3: 216, 240, 275, 490, 365, 0Batch 4: 12, 30, 12, 43, 64, 0Batch 5: 20, 46, 63, 40, 28, 0Batch 6: 110, 29, 606, 574, 514, 467Batch 7: 360, 744, 630, 662, 649, 568Batch 8: 40, 33, 143, 30, 30, 18Batch 9: 100, 75, 78, 55, 61, 101Batch 10: 600, 600, 600, 600, 600, 600 The dataset is organized in files, each representing a different batch. Within the files, each line represents a measurement. The first character (1-6) codes the analyte, followed by the concentration level:1: Ethanol; 2: Ethylene; 3: Ammonia; 4: Acetaldehyde; 5: Acetone; 6: TolueneThe data format follows the same coding style as in libsvm format x:v, where x stands for the feature number and v for the actual value of the feature. For example, in 1;10.000000 1:15596.162100 2:1.868245 3:2.371604 4:2.803678 5:7.512213 Ã¢â‚¬Â¦ 128:-2.654529 The number 1 stands for the class number (in this case Ethanol), the gas concentration level was 10ppmv, and the remaining 128 columns list the actual feature values for each measurement recording organized as described above. ","This archive contains 13910 measurements from 16 chemical sensors exposed to 6 different gases at various concentration levels.This data set contains 13,910 measurements from 16 chemical sensors exposed to 6 gases at different concentration levels. This dataset is an extension of the Gas Sensor Array Drift Dataset ([Web Link]), providing now the information about the concentration level at which the sensors were exposed for each measurement. The primary purpose of making this dataset freely accessible on-line is to provide an extensive dataset to the sensor and artificial intelligence research communities to develop and test strategies to solve a wide variety of tasks, including sensor drift, classification, regression, among others. The dataset can be used exclusively for research purposes. Commercial purposes are fully excluded. Citation of both Vergara et al. 'Chemical gas sensor drift compensation using classifier ensembles' and Rodriguez-Lujan et al. Ã¢â‚¬Å“On the calibration of sensor arrays for pattern recognition using the minimal number of experimentsÃ¢â‚¬Â� is required (see below).The dataset was gathered during the period of January 2008 to February 2011 (36 months) in a gas delivery platform facility situated at the ChemoSignals Laboratory in the BioCircuits Institute, University of California San Diego. The measurement system platform provides versatility for obtaining the desired concentrations of the chemical substances of interest with high accuracy and in a highly reproducible manner, minimizing thereby the common mistakes caused by human intervention and making it possible to exclusively concentrate on the chemical sensors. See reference 1 for more details on the experimental setup. The resulting dataset comprises recordings from six distinct pure gaseous substances, namely Ammonia, Acetaldehyde, Acetone, Ethylene, Ethanol, and Toluene, dosed at a wide variety of concentration levels in the intervals (50,1000), (5,500), (12,1000), (10,300), (10,600), and (10,100) ppmv, respectively.The responses of the said sensors are read in the form of the resistance across the active layer of each sensor; hence, each measurement produced a 16-channel time series, each  represented by an aggregate of features reflecting the dynamic processes occurring at the sensor surface in reaction to the chemical substance being evaluated. In particular, two distinct types of features were considered in the creation of this dataset: (i) the so-called steady-state feature (DR), defined as the maximal resistance change with respect to the baseline and its DR normalized version (DR divided by the acquired value when the chemical vapor is present in the test chamber). And (ii), an aggregate of features reflecting the sensor dynamics of the increasing/decaying transient portion of the sensor response during the entire measurement. This aggregate of features is a transformation, borrowed from the field of econometrics and originally introduced to the chemo-sensing community by Muezzinoglu et al. (2009), that converts the transient portion of the sensor response into a real scalar by estimating the maximum/minimum value y[k] for the rising/decaying portion of the exponential moving average of the sensor response:y[k] = (1-Alfa) y[k-1]+Alfa(R[k]-R[k-1])where R[k] is the sensor resistance measured at time k and Alfa is a scalar smoothing parameter between 0 and 1.In particular, three different values for Alfa=0.1, 0.01, 0.001 were set to obtain three different feature values from the rising portion of the sensor response and three additional features with the same Alfa values for the decaying portion of the sensor response, covering thus the entire sensor response dynamics. Thus, each feature vector contains the 8 features extracted from each particular sensor, resulting in a 128-dimensional feature vector (8 features x 16 sensors) containing all the features and organized as follows:DR_1, |DR|_1, EMAi0.001_1, EMAi0.01_1, EMAi0.1_1, EMAd0.001_1, EMAd0.01_1, EMAd0.1_1, DR_2, |DR|_2, EMAi0.001_2, EMAi0.01_2, EMAi0.1_2, EMAd0.001_2, EMAd0.01_2, EMAd0.1_2,..., DR_16, |DR|_16, EMAi0.001_16, EMAi0.01_16, EMAi0.1_16, EMAd0.001_16, EMAd0.01_16, EMAd0.1_16where: DR_j and |DR|_j are the R and the normalized R features, respectively. EMAi0.001_j, EMAi0.01_j, and EMAi0.1_j, are the emaR of the rising transient portion of the sensor response for Alfa 0.001, 0.01, and 0.1, respectively. EMAd0.001_j, EMAd0.01_j, and EMAd0.1_j, are emaR of the decaying transient portion of the sensor response for Alfa 0.001, 0.01, and 0.1, respectively. The index j=1Ã¢â‚¬Â¦16 represents the number of the sensor, forming thus the 128-dimensional feature vector. For processing purposes, the dataset is organized into ten batches, each containing the number of measurements per class and month indicated in the tables below. This reorganization of data was done to ensure having a sufficient and as uniformly distributed as possible number of experiments in each batch. Batch ID	Month IDs Batch 1	 Months 1 and 2 Batch 2	 Months 3, 4, 8, 9 and 10 Batch 3	 Months 11, 12, and 13 Batch 4	 Months 14 and 15 Batch 5	 Month 16 Batch 6	 Months 17, 18, 19, and 20 Batch 7	 Month 21 Batch 8	 Months 22 and 23 Batch 9	 Months 24 and 30 Batch 10 Month 36 Batch ID: Ethanol, Ethylene, Ammonia, Acetaldehyde, Acetone, TolueneBatch 1: 83, 30, 70, 98, 90, 74Batch 2: 100, 109, 532, 334, 164, 5Batch 3: 216, 240, 275, 490, 365, 0Batch 4: 12, 30, 12, 43, 64, 0Batch 5: 20, 46, 63, 40, 28, 0Batch 6: 110, 29, 606, 574, 514, 467Batch 7: 360, 744, 630, 662, 649, 568Batch 8: 40, 33, 143, 30, 30, 18Batch 9: 100, 75, 78, 55, 61, 101Batch 10: 600, 600, 600, 600, 600, 600 The dataset is organized in files, each representing a different batch. Within the files, each line represents a measurement. The first character (1-6) codes the analyte, followed by the concentration level:1: Ethanol; 2: Ethylene; 3: Ammonia; 4: Acetaldehyde; 5: Acetone; 6: TolueneThe data format follows the same coding style as in libsvm format x:v, where x stands for the feature number and v for the actual value of the feature. For example, in 1;10.000000 1:15596.162100 2:1.868245 3:2.371604 4:2.803678 5:7.512213 Ã¢â‚¬Â¦ 128:-2.654529 The number 1 stands for the class number (in this case Ethanol), the gas concentration level was 10ppmv, and the remaining 128 columns list the actual feature values for each measurement recording organized as described above. "
Gas Sensor Array Drift Dataset,Gas Sensor Array Drift Dataset,This archive contains 13910 measurements from 16 chemical sensors utilized in simulations for drift compensation in a discrimination task of 6 gases at various levels of concentrations.,Gas+Sensor+Array+Drift+Dataset,https://archive.ics.uci.edu/ml//machine-learning-databases/00224/,https://archive.ics.uci.edu/ml/datasets/Gas+Sensor+Array+Drift+Dataset,"This archive contains 13910 measurements from 16 chemical sensors utilized in simulations for drift compensation in a discrimination task of 6 gases at various levels of concentrations. The goal is to achieve good performance (or as low degradation as possible) over time, as reported in the paper mentioned below in Section 2: Data collection. The primary purpose of providing this dataset is to make it freely accessible on-line to the chemo-sensor research community and artificial intelligence to develop strategies to cope with sensor/concept drift. The dataset can be used exclusively for research purposes. Commercial purposes are fully excluded.The dataset was gathered within January 2007 to February 2011 (36 months) in a gas delivery platform facility situated at the ChemoSignals Laboratory in the BioCircuits Institute, University of California San Diego. Being completely operated by a fully computerized environment Ã¢â‚¬â€�controlled by a LabVIEWÃ¢â‚¬â€œNational Instruments software on a PC fitted with the appropriate serial data acquisition boards. The measurement system platform provides versatility for obtaining the desired concentrations of the chemical substances of interest with high accuracy and in a highly reproducible manner, minimizing thereby the common mistakes caused by human intervention and making it possible to exclusively concentrate on the chemical sensors for compensating real drift.The resulting dataset comprises recordings from six distinct pure gaseous substances, namely Ammonia, Acetaldehyde, Acetone, Ethylene, Ethanol, and Toluene, each dosed at a wide variety of concentration values ranging from 5 to 1000 ppmv. See Tables 1 and 2 of the below cited manuscript for details on the gas identity name, concentration values, and time distribution sequence of the measurement recordings considered in this dataset.Batch10.dat was updated on 10/14/2013 to correct some corrupted values in the last 120 lines of the file.An extension of this dataset with the concentration values is available at Gas Sensor Array Drift Dataset at Different Concentrations Data Set [Web Link]",Computer,"The response of the said sensors is read-out in the form of the resistance across the active layer of each sensor; hence each measurement produced a 16-channel time series, each of which represented by an aggregate of features reflecting all the dynamic processes occurring at the sensor surface in reaction to the chemical substance being evaluated. In particular, two distinct types of features were considered in the creation of this dataset: (i) The so-called steady-state feature (ÃŽâ€�R), defined as the difference of the maximal resistance change and the baseline and its normalized version expressed by the ratio of the maximal resistance and the baseline values when the chemical vapor is present in the test chamber. And (ii), an aggregate of features reflecting the sensor dynamics of the increasing/decaying transient portion of the sensor response during the entire measurement procedure under controlled conditions, namely the exponential moving average (emaÃŽÂ±). These aggregate of features is a transform, borrowed from the field of econometrics originally introduced to the chemo-sensing community by Muezzinoglu et al. (2009), that converts the said transient portion into a real scalar,  by estimating the maximum value Ã¢â‚¬â€�minimum for the decaying portion of the sensor responseÃ¢â‚¬â€� of its exponential moving average (emaÃŽÂ±), with an initial condition set to zero and a scalar smoothing parameter of the operator, ÃŽÂ±, that defines both the quality of the feature and the time of its occurrence along the time series the scalar, set to range between 0 and 1. In particular, three different values for ÃŽÂ± were set to obtain three different feature values from the pre-recorded rising portion of the sensor response  and three additional features with the same ÃŽÂ± values but for the decaying portion of the sensor response, covering thus the entire sensor response dynamics. For a more detailed analysis and discussion on these features as well as a graphical illustration of them please refer to Section 2.3 and Figure 2, respectively of the annotated manuscript.Once the abovementioned features are calculated, one is to form a feature vector containing the 8 features extracted from each particular sensor multiplied by the 16 sensors considered here. In the end, the resulting 128-dimensional feature vector containing all the features indicated above (8 features Ãƒâ€” 16 sensors) is organized as follows:ÃŽâ€�R_1, |ÃŽâ€�R|_1, EMAi0.001_1, EMAi0.01_1, EMAi0.1_1, EMAd0.001_1, EMAd0.01_1, EMAd0.1_1, ÃŽâ€�R_2, |ÃŽâ€�R|_2, EMAi0.001_2, EMAi0.01_2, EMAi0.1_2, EMAd0.001_2, EMAd0.01_2, EMAd0.1_2,..., ÃŽâ€�R_16, |ÃŽâ€�R|_16, EMAi0.001_16, EMAi0.01_16, EMAi0.1_16, EMAd0.001_16, EMAd0.01_16, EMAd0.1_16,where: Ã¢â‚¬Å“ÃŽâ€�R_1Ã¢â‚¬Â� and Ã¢â‚¬Å“|ÃŽâ€�R|_1Ã¢â‚¬Â� is the ÃŽâ€�R and the normalized ÃŽâ€�R feature, respectively, Ã¢â‚¬Å“EMAi0.001_1Ã¢â‚¬Â�, Ã¢â‚¬Å“EMAi0.01_1Ã¢â‚¬Â�, and Ã¢â‚¬Å“EMAi0.1_1Ã¢â‚¬Â�, the emaÃŽÂ± of the rising transient portion of the sensor response for ÃŽÂ± equals to 0.001, 0.01, and 0.1, respectively, and Ã¢â‚¬Å“EMAd0.001_1Ã¢â‚¬Â�, Ã¢â‚¬Å“EMAd0.01_1Ã¢â‚¬Â�, and Ã¢â‚¬Å“EMAd0.1_1Ã¢â‚¬Â�, the emaÃŽÂ± of the decaying transient portion of the sensor response for ÃŽÂ± equals to 0.001, 0.01, and 0.1, respectively, all corresponding to sensor # 1; Ã¢â‚¬Å“ÃŽâ€�R_2Ã¢â‚¬Â� and Ã¢â‚¬Å“|ÃŽâ€�R|_2Ã¢â‚¬Â� is the ÃŽâ€�R and the normalized ÃŽâ€�R feature, respectively, Ã¢â‚¬Å“EMAi0.001_2Ã¢â‚¬Â�, Ã¢â‚¬Å“EMAi0.01_2Ã¢â‚¬Â�, and Ã¢â‚¬Å“EMAi0.1_2Ã¢â‚¬Â�, the emaÃŽÂ± of the rising transient portion of the sensor response for ÃŽÂ± equals to 0.001, 0.01, and 0.1, respectively, and Ã¢â‚¬Å“EMAd0.001_2Ã¢â‚¬Â�, Ã¢â‚¬Å“EMAd0.01_2Ã¢â‚¬Â�, and Ã¢â‚¬Å“EMAd0.1_2Ã¢â‚¬Â�, the emaÃŽÂ± of the decaying transient portion of the sensor response for ÃŽÂ± equals to 0.001, 0.01, and 0.1, respectively, all corresponding to sensor # 2; and so forth up until sensor # 16, forming thus the 128-dimensional feature vector that is to be fetched to the classifiers for training.For processing purposes, the data is organized into ten batches, each containing the number of measurements per class and month indicated in the table below. This reorganization of data was done to ensure having a sufficient and as uniformly distributed as possible number of experiments in each class and month when training the classifier.Dataset organization details. Each row corresponds to months that were combined to form a batch:Batch ID	Month IDsBatch 1	        Months 1 and 2Batch 2	        Months 3, 4, 8, 9 and 10Batch 3	        Months 11, 12, and 13Batch 4	        Months 14 and 15Batch 5	        Month 16Batch 6	        Months 17, 18, 19, and 20Batch 7	        Month 21Batch 8	        Months 22 and 23Batch 9	        Months 24 and 30Batch 10	Month 36The data format follows the same coding style as in libsvm, in which one indicates the class each data point belongs to (1: Ethanol; 2: Ethylene; 3:Ammonia; 4: Acetaldehyde; 5: Acetone; 6: Toluene), and, then, the collection of features in a format x:v, where x stands for the feature number and v for the actual value of the feature. For example, in 1 1:15596.162100 2:1.868245 3:2.371604 4:2.803678 5:7.512213 Ã¢â‚¬Â¦ 128:-2.654529 The number Ã¢â‚¬Å“1Ã¢â‚¬Â� stands for the class number (in this case Ethanol), whereas the remaining 128 columns list the actual feature values for each measurement recording organized as described above. Finally, to make the results presented in the associated article reproducible for the reader, please use the following parameter values in the training task:Ã¢â‚¬Â¢	folds: 10Ã¢â‚¬Â¢	log2c = -5, 10, 1Ã¢â‚¬Â¢	log2g = -10, 5, 1Ã¢â‚¬Â¢	Scale the features in the training set appropriately to lie between -1 and +1.Ã¢â‚¬Â¢	And use the following cross validation parameters:Batch	C	Gamma (Ã‰Â¤)	Rate1	256.0	0.03125	        98.87642	64.0	0.00390625	99.75883	128.0	0.03125	        100.04	1.0	0.25	        100.05	2.0	0.015625	99.49246	256.0	0.0009765625	99.52177	64.0	0.0625	        99.97238	1024.0	0.0078125	99.65999	2.0	0.00390625	100.0","This archive contains 13910 measurements from 16 chemical sensors utilized in simulations for drift compensation in a discrimination task of 6 gases at various levels of concentrations.This archive contains 13910 measurements from 16 chemical sensors utilized in simulations for drift compensation in a discrimination task of 6 gases at various levels of concentrations. The goal is to achieve good performance (or as low degradation as possible) over time, as reported in the paper mentioned below in Section 2: Data collection. The primary purpose of providing this dataset is to make it freely accessible on-line to the chemo-sensor research community and artificial intelligence to develop strategies to cope with sensor/concept drift. The dataset can be used exclusively for research purposes. Commercial purposes are fully excluded.The dataset was gathered within January 2007 to February 2011 (36 months) in a gas delivery platform facility situated at the ChemoSignals Laboratory in the BioCircuits Institute, University of California San Diego. Being completely operated by a fully computerized environment Ã¢â‚¬â€�controlled by a LabVIEWÃ¢â‚¬â€œNational Instruments software on a PC fitted with the appropriate serial data acquisition boards. The measurement system platform provides versatility for obtaining the desired concentrations of the chemical substances of interest with high accuracy and in a highly reproducible manner, minimizing thereby the common mistakes caused by human intervention and making it possible to exclusively concentrate on the chemical sensors for compensating real drift.The resulting dataset comprises recordings from six distinct pure gaseous substances, namely Ammonia, Acetaldehyde, Acetone, Ethylene, Ethanol, and Toluene, each dosed at a wide variety of concentration values ranging from 5 to 1000 ppmv. See Tables 1 and 2 of the below cited manuscript for details on the gas identity name, concentration values, and time distribution sequence of the measurement recordings considered in this dataset.Batch10.dat was updated on 10/14/2013 to correct some corrupted values in the last 120 lines of the file.An extension of this dataset with the concentration values is available at Gas Sensor Array Drift Dataset at Different Concentrations Data Set [Web Link]The response of the said sensors is read-out in the form of the resistance across the active layer of each sensor; hence each measurement produced a 16-channel time series, each of which represented by an aggregate of features reflecting all the dynamic processes occurring at the sensor surface in reaction to the chemical substance being evaluated. In particular, two distinct types of features were considered in the creation of this dataset: (i) The so-called steady-state feature (ÃŽâ€�R), defined as the difference of the maximal resistance change and the baseline and its normalized version expressed by the ratio of the maximal resistance and the baseline values when the chemical vapor is present in the test chamber. And (ii), an aggregate of features reflecting the sensor dynamics of the increasing/decaying transient portion of the sensor response during the entire measurement procedure under controlled conditions, namely the exponential moving average (emaÃŽÂ±). These aggregate of features is a transform, borrowed from the field of econometrics originally introduced to the chemo-sensing community by Muezzinoglu et al. (2009), that converts the said transient portion into a real scalar,  by estimating the maximum value Ã¢â‚¬â€�minimum for the decaying portion of the sensor responseÃ¢â‚¬â€� of its exponential moving average (emaÃŽÂ±), with an initial condition set to zero and a scalar smoothing parameter of the operator, ÃŽÂ±, that defines both the quality of the feature and the time of its occurrence along the time series the scalar, set to range between 0 and 1. In particular, three different values for ÃŽÂ± were set to obtain three different feature values from the pre-recorded rising portion of the sensor response  and three additional features with the same ÃŽÂ± values but for the decaying portion of the sensor response, covering thus the entire sensor response dynamics. For a more detailed analysis and discussion on these features as well as a graphical illustration of them please refer to Section 2.3 and Figure 2, respectively of the annotated manuscript.Once the abovementioned features are calculated, one is to form a feature vector containing the 8 features extracted from each particular sensor multiplied by the 16 sensors considered here. In the end, the resulting 128-dimensional feature vector containing all the features indicated above (8 features Ãƒâ€” 16 sensors) is organized as follows:ÃŽâ€�R_1, |ÃŽâ€�R|_1, EMAi0.001_1, EMAi0.01_1, EMAi0.1_1, EMAd0.001_1, EMAd0.01_1, EMAd0.1_1, ÃŽâ€�R_2, |ÃŽâ€�R|_2, EMAi0.001_2, EMAi0.01_2, EMAi0.1_2, EMAd0.001_2, EMAd0.01_2, EMAd0.1_2,..., ÃŽâ€�R_16, |ÃŽâ€�R|_16, EMAi0.001_16, EMAi0.01_16, EMAi0.1_16, EMAd0.001_16, EMAd0.01_16, EMAd0.1_16,where: Ã¢â‚¬Å“ÃŽâ€�R_1Ã¢â‚¬Â� and Ã¢â‚¬Å“|ÃŽâ€�R|_1Ã¢â‚¬Â� is the ÃŽâ€�R and the normalized ÃŽâ€�R feature, respectively, Ã¢â‚¬Å“EMAi0.001_1Ã¢â‚¬Â�, Ã¢â‚¬Å“EMAi0.01_1Ã¢â‚¬Â�, and Ã¢â‚¬Å“EMAi0.1_1Ã¢â‚¬Â�, the emaÃŽÂ± of the rising transient portion of the sensor response for ÃŽÂ± equals to 0.001, 0.01, and 0.1, respectively, and Ã¢â‚¬Å“EMAd0.001_1Ã¢â‚¬Â�, Ã¢â‚¬Å“EMAd0.01_1Ã¢â‚¬Â�, and Ã¢â‚¬Å“EMAd0.1_1Ã¢â‚¬Â�, the emaÃŽÂ± of the decaying transient portion of the sensor response for ÃŽÂ± equals to 0.001, 0.01, and 0.1, respectively, all corresponding to sensor # 1; Ã¢â‚¬Å“ÃŽâ€�R_2Ã¢â‚¬Â� and Ã¢â‚¬Å“|ÃŽâ€�R|_2Ã¢â‚¬Â� is the ÃŽâ€�R and the normalized ÃŽâ€�R feature, respectively, Ã¢â‚¬Å“EMAi0.001_2Ã¢â‚¬Â�, Ã¢â‚¬Å“EMAi0.01_2Ã¢â‚¬Â�, and Ã¢â‚¬Å“EMAi0.1_2Ã¢â‚¬Â�, the emaÃŽÂ± of the rising transient portion of the sensor response for ÃŽÂ± equals to 0.001, 0.01, and 0.1, respectively, and Ã¢â‚¬Å“EMAd0.001_2Ã¢â‚¬Â�, Ã¢â‚¬Å“EMAd0.01_2Ã¢â‚¬Â�, and Ã¢â‚¬Å“EMAd0.1_2Ã¢â‚¬Â�, the emaÃŽÂ± of the decaying transient portion of the sensor response for ÃŽÂ± equals to 0.001, 0.01, and 0.1, respectively, all corresponding to sensor # 2; and so forth up until sensor # 16, forming thus the 128-dimensional feature vector that is to be fetched to the classifiers for training.For processing purposes, the data is organized into ten batches, each containing the number of measurements per class and month indicated in the table below. This reorganization of data was done to ensure having a sufficient and as uniformly distributed as possible number of experiments in each class and month when training the classifier.Dataset organization details. Each row corresponds to months that were combined to form a batch:Batch ID	Month IDsBatch 1	        Months 1 and 2Batch 2	        Months 3, 4, 8, 9 and 10Batch 3	        Months 11, 12, and 13Batch 4	        Months 14 and 15Batch 5	        Month 16Batch 6	        Months 17, 18, 19, and 20Batch 7	        Month 21Batch 8	        Months 22 and 23Batch 9	        Months 24 and 30Batch 10	Month 36The data format follows the same coding style as in libsvm, in which one indicates the class each data point belongs to (1: Ethanol; 2: Ethylene; 3:Ammonia; 4: Acetaldehyde; 5: Acetone; 6: Toluene), and, then, the collection of features in a format x:v, where x stands for the feature number and v for the actual value of the feature. For example, in 1 1:15596.162100 2:1.868245 3:2.371604 4:2.803678 5:7.512213 Ã¢â‚¬Â¦ 128:-2.654529 The number Ã¢â‚¬Å“1Ã¢â‚¬Â� stands for the class number (in this case Ethanol), whereas the remaining 128 columns list the actual feature values for each measurement recording organized as described above. Finally, to make the results presented in the associated article reproducible for the reader, please use the following parameter values in the training task:Ã¢â‚¬Â¢	folds: 10Ã¢â‚¬Â¢	log2c = -5, 10, 1Ã¢â‚¬Â¢	log2g = -10, 5, 1Ã¢â‚¬Â¢	Scale the features in the training set appropriately to lie between -1 and +1.Ã¢â‚¬Â¢	And use the following cross validation parameters:Batch	C	Gamma (Ã‰Â¤)	Rate1	256.0	0.03125	        98.87642	64.0	0.00390625	99.75883	128.0	0.03125	        100.04	1.0	0.25	        100.05	2.0	0.015625	99.49246	256.0	0.0009765625	99.52177	64.0	0.0625	        99.97238	1024.0	0.0078125	99.65999	2.0	0.00390625	100.0"
Gait Classification,Gait Classification,"Gait is considered a biometric criterion. Therefore, we tried to classify people with gait analysis with this gait data set.",Gait+Classification,https://archive.ics.uci.edu/ml//machine-learning-databases/00604/,https://archive.ics.uci.edu/ml/datasets/Gait+Classification,"This data set was created by calculating the walking parameters of a total of 16 different volunteers, 7 female and 9 male. The volunteers of 16 volunteers ranged between 20 and 34 years old, and their weight ranged from 53 to 95. In order to calculate each walking parameter, people were asked to walk the 30-meter long course for three rounds. The shared file contains X and Y data. X represents gait data and y represents person information for the relevant sample.",Computer,"Gait Data consists of the following parameters. Basic Parameters (Speed, Variability, Symmetry), Temporary Parameters (Heel Press Time, Cycle Time, Cadence, Posture, Oscillation, Loading, Foot Press, Thrust, Double Support), Spatial Parameters (Step Length, Step Speed, Peak Angle Speed, Maximum Swing Speed, Rotation Angle, Step Angle, Lift Angle, Swing Width, 3D Path Length), Height Parameters (Maximum Heel Height, Maximum Finger Tip Height, Minimum Finger Tip Height)","Gait is considered a biometric criterion. Therefore, we tried to classify people with gait analysis with this gait data set.This data set was created by calculating the walking parameters of a total of 16 different volunteers, 7 female and 9 male. The volunteers of 16 volunteers ranged between 20 and 34 years old, and their weight ranged from 53 to 95. In order to calculate each walking parameter, people were asked to walk the 30-meter long course for three rounds. The shared file contains X and Y data. X represents gait data and y represents person information for the relevant sample.Gait Data consists of the following parameters. Basic Parameters (Speed, Variability, Symmetry), Temporary Parameters (Heel Press Time, Cycle Time, Cadence, Posture, Oscillation, Loading, Foot Press, Thrust, Double Support), Spatial Parameters (Step Length, Step Speed, Peak Angle Speed, Maximum Swing Speed, Rotation Angle, Step Angle, Lift Angle, Swing Width, 3D Path Length), Height Parameters (Maximum Heel Height, Maximum Finger Tip Height, Minimum Finger Tip Height)"
FMA: A Dataset For Music Analysis,FMA: A Dataset For Music Analysis,"FMA features 106,574 tracks and includes song title, album, artist, genres; play counts, favorites, comments; description, biography, tags; together with audio (343 days, 917 GiB) and features.",FMA%3A+A+Dataset+For+Music+Analysis,https://archive.ics.uci.edu/ml//machine-learning-databases/00386/,https://archive.ics.uci.edu/ml/datasets/FMA%3A+A+Dataset+For+Music+Analysis,"* Audio track (encoded as mp3) of each of the 106,574 tracks. It is on average 10 millions samples per track.* Nine audio features (consisting of 518 attributes) for each of the 106,574 tracks.* Given the metadata, multiple problems can be explored: recommendation, genre recognition, artist identification, year prediction, music annotation, unsupervized categorization.* The dataset is split into four sizes: small, medium, large, full.* Please see the paper and the GitHub repository for more information ([Web Link])",Computer,"Nine audio features computed across time and summarized with seven statistics (mean, standard deviation, skew, kurtosis, median, minimum, maximum):1. Chroma, 84 attributes2. Tonnetz, 42 attributes3. Mel Frequency Cepstral Coefficient (MFCC), 140 attributes4. Spectral centroid, 7 attributes5. Spectral bandwidth, 7 attributes6. Spectral contrast, 49 attributes7. Spectral rolloff, 7 attributes8. Root Mean Square energy, 7 attributes9. Zero-crossing rate, 7 attributes","FMA features 106,574 tracks and includes song title, album, artist, genres; play counts, favorites, comments; description, biography, tags; together with audio (343 days, 917 GiB) and features.* Audio track (encoded as mp3) of each of the 106,574 tracks. It is on average 10 millions samples per track.* Nine audio features (consisting of 518 attributes) for each of the 106,574 tracks.* Given the metadata, multiple problems can be explored: recommendation, genre recognition, artist identification, year prediction, music annotation, unsupervized categorization.* The dataset is split into four sizes: small, medium, large, full.* Please see the paper and the GitHub repository for more information ([Web Link])Nine audio features computed across time and summarized with seven statistics (mean, standard deviation, skew, kurtosis, median, minimum, maximum):1. Chroma, 84 attributes2. Tonnetz, 42 attributes3. Mel Frequency Cepstral Coefficient (MFCC), 140 attributes4. Spectral centroid, 7 attributes5. Spectral bandwidth, 7 attributes6. Spectral contrast, 49 attributes7. Spectral rolloff, 7 attributes8. Root Mean Square energy, 7 attributes9. Zero-crossing rate, 7 attributes"
First-order theorem proving,First-order theorem proving,"Given a theorem, predict which of five heuristics will give the fastest proof when used by a first-order prover. A sixth prediction declines to attempt a proof, should the theorem be too difficult.",First-order+theorem+proving,https://archive.ics.uci.edu/ml//machine-learning-databases/00249/,https://archive.ics.uci.edu/ml/datasets/First-order+theorem+proving,See the file bridge-holden-paulson-details.txt in the submitted tarball.,Computer,The attributes are a mixture of static and dynamic features derived from theorems to be proved. See the paper for full details.,"Given a theorem, predict which of five heuristics will give the fastest proof when used by a first-order prover. A sixth prediction declines to attempt a proof, should the theorem be too difficult.See the file bridge-holden-paulson-details.txt in the submitted tarball.The attributes are a mixture of static and dynamic features derived from theorems to be proved. See the paper for full details."
YouTube Spam Collection,YouTube Spam Collection,"It is a public set of comments collected for spam research. It has five datasets composed by 1,956 real messages extracted from five videos that were among the 10 most viewed on the collection period.",YouTube+Spam+Collection,https://archive.ics.uci.edu/ml//machine-learning-databases/00380/,https://archive.ics.uci.edu/ml/datasets/YouTube+Spam+Collection,"The table below lists the datasets, the YouTube video ID, the amount of samples in each class and the total number of samples per dataset.Dataset --- YouTube ID -- # Spam - # Ham - TotalPsy ------- 9bZkp7q19f0 --- 175 --- 175 --- 350KatyPerry - CevxZvSJLk8 --- 175 --- 175 --- 350LMFAO ----- KQ6zr6kCPj8 --- 236 --- 202 --- 438Eminem ---- uelHwf8o7_U --- 245 --- 203 --- 448Shakira --- pRpeEdMmmQ0 --- 174 --- 196 --- 370Note: the chronological order of the comments were kept.",Computer,"The collection is composed by one CSV file per dataset, where each line has the following attributes:COMMENT_ID,AUTHOR,DATE,CONTENT,TAGWe offer one example bellow:z12oglnpoq3gjh4om04cfdlbgp2uepyytpw0k,Francisco Nora,2013-11-28T19:52:35,please like :D [Web Link],1","It is a public set of comments collected for spam research. It has five datasets composed by 1,956 real messages extracted from five videos that were among the 10 most viewed on the collection period.The table below lists the datasets, the YouTube video ID, the amount of samples in each class and the total number of samples per dataset.Dataset --- YouTube ID -- # Spam - # Ham - TotalPsy ------- 9bZkp7q19f0 --- 175 --- 175 --- 350KatyPerry - CevxZvSJLk8 --- 175 --- 175 --- 350LMFAO ----- KQ6zr6kCPj8 --- 236 --- 202 --- 438Eminem ---- uelHwf8o7_U --- 245 --- 203 --- 448Shakira --- pRpeEdMmmQ0 --- 174 --- 196 --- 370Note: the chronological order of the comments were kept.The collection is composed by one CSV file per dataset, where each line has the following attributes:COMMENT_ID,AUTHOR,DATE,CONTENT,TAGWe offer one example bellow:z12oglnpoq3gjh4om04cfdlbgp2uepyytpw0k,Francisco Nora,2013-11-28T19:52:35,please like :D [Web Link],1"
GNFUV Unmanned Surface Vehicles Sensor Data Set 2,GNFUV Unmanned Surface Vehicles Sensor Data Set 2,"The data-set contains eight (2x4) data-sets of mobile sensor readings data (humidity, temperature) corresponding to a swarm of four Unmanned Surface Vehicles (USVs) in a test-bed, Athens, Greece.",GNFUV+Unmanned+Surface+Vehicles+Sensor+Data+Set+2,https://archive.ics.uci.edu/ml//machine-learning-databases/00466/,https://archive.ics.uci.edu/ml/datasets/GNFUV+Unmanned+Surface+Vehicles+Sensor+Data+Set+2,"The data-set comprises 2 x (4) sets of mobile sensor readings data (humidity, temperature) from four (4) Raspberry Pi's corresponding to a swarm of four (4) Unmanned Surface Vehicles (USVs). Each USV set contains records of the format: {'Device'; 'humidity-value'; 'temperature-value'; 'experiment-id';'sensing-time','Pi'}. The swarm of the USVs is moving according to a GPS pre-defined trajectory. The USVs are floating over the sea surface in a coastal area of Athens (Greece). More information: [Web Link]",Computer,Attributes: 'device' = USV ID (String) 'humidity' = sensed humidity value from the USV sensor (real value) 'temperature' = sensed temperature value from the USV sensor (real value) 'experiment' = 1 (constant real value) 'time' = the sensing and reporting time (real value)'pi' = Raspberry Pi ID,"The data-set contains eight (2x4) data-sets of mobile sensor readings data (humidity, temperature) corresponding to a swarm of four Unmanned Surface Vehicles (USVs) in a test-bed, Athens, Greece.The data-set comprises 2 x (4) sets of mobile sensor readings data (humidity, temperature) from four (4) Raspberry Pi's corresponding to a swarm of four (4) Unmanned Surface Vehicles (USVs). Each USV set contains records of the format: {'Device'; 'humidity-value'; 'temperature-value'; 'experiment-id';'sensing-time','Pi'}. The swarm of the USVs is moving according to a GPS pre-defined trajectory. The USVs are floating over the sea surface in a coastal area of Athens (Greece). More information: [Web Link]Attributes: 'device' = USV ID (String) 'humidity' = sensed humidity value from the USV sensor (real value) 'temperature' = sensed temperature value from the USV sensor (real value) 'experiment' = 1 (constant real value) 'time' = the sensing and reporting time (real value)'pi' = Raspberry Pi ID"
KDC-4007 dataset Collection,KDC-4007 dataset Collection,KDC-4007 dataset Collection is the Kurdish Documents Classification text used in categories regarding Kurdish Sorani news and articles.,KDC-4007+dataset+Collection,https://archive.ics.uci.edu/ml//machine-learning-databases/00376/,https://archive.ics.uci.edu/ml/datasets/KDC-4007+dataset+Collection,"The most important feature of this dataset is its simplicity to use and its being well-documented, which can be widely used in various studies of text analysis regarding Kurdish Sorani news and articles.   The documents consist of eight categories, which are Sport, Religion, Art, Economic, Education, Social, Style, and Health. Each of them consisted of 500 text documents, where the total size of the corpus is 4,007 text files. The dataset and documents have become freely accessible in order to have repeatable outcomes for experimental assessment.",Computer,"There is four collection: - ST-Ds datasets, just stop words elimination is performed by using Kurdish preprocessing-step approach. - The pre-ds dataset, Kurdish preprocessing-step approach is used. - The Pre+TW-Ds dataset, TFÃƒâ€”IDF term weighting on the Pre-Ds dataset is performed. - Orig-Ds datasets, no process is used which is the original dataset.","KDC-4007 dataset Collection is the Kurdish Documents Classification text used in categories regarding Kurdish Sorani news and articles.The most important feature of this dataset is its simplicity to use and its being well-documented, which can be widely used in various studies of text analysis regarding Kurdish Sorani news and articles.   The documents consist of eight categories, which are Sport, Religion, Art, Economic, Education, Social, Style, and Health. Each of them consisted of 500 text documents, where the total size of the corpus is 4,007 text files. The dataset and documents have become freely accessible in order to have repeatable outcomes for experimental assessment.There is four collection: - ST-Ds datasets, just stop words elimination is performed by using Kurdish preprocessing-step approach. - The pre-ds dataset, Kurdish preprocessing-step approach is used. - The Pre+TW-Ds dataset, TFÃƒâ€”IDF term weighting on the Pre-Ds dataset is performed. - Orig-Ds datasets, no process is used which is the original dataset."
GPS Trajectories,GPS Trajectories,The dataset has been feed by Android app called Go!Track. It is available at Goolge Play Store(https://play.google.com/store/apps/details?id=com.go.router). ,GPS+Trajectories,https://archive.ics.uci.edu/ml//machine-learning-databases/00354/,https://archive.ics.uci.edu/ml/datasets/GPS+Trajectories,The dataset is composed by two tables. The first table go_track_tracks presents general attributes and each instance has one trajectory that is represented by the tablego_track_trackspoints.,Computer,"(1) go_track_tracks.csv: a list of trajectoriesid_android - it represents the device used to capture the instance;speed - it represents the average speed (Km/H)distance - it represent the total distance (Km)rating - it is an evaluation parameter. Evaluation the traffic is a way to verify the volunteers perception about the traffic during the travel, in other words,if volunteers move to  some place and face traffic jam, maybe they will evaluate 'bad'. (3- good, 2- normal, 1-bad).rating_bus - it is other evaluation parameter. (1 - The amount of people inside the bus is little, 2 - The bus is not crowded, 3- The bus is crowded.rating_weather - it is another evaluation parameter. ( 2- sunny, 1- raining).car_or_bus - (1 - car, 2-bus)linha - information about the bus that does the pathway (2) go_track_trackspoints.csv: localization points of each trajectoryid: unique key to identify each pointlatitude: latitude from where the point islongitude: longitude from where the point istrack_id: identify the trajectory which the point belongtime: datetime when the point was collected (GMT-3)","The dataset has been feed by Android app called Go!Track. It is available at Goolge Play Store(https://play.google.com/store/apps/details?id=com.go.router). The dataset is composed by two tables. The first table go_track_tracks presents general attributes and each instance has one trajectory that is represented by the tablego_track_trackspoints.(1) go_track_tracks.csv: a list of trajectoriesid_android - it represents the device used to capture the instance;speed - it represents the average speed (Km/H)distance - it represent the total distance (Km)rating - it is an evaluation parameter. Evaluation the traffic is a way to verify the volunteers perception about the traffic during the travel, in other words,if volunteers move to  some place and face traffic jam, maybe they will evaluate 'bad'. (3- good, 2- normal, 1-bad).rating_bus - it is other evaluation parameter. (1 - The amount of people inside the bus is little, 2 - The bus is not crowded, 3- The bus is crowded.rating_weather - it is another evaluation parameter. ( 2- sunny, 1- raining).car_or_bus - (1 - car, 2-bus)linha - information about the bus that does the pathway (2) go_track_trackspoints.csv: localization points of each trajectoryid: unique key to identify each pointlatitude: latitude from where the point islongitude: longitude from where the point istrack_id: identify the trajectory which the point belongtime: datetime when the point was collected (GMT-3)"
Grammatical Facial Expressions,Grammatical Facial Expressions,This dataset supports the development of models that make possible to interpret Grammatical Facial Expressions from Brazilian Sign Language (Libras).,Grammatical+Facial+Expressions,https://archive.ics.uci.edu/ml//machine-learning-databases/00317/,https://archive.ics.uci.edu/ml/datasets/Grammatical+Facial+Expressions,"   The automated analysis of facial expressions has been widely used in different research areas, such as biometrics or emotional analysis. Special importance is attached to facial expressions in the area of sign language, since they help to form the grammatical structure of the language and allow for the creation of language disambiguation, and thus are called Grammatical Facial Expressions. This dataset was already used in the experiments described in Freitas et al. (2014).   The dataset is composed by eighteen videos recorded using Microsoft Kinect sensor. In each video, a user performs (five times), in front of the sensor, five sentences in Libras (Brazilian Sign Language) that require the use of a grammatical facial expression. By using Microsoft Kinect, we have obtained: (a) a image of each frame, identified by a timestamp; (b) a text file containing one hundred coordinates (x, y, z) of points from eyes, nose, eyebrows, face contour and iris; each line in the file corresponds to points extracted from one frame. The images enabled a manual labeling of each file by a specialist, providing a ground truth for classification.   The dataset is organized in 36 files: 18 datapoint files and 18 target files, one pair for each video which compose the dataset.The name of the file refers to each video: the letter corresponding to the user (A and B), name of grammatical facial expression and a specification (target or datapoints). ",Computer,"Datapoints files:   Coordinates x and y are given in pixels.   Coordinates z are given in millimetres.   Label of frame   0 - 7	(x,y,z) - left eye   8 - 15 	(x,y,z) - right eye   16 - 25	(x,y,z) - left eyebrow   26 - 35	(x,y,z) - right eyebrow   36 - 47	(x,y,z) - nose   48 - 67	(x,y,z) - mouth   68 - 86	(x,y,z) - face contour   87		(x,y,z) - left iris   88 		(x,y,z) - right iris   89		(x,y,z) - nose tip   90 - 94	(x,y,z) - line above left eyebrow   95 - 99	(x,y,z) - line above right eyebrow","This dataset supports the development of models that make possible to interpret Grammatical Facial Expressions from Brazilian Sign Language (Libras).   The automated analysis of facial expressions has been widely used in different research areas, such as biometrics or emotional analysis. Special importance is attached to facial expressions in the area of sign language, since they help to form the grammatical structure of the language and allow for the creation of language disambiguation, and thus are called Grammatical Facial Expressions. This dataset was already used in the experiments described in Freitas et al. (2014).   The dataset is composed by eighteen videos recorded using Microsoft Kinect sensor. In each video, a user performs (five times), in front of the sensor, five sentences in Libras (Brazilian Sign Language) that require the use of a grammatical facial expression. By using Microsoft Kinect, we have obtained: (a) a image of each frame, identified by a timestamp; (b) a text file containing one hundred coordinates (x, y, z) of points from eyes, nose, eyebrows, face contour and iris; each line in the file corresponds to points extracted from one frame. The images enabled a manual labeling of each file by a specialist, providing a ground truth for classification.   The dataset is organized in 36 files: 18 datapoint files and 18 target files, one pair for each video which compose the dataset.The name of the file refers to each video: the letter corresponding to the user (A and B), name of grammatical facial expression and a specification (target or datapoints). Datapoints files:   Coordinates x and y are given in pixels.   Coordinates z are given in millimetres.   Label of frame   0 - 7	(x,y,z) - left eye   8 - 15 	(x,y,z) - right eye   16 - 25	(x,y,z) - left eyebrow   26 - 35	(x,y,z) - right eyebrow   36 - 47	(x,y,z) - nose   48 - 67	(x,y,z) - mouth   68 - 86	(x,y,z) - face contour   87		(x,y,z) - left iris   88 		(x,y,z) - right iris   89		(x,y,z) - nose tip   90 - 94	(x,y,z) - line above left eyebrow   95 - 99	(x,y,z) - line above right eyebrow"
Wheat kernels,Wheat kernels,"Measurements of morphological descriptors  of wheat kernels from Punjab State. A machine Learning based technique was used to extract 15 features, all are real valued attributes",Wheat+kernels,https://archive.ics.uci.edu/ml//machine-learning-databases/00596/,https://archive.ics.uci.edu/ml/datasets/Wheat+kernels,The examined group comprised kernels of wheat : PBW-550U randomly selected for the experiment. High Quality Manual Visualisation of the external Kernel. It is non-destructive technique.The images were recorded using Basler Sca-17fc industrial graded color camera. The dataset can be used for tasks of classification.,Computer,"Area, Major Axis Length, Minor Axis Length, Perimeter, Length, Width, Thinness Ratio, Aspect Ratio, Rectangular Aspect ratio, Area Ratio, Distance Max,Distance Min, Distance Ratio, Std Deviation,Mean ","Measurements of morphological descriptors  of wheat kernels from Punjab State. A machine Learning based technique was used to extract 15 features, all are real valued attributesThe examined group comprised kernels of wheat : PBW-550U randomly selected for the experiment. High Quality Manual Visualisation of the external Kernel. It is non-destructive technique.The images were recorded using Basler Sca-17fc industrial graded color camera. The dataset can be used for tasks of classification.Area, Major Axis Length, Minor Axis Length, Perimeter, Length, Width, Thinness Ratio, Aspect Ratio, Rectangular Aspect ratio, Area Ratio, Distance Max,Distance Min, Distance Ratio, Std Deviation,Mean "
ISOLET,ISOLET, Goal: Predict which letter-name was spoken--a simple classification task.,ISOLET,https://archive.ics.uci.edu/ml//machine-learning-databases/isolet/,https://archive.ics.uci.edu/ml/datasets/ISOLET,"This data set was generated as follows. 150 subjects spoke the name of each letter of the alphabet twice. Hence, we have 52 training examples from each speaker. The speakers are grouped into sets of 30 speakers each, and are referred to as isolet1, isolet2, isolet3, isolet4, and isolet5. The data appears in isolet1+2+3+4.data in sequential order, first the speakers from isolet1, then isolet2, and so on.  The test set, isolet5, is a separate file.You will note that 3 examples are missing.  I believe they were dropped due to difficulties in recording.I believe this is a good domain for a noisy, perceptual task.  It is also a very good domain for testing the scaling abilities of algorithms. For example, C4.5 on this domain is slower than backpropagation!I have formatted the data for C4.5 and provided a C4.5-style names file as well.",Computer,"The features are described in the paper by Cole and Fanty cited above.  The features include spectral coefficients; contour features, sonorant features, pre-sonorant features, and post-sonorant features.  Exact order of appearance of the features is not known."," Goal: Predict which letter-name was spoken--a simple classification task.This data set was generated as follows. 150 subjects spoke the name of each letter of the alphabet twice. Hence, we have 52 training examples from each speaker. The speakers are grouped into sets of 30 speakers each, and are referred to as isolet1, isolet2, isolet3, isolet4, and isolet5. The data appears in isolet1+2+3+4.data in sequential order, first the speakers from isolet1, then isolet2, and so on.  The test set, isolet5, is a separate file.You will note that 3 examples are missing.  I believe they were dropped due to difficulties in recording.I believe this is a good domain for a noisy, perceptual task.  It is also a very good domain for testing the scaling abilities of algorithms. For example, C4.5 on this domain is slower than backpropagation!I have formatted the data for C4.5 and provided a C4.5-style names file as well.The features are described in the paper by Cole and Fanty cited above.  The features include spectral coefficients; contour features, sonorant features, pre-sonorant features, and post-sonorant features.  Exact order of appearance of the features is not known."
Internet Usage Data,Internet Usage Data,This data contains general demographic information on internet users in 1997.,Internet+Usage+Data,https://archive.ics.uci.edu/ml//machine-learning-databases/internet_usage-mld/,https://archive.ics.uci.edu/ml/datasets/Internet+Usage+Data,"This data comes from a survey conducted by the Graphics and Visualization Unit at Georgia Tech October 10 to November 16, 1997. The full details of the survey are available here: [Web Link]The particular subset of the survey provided here is the ""general demographics"" of internet users. The data have been recoded as entirely numeric, with an index to the codes described in the ""Coding"" file. The full survey is available from the web site above, along with summaries, tables and graphs of their analyses. In addition there is information on other parts of the survey, including technology demographics and web commerce. The data is stored in an ASCII files with one observation per line. Spaces separate fields. ",Computer,,"This data contains general demographic information on internet users in 1997.This data comes from a survey conducted by the Graphics and Visualization Unit at Georgia Tech October 10 to November 16, 1997. The full details of the survey are available here: [Web Link]The particular subset of the survey provided here is the ""general demographics"" of internet users. The data have been recoded as entirely numeric, with an index to the codes described in the ""Coding"" file. The full survey is available from the web site above, along with summaries, tables and graphs of their analyses. In addition there is information on other parts of the survey, including technology demographics and web commerce. The data is stored in an ASCII files with one observation per line. Spaces separate fields. nan"
Wireless Indoor Localization,Wireless Indoor Localization,Collected in indoor space by observing signal strengths of seven WiFi signals visible on a smartphone. The decision variable is one of the four rooms. ,Wireless+Indoor+Localization,https://archive.ics.uci.edu/ml//machine-learning-databases/00422/,https://archive.ics.uci.edu/ml/datasets/Wireless+Indoor+Localization,Collected to perform experimentation on how wifi signal strengths can be used to determine one of the indoor locations.,Computer,Each attribute is wifi signal strength observed on smartphone.,Collected in indoor space by observing signal strengths of seven WiFi signals visible on a smartphone. The decision variable is one of the four rooms. Collected to perform experimentation on how wifi signal strengths can be used to determine one of the indoor locations.Each attribute is wifi signal strength observed on smartphone.
Internet Firewall Data,Internet Firewall Data,this data set was collected from the internet traffic records on a university's firewall.,Internet+Firewall+Data,https://archive.ics.uci.edu/ml//machine-learning-databases/00542/,https://archive.ics.uci.edu/ml/datasets/Internet+Firewall+Data,"There are 12 features in total. Action feature is used as a class. There are 4 classes in total. These are allow, action, drop and reset-both classes.",Computer,"Source Port,Destination Port,NAT Source Port,NAT Destination Port,Action,Bytes,Bytes Sent,Bytes Received,Packets,Elapsed Time (sec),pkts_sent,pkts_received","this data set was collected from the internet traffic records on a university's firewall.There are 12 features in total. Action feature is used as a class. There are 4 classes in total. These are allow, action, drop and reset-both classes.Source Port,Destination Port,NAT Source Port,NAT Destination Port,Action,Bytes,Bytes Sent,Bytes Received,Packets,Elapsed Time (sec),pkts_sent,pkts_received"
Internet Advertisements,Internet Advertisements,This dataset represents a set of possible advertisements on Internet pages.,Internet+Advertisements,https://archive.ics.uci.edu/ml//machine-learning-databases/internet_ads/,https://archive.ics.uci.edu/ml/datasets/Internet+Advertisements,"This dataset represents a set of possible advertisements on Internet pages.  The features encode the geometry of the image (if available) as well as phrases occuring in the URL, the image's URL and alt text, the anchor text, and words occuring near the anchor text. The task is to predict whether an image is an advertisement (""ad"") or not (""nonad"").",Computer,"(3 continous; others binary; this is the ""STANDARD encoding"" mentioned in the [Kushmerick, 99].)One or more of the three continous features are missing in 28% of the instances; missing values should be interpreted as ""unknown"".","This dataset represents a set of possible advertisements on Internet pages.This dataset represents a set of possible advertisements on Internet pages.  The features encode the geometry of the image (if available) as well as phrases occuring in the URL, the image's URL and alt text, the anchor text, and words occuring near the anchor text. The task is to predict whether an image is an advertisement (""ad"") or not (""nonad"").(3 continous; others binary; this is the ""STANDARD encoding"" mentioned in the [Kushmerick, 99].)One or more of the three continous features are missing in 28% of the instances; missing values should be interpreted as ""unknown""."
Indoor User Movement Prediction from RSS data,Indoor User Movement Prediction from RSS data,This dataset contains temporal data from a Wireless Sensor Network deployed in real-world office environments. The task is intended as real-life benchmark in the area of Ambient Assisted Living.,Indoor+User+Movement+Prediction+from+RSS+data,https://archive.ics.uci.edu/ml//machine-learning-databases/00348/,https://archive.ics.uci.edu/ml/datasets/Indoor+User+Movement+Prediction+from+RSS+data,"This dataset represents a real-life benchmark in the area of Ambient Assisted Living applications, as described in [1].The binary classification task consists in predicting  the pattern of user movements in real-world office environments from time-series generated by a Wireless Sensor Network (WSN). Input data contains temporal streams of radio signal strength (RSS) measured between the nodes of a WSN, comprising 5 sensors: 4 anchors deployed in the environment and 1 mote worn by the user. Data has been collected during user movements at the frequency of 8 Hz (8 samples per second). In the provided dataset, the RSS signals have been rescaled to the interval [-1,1], singly on the set of traces collected from each anchor (as in [1]).Target data consists in a class label indicating whether the user's trajectory will lead to a change in the spatial context (i.e. a room change) or not. In particular, the target class +1 is associated to the location changing movements, while the target class -1 is associated to the location preserving movements.The measurement campaign involved a number of 3 different environmental settings, each of which comprises 2 rooms (containing typical office furniture) separated by a corridor. A sketch of the common setup considered is provided in the attached Figure. In each environmental setting, the anchors are deployed in fixed positions near the rooms corners (at the height of 1.5 m from the ground), while the mobile is worn on the chest of the user. The Figure also shows a simplified illustration of the types of user trajectories considered, with straight paths yielding to a spatial context change and curved ones leading to spatial context preservation. Each path produces a trace of RSS measurements from the beginning of the trajectory until a marker point, which is denoted as M in the Figure. The marker M is the same for all the movements, therefore different paths cannot be distinguished based only on the RSS values collected at M.Each input file in the provided dataset contains data pertaining to one temporal sequence of input RSS data (1 user trajectory for each file). The dataset contains 314 sequences, for a total number of 13197 steps.Further information can be found at the webpage: [Web Link].A complete description of this dataset can be found in [1], which also provides details on the performance achieved by Echo State Networks on the corresponding classification task.",Computer,"Data is provided in comma separated value (csv) format. - Input dataInput RSS streams are provided in files named MovementAAL_RSS_SEQID.csv, where IDSEQ is the progressive numeric sequence ID.In each file, each row corresponds to a time step measurement (in temporal order) and contains the following information:RSS_anchor1, RSS_anchor2, RSS_anchor3, RSS_anchor4 - Target dataTarget data is provided in the file MovementAAL_target.csvEach row in this file contains:sequence_ID, class_label- Dataset groupingData is grouped in 3 sets, as described in [1].File MovementAAL_DatasetGroup.csv, provides information about such data grouping.Each row in this file contains:sequence_ID, dataset_ID- Path groupingUsers' movements are divided in 6 prototypical paths, as described in [1].File MovementAAL_Paths.csv provides information about data grouping based on path type.Each row in this file contains:sequence_ID, path_ID","This dataset contains temporal data from a Wireless Sensor Network deployed in real-world office environments. The task is intended as real-life benchmark in the area of Ambient Assisted Living.This dataset represents a real-life benchmark in the area of Ambient Assisted Living applications, as described in [1].The binary classification task consists in predicting  the pattern of user movements in real-world office environments from time-series generated by a Wireless Sensor Network (WSN). Input data contains temporal streams of radio signal strength (RSS) measured between the nodes of a WSN, comprising 5 sensors: 4 anchors deployed in the environment and 1 mote worn by the user. Data has been collected during user movements at the frequency of 8 Hz (8 samples per second). In the provided dataset, the RSS signals have been rescaled to the interval [-1,1], singly on the set of traces collected from each anchor (as in [1]).Target data consists in a class label indicating whether the user's trajectory will lead to a change in the spatial context (i.e. a room change) or not. In particular, the target class +1 is associated to the location changing movements, while the target class -1 is associated to the location preserving movements.The measurement campaign involved a number of 3 different environmental settings, each of which comprises 2 rooms (containing typical office furniture) separated by a corridor. A sketch of the common setup considered is provided in the attached Figure. In each environmental setting, the anchors are deployed in fixed positions near the rooms corners (at the height of 1.5 m from the ground), while the mobile is worn on the chest of the user. The Figure also shows a simplified illustration of the types of user trajectories considered, with straight paths yielding to a spatial context change and curved ones leading to spatial context preservation. Each path produces a trace of RSS measurements from the beginning of the trajectory until a marker point, which is denoted as M in the Figure. The marker M is the same for all the movements, therefore different paths cannot be distinguished based only on the RSS values collected at M.Each input file in the provided dataset contains data pertaining to one temporal sequence of input RSS data (1 user trajectory for each file). The dataset contains 314 sequences, for a total number of 13197 steps.Further information can be found at the webpage: [Web Link].A complete description of this dataset can be found in [1], which also provides details on the performance achieved by Echo State Networks on the corresponding classification task.Data is provided in comma separated value (csv) format. - Input dataInput RSS streams are provided in files named MovementAAL_RSS_SEQID.csv, where IDSEQ is the progressive numeric sequence ID.In each file, each row corresponds to a time step measurement (in temporal order) and contains the following information:RSS_anchor1, RSS_anchor2, RSS_anchor3, RSS_anchor4 - Target dataTarget data is provided in the file MovementAAL_target.csvEach row in this file contains:sequence_ID, class_label- Dataset groupingData is grouped in 3 sets, as described in [1].File MovementAAL_DatasetGroup.csv, provides information about such data grouping.Each row in this file contains:sequence_ID, dataset_ID- Path groupingUsers' movements are divided in 6 prototypical paths, as described in [1].File MovementAAL_Paths.csv provides information about data grouping based on path type.Each row in this file contains:sequence_ID, path_ID"
WISDM Smartphone and Smartwatch Activity and Biometrics Dataset ,WISDM Smartphone and Smartwatch Activity and Biometrics Dataset ,Contains accelerometer and gyroscope time-series sensor data collected from a smartphone and smartwatch as 51 test subjects perform 18 activities for 3 minutes each. ,WISDM+Smartphone+and+Smartwatch+Activity+and+Biometrics+Dataset+,https://archive.ics.uci.edu/ml//machine-learning-databases/00507/,https://archive.ics.uci.edu/ml/datasets/WISDM+Smartphone+and+Smartwatch+Activity+and+Biometrics+Dataset+,"For a detailed description of the dataset, please see the following pdf file that is stored with the data:  WISDM-dataset-description.pdf. The raw  accelerometer and gyroscope sensor data is collected from the smartphone and smartwatch at a rate of 20Hz. It is collected from 51 test subjects as they perform 18 activities for 3 minutes apiece. The sensor data for each device (phone, watch) and type of sensor (accelerometer, gyroscope) is stored in a different directory (so there are 4 data directories). In each directory there are 51 files corresponding to the 51 test subjects. The format of every entry is the same: . The descriptions of these attributes are provided with the attribute information. In addition to the raw time-series sensor data we also generate examples that describe the sensor data using a 10-second window. See the dataset description document for details. Although this data can most naturally be used for activity recognition, it can also be used to build behavioral biometric models since each sensor reading is associated with a specific subject.",Computer,subject-id: value from 1600- 1650 that identifies one of the 51 test subjectsactivity-code: character between 'A' and 'S' (no 'N') that identifies the activity. The mapping from code to activity is provided in the activity_key.txt file and in our dataset description document.timestamp: Unix time (integer)x: represents the sensor reading (accelerometer or gyroscope) for the x dimensiony: represents the sensor reading (accelerometer or gyroscope) for the y dimensionz: represents the sensor reading (accelerometer or gyroscope) for the z dimension,"Contains accelerometer and gyroscope time-series sensor data collected from a smartphone and smartwatch as 51 test subjects perform 18 activities for 3 minutes each. For a detailed description of the dataset, please see the following pdf file that is stored with the data:  WISDM-dataset-description.pdf. The raw  accelerometer and gyroscope sensor data is collected from the smartphone and smartwatch at a rate of 20Hz. It is collected from 51 test subjects as they perform 18 activities for 3 minutes apiece. The sensor data for each device (phone, watch) and type of sensor (accelerometer, gyroscope) is stored in a different directory (so there are 4 data directories). In each directory there are 51 files corresponding to the 51 test subjects. The format of every entry is the same: . The descriptions of these attributes are provided with the attribute information. In addition to the raw time-series sensor data we also generate examples that describe the sensor data using a 10-second window. See the dataset description document for details. Although this data can most naturally be used for activity recognition, it can also be used to build behavioral biometric models since each sensor reading is associated with a specific subject.subject-id: value from 1600- 1650 that identifies one of the 51 test subjectsactivity-code: character between 'A' and 'S' (no 'N') that identifies the activity. The mapping from code to activity is provided in the activity_key.txt file and in our dataset description document.timestamp: Unix time (integer)x: represents the sensor reading (accelerometer or gyroscope) for the x dimensiony: represents the sensor reading (accelerometer or gyroscope) for the y dimensionz: represents the sensor reading (accelerometer or gyroscope) for the z dimension"
YouTube Comedy Slam Preference Data,YouTube Comedy Slam Preference Data,This dataset provides user vote data on which video from a pair of videos is funnier collected on YouTube Comedy Slam. The task is to automatically predict this preference based on video metadata.,YouTube+Comedy+Slam+Preference+Data,https://archive.ics.uci.edu/ml//machine-learning-databases/00223/,https://archive.ics.uci.edu/ml/datasets/YouTube+Comedy+Slam+Preference+Data,"YouTube Comedy Slam ([Web Link]) is a video discovery experiment running on YouTube's version of labs (called TestTube) for a few months in 2011 and 2012. In this experiment, a pair of videos were shown to the user and the user was asked to vote for the video that they found funnier. Left/right positions of the videos were randomly selected before being presented to the user to eliminate position bias. Videos were selected from a large pool of weekly updated sets of videos.One of the outcomes of this experiment is a training dataset for automatically predicting which video would be deemed funnier by users using a variety of features.  For example, uploader supplied metadata and/or user comments on watch pages of these videos could be used as features. See [Web Link] for more detail. The attached dataset includes roughly 1.7 million preference votes. The votes were recorded chronologically. The first 80% are provided here as the training dataset and the remaining 20% as the testing dataset. Each line in this dataset corresponds to one vote over a pair of YouTube videos. Each video is represented by its YouTube video ID. For example, the watch page URL for video ID 'txqiwrbYGrs' is [Web Link]. User preference over a pair of videos is presented in the form of string Ã¢â‚¬Å“leftÃ¢â‚¬Â� if the left video was deemed funnier, and Ã¢â‚¬Å“rightÃ¢â‚¬Â� otherwise. This user vote should be used as ground truth for both training and testing. Evaluation should be based on average accuracy in predicting this preference over the testing partition (provided). Any other information about the vote (e.g. ID of the user) is not provided.",Computer,Each row in this text file represents one anonymous user vote. Each line contains three comma-separated fields. The first two fields are YouTube video IDs. The third field is either 'left' or 'right'. Left indicates the first video from the pair was voted to be funnier than the second. Right indicates the opposite preference.,"This dataset provides user vote data on which video from a pair of videos is funnier collected on YouTube Comedy Slam. The task is to automatically predict this preference based on video metadata.YouTube Comedy Slam ([Web Link]) is a video discovery experiment running on YouTube's version of labs (called TestTube) for a few months in 2011 and 2012. In this experiment, a pair of videos were shown to the user and the user was asked to vote for the video that they found funnier. Left/right positions of the videos were randomly selected before being presented to the user to eliminate position bias. Videos were selected from a large pool of weekly updated sets of videos.One of the outcomes of this experiment is a training dataset for automatically predicting which video would be deemed funnier by users using a variety of features.  For example, uploader supplied metadata and/or user comments on watch pages of these videos could be used as features. See [Web Link] for more detail. The attached dataset includes roughly 1.7 million preference votes. The votes were recorded chronologically. The first 80% are provided here as the training dataset and the remaining 20% as the testing dataset. Each line in this dataset corresponds to one vote over a pair of YouTube videos. Each video is represented by its YouTube video ID. For example, the watch page URL for video ID 'txqiwrbYGrs' is [Web Link]. User preference over a pair of videos is presented in the form of string Ã¢â‚¬Å“leftÃ¢â‚¬Â� if the left video was deemed funnier, and Ã¢â‚¬Å“rightÃ¢â‚¬Â� otherwise. This user vote should be used as ground truth for both training and testing. Evaluation should be based on average accuracy in predicting this preference over the testing partition (provided). Any other information about the vote (e.g. ID of the user) is not provided.Each row in this text file represents one anonymous user vote. Each line contains three comma-separated fields. The first two fields are YouTube video IDs. The third field is either 'left' or 'right'. Left indicates the first video from the pair was voted to be funnier than the second. Right indicates the opposite preference."
Image Recognition Task Execution Times in Mobile Edge Computing,Image Recognition Task Execution Times in Mobile Edge Computing,This file contains four (4) datasets of the execution times for image recognition tasks executed in different edge computing servers.,Image+Recognition+Task+Execution+Times+in+Mobile+Edge+Computing,https://archive.ics.uci.edu/ml//machine-learning-databases/00633/,https://archive.ics.uci.edu/ml/datasets/Image+Recognition+Task+Execution+Times+in+Mobile+Edge+Computing,"This dataset contains the turnaround execution times (in seconds) for offloaded image recognition tasks when executed in different edge servers. The edge servers are MacBook Pro Processor: 1.4 GHz Quad-Core Intel Core i5 RAM: 8 GB 2133 MHz LPDDR3, MacBook Pro Processor: 2.5  GHz Dual-Core Intel Core i5 RAM: 8 GB 1600 MHz DDR3, Ubuntu VM Using VirtualBox RAM: 2 GB and Raspberry Pi 4B Processor: a quad-core 64-bit ARM Cortex-A72 CPU RAM: 4Gb. The client (mobile edge node) was simulated as a process in one of these devices. The client sends an image to be recognized by one of the servers above, i.e. server. The turnaround execution time is the time duration once the connection is established (when the edge node starts sending the image) until it receives the recognition result from the edge server. The execution time is recorded for each edge server. ",Computer,"[1] Time:  day, date, hours, minutes, second, year.[2] Turnaround Task Execution time: in seconds. ","This file contains four (4) datasets of the execution times for image recognition tasks executed in different edge computing servers.This dataset contains the turnaround execution times (in seconds) for offloaded image recognition tasks when executed in different edge servers. The edge servers are MacBook Pro Processor: 1.4 GHz Quad-Core Intel Core i5 RAM: 8 GB 2133 MHz LPDDR3, MacBook Pro Processor: 2.5  GHz Dual-Core Intel Core i5 RAM: 8 GB 1600 MHz DDR3, Ubuntu VM Using VirtualBox RAM: 2 GB and Raspberry Pi 4B Processor: a quad-core 64-bit ARM Cortex-A72 CPU RAM: 4Gb. The client (mobile edge node) was simulated as a process in one of these devices. The client sends an image to be recognized by one of the servers above, i.e. server. The turnaround execution time is the time duration once the connection is established (when the edge node starts sending the image) until it receives the recognition result from the edge server. The execution time is recorded for each edge server. [1] Time:  day, date, hours, minutes, second, year.[2] Turnaround Task Execution time: in seconds. "
IIWA14-R820-Gazebo-Dataset-10Trajectories,IIWA14-R820-Gazebo-Dataset-10Trajectories,This dataset contain 10 Trajectories of IIWA14-R820 Gazebo robot model. Based in paper 'Improving the Inverse Dynamics Model of the KUKA LWR IV+ using Independent Joint Learning' of Shareef (2016).,IIWA14-R820-Gazebo-Dataset-10Trajectories,https://archive.ics.uci.edu/ml//machine-learning-databases/00574/,https://archive.ics.uci.edu/ml/datasets/IIWA14-R820-Gazebo-Dataset-10Trajectories,Provide all relevant information about your data set.,Computer,Provide information about each attribute in your data set.,This dataset contain 10 Trajectories of IIWA14-R820 Gazebo robot model. Based in paper 'Improving the Inverse Dynamics Model of the KUKA LWR IV+ using Independent Joint Learning' of Shareef (2016).Provide all relevant information about your data set.Provide information about each attribute in your data set.
IDA2016Challenge,IDA2016Challenge,The dataset consists of data collected from heavy Scania trucks in everyday usage. ,IDA2016Challenge,https://archive.ics.uci.edu/ml//machine-learning-databases/00414/,https://archive.ics.uci.edu/ml/datasets/IDA2016Challenge,"This file is part of APS Failure and Operational Data for Scania Trucks.Copyright (c) <2016> This program (APS Failure and Operational Data for Scania Trucks) is free software: you can redistribute it and/or modifyit under the terms of the GNU General Public License as published bythe Free Software Foundation, either version 3 of the License, or(at your option) any later version.This program is distributed in the hope that it will be useful,but WITHOUT ANY WARRANTY; without even the implied warranty ofMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See theGNU General Public License for more details.You should have received a copy of the GNU General Public Licensealong with this program.  If not, see <[Web Link]>.------------------------------------------------------------------------1. Title: APS Failure at Scania Trucks2. Source Information   -- Creator: Scania CV AB               VagnmakarvÃƒÂ¤gen 1                151 32 SÃƒÂ¶dertÃƒÂ¤lje                Stockholm               Sweden    -- Donor:   Tony Lindgren (tony '@' dsv.su.se) and Jonas Biteus (jonas.biteus '@' scania.com)   -- Date:    September, 2016 3. Past Usage:   Industrial Challenge 2016 at The 15th International Symposium on Intelligent Data Analysis (IDA)    -- Results:              The top three contestants                                                | Score | Number of Type 1 faults | Number of Type 2 faults     ------------------------------------------------------------------------------------------------------------------------------------     Camila F. Costa and Mario A. Nascimento                                  | 9920  | 542                     | 9     Christopher Gondek, Daniel Hafner and Oliver R. Sampson                  | 10900 | 490                     | 12     Sumeet Garnaik, Sushovan Das, Rama Syamala Sreepada and Bidyut Kr. Patra | 11480 | 398                     | 154. Relevant Information:   -- Introduction     The dataset consists of data collected from heavy Scania      trucks in everyday usage. The system in focus is the      Air Pressure system (APS) which generates pressurised      air that are utilized in various functions in a truck,      such as braking and gear changes. The datasets'      positive class consists of component failures      for a specific component of the APS system.      The negative class consists of trucks with failures      for components not related to the APS. The data consists      of a subset of all available data, selected by experts.    -- Challenge metric       Cost-metric of miss-classification:     Predicted class |      True class       |                     |    pos    |    neg    |     -----------------------------------------      pos            |     -     |  Cost_1   |     -----------------------------------------      neg            |  Cost_2   |     -     |     -----------------------------------------     Cost_1 = 10 and cost_2 = 500     The total cost of a prediction model the sum of 'Cost_1'      multiplied by the number of Instances with type 1 failure      and 'Cost_2' with the number of instances with type 2 failure,      resulting in a 'Total_cost'.     In this case Cost_1 refers to the cost that an unnessecary      check needs to be done by an mechanic at an workshop, while      Cost_2 refer to the cost of missing a faulty truck,      which may cause a breakdown.     Total_cost = Cost_1*No_Instances + Cost_2*No_Instances.5. Number of Instances:      The training set contains 60000 examples in total in which      59000 belong to the negative class and 1000 positive class.      The test set contains 16000 examples. 6. Number of Attributes: 171 7. Attribute Information:   The attribute names of the data have been anonymized for    proprietary reasons. It consists of both single numerical    counters and histograms consisting of bins with different    conditions. Typically the histograms have open-ended    conditions at each end. For example if we measuring    the ambient temperature 'T' then the histogram could    be defined with 4 bins where:    bin 1 collect values for temperature T < -20   bin 2 collect values for temperature T >= -20 and T < 0        bin 3 collect values for temperature T >= 0 and T < 20     bin 4 collect values for temperature T > 20    |  b1  |  b2  |  b3  |  b4  |      -----------------------------          -20     0      20  The attributes are as follows: class, then   anonymized operational data. The operational data have   an identifier and a bin id, like 'Identifier_Bin'.  In total there are 171 attributes, of which 7 are   histogram variabels. Missing values are denoted by 'na'.",Computer," The attribute names of the data have been anonymized for    proprietary reasons. It consists of both single numerical    counters and histograms consisting of bins with different    conditions. Typically the histograms have open-ended    conditions at each end. For example if we measuring    the ambient temperature 'T' then the histogram could    be defined with 4 bins where:    bin 1 collect values for temperature T < -20   bin 2 collect values for temperature T >= -20 and T < 0        bin 3 collect values for temperature T >= 0 and T < 20     bin 4 collect values for temperature T > 20    |  b1  |  b2  |  b3  |  b4  |      -----------------------------          -20     0      20The attributes are as follows: class, then anonymized operational data. The operational data have an identifier and a bin id, like 'Identifier_Bin'.In total there are 171 attributes, of which 7 are histogram variabels. Missing values are denoted by 'na'.","The dataset consists of data collected from heavy Scania trucks in everyday usage. This file is part of APS Failure and Operational Data for Scania Trucks.Copyright (c) <2016> This program (APS Failure and Operational Data for Scania Trucks) is free software: you can redistribute it and/or modifyit under the terms of the GNU General Public License as published bythe Free Software Foundation, either version 3 of the License, or(at your option) any later version.This program is distributed in the hope that it will be useful,but WITHOUT ANY WARRANTY; without even the implied warranty ofMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See theGNU General Public License for more details.You should have received a copy of the GNU General Public Licensealong with this program.  If not, see <[Web Link]>.------------------------------------------------------------------------1. Title: APS Failure at Scania Trucks2. Source Information   -- Creator: Scania CV AB               VagnmakarvÃƒÂ¤gen 1                151 32 SÃƒÂ¶dertÃƒÂ¤lje                Stockholm               Sweden    -- Donor:   Tony Lindgren (tony '@' dsv.su.se) and Jonas Biteus (jonas.biteus '@' scania.com)   -- Date:    September, 2016 3. Past Usage:   Industrial Challenge 2016 at The 15th International Symposium on Intelligent Data Analysis (IDA)    -- Results:              The top three contestants                                                | Score | Number of Type 1 faults | Number of Type 2 faults     ------------------------------------------------------------------------------------------------------------------------------------     Camila F. Costa and Mario A. Nascimento                                  | 9920  | 542                     | 9     Christopher Gondek, Daniel Hafner and Oliver R. Sampson                  | 10900 | 490                     | 12     Sumeet Garnaik, Sushovan Das, Rama Syamala Sreepada and Bidyut Kr. Patra | 11480 | 398                     | 154. Relevant Information:   -- Introduction     The dataset consists of data collected from heavy Scania      trucks in everyday usage. The system in focus is the      Air Pressure system (APS) which generates pressurised      air that are utilized in various functions in a truck,      such as braking and gear changes. The datasets'      positive class consists of component failures      for a specific component of the APS system.      The negative class consists of trucks with failures      for components not related to the APS. The data consists      of a subset of all available data, selected by experts.    -- Challenge metric       Cost-metric of miss-classification:     Predicted class |      True class       |                     |    pos    |    neg    |     -----------------------------------------      pos            |     -     |  Cost_1   |     -----------------------------------------      neg            |  Cost_2   |     -     |     -----------------------------------------     Cost_1 = 10 and cost_2 = 500     The total cost of a prediction model the sum of 'Cost_1'      multiplied by the number of Instances with type 1 failure      and 'Cost_2' with the number of instances with type 2 failure,      resulting in a 'Total_cost'.     In this case Cost_1 refers to the cost that an unnessecary      check needs to be done by an mechanic at an workshop, while      Cost_2 refer to the cost of missing a faulty truck,      which may cause a breakdown.     Total_cost = Cost_1*No_Instances + Cost_2*No_Instances.5. Number of Instances:      The training set contains 60000 examples in total in which      59000 belong to the negative class and 1000 positive class.      The test set contains 16000 examples. 6. Number of Attributes: 171 7. Attribute Information:   The attribute names of the data have been anonymized for    proprietary reasons. It consists of both single numerical    counters and histograms consisting of bins with different    conditions. Typically the histograms have open-ended    conditions at each end. For example if we measuring    the ambient temperature 'T' then the histogram could    be defined with 4 bins where:    bin 1 collect values for temperature T < -20   bin 2 collect values for temperature T >= -20 and T < 0        bin 3 collect values for temperature T >= 0 and T < 20     bin 4 collect values for temperature T > 20    |  b1  |  b2  |  b3  |  b4  |      -----------------------------          -20     0      20  The attributes are as follows: class, then   anonymized operational data. The operational data have   an identifier and a bin id, like 'Identifier_Bin'.  In total there are 171 attributes, of which 7 are   histogram variabels. Missing values are denoted by 'na'. The attribute names of the data have been anonymized for    proprietary reasons. It consists of both single numerical    counters and histograms consisting of bins with different    conditions. Typically the histograms have open-ended    conditions at each end. For example if we measuring    the ambient temperature 'T' then the histogram could    be defined with 4 bins where:    bin 1 collect values for temperature T < -20   bin 2 collect values for temperature T >= -20 and T < 0        bin 3 collect values for temperature T >= 0 and T < 20     bin 4 collect values for temperature T > 20    |  b1  |  b2  |  b3  |  b4  |      -----------------------------          -20     0      20The attributes are as follows: class, then anonymized operational data. The operational data have an identifier and a bin id, like 'Identifier_Bin'.In total there are 171 attributes, of which 7 are histogram variabels. Missing values are denoted by 'na'."
"Hybrid Indoor Positioning Dataset from WiFi RSSI, Bluetooth and magnetometer","Hybrid Indoor Positioning Dataset from WiFi RSSI, Bluetooth and magnetometer","The dataset was created for the comparison and evaluation of hybrid indoor positioning methods. The dataset presented contains data from W-LAN and Bluetooth interfaces, and Magnetometer. ",Hybrid+Indoor+Positioning+Dataset+from+WiFi+RSSI%2C+Bluetooth+and+magnetometer,https://archive.ics.uci.edu/ml//machine-learning-databases/00402/,https://archive.ics.uci.edu/ml/datasets/Hybrid+Indoor+Positioning+Dataset+from+WiFi+RSSI%2C+Bluetooth+and+magnetometer,"The measurements were created to ease the development, comparison and evaluation of fingerprinting based hybrid indoor positioning methods. The measurements were recorded by the same kind of Android devices in order to reduce the effect of the variety of the hardware. The recording was preformed at weekend to reduce the noise of the environment. The measurements were performed in a three-story building and cover about 50% of it. ",Computer,"#Measurement Info1) 	Measurement Id - Java UUID2) 	Timestamp - YYYY-MM-dd hh:mm:ss #Position Info3-5) 	Coordinates of the absolute position (x,y,z)6-7) 	Symbolic position - UUID and name of the position#Measruement Values8-10) 	Magnetometer values x,y,z, real11-42) 	WiFi RSSI values, negative integeres [-255,0]43-65) 	Bluetooth devices {0,1} - 1 if the given devices was sensed in during the measurement.","The dataset was created for the comparison and evaluation of hybrid indoor positioning methods. The dataset presented contains data from W-LAN and Bluetooth interfaces, and Magnetometer. The measurements were created to ease the development, comparison and evaluation of fingerprinting based hybrid indoor positioning methods. The measurements were recorded by the same kind of Android devices in order to reduce the effect of the variety of the hardware. The recording was preformed at weekend to reduce the noise of the environment. The measurements were performed in a three-story building and cover about 50% of it. #Measurement Info1) 	Measurement Id - Java UUID2) 	Timestamp - YYYY-MM-dd hh:mm:ss #Position Info3-5) 	Coordinates of the absolute position (x,y,z)6-7) 	Symbolic position - UUID and name of the position#Measruement Values8-10) 	Magnetometer values x,y,z, real11-42) 	WiFi RSSI values, negative integeres [-255,0]43-65) 	Bluetooth devices {0,1} - 1 if the given devices was sensed in during the measurement."
Human Activity Recognition Using Smartphones,Human Activity Recognition Using Smartphones,Human Activity Recognition database built from the recordings of 30 subjects performing activities of daily living (ADL) while carrying a waist-mounted smartphone with embedded inertial sensors.,Human+Activity+Recognition+Using+Smartphones,https://archive.ics.uci.edu/ml//machine-learning-databases/00240/,https://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones,"The experiments have been carried out with a group of 30 volunteers within an age bracket of 19-48 years. Each person performed six activities (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING) wearing a smartphone (Samsung Galaxy S II) on the waist. Using its embedded accelerometer and gyroscope, we captured 3-axial linear acceleration and 3-axial angular velocity at a constant rate of 50Hz. The experiments have been video-recorded to label the data manually. The obtained dataset has been randomly partitioned into two sets, where 70% of the volunteers was selected for generating the training data and 30% the test data. The sensor signals (accelerometer and gyroscope) were pre-processed by applying noise filters and then sampled in fixed-width sliding windows of 2.56 sec and 50% overlap (128 readings/window). The sensor acceleration signal, which has gravitational and body motion components, was separated using a Butterworth low-pass filter into body acceleration and gravity. The gravitational force is assumed to have only low frequency components, therefore a filter with 0.3 Hz cutoff frequency was used. From each window, a vector of features was obtained by calculating variables from the time and frequency domain.Check the README.txt file for further details about this dataset. A video of the experiment including an example of the 6 recorded activities with one of the participants can be seen in the following link: [Web Link]An updated version of this dataset can be found at [Web Link]. It includes labels of postural transitions between activities and also the full raw inertial signals instead of the ones pre-processed into windows. ",Computer,For each record in the dataset it is provided:- Triaxial acceleration from the accelerometer (total acceleration) and the estimated body acceleration.- Triaxial Angular velocity from the gyroscope. - A 561-feature vector with time and frequency domain variables. - Its activity label. - An identifier of the subject who carried out the experiment. ,"Human Activity Recognition database built from the recordings of 30 subjects performing activities of daily living (ADL) while carrying a waist-mounted smartphone with embedded inertial sensors.The experiments have been carried out with a group of 30 volunteers within an age bracket of 19-48 years. Each person performed six activities (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING) wearing a smartphone (Samsung Galaxy S II) on the waist. Using its embedded accelerometer and gyroscope, we captured 3-axial linear acceleration and 3-axial angular velocity at a constant rate of 50Hz. The experiments have been video-recorded to label the data manually. The obtained dataset has been randomly partitioned into two sets, where 70% of the volunteers was selected for generating the training data and 30% the test data. The sensor signals (accelerometer and gyroscope) were pre-processed by applying noise filters and then sampled in fixed-width sliding windows of 2.56 sec and 50% overlap (128 readings/window). The sensor acceleration signal, which has gravitational and body motion components, was separated using a Butterworth low-pass filter into body acceleration and gravity. The gravitational force is assumed to have only low frequency components, therefore a filter with 0.3 Hz cutoff frequency was used. From each window, a vector of features was obtained by calculating variables from the time and frequency domain.Check the README.txt file for further details about this dataset. A video of the experiment including an example of the 6 recorded activities with one of the participants can be seen in the following link: [Web Link]An updated version of this dataset can be found at [Web Link]. It includes labels of postural transitions between activities and also the full raw inertial signals instead of the ones pre-processed into windows. For each record in the dataset it is provided:- Triaxial acceleration from the accelerometer (total acceleration) and the estimated body acceleration.- Triaxial Angular velocity from the gyroscope. - A 561-feature vector with time and frequency domain variables. - Its activity label. - An identifier of the subject who carried out the experiment. "
Heterogeneity Activity Recognition,Heterogeneity Activity Recognition,"The Heterogeneity Human Activity Recognition (HHAR) dataset from Smartphones and Smartwatches is a dataset devised to benchmark human activity recognition algorithms (classification, automatic data segmentation, sensor fusion, feature extraction, etc.) in real-world contexts; specifically, the dataset is gathered with a variety of different device models and use-scenarios, in order to reflect sensing heterogeneities to be expected in real deployments.",Heterogeneity+Activity+Recognition,https://archive.ics.uci.edu/ml//machine-learning-databases/00344/,https://archive.ics.uci.edu/ml/datasets/Heterogeneity+Activity+Recognition,"The Heterogeneity Dataset for Human Activity Recognition from Smartphone and Smartwatch sensors consists of two datasets devised to investigate sensor heterogeneities' impacts on human activity recognition algorithms (classification, automatic data segmentation, sensor fusion, feature extraction, etc). The datasets were used for the results and analyses produced in [1]. Activity recognition data setThe dataset contains the readings of two motion sensors commonly found in smartphones. Reading were recorded while users executed activities scripted in no specific order carrying smartwatches and smartphones.Activities: â€˜Bikingâ€™, â€˜Sittingâ€™, â€˜Standingâ€™, â€˜Walkingâ€™, â€˜Stair Upâ€™ and â€˜Stair downâ€™.Sensors: Sensors: Two embedded sensors, i.e., Accelerometer and Gyroscope, sampled at the highest frequency the respective device allows.Devices: 4 smartwatches (2 LG watches, 2 Samsung Galaxy Gears)8 smartphones (2 Samsung Galaxy S3 mini, 2 Samsung Galaxy S3, 2 LG Nexus 4, 2 Samsung Galaxy S+)Recordings: 9 users  Recording scenario===============The activity recognition environment and scenario has been designed to generate many activity primitives, yet in a realistic manner. Users took 2 different routes for the biking and walking, and 2 different set of stairs were used for the stairs up and down. Still experiment data set===================Accelerometer recordings as above but with devices lying still, in 6 different orientations. Devices used comprise 31 smartphones, 4 smartwatches and 1 tablet, representing 13 different models from 4 manufacturers, running variants of Android and iOS.",Computer,"Activity recognition data set accelerometer Samples ------------ The Phones_accelerometer.csv contains all smartphone accelerometer samples from all devices and users. The csv file consist of the following columns: 'Index', 'Arrival_Time', 'Creation_Time', 'x', 'y', 'z', 'User', 'Model', 'Device', 'gt' All samples from all the experiments is a row in the file containing each column value. ------------- Groundtruths -------------------- The null class is defined as null in the gt (groundtruth) column, whereas the rest of the classes can be seen in the column. ------------- Devices -------------------------- the phones from the still experiment which has been used for activity recognition is the following: Ã¢â‚¬Ëœit-116', 'it-133', 'it-108', 'it-103','it-123','3Renault-AH', 'no-name/LG-Nexus4','G-Watch' The device numbering used in the data set is: LG-Nexus 4 'nexus4_1' 'nexus4_2' Saumsung Galaxy S3 's3_1' 's3_2Ã¢â‚¬â„¢ Samsung Galaxy S3 min: 's3mini_1' 's3mini_2' Samsung Galaxy S+: 'samsungold_1' 'samsungold_2' Still experiment data set This is the Heterogeneity Dataset for Human Activity Recognition, and contains all the samples from the static still experiment. Where the phones where place in the 6 different possible orientation. The data set is structured in the following way: ------------- Static Accelerometer Samples ------------ Each specific device is located in the following way: Orientation/[Web Link] Where the 6 different orientations can be either one of the following: Phoneonback,Phoneonbottom,Phoneonfront,Phoneonleft,Phoneonright,Phoneontop For example to get the samples from the device named 3Renault-AH of the model Samsung-Galaxy-S3 Mini when laying static on the back we get the following structure: Phoneonback/3Renault-AH/Samsung-Galaxy-S3 Mini.csv. Each CSV file consist of 6 columns creation time, sensor time,arrival time,x,y,z. The six axes from the accelerometer is the x,y,z columns. ","The Heterogeneity Human Activity Recognition (HHAR) dataset from Smartphones and Smartwatches is a dataset devised to benchmark human activity recognition algorithms (classification, automatic data segmentation, sensor fusion, feature extraction, etc.) in real-world contexts; specifically, the dataset is gathered with a variety of different device models and use-scenarios, in order to reflect sensing heterogeneities to be expected in real deployments.The Heterogeneity Dataset for Human Activity Recognition from Smartphone and Smartwatch sensors consists of two datasets devised to investigate sensor heterogeneities' impacts on human activity recognition algorithms (classification, automatic data segmentation, sensor fusion, feature extraction, etc). The datasets were used for the results and analyses produced in [1]. Activity recognition data setThe dataset contains the readings of two motion sensors commonly found in smartphones. Reading were recorded while users executed activities scripted in no specific order carrying smartwatches and smartphones.Activities: â€˜Bikingâ€™, â€˜Sittingâ€™, â€˜Standingâ€™, â€˜Walkingâ€™, â€˜Stair Upâ€™ and â€˜Stair downâ€™.Sensors: Sensors: Two embedded sensors, i.e., Accelerometer and Gyroscope, sampled at the highest frequency the respective device allows.Devices: 4 smartwatches (2 LG watches, 2 Samsung Galaxy Gears)8 smartphones (2 Samsung Galaxy S3 mini, 2 Samsung Galaxy S3, 2 LG Nexus 4, 2 Samsung Galaxy S+)Recordings: 9 users  Recording scenario===============The activity recognition environment and scenario has been designed to generate many activity primitives, yet in a realistic manner. Users took 2 different routes for the biking and walking, and 2 different set of stairs were used for the stairs up and down. Still experiment data set===================Accelerometer recordings as above but with devices lying still, in 6 different orientations. Devices used comprise 31 smartphones, 4 smartwatches and 1 tablet, representing 13 different models from 4 manufacturers, running variants of Android and iOS.Activity recognition data set accelerometer Samples ------------ The Phones_accelerometer.csv contains all smartphone accelerometer samples from all devices and users. The csv file consist of the following columns: 'Index', 'Arrival_Time', 'Creation_Time', 'x', 'y', 'z', 'User', 'Model', 'Device', 'gt' All samples from all the experiments is a row in the file containing each column value. ------------- Groundtruths -------------------- The null class is defined as null in the gt (groundtruth) column, whereas the rest of the classes can be seen in the column. ------------- Devices -------------------------- the phones from the still experiment which has been used for activity recognition is the following: Ã¢â‚¬Ëœit-116', 'it-133', 'it-108', 'it-103','it-123','3Renault-AH', 'no-name/LG-Nexus4','G-Watch' The device numbering used in the data set is: LG-Nexus 4 'nexus4_1' 'nexus4_2' Saumsung Galaxy S3 's3_1' 's3_2Ã¢â‚¬â„¢ Samsung Galaxy S3 min: 's3mini_1' 's3mini_2' Samsung Galaxy S+: 'samsungold_1' 'samsungold_2' Still experiment data set This is the Heterogeneity Dataset for Human Activity Recognition, and contains all the samples from the static still experiment. Where the phones where place in the 6 different possible orientation. The data set is structured in the following way: ------------- Static Accelerometer Samples ------------ Each specific device is located in the following way: Orientation/[Web Link] Where the 6 different orientations can be either one of the following: Phoneonback,Phoneonbottom,Phoneonfront,Phoneonleft,Phoneonright,Phoneontop For example to get the samples from the device named 3Renault-AH of the model Samsung-Galaxy-S3 Mini when laying static on the back we get the following structure: Phoneonback/3Renault-AH/Samsung-Galaxy-S3 Mini.csv. Each CSV file consist of 6 columns creation time, sensor time,arrival time,x,y,z. The six axes from the accelerometer is the x,y,z columns. "
Health News in Twitter,Health News in Twitter,"The data was collected in 2015 using Twitter API. This dataset contains health news from more than 15 major health news agencies such as BBC, CNN, and NYT. ",Health+News+in+Twitter,https://archive.ics.uci.edu/ml//machine-learning-databases/00438/,https://archive.ics.uci.edu/ml/datasets/Health+News+in+Twitter,"Each file is related to one Twitter account of a news agency. For example, bbchealth.txt is related to BBC health news. Each line contains tweet id|date and time|tweet. The separator is '|'. This text data has been used to evaluate the performance of topic models on short text data. However, it can be used for other tasks such as clustering. ",Computer,,"The data was collected in 2015 using Twitter API. This dataset contains health news from more than 15 major health news agencies such as BBC, CNN, and NYT. Each file is related to one Twitter account of a news agency. For example, bbchealth.txt is related to BBC health news. Each line contains tweet id|date and time|tweet. The separator is '|'. This text data has been used to evaluate the performance of topic models on short text data. However, it can be used for other tasks such as clustering. nan"
Youtube cookery channels viewers comments in Hinglish,Youtube cookery channels viewers comments in Hinglish,"The datasets are taken from top 2 Indian cooking channel named Nisha Madhulika channel and Kabitaâ€™s Kitchen channel.
The data set is in Hinglish Language. 


",Youtube+cookery+channels+viewers+comments+in+Hinglish,https://archive.ics.uci.edu/ml//machine-learning-databases/00535/,https://archive.ics.uci.edu/ml/datasets/Youtube+cookery+channels+viewers+comments+in+Hinglish,"The datasets are taken from top 2 Indian cooking channel named Nisha Madhulika channel and KabitaÃ¢â‚¬â„¢s  Kitchen channel.Both the datasets are divided into seven categories :-Label 1- GratitudeLabel 2- About the recipeLabel 3- About the videoLabel 4- PraisingLabel 5- HybridLabel 6- UndefinedLabel 7- Suggestions and queriesAll the labelling has been done manually.Nisha Madhulika dataset:Dataset characteristics: MultivariateNumber of instances: 4900Area: Cooking Attribute characteristics: RealNumber of attributes: 3Date donated: March, 2019Associate tasks: ClassificationMissing values: NullNumber of subscribers: 7,063,604Kabita Kitchen dataset:Dataset characteristics: MultivariateNumber of instances: 4900Area: Cooking Attribute characteristics: RealNumber of attributes: 3Date donated: March, 2019Associate tasks: ClassificationMissing values: NullNumber of subscribers: 4,867,502There are two separate datasets file of each channel. The files with preprocessing names are generated after doing the preprocessing and exploratory data analysis on both the datasets. This file includes:Ã¢â‚¬Â¢	 IdÃ¢â‚¬Â¢	Comment text Ã¢â‚¬Â¢	Labels Ã¢â‚¬Â¢	Count of stop-wordsÃ¢â‚¬Â¢	Uppercase wordsÃ¢â‚¬Â¢	HashtagsÃ¢â‚¬Â¢	Word count Ã¢â‚¬Â¢	Char countÃ¢â‚¬Â¢	Average wordsÃ¢â‚¬Â¢	NumericThe main file includes:Ã¢â‚¬Â¢	IdÃ¢â‚¬Â¢	comment text Ã¢â‚¬Â¢	Labels ",Computer,Provide information about each attribute in your data set.,"The datasets are taken from top 2 Indian cooking channel named Nisha Madhulika channel and Kabitaâ€™s Kitchen channel.
The data set is in Hinglish Language. 


The datasets are taken from top 2 Indian cooking channel named Nisha Madhulika channel and KabitaÃ¢â‚¬â„¢s  Kitchen channel.Both the datasets are divided into seven categories :-Label 1- GratitudeLabel 2- About the recipeLabel 3- About the videoLabel 4- PraisingLabel 5- HybridLabel 6- UndefinedLabel 7- Suggestions and queriesAll the labelling has been done manually.Nisha Madhulika dataset:Dataset characteristics: MultivariateNumber of instances: 4900Area: Cooking Attribute characteristics: RealNumber of attributes: 3Date donated: March, 2019Associate tasks: ClassificationMissing values: NullNumber of subscribers: 7,063,604Kabita Kitchen dataset:Dataset characteristics: MultivariateNumber of instances: 4900Area: Cooking Attribute characteristics: RealNumber of attributes: 3Date donated: March, 2019Associate tasks: ClassificationMissing values: NullNumber of subscribers: 4,867,502There are two separate datasets file of each channel. The files with preprocessing names are generated after doing the preprocessing and exploratory data analysis on both the datasets. This file includes:Ã¢â‚¬Â¢	 IdÃ¢â‚¬Â¢	Comment text Ã¢â‚¬Â¢	Labels Ã¢â‚¬Â¢	Count of stop-wordsÃ¢â‚¬Â¢	Uppercase wordsÃ¢â‚¬Â¢	HashtagsÃ¢â‚¬Â¢	Word count Ã¢â‚¬Â¢	Char countÃ¢â‚¬Â¢	Average wordsÃ¢â‚¬Â¢	NumericThe main file includes:Ã¢â‚¬Â¢	IdÃ¢â‚¬Â¢	comment text Ã¢â‚¬Â¢	Labels Provide information about each attribute in your data set."
YouTube Multiview Video Games Dataset,YouTube Multiview Video Games Dataset,"This dataset contains about 120k instances, each described by 13 feature types, with class information, specially useful for exploring multiview topics (cotraining, ensembles, clustering,..).",YouTube+Multiview+Video+Games+Dataset,https://archive.ics.uci.edu/ml//machine-learning-databases/00269/,https://archive.ics.uci.edu/ml/datasets/YouTube+Multiview+Video+Games+Dataset,"Please see the README for the details on the data organization, and so on.",Computer,Please see the README.,"This dataset contains about 120k instances, each described by 13 feature types, with class information, specially useful for exploring multiview topics (cotraining, ensembles, clustering,..).Please see the README for the details on the data organization, and so on.Please see the README."
Kain Tradisional Sambas,Kain Tradisional Sambas,"This data set consist of 5 patterns of Kain Tradisional Sambas's features from CFS (Correlation-Based Feature Selection) method which are Angular Second Moment, Contrast, and Correlation",Kain+Tradisional+Sambas,https://archive.ics.uci.edu/ml//machine-learning-databases/00632/,https://archive.ics.uci.edu/ml/datasets/Kain+Tradisional+Sambas,"This data set consist of 5 patterns of Kain Tradisional Sambas. The patterns are bunga kangkung, bunga tabur, rantai, zigzag, and sapar peranggi. Each pattern contains 30 instances which mean the total count are 150 instances. Image acquisition conducted by digital camera. Each pattern were photographed 30 times continously with fix position and good illumination. This data sets is developed by several steps which are image acquisition, preprocessing to reduce image noise, feature extraction to obtain image features, and feature selection. GLCM is implemented as feature extraction method.  Feature extraction result will be used in feature selection process using CFS (Correlation based Feature Selection) methods. Selected features from CFS process are Angular Second Moment, Contrast, and Correlation.",Computer,Provide information about each attribute in your data set.,"This data set consist of 5 patterns of Kain Tradisional Sambas's features from CFS (Correlation-Based Feature Selection) method which are Angular Second Moment, Contrast, and CorrelationThis data set consist of 5 patterns of Kain Tradisional Sambas. The patterns are bunga kangkung, bunga tabur, rantai, zigzag, and sapar peranggi. Each pattern contains 30 instances which mean the total count are 150 instances. Image acquisition conducted by digital camera. Each pattern were photographed 30 times continously with fix position and good illumination. This data sets is developed by several steps which are image acquisition, preprocessing to reduce image noise, feature extraction to obtain image features, and feature selection. GLCM is implemented as feature extraction method.  Feature extraction result will be used in feature selection process using CFS (Correlation based Feature Selection) methods. Selected features from CFS process are Angular Second Moment, Contrast, and Correlation.Provide information about each attribute in your data set."
Online Video Characteristics and Transcoding Time Dataset,Online Video Characteristics and Transcoding Time Dataset,The dataset contains a million randomly sampled video instances listing 10 fundamental video characteristics along with the YouTube video ID. ,Online+Video+Characteristics+and+Transcoding+Time+Dataset,https://archive.ics.uci.edu/ml//machine-learning-databases/00335/,https://archive.ics.uci.edu/ml/datasets/Online+Video+Characteristics+and+Transcoding+Time+Dataset,"The presented dataset is composed of two tsv files named 'youtube_videos.tsv' and 'transcoding_mesurment.tsv'. The first contains 10 columns of fundamental video characteristics for 1.6 million youtube videos; It contains YouTube video id, duration, bitrate(total in Kbits), bitrate(video bitrate in Kbits), height(in pixle), width(in pixles), framrate, estimated framerate, codec, category, and direct video link. This dataset can be used to gain insightin characteristics of consumer videos found on UGC(Youtube).The second file of our dataset contains 20 columns(see column names for names) which include input and output video characteristics along with their transcoding time and memory resource requirements while transcoding videos to diffrent but valid formats. The second dataset was collected based on experiments on an Intel i7-3720QM CPU through randomly picking two rows from the first dataset and using these as input and output parameters of a video transcoding application, ffmpeg 4 . In section 6 we will use the second dataset to build a transcoding time predictionmodel and show the significance of our datasets.",Computer,id  = Youtube videp id     duration = duration of video        bitrate bitrate(video) = video bitrate  height = height of video in pixles  width  = width of video in pixlesframe rate = actual video frame rate      frame rate(est.) =  estimated video frame rate       codec = coding standard used for the video   category = YouTube video category        url = direct link to video (has expiration date)i = number of i frames in the video    p = number of p frames in the video    b = number of b frames in the videoframes = number of frames in videoi_size = total size in byte of i videos         p_size = total size in byte of p videos        b_size = total size in byte of b videos        size = total size of video  o_codec = output codec used for transcodingo_bitrate = output bitrate used for transcoding      o_framerate = output framerate used for transcodingo_width = output width in pixel used for transcodingo_height = output height used in pixel for transcodingumem = total codec allocated memory for transcoding   utime = total transcoding time for transcoding,"The dataset contains a million randomly sampled video instances listing 10 fundamental video characteristics along with the YouTube video ID. The presented dataset is composed of two tsv files named 'youtube_videos.tsv' and 'transcoding_mesurment.tsv'. The first contains 10 columns of fundamental video characteristics for 1.6 million youtube videos; It contains YouTube video id, duration, bitrate(total in Kbits), bitrate(video bitrate in Kbits), height(in pixle), width(in pixles), framrate, estimated framerate, codec, category, and direct video link. This dataset can be used to gain insightin characteristics of consumer videos found on UGC(Youtube).The second file of our dataset contains 20 columns(see column names for names) which include input and output video characteristics along with their transcoding time and memory resource requirements while transcoding videos to diffrent but valid formats. The second dataset was collected based on experiments on an Intel i7-3720QM CPU through randomly picking two rows from the first dataset and using these as input and output parameters of a video transcoding application, ffmpeg 4 . In section 6 we will use the second dataset to build a transcoding time predictionmodel and show the significance of our datasets.id  = Youtube videp id     duration = duration of video        bitrate bitrate(video) = video bitrate  height = height of video in pixles  width  = width of video in pixlesframe rate = actual video frame rate      frame rate(est.) =  estimated video frame rate       codec = coding standard used for the video   category = YouTube video category        url = direct link to video (has expiration date)i = number of i frames in the video    p = number of p frames in the video    b = number of b frames in the videoframes = number of frames in videoi_size = total size in byte of i videos         p_size = total size in byte of p videos        b_size = total size in byte of b videos        size = total size of video  o_codec = output codec used for transcodingo_bitrate = output bitrate used for transcoding      o_framerate = output framerate used for transcodingo_width = output width in pixel used for transcodingo_height = output height used in pixel for transcodingumem = total codec allocated memory for transcoding   utime = total transcoding time for transcoding"
Open University Learning Analytics dataset,Open University Learning Analytics dataset,"Open University Learning Analytics Dataset contains data about courses, students and their interactions with Virtual Learning Environment for seven selected courses and more than 30000 students.",Open+University+Learning+Analytics+dataset,https://archive.ics.uci.edu/ml//machine-learning-databases/00349/,https://archive.ics.uci.edu/ml/datasets/Open+University+Learning+Analytics+dataset,"Open University Learning Analytics Dataset (OULAD) contains data about courses, students and their interactions with Virtual Learning Environment (VLE) for seven selected courses (called modules). Presentations of courses start in February and October - they are marked by 'B' and 'J' respectively. The dataset consists of tables connected using unique identifiers. Dataset is stored in several csv files. More information, examples and news can be found at:       [Web Link]",Computer,see description file,"Open University Learning Analytics Dataset contains data about courses, students and their interactions with Virtual Learning Environment for seven selected courses and more than 30000 students.Open University Learning Analytics Dataset (OULAD) contains data about courses, students and their interactions with Virtual Learning Environment (VLE) for seven selected courses (called modules). Presentations of courses start in February and October - they are marked by 'B' and 'J' respectively. The dataset consists of tables connected using unique identifiers. Dataset is stored in several csv files. More information, examples and news can be found at:       [Web Link]see description file"
Skin Segmentation,Skin Segmentation,"The Skin Segmentation dataset is constructed over B, G, R color space. Skin and Nonskin dataset is generated using skin textures from face images of diversity of age, gender, and race people.",Skin+Segmentation,https://archive.ics.uci.edu/ml//machine-learning-databases/00229/,https://archive.ics.uci.edu/ml/datasets/Skin+Segmentation,"The skin dataset is collected by randomly sampling B,G,R values from face images of various age groups (young, middle, and old), race groups (white, black, and asian), and genders obtained from FERET database and PAL database. Total learning sample size is 245057; out of which 50859 is the skin samples and 194198 is non-skin samples. Color FERET Image Database: [Web Link], PAL Face Database from Productive Aging Laboratory, The University of Texas at Dallas: [Web Link].  ",Computer,"This dataset is of the dimension 245057 * 4 where first three columns are B,G,R (x1,x2, and x3 features) values and fourth column is of the class labels (decision variable y). ","The Skin Segmentation dataset is constructed over B, G, R color space. Skin and Nonskin dataset is generated using skin textures from face images of diversity of age, gender, and race people.The skin dataset is collected by randomly sampling B,G,R values from face images of various age groups (young, middle, and old), race groups (white, black, and asian), and genders obtained from FERET database and PAL database. Total learning sample size is 245057; out of which 50859 is the skin samples and 194198 is non-skin samples. Color FERET Image Database: [Web Link], PAL Face Database from Productive Aging Laboratory, The University of Texas at Dallas: [Web Link].  This dataset is of the dimension 245057 * 4 where first three columns are B,G,R (x1,x2, and x3 features) values and fourth column is of the class labels (decision variable y). "
SIFT10M,SIFT10M,"In SIFT10M, each data point is a SIFT feature which is extracted from Caltech-256 by the open source VLFeat library. The corresponding patches of the SIFT features are provided.",SIFT10M,https://archive.ics.uci.edu/ml//machine-learning-databases/00353/,https://archive.ics.uci.edu/ml/datasets/SIFT10M,"In SIFT10M, the titles of the png files indicate the columns position of the SIFT features. This data set has been used for evaluating the approximate nearest neighbour search methods. The patches can be used for visualisation purpose and helps for analysing the performance of the corresponding approximate nearest neighbour search methods.",Computer,"Each SIFT feature is a 128D column, and the corresponding patch is saved in  41*41 png format. The png files are compressed into 307 tar files for downloading.","In SIFT10M, each data point is a SIFT feature which is extracted from Caltech-256 by the open source VLFeat library. The corresponding patches of the SIFT features are provided.In SIFT10M, the titles of the png files indicate the columns position of the SIFT features. This data set has been used for evaluating the approximate nearest neighbour search methods. The patches can be used for visualisation purpose and helps for analysing the performance of the corresponding approximate nearest neighbour search methods.Each SIFT feature is a 128D column, and the corresponding patch is saved in  41*41 png format. The png files are compressed into 307 tar files for downloading."
Shill Bidding Dataset,Shill Bidding Dataset,"We scraped a large number of eBay auctions of a popular product. After preprocessing the auction data, we build the SB dataset. The goal is to share the labelled SB dataset with the researchers.",Shill+Bidding+Dataset,https://archive.ics.uci.edu/ml//machine-learning-databases/00562/,https://archive.ics.uci.edu/ml/datasets/Shill+Bidding+Dataset,Provide all relevant information about your data set.,Computer,Record ID: Unique identifier of a record in the dataset.Auction ID: Unique identifier of an auction.Bidder ID: Unique identifier of a bidder.Bidder Tendency: A shill bidder participates exclusively in auctions of few sellers rather than a diversified lot.  This is a collusive act involving the fraudulent seller and an accomplice.Bidding Ratio: A shill bidder participates more frequently to raise the auction price and attract higher bids from legitimate participants.Successive Outbidding: A shill bidder successively outbids himself even though he is the current winner to increase the price gradually with small consecutive increments.Last Bidding: A shill bidder becomes inactive at the last stage of the auction (more than 90\% of the auction duration) to avoid winning the auction.Auction Bids: Auctions with SB activities tend to have a much higher number of bids than the average of bids in concurrent auctions.Auction Starting Price:  a shill bidder usually offers a small starting price to attract legitimate bidders into the auction.Early Bidding: A shill bidder tends to bid pretty early in the auction (less than 25\% of the auction duration) to get the attention of auction users.Winning Ratio: A shill bidder competes in many auctions but hardly wins any auctions. Auction Duration:  How long an auction lasted.Class: 0 for normal behaviour bidding; 1 for otherwise.,"We scraped a large number of eBay auctions of a popular product. After preprocessing the auction data, we build the SB dataset. The goal is to share the labelled SB dataset with the researchers.Provide all relevant information about your data set.Record ID: Unique identifier of a record in the dataset.Auction ID: Unique identifier of an auction.Bidder ID: Unique identifier of a bidder.Bidder Tendency: A shill bidder participates exclusively in auctions of few sellers rather than a diversified lot.  This is a collusive act involving the fraudulent seller and an accomplice.Bidding Ratio: A shill bidder participates more frequently to raise the auction price and attract higher bids from legitimate participants.Successive Outbidding: A shill bidder successively outbids himself even though he is the current winner to increase the price gradually with small consecutive increments.Last Bidding: A shill bidder becomes inactive at the last stage of the auction (more than 90\% of the auction duration) to avoid winning the auction.Auction Bids: Auctions with SB activities tend to have a much higher number of bids than the average of bids in concurrent auctions.Auction Starting Price:  a shill bidder usually offers a small starting price to attract legitimate bidders into the auction.Early Bidding: A shill bidder tends to bid pretty early in the auction (less than 25\% of the auction duration) to get the attention of auction users.Winning Ratio: A shill bidder competes in many auctions but hardly wins any auctions. Auction Duration:  How long an auction lasted.Class: 0 for normal behaviour bidding; 1 for otherwise."
SGEMM GPU kernel performance,SGEMM GPU kernel performance,Running times for multiplying two 2048 x 2048 matrices using a GPU OpenCL SGEMM kernel with varying parameters (using the library 'CLTune').,SGEMM+GPU+kernel+performance,https://archive.ics.uci.edu/ml//machine-learning-databases/00440/,https://archive.ics.uci.edu/ml/datasets/SGEMM+GPU+kernel+performance,"This data set measures the running time of a matrix-matrix product A*B = C, where all matrices have size 2048 x 2048, using a parameterizable SGEMM GPU kernel with 241600 possible parameter combinations. For each tested combination, 4 runs were performed and their results are reported as the 4 last columns. All times are measured in milliseconds*.There are 14 parameter, the first 10 are ordinal and can only take up to 4 different powers of two values, and the 4 last variables are binary. Out of 1327104 total parameter combinations, only 241600 are feasible (due to various kernel constraints). This data set contains the results for all these feasible combinations.The experiment was run on a desktop workstation running Ubuntu 16.04 Linux with an Intel Core i5 (3.5GHz), 16GB RAM, and a NVidia Geforce GTX 680 4GB GF580 GTX-1.5GB GPU. We use the 'gemm_fast' kernel from the automatic OpenCL kernel tuning library 'CLTune' ([Web Link]).* Note: for this kind of data sets it is usually better to work with the logarithm of the running times (see e.g. Falch and Elster, 'Machine learning-based auto-tuning for enhanced performance portability of OpenCL applications', 2015).",Computer,"- Independent variables:    1-2. MWG, NWG: per-matrix 2D tiling at workgroup level: {16, 32, 64, 128} (integer)    3. KWG: inner dimension of 2D tiling at workgroup level: {16, 32} (integer)    4-5. MDIMC, NDIMC: local workgroup size: {8, 16, 32} (integer)    6-7. MDIMA, NDIMB: local memory shape: {8, 16, 32} (integer)    8. KWI: kernel loop unrolling factor: {2, 8} (integer)    9-10. VWM, VWN: per-matrix vector widths for loading and storing: {1, 2, 4, 8} (integer)    11-12. STRM, STRN: enable stride for accessing off-chip memory within a single thread: {0, 1} (categorical)    13-14. SA, SB: per-matrix manual caching of the 2D workgroup tile: {0, 1} (categorical)- Output:    15-18. Run1, Run2, Run3, Run4: performance times in milliseconds for 4 independent runs using the same parameters. They range between 13.25 and 3397.08.","Running times for multiplying two 2048 x 2048 matrices using a GPU OpenCL SGEMM kernel with varying parameters (using the library 'CLTune').This data set measures the running time of a matrix-matrix product A*B = C, where all matrices have size 2048 x 2048, using a parameterizable SGEMM GPU kernel with 241600 possible parameter combinations. For each tested combination, 4 runs were performed and their results are reported as the 4 last columns. All times are measured in milliseconds*.There are 14 parameter, the first 10 are ordinal and can only take up to 4 different powers of two values, and the 4 last variables are binary. Out of 1327104 total parameter combinations, only 241600 are feasible (due to various kernel constraints). This data set contains the results for all these feasible combinations.The experiment was run on a desktop workstation running Ubuntu 16.04 Linux with an Intel Core i5 (3.5GHz), 16GB RAM, and a NVidia Geforce GTX 680 4GB GF580 GTX-1.5GB GPU. We use the 'gemm_fast' kernel from the automatic OpenCL kernel tuning library 'CLTune' ([Web Link]).* Note: for this kind of data sets it is usually better to work with the logarithm of the running times (see e.g. Falch and Elster, 'Machine learning-based auto-tuning for enhanced performance portability of OpenCL applications', 2015).- Independent variables:    1-2. MWG, NWG: per-matrix 2D tiling at workgroup level: {16, 32, 64, 128} (integer)    3. KWG: inner dimension of 2D tiling at workgroup level: {16, 32} (integer)    4-5. MDIMC, NDIMC: local workgroup size: {8, 16, 32} (integer)    6-7. MDIMA, NDIMB: local memory shape: {8, 16, 32} (integer)    8. KWI: kernel loop unrolling factor: {2, 8} (integer)    9-10. VWM, VWN: per-matrix vector widths for loading and storing: {1, 2, 4, 8} (integer)    11-12. STRM, STRN: enable stride for accessing off-chip memory within a single thread: {0, 1} (categorical)    13-14. SA, SB: per-matrix manual caching of the 2D workgroup tile: {0, 1} (categorical)- Output:    15-18. Run1, Run2, Run3, Run4: performance times in milliseconds for 4 independent runs using the same parameters. They range between 13.25 and 3397.08."
Servo,Servo,Data was from a simulation of a servo system,Servo,https://archive.ics.uci.edu/ml//machine-learning-databases/servo/,https://archive.ics.uci.edu/ml/datasets/Servo,"Ross Quinlan:This data was given to me by Karl Ulrich at MIT in 1986.  I didn't record his description at the time, but here's his subsequent (1992) recollection: ""I seem to remember that the data was from a simulation of a servo system involving a servo amplifier, a motor, a lead screw/nut, and a sliding carriage of some sort.  It may have been on of the translational axes of a robot on the 9th floor of the AI lab.  In any case, the output value is almost certainly a rise time, or the time required for the system to respond to a step change in a position set point."" (Quinlan, ML'93)""This is an interesting collection of data provided by Karl Ulrich.  It covers an extremely non-linear phenomenon - predicting the rise time of a servomechanism in terms of two (continuous) gain settings and two (discrete) choices of mechanical linkages.""",Computer,"   1. motor: A,B,C,D,E   2. screw: A,B,C,D,E   3. pgain: 3,4,5,6   4. vgain: 1,2,3,4,5   5. class: 0.13 to 7.10","Data was from a simulation of a servo systemRoss Quinlan:This data was given to me by Karl Ulrich at MIT in 1986.  I didn't record his description at the time, but here's his subsequent (1992) recollection: ""I seem to remember that the data was from a simulation of a servo system involving a servo amplifier, a motor, a lead screw/nut, and a sliding carriage of some sort.  It may have been on of the translational axes of a robot on the 9th floor of the AI lab.  In any case, the output value is almost certainly a rise time, or the time required for the system to respond to a step change in a position set point."" (Quinlan, ML'93)""This is an interesting collection of data provided by Karl Ulrich.  It covers an extremely non-linear phenomenon - predicting the rise time of a servomechanism in terms of two (continuous) gain settings and two (discrete) choices of mechanical linkages.""   1. motor: A,B,C,D,E   2. screw: A,B,C,D,E   3. pgain: 3,4,5,6   4. vgain: 1,2,3,4,5   5. class: 0.13 to 7.10"
ser Knowledge Modeling Data (Students' Knowledge Levels on DC Electrical Machines),ser Knowledge Modeling Data (Students' Knowledge Levels on DC Electrical Machines),The dataset is about the users' learning activities and knowledge levels on subjects of DC  Electrical Machines. The dataset had been obtained from online web-courses  and reported in my Ph.D. Thesis.,ser+Knowledge+Modeling+Data+%28Students%27+Knowledge+Levels+on+DC+Electrical+Machines%29,https://archive.ics.uci.edu/ml//machine-learning-databases/00263/,https://archive.ics.uci.edu/ml/datasets/ser+Knowledge+Modeling+Data+%28Students%27+Knowledge+Levels+on+DC+Electrical+Machines%29,"-- The users' knowledge class were classified by the authors      using intuitive knowledge classifier (a hybrid ML technique of k-NN and meta-heuristic exploring methods), k-nearest neighbor algorithm.       See article for more details on how the users' data was collected and evaluated by the user modeling server.	Kahraman, H. T., Sagiroglu, S., Colak, I., Developing intuitive knowledge classifier and modeling of users' domain dependent data in web,         Knowledge Based Systems, vol. 37, pp. 283-295, 2013. 	        Kahraman, H. T. (2009). Designing and Application of Web-Based Adaptive Intelligent Education System. Gazi University Ph. D. Thesis, Turkey, 1-156.",Computer,"        STG (The degree of study time for goal object materails), (input value) 	SCG (The degree of repetition number of user for goal object materails) (input value) 	STR (The degree of study time of user for related objects with goal object) (input value) 	LPR (The exam performance of user for related objects with goal object) (input value) 	PEG (The exam performance of user for goal objects) (input value) 	UNS (The knowledge level of user) (target value)  Class Distribution: the class value (UNS).        Very Low: 50	Low:129	Middle: 122	high 130","The dataset is about the users' learning activities and knowledge levels on subjects of DC  Electrical Machines. The dataset had been obtained from online web-courses  and reported in my Ph.D. Thesis.-- The users' knowledge class were classified by the authors      using intuitive knowledge classifier (a hybrid ML technique of k-NN and meta-heuristic exploring methods), k-nearest neighbor algorithm.       See article for more details on how the users' data was collected and evaluated by the user modeling server.	Kahraman, H. T., Sagiroglu, S., Colak, I., Developing intuitive knowledge classifier and modeling of users' domain dependent data in web,         Knowledge Based Systems, vol. 37, pp. 283-295, 2013. 	        Kahraman, H. T. (2009). Designing and Application of Web-Based Adaptive Intelligent Education System. Gazi University Ph. D. Thesis, Turkey, 1-156.        STG (The degree of study time for goal object materails), (input value) 	SCG (The degree of repetition number of user for goal object materails) (input value) 	STR (The degree of study time of user for related objects with goal object) (input value) 	LPR (The exam performance of user for related objects with goal object) (input value) 	PEG (The exam performance of user for goal objects) (input value) 	UNS (The knowledge level of user) (target value)  Class Distribution: the class value (UNS).        Very Low: 50	Low:129	Middle: 122	high 130"
Seoul Bike Sharing Demand,Seoul Bike Sharing Demand,The dataset contains count of public bikes rented at each hour in Seoul Bike haring System with the corresponding Weather data and Holidays information,Seoul+Bike+Sharing+Demand,https://archive.ics.uci.edu/ml//machine-learning-databases/00560/,https://archive.ics.uci.edu/ml/datasets/Seoul+Bike+Sharing+Demand,"Currently Rental bikes are introduced in many urban cities for the enhancement of mobility comfort. It is important to make the rental bike available and accessible to the public at the right time as it lessens the waiting time. Eventually, providing the city with a stable supply of rental bikes becomes a major concern. The crucial part is the prediction of bike count required at each hour for the stable supply of rental bikes. The dataset contains weather information (Temperature, Humidity, Windspeed, Visibility, Dewpoint, Solar radiation, Snowfall, Rainfall), the number of bikes rented per hour and date information. ",Computer,"Date : year-month-dayRented Bike count - Count of bikes rented at each hourHour - Hour of he dayTemperature-Temperature in CelsiusHumidity - %Windspeed - m/sVisibility - 10mDew point temperature - Celsius Solar radiation - MJ/m2Rainfall - mmSnowfall - cmSeasons - Winter, Spring, Summer, AutumnHoliday - Holiday/No holidayFunctional Day - NoFunc(Non Functional Hours), Fun(Functional hours)","The dataset contains count of public bikes rented at each hour in Seoul Bike haring System with the corresponding Weather data and Holidays informationCurrently Rental bikes are introduced in many urban cities for the enhancement of mobility comfort. It is important to make the rental bike available and accessible to the public at the right time as it lessens the waiting time. Eventually, providing the city with a stable supply of rental bikes becomes a major concern. The crucial part is the prediction of bike count required at each hour for the stable supply of rental bikes. The dataset contains weather information (Temperature, Humidity, Windspeed, Visibility, Dewpoint, Solar radiation, Snowfall, Rainfall), the number of bikes rented per hour and date information. Date : year-month-dayRented Bike count - Count of bikes rented at each hourHour - Hour of he dayTemperature-Temperature in CelsiusHumidity - %Windspeed - m/sVisibility - 10mDew point temperature - Celsius Solar radiation - MJ/m2Rainfall - mmSnowfall - cmSeasons - Winter, Spring, Summer, AutumnHoliday - Holiday/No holidayFunctional Day - NoFunc(Non Functional Hours), Fun(Functional hours)"
Smartphone Dataset for Human Activity Recognition (HAR) in Ambient Assisted Living (AAL),Smartphone Dataset for Human Activity Recognition (HAR) in Ambient Assisted Living (AAL),This data is an addition to an existing dataset on UCI. We collected more data to improve the accuracy of our human activity recognition algorithms applied in the domain of Ambient Assisted Living.  ,Smartphone+Dataset+for+Human+Activity+Recognition+%28HAR%29+in+Ambient+Assisted+Living+%28AAL%29,https://archive.ics.uci.edu/ml//machine-learning-databases/00364/,https://archive.ics.uci.edu/ml/datasets/Smartphone+Dataset+for+Human+Activity+Recognition+%28HAR%29+in+Ambient+Assisted+Living+%28AAL%29,"This dataset is an addition to the dataset at       [Web Link]      We collected more dataset to improve the accuracy of our HAR algorithms applied in       a Social connectedness experiment in the domain of Ambient Assisted Living.       The dataset was collected from the in-built accelerometer and gyroscope of a       smartphone worn around the waist of participants. See waist_mounted_phone.PNG.      The data was collected from 30 participants within the age group of 22-79 years.       Each activity (standing, sitting, laying, walking, walking upstairs, walking downstairs) was       performed for 60secs and the 3-axial linear acceleration and 3-axial angular velocity  were       collected at a constant rate of 50Hz.",Computer,"For each record in the dataset it is provided:    - Triaxial acceleration from the accelerometer (total acceleration).      Filenames: final_acc_train.txt, final_acc_test.txt   - Triaxial Angular velocity from the gyroscope.      Filenames: final_gyro_train.txt, final_gyro_test.txt   - A 561-feature vector with time and frequency domain variables      (extracted from the triaxial data)      Filenames: final_X_train.txt, final_X_test.txt     For more information about the features extracted see (features.txt and features_info.txt)   - The corresponding activity labels. Filenames: final_y_train.txt and final_y_test.txt.","This data is an addition to an existing dataset on UCI. We collected more data to improve the accuracy of our human activity recognition algorithms applied in the domain of Ambient Assisted Living.  This dataset is an addition to the dataset at       [Web Link]      We collected more dataset to improve the accuracy of our HAR algorithms applied in       a Social connectedness experiment in the domain of Ambient Assisted Living.       The dataset was collected from the in-built accelerometer and gyroscope of a       smartphone worn around the waist of participants. See waist_mounted_phone.PNG.      The data was collected from 30 participants within the age group of 22-79 years.       Each activity (standing, sitting, laying, walking, walking upstairs, walking downstairs) was       performed for 60secs and the 3-axial linear acceleration and 3-axial angular velocity  were       collected at a constant rate of 50Hz.For each record in the dataset it is provided:    - Triaxial acceleration from the accelerometer (total acceleration).      Filenames: final_acc_train.txt, final_acc_test.txt   - Triaxial Angular velocity from the gyroscope.      Filenames: final_gyro_train.txt, final_gyro_test.txt   - A 561-feature vector with time and frequency domain variables      (extracted from the triaxial data)      Filenames: final_X_train.txt, final_X_test.txt     For more information about the features extracted see (features.txt and features_info.txt)   - The corresponding activity labels. Filenames: final_y_train.txt and final_y_test.txt."
sentiment analysis in Saudi Arabia about distance education during Covid-19 ,sentiment analysis in Saudi Arabia about distance education during Covid-19 ,"The data were collected from Twitter. About distance education in Saudi Arabia due to Covid-19 pandemic. Data were gathered from Sep 2 to 17, 2020. Arabic Tweets classified as positive or negative.",sentiment+analysis+in+Saudi+Arabia+about+distance+education+during+Covid-19+,https://archive.ics.uci.edu/ml//machine-learning-databases/00631/,https://archive.ics.uci.edu/ml/datasets/sentiment+analysis+in+Saudi+Arabia+about+distance+education+during+Covid-19+,"The data were collected by Twint from Twitter. About distance education in Saudi Arabia due to the Covid-19 pandemic. Data were gathered between September 2 and September 17, 2020, which were the first two weeks in the new academic year. From four trending hashtags about education. All Tweets in the Arabic language classified into positive or negative.",Computer,"Date: the date of the tweetTime: the time of a tweetTweet: the text of a tweetreplies_count: the number of reply to the tweetretweets_count: the number of retweet for the tweetlikes_count: the number of likes for the tweethashtags: number of hashtags used in the tweet near: the name of the city where we collected week: week of the tweet if it is in the first or second weekclass: 0 for the reject, 1 for support the distance education","The data were collected from Twitter. About distance education in Saudi Arabia due to Covid-19 pandemic. Data were gathered from Sep 2 to 17, 2020. Arabic Tweets classified as positive or negative.The data were collected by Twint from Twitter. About distance education in Saudi Arabia due to the Covid-19 pandemic. Data were gathered between September 2 and September 17, 2020, which were the first two weeks in the new academic year. From four trending hashtags about education. All Tweets in the Arabic language classified into positive or negative.Date: the date of the tweetTime: the time of a tweetTweet: the text of a tweetreplies_count: the number of reply to the tweetretweets_count: the number of retweet for the tweetlikes_count: the number of likes for the tweethashtags: number of hashtags used in the tweet near: the name of the city where we collected week: week of the tweet if it is in the first or second weekclass: 0 for the reject, 1 for support the distance education"
selfBACK,selfBACK,"The SELFBACK dataset is a Human Activity Recognition Dataset of 9
activity classes recorded with two tri-axial accelerometers.",selfBACK,https://archive.ics.uci.edu/ml//machine-learning-databases/00521/,https://archive.ics.uci.edu/ml/datasets/selfBACK,"The SELFBACK dataset contains data of 9 activity classes; 6 ambulatory activitiesand 3 sedentary activities, performed by 33 participants.Data are recorded with two tri-axial accelerometers sampling at 100Hz, mounted onthe dominant side wrist and the thigh of the participant.**Application**The dataset can be used for human activity recognition by developing algorithms forpre-processing, feature extraction, sensor fusion, segmentation and classification.** Data collection method **Each participant performed an activity for approximately 3 minutes.** Sensors**Axivity AX3 3-Axis Logging Accelerometer- sampling frequency -- 100Hz- range -- 8g** Activity Classes**- Walking Upstairs- Walking Downstairs- Walking in slow pace- Walking in medium pace- Walking in fast pace- Jogging- Standing- Sitting- Lying** Data folder **SELFBACK dataset has three folders, two folders one for each sensor modalitynamed ""w"" for wrist and ""t"" for thigh and an additional folder where two sensormodalities are merged using timestamp named ""wt"" for wrist and thigh.Inside ""w"" and ""t"" folders, 9 folders can be found, one for each activity class, andinside, there are 33 files, one file for each participant.Inside ""wt"" folder, there are 297(33 X 9) files where the file name indicates theperson and the activity.",Computer,The 4 columns in the files in t and w folder is organized as follows:1 -- timestamp2 -- x value3 -- y value4 -- z valueMin value = -8Max value = +8The 6 columns in the files in wt folder is organized as follows:1 -- wrist x value2 -- wrist y value3 -- wrist z value4 -- thigh x value5 -- thigh y value6 -- thigh z valueMin value = -8Max value = +8,"The SELFBACK dataset is a Human Activity Recognition Dataset of 9
activity classes recorded with two tri-axial accelerometers.The SELFBACK dataset contains data of 9 activity classes; 6 ambulatory activitiesand 3 sedentary activities, performed by 33 participants.Data are recorded with two tri-axial accelerometers sampling at 100Hz, mounted onthe dominant side wrist and the thigh of the participant.**Application**The dataset can be used for human activity recognition by developing algorithms forpre-processing, feature extraction, sensor fusion, segmentation and classification.** Data collection method **Each participant performed an activity for approximately 3 minutes.** Sensors**Axivity AX3 3-Axis Logging Accelerometer- sampling frequency -- 100Hz- range -- 8g** Activity Classes**- Walking Upstairs- Walking Downstairs- Walking in slow pace- Walking in medium pace- Walking in fast pace- Jogging- Standing- Sitting- Lying** Data folder **SELFBACK dataset has three folders, two folders one for each sensor modalitynamed ""w"" for wrist and ""t"" for thigh and an additional folder where two sensormodalities are merged using timestamp named ""wt"" for wrist and thigh.Inside ""w"" and ""t"" folders, 9 folders can be found, one for each activity class, andinside, there are 33 files, one file for each participant.Inside ""wt"" folder, there are 297(33 X 9) files where the file name indicates theperson and the activity.The 4 columns in the files in t and w folder is organized as follows:1 -- timestamp2 -- x value3 -- y value4 -- z valueMin value = -8Max value = +8The 6 columns in the files in wt folder is organized as follows:1 -- wrist x value2 -- wrist y value3 -- wrist z value4 -- thigh x value5 -- thigh y value6 -- thigh z valueMin value = -8Max value = +8"
SECOM,SECOM,Data from a semi-conductor manufacturing process,SECOM,https://archive.ics.uci.edu/ml//machine-learning-databases/secom/,https://archive.ics.uci.edu/ml/datasets/SECOM,"A complex modern semi-conductor manufacturing process is normally under consistent surveillance via the monitoring of signals/variables collected from sensors and or process measurement points. However, not all of these signals are equally valuable in a specific monitoring system. The measured signals contain a combination of useful information, irrelevant information as well as noise. It is often the case that useful information is buried in the latter two. Engineers typically have a much larger number of signals than are actually required. If we consider each type of signal as a feature, then feature selection may be applied to identify the most relevant signals. The Process Engineers may then use these signals to determine key factors contributing to yield excursions downstream in the process. This will enable an increase in process throughput, decreased time to learning and reduce the per unit production costs.To enhance current business improvement techniques the application of feature selection as an intelligent systems technique is being investigated.The dataset presented in this case represents a selection of such features where each example represents a single production entity with associated measured features and the labels represent a simple pass/fail yield for in house line testing, figure 2, and associated date time stamp. Where â€“1 corresponds to a pass and 1 corresponds to a fail and the data time stamp is for that specific test point.Using feature selection techniques it is desired to rank features according to their impact on the overall yield for the product, causal relationships may also be considered with a view to identifying the key features.Results may be submitted in terms of feature relevance for predictability using error rates as our evaluation metrics. It is suggested that cross validation be applied to generate these results. Some baseline results are shown below for basic feature selection techniques using a simple kernel ridge classifier and 10 fold cross validation.Baseline Results: Pre-processing objects were applied to the dataset simply to standardize the data and remove the constant features and then a number of different feature selection objects selecting 40 highest ranked features were applied with a simple classifier to achieve some initial results. 10 fold cross validation was used and the balanced error rate (*BER) generated as our initial performance metric to help investigate this dataset.SECOM Dataset: 1567 examples 591 features, 104 failsFSmethod (40 features) BER % True + % True - %S2N (signal to noise) 34.5 +-2.6 57.8 +-5.3 73.1 +2.1Ttest 33.7 +-2.1 59.6 +-4.7 73.0 +-1.8Relief 40.1 +-2.8 48.3 +-5.9 71.6 +-3.2Pearson 34.1 +-2.0 57.4 +-4.3 74.4 +-4.9Ftest 33.5 +-2.2 59.1 +-4.8 73.8 +-1.8Gram Schmidt 35.6 +-2.4 51.2 +-11.8 77.5 +-2.3",Computer,Key facts: Data Structure: The data consists of 2 files the dataset file SECOM consisting of 1567 examples each with 591 features a 1567 x 591 matrix and a labels file containing the classifications and date time stamp for each example. As with any real life data situations this data contains null values varying in intensity depending on the individuals features. This needs to be taken into consideration when investigating the data either through pre-processing or within the technique applied. The data is represented in a raw text file each line representing an individual example and the features seperated by spaces. The null values are represented by the 'NaN' value as per MatLab. ,"Data from a semi-conductor manufacturing processA complex modern semi-conductor manufacturing process is normally under consistent surveillance via the monitoring of signals/variables collected from sensors and or process measurement points. However, not all of these signals are equally valuable in a specific monitoring system. The measured signals contain a combination of useful information, irrelevant information as well as noise. It is often the case that useful information is buried in the latter two. Engineers typically have a much larger number of signals than are actually required. If we consider each type of signal as a feature, then feature selection may be applied to identify the most relevant signals. The Process Engineers may then use these signals to determine key factors contributing to yield excursions downstream in the process. This will enable an increase in process throughput, decreased time to learning and reduce the per unit production costs.To enhance current business improvement techniques the application of feature selection as an intelligent systems technique is being investigated.The dataset presented in this case represents a selection of such features where each example represents a single production entity with associated measured features and the labels represent a simple pass/fail yield for in house line testing, figure 2, and associated date time stamp. Where â€“1 corresponds to a pass and 1 corresponds to a fail and the data time stamp is for that specific test point.Using feature selection techniques it is desired to rank features according to their impact on the overall yield for the product, causal relationships may also be considered with a view to identifying the key features.Results may be submitted in terms of feature relevance for predictability using error rates as our evaluation metrics. It is suggested that cross validation be applied to generate these results. Some baseline results are shown below for basic feature selection techniques using a simple kernel ridge classifier and 10 fold cross validation.Baseline Results: Pre-processing objects were applied to the dataset simply to standardize the data and remove the constant features and then a number of different feature selection objects selecting 40 highest ranked features were applied with a simple classifier to achieve some initial results. 10 fold cross validation was used and the balanced error rate (*BER) generated as our initial performance metric to help investigate this dataset.SECOM Dataset: 1567 examples 591 features, 104 failsFSmethod (40 features) BER % True + % True - %S2N (signal to noise) 34.5 +-2.6 57.8 +-5.3 73.1 +2.1Ttest 33.7 +-2.1 59.6 +-4.7 73.0 +-1.8Relief 40.1 +-2.8 48.3 +-5.9 71.6 +-3.2Pearson 34.1 +-2.0 57.4 +-4.3 74.4 +-4.9Ftest 33.5 +-2.2 59.1 +-4.8 73.8 +-1.8Gram Schmidt 35.6 +-2.4 51.2 +-11.8 77.5 +-2.3Key facts: Data Structure: The data consists of 2 files the dataset file SECOM consisting of 1567 examples each with 591 features a 1567 x 591 matrix and a labels file containing the classifications and date time stamp for each example. As with any real life data situations this data contains null values varying in intensity depending on the individuals features. This needs to be taken into consideration when investigating the data either through pre-processing or within the technique applied. The data is represented in a raw text file each line representing an individual example and the features seperated by spaces. The null values are represented by the 'NaN' value as per MatLab. "
Sattriya_Dance_Single_Hand_Gestures Dataset,Sattriya_Dance_Single_Hand_Gestures Dataset,The Sattriya_Dance_Single_Hand_Gestures dataset contains 1450 images of 29 Sattriya dance single-hand gestures consisting 50 samples from each hasta. ,Sattriya_Dance_Single_Hand_Gestures+Dataset,https://archive.ics.uci.edu/ml//machine-learning-databases/00538/,https://archive.ics.uci.edu/ml/datasets/Sattriya_Dance_Single_Hand_Gestures+Dataset,"The Sattriya_Dance_Single_Hand_Gestures dataset contains 1450 images of 29 Sattriya dancesingle-hand gestures consisting 50 samples from each hasta. This dataset was collected from 6dancers. Out of six dancers, four dancers contributed 1160 (29 Ãƒâ€”10 Ãƒâ€”4) samples comprising 10samples from each dancer for each hasta. The remaining two dancers contributed 290 (29 Ãƒâ€”5Ãƒâ€”2)samples comprising five samples from each dancer for each hasta",Computer,Provide information about each attribute in your data set.,"The Sattriya_Dance_Single_Hand_Gestures dataset contains 1450 images of 29 Sattriya dance single-hand gestures consisting 50 samples from each hasta. The Sattriya_Dance_Single_Hand_Gestures dataset contains 1450 images of 29 Sattriya dancesingle-hand gestures consisting 50 samples from each hasta. This dataset was collected from 6dancers. Out of six dancers, four dancers contributed 1160 (29 Ãƒâ€”10 Ãƒâ€”4) samples comprising 10samples from each dancer for each hasta. The remaining two dancers contributed 290 (29 Ãƒâ€”5Ãƒâ€”2)samples comprising five samples from each dancer for each hastaProvide information about each attribute in your data set."
Room Occupancy Estimation,Room Occupancy Estimation,"Data set for estimating the precise number of occupants in a room using multiple non-intrusive environmental sensors like temperature, light, sound, CO2 and PIR.",Room+Occupancy+Estimation,https://archive.ics.uci.edu/ml//machine-learning-databases/00640/,https://archive.ics.uci.edu/ml/datasets/Room+Occupancy+Estimation,"The experimental testbed for occupancy estimation was deployed in a 6m Ãƒâ€” 4.6m room. The setup consisted of 7 sensor nodes and one edge node in a star configuration with the sensor nodes transmitting data to the edge every 30s using wireless transceivers. No HVAC systems were in use while the dataset was being collected.Five different types of non-intrusive sensors were used in this experiment: temperature, light, sound, CO2 and digital passive infrared (PIR). The CO2, sound and PIR sensors needed manual calibration. For the CO2 sensor, zero-point calibration was manually done before its first use by keeping it in a clean environment for over 20 minutes and then pulling the calibration pin (HD pin) low for over 7s. The sound sensor is essentially a microphone with a variable-gain analog amplifier attached to it. Therefore, the output of this sensor is analog which is read by the microcontrollerÃ¢â‚¬â„¢s ADC in volts. The potentiometer tied to the gain of the amplifier was adjusted to ensure the highest sensitivity. The PIR sensor has two trimpots: one to tweak the sensitivity and the other to tweak the time for which the output stays high after detecting motion. Both of these were adjusted to the highest values. Sensor nodes S1-S4 consisted of temperature, light and sound sensors, S5 had a CO2 sensor and S6 and S7 had one PIR sensor each that were deployed on the ceiling ledges at an angle that maximized the sensorÃ¢â‚¬â„¢s field of view for motion detection.The data was collected for a period of 4 days in a controlled manner with the occupancy in the room varying between 0 and 3 people. The ground truth of the occupancy count in the room was noted manually.Please refer to our publications for more details.",Computer,Date: YYYY/MM/DDTime: HH:MM:SSTemperature: In degree CelsiusLight: In LuxSound: In Volts (amplifier output read by ADC)CO2: In PPMCO2 Slope: Slope of CO2 values taken in a sliding windowPIR: Binary value conveying motion detectionRoom_Occupancy_Count: Ground Truth,"Data set for estimating the precise number of occupants in a room using multiple non-intrusive environmental sensors like temperature, light, sound, CO2 and PIR.The experimental testbed for occupancy estimation was deployed in a 6m Ãƒâ€” 4.6m room. The setup consisted of 7 sensor nodes and one edge node in a star configuration with the sensor nodes transmitting data to the edge every 30s using wireless transceivers. No HVAC systems were in use while the dataset was being collected.Five different types of non-intrusive sensors were used in this experiment: temperature, light, sound, CO2 and digital passive infrared (PIR). The CO2, sound and PIR sensors needed manual calibration. For the CO2 sensor, zero-point calibration was manually done before its first use by keeping it in a clean environment for over 20 minutes and then pulling the calibration pin (HD pin) low for over 7s. The sound sensor is essentially a microphone with a variable-gain analog amplifier attached to it. Therefore, the output of this sensor is analog which is read by the microcontrollerÃ¢â‚¬â„¢s ADC in volts. The potentiometer tied to the gain of the amplifier was adjusted to ensure the highest sensitivity. The PIR sensor has two trimpots: one to tweak the sensitivity and the other to tweak the time for which the output stays high after detecting motion. Both of these were adjusted to the highest values. Sensor nodes S1-S4 consisted of temperature, light and sound sensors, S5 had a CO2 sensor and S6 and S7 had one PIR sensor each that were deployed on the ceiling ledges at an angle that maximized the sensorÃ¢â‚¬â„¢s field of view for motion detection.The data was collected for a period of 4 days in a controlled manner with the occupancy in the room varying between 0 and 3 people. The ground truth of the occupancy count in the room was noted manually.Please refer to our publications for more details.Date: YYYY/MM/DDTime: HH:MM:SSTemperature: In degree CelsiusLight: In LuxSound: In Volts (amplifier output read by ADC)CO2: In PPMCO2 Slope: Slope of CO2 values taken in a sliding windowPIR: Binary value conveying motion detectionRoom_Occupancy_Count: Ground Truth"
UJIIndoorLoc-Mag,UJIIndoorLoc-Mag,The UJIIndoorLoc-Mag is an indoor localization database to test Indoor Positioning System that rely on Earth's magnetic field variations.,UJIIndoorLoc-Mag,https://archive.ics.uci.edu/ml//machine-learning-databases/00343/,https://archive.ics.uci.edu/ml/datasets/UJIIndoorLoc-Mag,"Indoor localization is a key topic for mobile computing. However, it is still very difficult for the mobile sensing community to compare state-of-art Indoor Positioning Systems due to the scarcity of publicly available databases. Magnetic field-based methods are becoming an important trend in this research field. Here, we present UJIIndoorLoc-Mag database, which can be used to compare magnetic field-based indoor localization methods. It consists of 270 continuous samples for training and 11 for testing. Each sample comprises a set of discrete captures taken along a corridor (or an intersection) with a period of 0.1 seconds. In total, there are almost 40.000 discrete captures, where each one contains features obtained from the magnetometer, the accelerometer and the orientation sensor of the device.Data has been stored as a simple text file as follows: ts_1	mx_1	my_1	mz_1	ax_1	ay_1	az_1	ox_1	oy_1	oz_1Ã¢â‚¬Â¦									ts_n	mx_n	my_n	mz_n	ax_n	ay_n	az_n	ox_n	oy_n	oz_n									lat_1	lon_1	lat_2	lon_2	FS_1	LS_1				Ã¢â‚¬Â¦									lat_m	lon_m	lat_m+1	lon_m+1	FS_m	LS_m				Where n is the number of samples collected in the trajectory at a 0.1 seconds frequency and m is the number of segments (corridors) in the trajectory. Each sample contains the timestamp ts and the values from magnetometer, accelerometer and orientation sensors in the three axes, which are denoted with mx, my, mz, ax, ay, az, ox, oy and oz. Finally, lat_i and lon_i corresponds to the coordinates (latitude & longitude in decimal degrees) of the initial, intermediate (intersections) and final points. A trajectory with m corridors has m+1 points. FS_i and LS_i state for the i-th trajectoryÃ¢â‚¬â„¢s first and last sample respectively in the full sequence of samples collected during the trajectory mapping. According to the previous structure, the text files are composed by two well-differentiated parts separated by the row indicating the number of segments in the trajectory: 1) the sequence of discrete samples taken during the trajectory mapping, and 2) the configuration data. The first part contains the timestamp (the UNIX time format in milliseconds) and the vector data from magnetometer (AndroidÃ¢â‚¬â„¢s TYPE_MAGNETIC_FIELD), accelerometer (TYPE_LINEAR_ACCELERATION) and orientation (TYPE_ORIENTATION) sensors. The accelerometerÃ¢â‚¬â„¢s values do not include the gravity force to have a better representation of userÃ¢â‚¬â„¢s real movement. The second part contains the information about location of initial, intermediate and ending points Moreover, the samples can be associated to corridor segments and, moreover, information about turnings is also provided in all the samples.The database consists of 281 continuous samples, 270 are for training and 11 for testing. They have been stored as independent text files. The training ones are grouped into two main categories Ã¢â‚¬Å“linesÃ¢â‚¬Â� and Ã¢â‚¬Å“curvesÃ¢â‚¬Â�. - The Ã¢â‚¬Å“linesÃ¢â‚¬Â� group has 80 files and they stand for the single corridor case. The format for filename is Ã¢â‚¬Å“lXX_ZZ.txtÃ¢â‚¬Â� where XX stands for the number of corridor & orientation (n or r) and ZZ stands for repetition. Example: l3r_03.txt- The Ã¢â‚¬Å“curvesÃ¢â‚¬Â� group has 190 files and they stand for all possible trajectories considering two connected corridors only. The format for that groupÃ¢â‚¬â„¢s filename is Ã¢â‚¬Å“cXXYY_ZZ.txtÃ¢â‚¬Â� where XX and YY stand for the number of corridor & orientation for the first and second corridors in the two corridors trajectory, and ZZ stands for repetition. Example: c5n1r_05.txt- The testing filesÃ¢â‚¬â„¢ filename format is Ã¢â‚¬Å“ttPP.txtÃ¢â‚¬Â� where PP stands for the complex testing trajectory number. Example: tt03.txt",Computer,"Each discrete sample contains.1- Timestamp[2,3,4] - Magnetometer values on the x,y,z axes[4,5,6] - Accelerometer values on the x,y,z axes[7,8,9] - Orientation sensor values on the x,y,z axesn your data set.","The UJIIndoorLoc-Mag is an indoor localization database to test Indoor Positioning System that rely on Earth's magnetic field variations.Indoor localization is a key topic for mobile computing. However, it is still very difficult for the mobile sensing community to compare state-of-art Indoor Positioning Systems due to the scarcity of publicly available databases. Magnetic field-based methods are becoming an important trend in this research field. Here, we present UJIIndoorLoc-Mag database, which can be used to compare magnetic field-based indoor localization methods. It consists of 270 continuous samples for training and 11 for testing. Each sample comprises a set of discrete captures taken along a corridor (or an intersection) with a period of 0.1 seconds. In total, there are almost 40.000 discrete captures, where each one contains features obtained from the magnetometer, the accelerometer and the orientation sensor of the device.Data has been stored as a simple text file as follows: ts_1	mx_1	my_1	mz_1	ax_1	ay_1	az_1	ox_1	oy_1	oz_1Ã¢â‚¬Â¦									ts_n	mx_n	my_n	mz_n	ax_n	ay_n	az_n	ox_n	oy_n	oz_n									lat_1	lon_1	lat_2	lon_2	FS_1	LS_1				Ã¢â‚¬Â¦									lat_m	lon_m	lat_m+1	lon_m+1	FS_m	LS_m				Where n is the number of samples collected in the trajectory at a 0.1 seconds frequency and m is the number of segments (corridors) in the trajectory. Each sample contains the timestamp ts and the values from magnetometer, accelerometer and orientation sensors in the three axes, which are denoted with mx, my, mz, ax, ay, az, ox, oy and oz. Finally, lat_i and lon_i corresponds to the coordinates (latitude & longitude in decimal degrees) of the initial, intermediate (intersections) and final points. A trajectory with m corridors has m+1 points. FS_i and LS_i state for the i-th trajectoryÃ¢â‚¬â„¢s first and last sample respectively in the full sequence of samples collected during the trajectory mapping. According to the previous structure, the text files are composed by two well-differentiated parts separated by the row indicating the number of segments in the trajectory: 1) the sequence of discrete samples taken during the trajectory mapping, and 2) the configuration data. The first part contains the timestamp (the UNIX time format in milliseconds) and the vector data from magnetometer (AndroidÃ¢â‚¬â„¢s TYPE_MAGNETIC_FIELD), accelerometer (TYPE_LINEAR_ACCELERATION) and orientation (TYPE_ORIENTATION) sensors. The accelerometerÃ¢â‚¬â„¢s values do not include the gravity force to have a better representation of userÃ¢â‚¬â„¢s real movement. The second part contains the information about location of initial, intermediate and ending points Moreover, the samples can be associated to corridor segments and, moreover, information about turnings is also provided in all the samples.The database consists of 281 continuous samples, 270 are for training and 11 for testing. They have been stored as independent text files. The training ones are grouped into two main categories Ã¢â‚¬Å“linesÃ¢â‚¬Â� and Ã¢â‚¬Å“curvesÃ¢â‚¬Â�. - The Ã¢â‚¬Å“linesÃ¢â‚¬Â� group has 80 files and they stand for the single corridor case. The format for filename is Ã¢â‚¬Å“lXX_ZZ.txtÃ¢â‚¬Â� where XX stands for the number of corridor & orientation (n or r) and ZZ stands for repetition. Example: l3r_03.txt- The Ã¢â‚¬Å“curvesÃ¢â‚¬Â� group has 190 files and they stand for all possible trajectories considering two connected corridors only. The format for that groupÃ¢â‚¬â„¢s filename is Ã¢â‚¬Å“cXXYY_ZZ.txtÃ¢â‚¬Â� where XX and YY stand for the number of corridor & orientation for the first and second corridors in the two corridors trajectory, and ZZ stands for repetition. Example: c5n1r_05.txt- The testing filesÃ¢â‚¬â„¢ filename format is Ã¢â‚¬Å“ttPP.txtÃ¢â‚¬Â� where PP stands for the complex testing trajectory number. Example: tt03.txtEach discrete sample contains.1- Timestamp[2,3,4] - Magnetometer values on the x,y,z axes[4,5,6] - Accelerometer values on the x,y,z axes[7,8,9] - Orientation sensor values on the x,y,z axesn your data set."
Roman Urdu Sentiment Analysis Dataset (RUSAD),Roman Urdu Sentiment Analysis Dataset (RUSAD),The dataset was gathered to carry out research on the task of sentiment analysis for Roman Urdu.,Roman+Urdu+Sentiment+Analysis+Dataset+%28RUSAD%29,https://archive.ics.uci.edu/ml//machine-learning-databases/00621/,https://archive.ics.uci.edu/ml/datasets/Roman+Urdu+Sentiment+Analysis+Dataset+%28RUSAD%29,"The dataset has two columns. The first column has the binary categorical information (positive, negative) and the second column has the actual review. ",Computer,"There are two attributes of this dataset. The first attribute holds the binary categorical information (positive, negative) while the second attribute holds the actual review. ","The dataset was gathered to carry out research on the task of sentiment analysis for Roman Urdu.The dataset has two columns. The first column has the binary categorical information (positive, negative) and the second column has the actual review. There are two attributes of this dataset. The first attribute holds the binary categorical information (positive, negative) while the second attribute holds the actual review. "
Roman Urdu Data Set,Roman Urdu Data Set,Roman Urdu (the scripting style for Urdu language) is one of the limited resource languages.A data corpus comprising of more than 20000 records was collected.,Roman+Urdu+Data+Set,https://archive.ics.uci.edu/ml//machine-learning-databases/00458/,https://archive.ics.uci.edu/ml/datasets/Roman+Urdu+Data+Set,"Tagged for Sentiment (Positive, Negative, Neutral)",Computer,Each record comprises of two string datatype values. One for Comment/Review and the second for sentiment.,"Roman Urdu (the scripting style for Urdu language) is one of the limited resource languages.A data corpus comprising of more than 20000 records was collected.Tagged for Sentiment (Positive, Negative, Neutral)Each record comprises of two string datatype values. One for Comment/Review and the second for sentiment."
Semeion Handwritten Digit,Semeion Handwritten Digit,"1593 handwritten digits from around 80 persons were scanned, stretched in a rectangular box 16x16 in a gray scale of 256 values.",Semeion+Handwritten+Digit,https://archive.ics.uci.edu/ml//machine-learning-databases/semeion/,https://archive.ics.uci.edu/ml/datasets/Semeion+Handwritten+Digit,"1593 handwritten digits from around 80 persons were scanned, stretched in a rectangular box 16x16 in a gray scale of 256 values.Then each pixel of each image was scaled into a bolean (1/0) value using a fixed threshold.Each person wrote on a paper all the digits from 0 to 9, twice. The commitment was to write the digit the first time in the normal way (trying to write each digit accurately) and the second time in a fast way (with no accuracy). The best validation protocol for this dataset seems to be a 5x2CV, 50% Tune (Train +Test) and completly blind 50% Validation",Computer,"This dataset consists of 1593 records (rows) and 256 attributes (columns).Each record represents a handwritten digit, orginally scanned with a resolution of 256 grays scale (28).Each pixel of the each original scanned image was first stretched,  and after scaled between 0 and 1 (setting to 0 every pixel whose value was under tha value 127 of the grey scale (127 included) and setting to 1 each pixel whose orinal value in the grey scale was over 127).Finally, each binary image was scaled again into a 16x16 square box (the final 256 binary attributes). ","1593 handwritten digits from around 80 persons were scanned, stretched in a rectangular box 16x16 in a gray scale of 256 values.1593 handwritten digits from around 80 persons were scanned, stretched in a rectangular box 16x16 in a gray scale of 256 values.Then each pixel of each image was scaled into a bolean (1/0) value using a fixed threshold.Each person wrote on a paper all the digits from 0 to 9, twice. The commitment was to write the digit the first time in the normal way (trying to write each digit accurately) and the second time in a fast way (with no accuracy). The best validation protocol for this dataset seems to be a 5x2CV, 50% Tune (Train +Test) and completly blind 50% ValidationThis dataset consists of 1593 records (rows) and 256 attributes (columns).Each record represents a handwritten digit, orginally scanned with a resolution of 256 grays scale (28).Each pixel of the each original scanned image was first stretched,  and after scaled between 0 and 1 (setting to 0 every pixel whose value was under tha value 127 of the grey scale (127 included) and setting to 1 each pixel whose orinal value in the grey scale was over 127).Finally, each binary image was scaled again into a 16x16 square box (the final 256 binary attributes). "
SML2010,SML2010,This dataset is collected from a monitor system mounted in a domotic house. It corresponds to approximately 40 days of monitoring data.,SML2010,https://archive.ics.uci.edu/ml//machine-learning-databases/00274/,https://archive.ics.uci.edu/ml/datasets/SML2010,"The dataset could contain missing values. The data was sampled every minute, computing and uploading it smoothed with 15 minute means. The header of the data file is a commentary (begins with #) indicating which data is stored at which column (in Spanish). The data is time information is in UTC.",Computer,"The attributes are:1. Date: in UTC.2. Time: in UTC.3. Indoor temperature (dinning-room), in Ã‚ÂºC.4. Indoor temperature (room), in Ã‚ÂºC.5. Weather forecast temperature, in Ã‚ÂºC.6. Carbon dioxide in ppm (dinning room).7. Carbon dioxide in ppm (room).8. Relative humidity (dinning room), in %.9. Relative humidity (room), in %.10. Lighting (dinning room), in Lux.11. Lighting (room), in Lux.12. Rain, the proportion of the last 15 minutes where rain was detected (a value in range [0,1]).13. Sun dusk.14. Wind, in m/s.15. Sun light in west facade, in Lux.16. Sun light in east facade, in Lux.17. Sun light in south facade, in Lux.18. Sun irradiance, in W/m2.19. Enthalpic motor 1, 0 or 1 (on-off).20. Enthalpic motor 2, 0 or 1 (on-off).21. Enthalpic motor turbo, 0 or 1 (on-off).22. Outdoor temperature, in Ã‚ÂºC.23. Outdoor relative humidity, in %.24. Day of the week (computed from the date), 1=Monday, 7=Sunday.","This dataset is collected from a monitor system mounted in a domotic house. It corresponds to approximately 40 days of monitoring data.The dataset could contain missing values. The data was sampled every minute, computing and uploading it smoothed with 15 minute means. The header of the data file is a commentary (begins with #) indicating which data is stored at which column (in Spanish). The data is time information is in UTC.The attributes are:1. Date: in UTC.2. Time: in UTC.3. Indoor temperature (dinning-room), in Ã‚ÂºC.4. Indoor temperature (room), in Ã‚ÂºC.5. Weather forecast temperature, in Ã‚ÂºC.6. Carbon dioxide in ppm (dinning room).7. Carbon dioxide in ppm (room).8. Relative humidity (dinning room), in %.9. Relative humidity (room), in %.10. Lighting (dinning room), in Lux.11. Lighting (room), in Lux.12. Rain, the proportion of the last 15 minutes where rain was detected (a value in range [0,1]).13. Sun dusk.14. Wind, in m/s.15. Sun light in west facade, in Lux.16. Sun light in east facade, in Lux.17. Sun light in south facade, in Lux.18. Sun irradiance, in W/m2.19. Enthalpic motor 1, 0 or 1 (on-off).20. Enthalpic motor 2, 0 or 1 (on-off).21. Enthalpic motor turbo, 0 or 1 (on-off).22. Outdoor temperature, in Ã‚ÂºC.23. Outdoor relative humidity, in %.24. Day of the week (computed from the date), 1=Monday, 7=Sunday."
UJIIndoorLoc,UJIIndoorLoc,The UJIIndoorLoc is a Multi-Building Multi-Floor indoor localization database to test Indoor Positioning System that rely on WLAN/WiFi fingerprint.,UJIIndoorLoc,https://archive.ics.uci.edu/ml//machine-learning-databases/00310/,https://archive.ics.uci.edu/ml/datasets/UJIIndoorLoc,"Many real world applications need to know the localization of a user in the world to provide their services. Therefore, automatic user localization has been a hot research topic in the last years. Automatic user localization consists of estimating the position of the user (latitude, longitude and altitude) by using an electronic device, usually a mobile phone. Outdoor localization problem can be solved very accurately thanks to the inclusion of GPS sensors into the mobile devices. However, indoor localization is still an open problem mainly due to the loss of GPS signal in indoor environments. Although, there are some indoor positioning technologies and methodologies, this database is focused on WLAN fingerprint-based ones (also know as WiFi Fingerprinting).Although there are many papers in the literature trying to solve the indoor localization problem using a WLAN fingerprint-based method, there still exists one important drawback in this field which is the lack of a common database for comparison purposes. So, UJIIndoorLoc database is presented to overcome this gap. We expect that the proposed database will become the reference database to compare different indoor localization methodologies based on WiFi fingerprinting.The UJIIndoorLoc database covers three buildings of Universitat Jaume I with 4 or more floors and almost 110.000m2. It can be used for classification, e.g. actual building and floor identification, or regression, e.g. actual longitude and latitude estimation. It was created in 2013 by means of more than 20 different users and 25 Android devices. The database consists of 19937 training/reference records (trainingData.csv file) and 1111 validation/test records (validationData.csv file).The 529 attributes contain the WiFi fingerprint, the coordinates where it was taken, and other useful information.Each WiFi fingerprint can be characterized by the detected Wireless Access Points (WAPs) and the corresponding Received Signal Strength Intensity (RSSI). The intensity values are represented as negative integer values ranging -104dBm (extremely poor signal) to 0dbM. The positive value 100 is used to denote when a WAP was not detected. During the database creation, 520 different WAPs were detected. Thus, the WiFi fingerprint is composed by 520 intensity values.Then the coordinates (latitude, longitude, floor) and Building ID are provided as the attributes to be predicted. Additional information has been provided.The particular space (offices, labs, etc.) and the relative position (inside/outside the space) where the capture was taken have been recorded. Outside means that the capture was taken in front of the door of the space.Information about who (user), how (android device & version) and when (timestamp) WiFi capture was taken is also recorded.",Computer,"Attribute 001 (WAP001): Intensity value for WAP001. Negative integer values from -104 to 0 and +100. Positive value 100 used if WAP001 was not detected.....Attribute 520 (WAP520): Intensity value for WAP520. Negative integer values from -104 to 0 and +100. Positive Vvalue 100 used if WAP520 was not detected.Attribute 521 (Longitude): Longitude. Negative real values from -7695.9387549299299000 to -7299.786516730871000Attribute 522 (Latitude): Latitude. Positive real values from 4864745.7450159714 to 4865017.3646842018.Attribute 523 (Floor): Altitude in floors inside the building. Integer values from 0 to 4.Attribute 524 (BuildingID): ID to identify the building. Measures were taken in three different buildings. Categorical integer values from 0 to 2.Attribute 525 (SpaceID): Internal ID number to identify the Space (office, corridor, classroom) where the capture was taken. Categorical integer values.Attribute 526 (RelativePosition): Relative position with respect to the Space (1 - Inside, 2 - Outside in Front of the door). Categorical integer values. Attribute 527 (UserID): User identifier (see below). Categorical integer values. Attribute 528 (PhoneID): Android device identifier (see below). Categorical integer values.  Attribute 529 (Timestamp): UNIX Time when the capture was taken. Integer value. ---------------------------------------------UserID Anonymized user           Height (cm)---------------------------------------------0     USER0000 (Validation User) N/A1     USER0001                   1702     USER0002                   1763     USER0003                   1724     USER0004                   1745     USER0005                   1846     USER0006                   1807     USER0007                   1608     USER0008                   1769     USER0009                   17710    USER0010                   18611    USER0011                   17612    USER0012                   15813    USER0013                   17414    USER0014                   17315    USER0015                   17416    USER0016                   17117    USER0017                   16618    USER0018                   162--------------------------------------------------------------------------------------------PhoneID  Android Device      Android Ver. UserID----------------------------------------------0        Celkon A27          4.0.4(6577)  01        GT-I8160            2.3.6        82        GT-I8160            4.1.2        03        GT-I9100            4.0.4        54        GT-I9300            4.1.2        05        GT-I9505            4.2.2        06        GT-S5360            2.3.6        77        GT-S6500            2.3.6        148        Galaxy Nexus        4.2.2        109        Galaxy Nexus        4.3          010       HTC Desire HD       2.3.5        1811       HTC One             4.1.2        1512       HTC One             4.2.2        013       HTC Wildfire S      2.3.5        0,1114       LT22i               4.0.4        0,1,9,1615       LT22i               4.1.2        016       LT26i               4.0.4        317       M1005D              4.0.4        1318       MT11i               2.3.4        419       Nexus 4             4.2.2        620       Nexus 4             4.3          021       Nexus S             4.1.2        022       Orange Monte Carlo  2.3.5        1723       Transformer TF101   4.0.3        224       bq Curie            4.1.1        12----------------------------------------------","The UJIIndoorLoc is a Multi-Building Multi-Floor indoor localization database to test Indoor Positioning System that rely on WLAN/WiFi fingerprint.Many real world applications need to know the localization of a user in the world to provide their services. Therefore, automatic user localization has been a hot research topic in the last years. Automatic user localization consists of estimating the position of the user (latitude, longitude and altitude) by using an electronic device, usually a mobile phone. Outdoor localization problem can be solved very accurately thanks to the inclusion of GPS sensors into the mobile devices. However, indoor localization is still an open problem mainly due to the loss of GPS signal in indoor environments. Although, there are some indoor positioning technologies and methodologies, this database is focused on WLAN fingerprint-based ones (also know as WiFi Fingerprinting).Although there are many papers in the literature trying to solve the indoor localization problem using a WLAN fingerprint-based method, there still exists one important drawback in this field which is the lack of a common database for comparison purposes. So, UJIIndoorLoc database is presented to overcome this gap. We expect that the proposed database will become the reference database to compare different indoor localization methodologies based on WiFi fingerprinting.The UJIIndoorLoc database covers three buildings of Universitat Jaume I with 4 or more floors and almost 110.000m2. It can be used for classification, e.g. actual building and floor identification, or regression, e.g. actual longitude and latitude estimation. It was created in 2013 by means of more than 20 different users and 25 Android devices. The database consists of 19937 training/reference records (trainingData.csv file) and 1111 validation/test records (validationData.csv file).The 529 attributes contain the WiFi fingerprint, the coordinates where it was taken, and other useful information.Each WiFi fingerprint can be characterized by the detected Wireless Access Points (WAPs) and the corresponding Received Signal Strength Intensity (RSSI). The intensity values are represented as negative integer values ranging -104dBm (extremely poor signal) to 0dbM. The positive value 100 is used to denote when a WAP was not detected. During the database creation, 520 different WAPs were detected. Thus, the WiFi fingerprint is composed by 520 intensity values.Then the coordinates (latitude, longitude, floor) and Building ID are provided as the attributes to be predicted. Additional information has been provided.The particular space (offices, labs, etc.) and the relative position (inside/outside the space) where the capture was taken have been recorded. Outside means that the capture was taken in front of the door of the space.Information about who (user), how (android device & version) and when (timestamp) WiFi capture was taken is also recorded.Attribute 001 (WAP001): Intensity value for WAP001. Negative integer values from -104 to 0 and +100. Positive value 100 used if WAP001 was not detected.....Attribute 520 (WAP520): Intensity value for WAP520. Negative integer values from -104 to 0 and +100. Positive Vvalue 100 used if WAP520 was not detected.Attribute 521 (Longitude): Longitude. Negative real values from -7695.9387549299299000 to -7299.786516730871000Attribute 522 (Latitude): Latitude. Positive real values from 4864745.7450159714 to 4865017.3646842018.Attribute 523 (Floor): Altitude in floors inside the building. Integer values from 0 to 4.Attribute 524 (BuildingID): ID to identify the building. Measures were taken in three different buildings. Categorical integer values from 0 to 2.Attribute 525 (SpaceID): Internal ID number to identify the Space (office, corridor, classroom) where the capture was taken. Categorical integer values.Attribute 526 (RelativePosition): Relative position with respect to the Space (1 - Inside, 2 - Outside in Front of the door). Categorical integer values. Attribute 527 (UserID): User identifier (see below). Categorical integer values. Attribute 528 (PhoneID): Android device identifier (see below). Categorical integer values.  Attribute 529 (Timestamp): UNIX Time when the capture was taken. Integer value. ---------------------------------------------UserID Anonymized user           Height (cm)---------------------------------------------0     USER0000 (Validation User) N/A1     USER0001                   1702     USER0002                   1763     USER0003                   1724     USER0004                   1745     USER0005                   1846     USER0006                   1807     USER0007                   1608     USER0008                   1769     USER0009                   17710    USER0010                   18611    USER0011                   17612    USER0012                   15813    USER0013                   17414    USER0014                   17315    USER0015                   17416    USER0016                   17117    USER0017                   16618    USER0018                   162--------------------------------------------------------------------------------------------PhoneID  Android Device      Android Ver. UserID----------------------------------------------0        Celkon A27          4.0.4(6577)  01        GT-I8160            2.3.6        82        GT-I8160            4.1.2        03        GT-I9100            4.0.4        54        GT-I9300            4.1.2        05        GT-I9505            4.2.2        06        GT-S5360            2.3.6        77        GT-S6500            2.3.6        148        Galaxy Nexus        4.2.2        109        Galaxy Nexus        4.3          010       HTC Desire HD       2.3.5        1811       HTC One             4.1.2        1512       HTC One             4.2.2        013       HTC Wildfire S      2.3.5        0,1114       LT22i               4.0.4        0,1,9,1615       LT22i               4.1.2        016       LT26i               4.0.4        317       M1005D              4.0.4        1318       MT11i               2.3.4        419       Nexus 4             4.2.2        620       Nexus 4             4.3          021       Nexus S             4.1.2        022       Orange Monte Carlo  2.3.5        1723       Transformer TF101   4.0.3        224       bq Curie            4.1.1        12----------------------------------------------"
SMS Spam Collection,SMS Spam Collection,The SMS Spam Collection is a public set of SMS labeled messages that have been collected for mobile phone spam research.,SMS+Spam+Collection,https://archive.ics.uci.edu/ml//machine-learning-databases/00228/,https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection,"This corpus has been collected from free or free for research sources at the Internet:-> A collection of 425 SMS spam messages was manually extracted from the Grumbletext Web site. This is a UK forum in which cell phone users make public claims about SMS spam messages, most of them without reporting the very spam message received. The identification of the text of spam messages in the claims is a very hard and time-consuming task, and it involved carefully scanning hundreds of web pages. The Grumbletext Web site is: [Web Link].-> A subset of 3,375 SMS randomly chosen ham messages of the NUS SMS Corpus (NSC), which is a dataset of about 10,000 legitimate messages collected for research at the Department of Computer Science at the National University of Singapore. The messages largely originate from Singaporeans and mostly from students attending the University. These messages were collected from volunteers who were made aware that their contributions were going to be made publicly available. The NUS SMS Corpus is avalaible at: [Web Link].-> A list of 450 SMS ham messages collected from Caroline Tag's PhD Thesis available at [Web Link].-> Finally, we have incorporated the SMS Spam Corpus v.0.1 Big. It has 1,002 SMS ham messages and 322 spam messages and it is public available at: [Web Link]. This corpus has been used in the following academic researches:[1] GÃƒÂ³mez Hidalgo, J.M., Cajigas Bringas, G., Puertas Sanz, E., Carrero GarcÃƒÂ­a, F. Content Based SMS Spam Filtering. Proceedings of the 2006 ACM Symposium on Document Engineering (ACM DOCENG'06), Amsterdam, The Netherlands, 10-13, 2006.[2] Cormack, G. V., GÃƒÂ³mez Hidalgo, J. M., and Puertas SÃƒÂ¡nz, E. Feature engineering for mobile (SMS) spam filtering.  Proceedings of the 30th Annual international ACM Conference on Research and Development in information Retrieval (ACM SIGIR'07), New York, NY, 871-872, 2007.[3] Cormack, G. V., GÃƒÂ³mez Hidalgo, J. M., and Puertas SÃƒÂ¡nz, E. Spam filtering for short messages. Proceedings of the 16th ACM Conference on Information and Knowledge Management (ACM CIKM'07). Lisbon, Portugal, 313-320, 2007.",Computer,"The collection is composed by just one text file, where each line has the correct class followed by the raw message. We offer some examples bellow:ham   What you doing?how are you?ham   Ok lar... Joking wif u oni...ham   dun say so early hor... U c already then say...ham   MY NO. IN LUTON 0125698789 RING ME IF UR AROUND! H*ham   Siva is in hostel aha:-.ham   Cos i was out shopping wif darren jus now n i called him 2 ask wat present he wan lor. Then he started guessing who i was wif n he finally guessed darren lor.spam  FreeMsg: Txt: CALL to No: 86888 & claim your reward of 3 hours talk time to use from your phone now! ubscribe6GBP/ mnth inc 3hrs 16 stop?txtStopspam  Sunshine Quiz! Win a super Sony DVD recorder if you canname the capital of Australia? Text MQUIZ to 82277. Bspam  URGENT! Your Mobile No 07808726822 was awarded a L2,000 Bonus Caller Prize on 02/09/03! This is our 2nd attempt to contact YOU! Call 0871-872-9758 BOX95QUNote: the messages are not chronologically sorted.","The SMS Spam Collection is a public set of SMS labeled messages that have been collected for mobile phone spam research.This corpus has been collected from free or free for research sources at the Internet:-> A collection of 425 SMS spam messages was manually extracted from the Grumbletext Web site. This is a UK forum in which cell phone users make public claims about SMS spam messages, most of them without reporting the very spam message received. The identification of the text of spam messages in the claims is a very hard and time-consuming task, and it involved carefully scanning hundreds of web pages. The Grumbletext Web site is: [Web Link].-> A subset of 3,375 SMS randomly chosen ham messages of the NUS SMS Corpus (NSC), which is a dataset of about 10,000 legitimate messages collected for research at the Department of Computer Science at the National University of Singapore. The messages largely originate from Singaporeans and mostly from students attending the University. These messages were collected from volunteers who were made aware that their contributions were going to be made publicly available. The NUS SMS Corpus is avalaible at: [Web Link].-> A list of 450 SMS ham messages collected from Caroline Tag's PhD Thesis available at [Web Link].-> Finally, we have incorporated the SMS Spam Corpus v.0.1 Big. It has 1,002 SMS ham messages and 322 spam messages and it is public available at: [Web Link]. This corpus has been used in the following academic researches:[1] GÃƒÂ³mez Hidalgo, J.M., Cajigas Bringas, G., Puertas Sanz, E., Carrero GarcÃƒÂ­a, F. Content Based SMS Spam Filtering. Proceedings of the 2006 ACM Symposium on Document Engineering (ACM DOCENG'06), Amsterdam, The Netherlands, 10-13, 2006.[2] Cormack, G. V., GÃƒÂ³mez Hidalgo, J. M., and Puertas SÃƒÂ¡nz, E. Feature engineering for mobile (SMS) spam filtering.  Proceedings of the 30th Annual international ACM Conference on Research and Development in information Retrieval (ACM SIGIR'07), New York, NY, 871-872, 2007.[3] Cormack, G. V., GÃƒÂ³mez Hidalgo, J. M., and Puertas SÃƒÂ¡nz, E. Spam filtering for short messages. Proceedings of the 16th ACM Conference on Information and Knowledge Management (ACM CIKM'07). Lisbon, Portugal, 313-320, 2007.The collection is composed by just one text file, where each line has the correct class followed by the raw message. We offer some examples bellow:ham   What you doing?how are you?ham   Ok lar... Joking wif u oni...ham   dun say so early hor... U c already then say...ham   MY NO. IN LUTON 0125698789 RING ME IF UR AROUND! H*ham   Siva is in hostel aha:-.ham   Cos i was out shopping wif darren jus now n i called him 2 ask wat present he wan lor. Then he started guessing who i was wif n he finally guessed darren lor.spam  FreeMsg: Txt: CALL to No: 86888 & claim your reward of 3 hours talk time to use from your phone now! ubscribe6GBP/ mnth inc 3hrs 16 stop?txtStopspam  Sunshine Quiz! Win a super Sony DVD recorder if you canname the capital of Australia? Text MQUIZ to 82277. Bspam  URGENT! Your Mobile No 07808726822 was awarded a L2,000 Bonus Caller Prize on 02/09/03! This is our 2nd attempt to contact YOU! Call 0871-872-9758 BOX95QUNote: the messages are not chronologically sorted."
TTC-3600: Benchmark dataset for Turkish text categorization,TTC-3600: Benchmark dataset for Turkish text categorization,"The TTC-3600 data set is a collection of Turkish news and articles including categorized 3,600 documents from 6 well-known portals in Turkey. It has 4 different forms in ARFF Weka format.",TTC-3600%3A+Benchmark+dataset+for+Turkish+text+categorization,https://archive.ics.uci.edu/ml//machine-learning-databases/00407/,https://archive.ics.uci.edu/ml/datasets/TTC-3600%3A+Benchmark+dataset+for+Turkish+text+categorization,"The dataset consists of a total of 3600 documents including 600 news/texts from six categories Ã¢â‚¬â€œ economy, culture-arts, health, politics, sports and technology Ã¢â‚¬â€œ obtainedfrom six well-known news portals and agencies (Hurriyet,Posta,Iha,HaberTurk,Radikal and Zaman). Documents of TTC-3600 dataset were collected between May and July 2015 via Rich Site Summary (RSS) feeds from six categories of the respective portals. All java scripts, HTML tags ( < img> , < a > , < p > , < strong> etc.), operators, punctuations, non-printable characters and irrelevant data such as advertising are removed.Three additional dataset versions are created on TTC-3600 by implementing different stemming methods. In all versions of datasets, first, removal-based pre-processing, which is explained in Section 3.2 in detail, is used. Then Turkish stop-words that have no discriminatory power (pronouns, prepositions, conjunctions, etc.) in regard to TC are removedfrom datasets except for the original one. In this study, a semi-automatically constructed stop-words list that contains 147 words is utilized.",Computer,ARFF (Attribute-Relation File Format) Weka format ,"The TTC-3600 data set is a collection of Turkish news and articles including categorized 3,600 documents from 6 well-known portals in Turkey. It has 4 different forms in ARFF Weka format.The dataset consists of a total of 3600 documents including 600 news/texts from six categories Ã¢â‚¬â€œ economy, culture-arts, health, politics, sports and technology Ã¢â‚¬â€œ obtainedfrom six well-known news portals and agencies (Hurriyet,Posta,Iha,HaberTurk,Radikal and Zaman). Documents of TTC-3600 dataset were collected between May and July 2015 via Rich Site Summary (RSS) feeds from six categories of the respective portals. All java scripts, HTML tags ( < img> , < a > , < p > , < strong> etc.), operators, punctuations, non-printable characters and irrelevant data such as advertising are removed.Three additional dataset versions are created on TTC-3600 by implementing different stemming methods. In all versions of datasets, first, removal-based pre-processing, which is explained in Section 3.2 in detail, is used. Then Turkish stop-words that have no discriminatory power (pronouns, prepositions, conjunctions, etc.) in regard to TC are removedfrom datasets except for the original one. In this study, a semi-automatically constructed stop-words list that contains 147 words is utilized.ARFF (Attribute-Relation File Format) Weka format "
Traffic Flow Forecasting,Traffic Flow Forecasting,The task for this dataset is to forecast the spatio-temporal traffic volume based on the historical traffic volume and other features in neighboring locations. ,Traffic+Flow+Forecasting,https://archive.ics.uci.edu/ml//machine-learning-databases/00630/,https://archive.ics.uci.edu/ml/datasets/Traffic+Flow+Forecasting,"The task for this dataset is to forecast the spatio-temporal traffic volume based on the historical traffic volume and other features in neighboring locations. Specifically, the traffic volume is measured every 15 minutes at 36 sensor locations along two major highways in Northern Virginia/Washington D.C. capital region. The 47 features include: 1) the historical sequence of traffic volume sensed during the 10 most recent sample points (10 features), 2) week day (7 features), 3) hour of day (24 features), 4) road direction (4 features), 5) number of lanes (1 feature), and 6) name of the road (1 feature). The goal is to predict the traffic volume 15 minutes into the future for all sensor locations. With a given road network, we know the spatial connectivity between sensor locations. For the detailed data information, please refer to the file README.docx",Computer,"The 47 features include: (1) the historical sequence of traffic volume sensed during the 10 most recent sample points (10 features), (2) week day (7 features), (3) hour of day (24 features), (4) road direction (4 features), (5) number of lanes (1 feature), and (6) name of the road (1 feature).","The task for this dataset is to forecast the spatio-temporal traffic volume based on the historical traffic volume and other features in neighboring locations. The task for this dataset is to forecast the spatio-temporal traffic volume based on the historical traffic volume and other features in neighboring locations. Specifically, the traffic volume is measured every 15 minutes at 36 sensor locations along two major highways in Northern Virginia/Washington D.C. capital region. The 47 features include: 1) the historical sequence of traffic volume sensed during the 10 most recent sample points (10 features), 2) week day (7 features), 3) hour of day (24 features), 4) road direction (4 features), 5) number of lanes (1 feature), and 6) name of the road (1 feature). The goal is to predict the traffic volume 15 minutes into the future for all sensor locations. With a given road network, we know the spatial connectivity between sensor locations. For the detailed data information, please refer to the file README.docxThe 47 features include: (1) the historical sequence of traffic volume sensed during the 10 most recent sample points (10 features), (2) week day (7 features), (3) hour of day (24 features), (4) road direction (4 features), (5) number of lanes (1 feature), and (6) name of the road (1 feature)."
"Taxi Service Trajectory - Prediction Challenge, ECML PKDD 2015","Taxi Service Trajectory - Prediction Challenge, ECML PKDD 2015","An accurate dataset describing trajectories performed by all the 442 taxis running in the city of Porto, in Portugal.
",Taxi+Service+Trajectory+-+Prediction+Challenge%2C+ECML+PKDD+2015,https://archive.ics.uci.edu/ml//machine-learning-databases/00339/,https://archive.ics.uci.edu/ml/datasets/Taxi+Service+Trajectory+-+Prediction+Challenge%2C+ECML+PKDD+2015,For complete information see the official challenge page:[Web Link],Computer,"Each data sample corresponds to one completed trip. It contains a total of 9 (nine) features, described as follows:TRIP_ID: (String) It contains a unique identifier for each trip;CALL_TYPE: (char) It identifies the way used to demand this service. It may contain one of three possible values:  - 'A' if this trip was dispatched from the central;  - 'B' if this trip was demanded directly to a taxi driver at a specific stand;  - 'C' otherwise (i.e. a trip demanded on a random street).ORIGIN_CALL: (integer) It contains a unique identifier for each phone number which was used to demand, at least, one service. It identifies the trip's customer if CALL_TYPE='A'. Otherwise, it assumes a NULL value;ORIGIN_STAND: (integer): It contains a unique identifier for the taxi stand. It identifies the starting point of the trip if CALL_TYPE='B'. Otherwise, it assumes a NULL value;TAXI_ID: (integer): It contains a unique identifier for the taxi driver that performed each trip;TIMESTAMP: (integer) Unix Timestamp (in seconds). It identifies the trip's start;DAYTYPE: (char) It identifies the daytype of the trip's start. It assumes one of three possible values:  - 'B' if this trip started on a holiday or any other special day (i.e. extending holidays, floating holidays, etc.);  - 'C' if the trip started on a day before a type-B day;  - 'A' otherwise (i.e. a normal day, workday or weekend).IMPORTANT NOTICE: This field has not been correctly calculated. Please see the following links as reliable sources for official holidays in Portugal.[Web Link][Web Link]MISSING_DATA: (Boolean) It is FALSE when the GPS data stream is complete and TRUE whenever one (or more) locations are missing;POLYLINE: (String): It contains a list of GPS coordinates (i.e. WGS84 format) mapped as a string. The beginning and the end of the string are identified with brackets (i.e. [ and ], respectively). Each pair of coordinates is also identified by the same brackets as [LONGITUDE, LATITUDE]. This list contains one pair of coordinates for each 15 seconds of trip. The last list item corresponds to the trip's destination while the first one represents its start.","An accurate dataset describing trajectories performed by all the 442 taxis running in the city of Porto, in Portugal.
For complete information see the official challenge page:[Web Link]Each data sample corresponds to one completed trip. It contains a total of 9 (nine) features, described as follows:TRIP_ID: (String) It contains a unique identifier for each trip;CALL_TYPE: (char) It identifies the way used to demand this service. It may contain one of three possible values:  - 'A' if this trip was dispatched from the central;  - 'B' if this trip was demanded directly to a taxi driver at a specific stand;  - 'C' otherwise (i.e. a trip demanded on a random street).ORIGIN_CALL: (integer) It contains a unique identifier for each phone number which was used to demand, at least, one service. It identifies the trip's customer if CALL_TYPE='A'. Otherwise, it assumes a NULL value;ORIGIN_STAND: (integer): It contains a unique identifier for the taxi stand. It identifies the starting point of the trip if CALL_TYPE='B'. Otherwise, it assumes a NULL value;TAXI_ID: (integer): It contains a unique identifier for the taxi driver that performed each trip;TIMESTAMP: (integer) Unix Timestamp (in seconds). It identifies the trip's start;DAYTYPE: (char) It identifies the daytype of the trip's start. It assumes one of three possible values:  - 'B' if this trip started on a holiday or any other special day (i.e. extending holidays, floating holidays, etc.);  - 'C' if the trip started on a day before a type-B day;  - 'A' otherwise (i.e. a normal day, workday or weekend).IMPORTANT NOTICE: This field has not been correctly calculated. Please see the following links as reliable sources for official holidays in Portugal.[Web Link][Web Link]MISSING_DATA: (Boolean) It is FALSE when the GPS data stream is complete and TRUE whenever one (or more) locations are missing;POLYLINE: (String): It contains a list of GPS coordinates (i.e. WGS84 format) mapped as a string. The beginning and the end of the string are identified with brackets (i.e. [ and ], respectively). Each pair of coordinates is also identified by the same brackets as [LONGITUDE, LATITUDE]. This list contains one pair of coordinates for each 15 seconds of trip. The last list item corresponds to the trip's destination while the first one represents its start."
TamilSentiMix,TamilSentiMix,"We created a gold standard Tamil-English code-switched, sentiment-annotated corpus containing 15,744 comment posts from YouTube. ",TamilSentiMix,https://archive.ics.uci.edu/ml//machine-learning-databases/00610/,https://archive.ics.uci.edu/ml/datasets/TamilSentiMix,"Understanding the sentiment of a comment from a video or an image is an essential task in many applications. Sentiment analysis of a text can be useful for various decision-making processes. One such application is to analyse the popular sentiments of videos on social media based on viewer comments. However, comments from social media do not follow strict rules of grammar, and they contain mixing of more than one language, often written in non-native scripts. Non-availability of annotated code-mixed data for a low-resourced language like Tamil also adds difficulty to this problem. To overcome this, we created a gold standard Tamil-English code-switched, sentiment-annotated corpus containing 15,744 comment posts from YouTube. In this paper, we describe the process of creating the corpus and assigning polarities. We present inter-annotator agreement and show the results of sentiment analysis trained on this corpus as a benchmark.[Web Link]#.X1oUNRQnbmF",Computer,Provide information about each attribute in your data set.,"We created a gold standard Tamil-English code-switched, sentiment-annotated corpus containing 15,744 comment posts from YouTube. Understanding the sentiment of a comment from a video or an image is an essential task in many applications. Sentiment analysis of a text can be useful for various decision-making processes. One such application is to analyse the popular sentiments of videos on social media based on viewer comments. However, comments from social media do not follow strict rules of grammar, and they contain mixing of more than one language, often written in non-native scripts. Non-availability of annotated code-mixed data for a low-resourced language like Tamil also adds difficulty to this problem. To overcome this, we created a gold standard Tamil-English code-switched, sentiment-annotated corpus containing 15,744 comment posts from YouTube. In this paper, we describe the process of creating the corpus and assigning polarities. We present inter-annotator agreement and show the results of sentiment analysis trained on this corpus as a benchmark.[Web Link]#.X1oUNRQnbmFProvide information about each attribute in your data set."
Turkish Music Emotion Dataset,Turkish Music Emotion Dataset,"There are four different classes of music emotions in the dataset: happy, sad, angry, and relax.",Turkish+Music+Emotion+Dataset,https://archive.ics.uci.edu/ml//machine-learning-databases/00638/,https://archive.ics.uci.edu/ml/datasets/Turkish+Music+Emotion+Dataset,"The dataset is designed as a discrete model, and there are four classes in the dataset: happy, sad, angry, relax. To prepare the dataset, verbal and non-verbal music are selected from different genres of Turkish music. A total of 100 music pieces are determined for each class in the database to have an equal number of samples in each class. There are 400 samples in the original dataset as 30 seconds from each sample.Number of Data in Each classHappy 100Sad 100Angry 100",Computer,"Features such as Mel Frequency Cepstral Coefficients (MFCCs), Tempo, Chromagram, Spectral and Harmonic features have been extracted to analyze the emotional content in music signals. MIR toolbox is used for feature extraction.","There are four different classes of music emotions in the dataset: happy, sad, angry, and relax.The dataset is designed as a discrete model, and there are four classes in the dataset: happy, sad, angry, relax. To prepare the dataset, verbal and non-verbal music are selected from different genres of Turkish music. A total of 100 music pieces are determined for each class in the database to have an equal number of samples in each class. There are 400 samples in the original dataset as 30 seconds from each sample.Number of Data in Each classHappy 100Sad 100Angry 100Features such as Mel Frequency Cepstral Coefficients (MFCCs), Tempo, Chromagram, Spectral and Harmonic features have been extracted to analyze the emotional content in music signals. MIR toolbox is used for feature extraction."
Syskill and Webert Web Page Ratings,Syskill and Webert Web Page Ratings,This database contains HTML source of web pages plus the ratings of a single user on these web pages. Web pages are on four seperate subjects (Bands- recording artists; Goats; Sheep; and BioMedical),Syskill+and+Webert+Web+Page+Ratings,https://archive.ics.uci.edu/ml//machine-learning-databases/SyskillWebert-mld/,https://archive.ics.uci.edu/ml/datasets/Syskill+and+Webert+Web+Page+Ratings,"The HTML source of a web page is given. Users looked at each web page and inidated on a 3 point scale (hot medium cold) 50-100 pages per domain. However, this is realistic because we want to learn user profiles from as few examples as possible so that users have an incentitive to rate pages.",Computer,"Each subject is in a separate directory. Within each directory, there is an file named ""index"". The index contains information on the other files. Each entry is a line of the form: file-name  |  rating  |  url  |  date-rated  |  title where file-name is the name of a file (usually an integer), rating is hot, medium, or cold. There are so few medium's that mediums are usually merged with cold in experiments.The other fields aren't used in learning, but they are collected by the interface for other purposes. They are the url of the html source, the date rated and the title of the web oage. ","This database contains HTML source of web pages plus the ratings of a single user on these web pages. Web pages are on four seperate subjects (Bands- recording artists; Goats; Sheep; and BioMedical)The HTML source of a web page is given. Users looked at each web page and inidated on a 3 point scale (hot medium cold) 50-100 pages per domain. However, this is realistic because we want to learn user profiles from as few examples as possible so that users have an incentitive to rate pages.Each subject is in a separate directory. Within each directory, there is an file named ""index"". The index contains information on the other files. Each entry is a line of the form: file-name  |  rating  |  url  |  date-rated  |  title where file-name is the name of a file (usually an integer), rating is hot, medium, or cold. There are so few medium's that mediums are usually merged with cold in experiments.The other fields aren't used in learning, but they are collected by the interface for other purposes. They are the url of the html source, the date rated and the title of the web oage. "
Synchronous Machine Data Set,Synchronous Machine Data Set,Synchronous motors (SMs) are AC motors with constant speed.A SM dataset is obtained from a real experimental set. The task is to create the strong models to estimate the excitation current of SM.,Synchronous+Machine+Data+Set,https://archive.ics.uci.edu/ml//machine-learning-databases/00607/,https://archive.ics.uci.edu/ml/datasets/Synchronous+Machine+Data+Set,Synchronous machine data were obtained in real time from the experimental operating environment.,Computer,Iy (Load Current)PF (Power factor)e (Power factor error)dIf (Changing of excitation current of synchronous machine)If (Excitation current of synchronous machine),Synchronous motors (SMs) are AC motors with constant speed.A SM dataset is obtained from a real experimental set. The task is to create the strong models to estimate the excitation current of SM.Synchronous machine data were obtained in real time from the experimental operating environment.Iy (Load Current)PF (Power factor)e (Power factor error)dIf (Changing of excitation current of synchronous machine)If (Excitation current of synchronous machine)
Swarm Behaviour,Swarm Behaviour,"This dataset achieved from an online survey, which is run by UNSW, Australia. It contains three data of ' Flocking - Not Flocking', 'Aligned - Not Aligned', and 'Grouped - Not Grouped'.",Swarm+Behaviour,https://archive.ics.uci.edu/ml//machine-learning-databases/00524/,https://archive.ics.uci.edu/ml/datasets/Swarm+Behaviour,"To access the survey, please use the following link:[Web Link]",Computer,"The attributes are xm, ym as the (X,Y) position of each boid, xVeln, yVeln as the velocity vector, xAm, yAm as the alignment vector, xSm, ySm as the separation vector, xCm, yCm as the cohesion vector, nACm as the number of boids in the radius of Alignment/Cohesion, and nSm as the number of boids in the radius of Separation. These attributes are repeated for all m boids, where m=1,...,200. Also, class labels are binary, which 1 refers to flocking, grouped, and aligned, and 0 refers to not flocking, not grouped, and not aligned. ","This dataset achieved from an online survey, which is run by UNSW, Australia. It contains three data of ' Flocking - Not Flocking', 'Aligned - Not Aligned', and 'Grouped - Not Grouped'.To access the survey, please use the following link:[Web Link]The attributes are xm, ym as the (X,Y) position of each boid, xVeln, yVeln as the velocity vector, xAm, yAm as the alignment vector, xSm, ySm as the separation vector, xCm, yCm as the cohesion vector, nACm as the number of boids in the radius of Alignment/Cohesion, and nSm as the number of boids in the radius of Separation. These attributes are repeated for all m boids, where m=1,...,200. Also, class labels are binary, which 1 refers to flocking, grouped, and aligned, and 0 refers to not flocking, not grouped, and not aligned. "
Student Performance on an entrance examination,Student Performance on an entrance examination,This dataset contains data of the candidates who qualified the medical entrance examination for admission to medical colleges of Assam of a particular year and collected by Prof. Jiten Hazarika.,Student+Performance+on+an+entrance+examination,https://archive.ics.uci.edu/ml//machine-learning-databases/00582/,https://archive.ics.uci.edu/ml/datasets/Student+Performance+on+an+entrance+examination,"Performance, Gender, Caste, coaching, Class_ten_education, twelve_education, medium, Class_ X_Percentage, Class_ XII_Percentage, Father_occupation, Mother_occupation",Computer,"Performance in Common Entrance Examination (CEE), Sex of the Candidate, Caste of the Candidate, Whether the candidate attended any coaching classes within Assam, outside Assam or not, Name of the board where the candidate studied at Class X level, Name of the board where the candidate studied at Class XII level, Medium of instructions for the study at Class XII level,The percentage secured by the candidate at Class X standard, The percentage secured by the candidate at Class XII standard, The occupation of the father of the candidate, The occupation of the mother of the candidate","This dataset contains data of the candidates who qualified the medical entrance examination for admission to medical colleges of Assam of a particular year and collected by Prof. Jiten Hazarika.Performance, Gender, Caste, coaching, Class_ten_education, twelve_education, medium, Class_ X_Percentage, Class_ XII_Percentage, Father_occupation, Mother_occupationPerformance in Common Entrance Examination (CEE), Sex of the Candidate, Caste of the Candidate, Whether the candidate attended any coaching classes within Assam, outside Assam or not, Name of the board where the candidate studied at Class X level, Name of the board where the candidate studied at Class XII level, Medium of instructions for the study at Class XII level,The percentage secured by the candidate at Class X standard, The percentage secured by the candidate at Class XII standard, The occupation of the father of the candidate, The occupation of the mother of the candidate"
Student Academics Performance,Student Academics Performance,"The dataset tried to find the end semester percentage prediction based on different social, economic and academic attributes. ",Student+Academics+Performance,https://archive.ics.uci.edu/ml//machine-learning-databases/00467/,https://archive.ics.uci.edu/ml/datasets/Student+Academics+Performance,Student Academic Performance Dataset,Computer,"@ATTRIBUTE ge  {M,F}@ATTRIBUTE cst {G,ST,SC,OBC,MOBC}@ATTRIBUTE tnp {Best,Vg,Good,Pass,Fail}@ATTRIBUTE twp {Best,Vg,Good,Pass,Fail}@ATTRIBUTE iap {Best,Vg,Good,Pass,Fail}@ATTRIBUTE esp {Best,Vg,Good,Pass,Fail}@ATTRIBUTE arr {Y,N}@ATTRIBUTE ms  {Married,Unmarried}@ATTRIBUTE ls  {T,V}@ATTRIBUTE as  {Free,Paid}@ATTRIBUTE fmi {Vh,High,Am,Medium,Low}@ATTRIBUTE fs  {Large,Average,Small}@ATTRIBUTE fq  {Il,Um,10,12,Degree,Pg}@ATTRIBUTE mq  {Il,Um,10,12,Degree,Pg}@ATTRIBUTE fo  {Service,Business,Retired,Farmer,Others}@ATTRIBUTE mo  {Service,Business,Retired,Housewife,Others}@ATTRIBUTE nf  {Large,Average,Small}@ATTRIBUTE sh  {Good,Average,Poor}@ATTRIBUTE ss  {Govt,Private}@ATTRIBUTE me  {Eng,Asm,Hin,Ben}@ATTRIBUTE tt  {Large,Average,Small}@ATTRIBUTE atd {Good,Average,Poor}","The dataset tried to find the end semester percentage prediction based on different social, economic and academic attributes. Student Academic Performance Dataset@ATTRIBUTE ge  {M,F}@ATTRIBUTE cst {G,ST,SC,OBC,MOBC}@ATTRIBUTE tnp {Best,Vg,Good,Pass,Fail}@ATTRIBUTE twp {Best,Vg,Good,Pass,Fail}@ATTRIBUTE iap {Best,Vg,Good,Pass,Fail}@ATTRIBUTE esp {Best,Vg,Good,Pass,Fail}@ATTRIBUTE arr {Y,N}@ATTRIBUTE ms  {Married,Unmarried}@ATTRIBUTE ls  {T,V}@ATTRIBUTE as  {Free,Paid}@ATTRIBUTE fmi {Vh,High,Am,Medium,Low}@ATTRIBUTE fs  {Large,Average,Small}@ATTRIBUTE fq  {Il,Um,10,12,Degree,Pg}@ATTRIBUTE mq  {Il,Um,10,12,Degree,Pg}@ATTRIBUTE fo  {Service,Business,Retired,Farmer,Others}@ATTRIBUTE mo  {Service,Business,Retired,Housewife,Others}@ATTRIBUTE nf  {Large,Average,Small}@ATTRIBUTE sh  {Good,Average,Poor}@ATTRIBUTE ss  {Govt,Private}@ATTRIBUTE me  {Eng,Asm,Hin,Ben}@ATTRIBUTE tt  {Large,Average,Small}@ATTRIBUTE atd {Good,Average,Poor}"
TV News Channel Commercial Detection Dataset,TV News Channel Commercial Detection Dataset,TV Commercials data set consists of  standard audio-visual features of video shots extracted from 150 hours of TV news broadcast of 3 Indian and 2 international news channels ( 30 Hours each).  ,TV+News+Channel+Commercial+Detection+Dataset,https://archive.ics.uci.edu/ml//machine-learning-databases/00326/,https://archive.ics.uci.edu/ml/datasets/TV+News+Channel+Commercial+Detection+Dataset,"Automatic identification of commercial blocks in news videos finds a lot of applications in the domain of television broadcast analysis and monitoring. Commercials occupy almost 40-60%  of total air time. Manual segmentation of commercials from thousands of TV news channels is time consuming, and economically infeasible hence prompts the need for machine learning based Method. Classifying TV News commercials is a semantic video classification problem. TV News commercials on particular news channel are combinations of video shots uniquely characterized by audio-visual presentation. Hence various audio visual features extracted from video shots are widely used for TV commercial classification.  Indian News channels do not follow any particular news presentation format, have large variability and  dynamic nature presenting a challenging machine learning problem.  Features from 150 Hours of broadcast news videos from 5 different ( 3 Indian and  2 International News channels)  news channels. Viz. CNNIBN, NDTV 24X7, TIMESNOW, BBC and CNN are presented in this dataset.  Videos are recorded at resolution of 720 X 576 at 25 fps  using a DVR and set top box. 3 Indian channels are recorded concurrently while 2 International are recorded together. Feature file preserves the order of occurrence of shots.  ",Computer,"Video shots are used as unit for generating instances. Broadcast News videos are segmented into video shots using RGB Colour Histogram matching Between consecutive video frames. From each video shot we have extracted 7 Audio ( viz. Short term energy,  zero crossing rate, Spectral Centroid, spectral Flux, spectral Roll off frequency, fundamental frequency and MFCC Bag of Audio Words) and 5 visual Features ( viz. Video shot length, Screen Text Distribution,  Motion Distribution, Frame Difference Distribution, Edge Change Ratio) from each video shot. Details of each extracted feature are as follows.Audio Features :- In general to attract viewer's attention TV commercials have higher audio amplitude, appropriate background music ( comparatively higher frequencies) as well as sharp transitions from one music to other or music to speech etc. We try to capture these properties by using low level audio features -- Short Time Energy (STE) ,  Zero Crossing Rate (ZCR), Spectral Centroid, Spectral Flux,  Spectral Roll-Off Frequency and Fundamental Frequency.  All of these short term audio features are calculated with audio frame size of 20 msec at 8000Hz sampling Frequency.  The Mean and standard deviation of all audio feature values are calculated over the shot, generating a 2D vector for each feature. The MFCC Bag of Audio Words have been successfully used in several existing speech/audio processing applications. This motivated us to compute the MFCC coefficients along with Delta and Delta-Delta Cepstrum from 150 hours of audio tracks. These coefficients are clustered into 4000 groups which form the Audio words. Each shot is then represented as a  4000 Dimensional Bag of Audio Words by forming the normalized histograms of the MFCC's extracted from 20 ms windows with overlap of 10 ms in the shots. Video Features : Commercial video shots are usually short in length, fast visual transitions with peculiar placement of overlaid text bands. Video Shot Length is directly used as one of the feature. Placement of overlaid text bands is represented by  15 dimensional overlaid Text Distribution. To calculate Text Distribution feature, video frame is divided into a grid of size 5 X 3( 15 grid blocks).  The text distribution feature is obtained by averaging the fraction of text area present in a grid block over all frames of the shot. Motion Distribution, Frame Change Distribution and Edge Change Ratio captures the dynamic nature of the commercial shots. Motion Distribution is obtained by first computing dense optical flow (Horn-Schunk formulation) followed by  construction of a distribution of flow magnitudes over the entire shot with 40 uniformly divided bins in range of [0, 40]. Sudden changes in pixel intensities are grasped by Frame Difference Distribution. Such changes are not registered by optical flow. Thus, Frame Difference Distribution is also computed along with flow magnitude distributions. We obtain the frame difference by averaging absolute frame difference in each of 3 color channels and the distribution is constructed with 32 bins in the range of [0, 255] . Edge Change Ratio Captures the motion of edges between consecutive frames and is defined as ratio of displaced edge pixels to the total number of edge pixels in a frame. We calculate the mean and variance of the ECR over the entire shot. The Feature File is represented in Lib SVM data format and contains approximetly 63% commercial instances( Positives). Dimension index for different Features are as FollowsLabels : - +1/-1 ( Commercials/Non Commercials) FeatureDimension Index in feature FileShot Length1Motion Distribution( Mean and Variance)2 - 3Frame Difference Distribution ( Mean and Variance)4 - 5Short time energy ( Mean and Variance)6 Ã¢â‚¬â€œ 7 ZCR( Mean and Variance)8 - 9Spectral Centroid ( Mean and Variance)10 - 11Spectral Roll off ( Mean and Variance)12 - 13Spectral Flux ( Mean and Variance)14 - 15Fundamental Frequency ( Mean and Variance)16 - 17Motion Distribution ( 40 bins)18 -  58Frame Difference Distribution ( 32 bins)59 - 91Text area distribution (  15 bins Mean  and 15 bins for variance )92 - 122Bag of Audio Words ( 4000 bins)123 -  4123Edge change Ratio ( Mean and Variance)4124 - 4125Key frames for shots can be made available on request.","TV Commercials data set consists of  standard audio-visual features of video shots extracted from 150 hours of TV news broadcast of 3 Indian and 2 international news channels ( 30 Hours each).  Automatic identification of commercial blocks in news videos finds a lot of applications in the domain of television broadcast analysis and monitoring. Commercials occupy almost 40-60%  of total air time. Manual segmentation of commercials from thousands of TV news channels is time consuming, and economically infeasible hence prompts the need for machine learning based Method. Classifying TV News commercials is a semantic video classification problem. TV News commercials on particular news channel are combinations of video shots uniquely characterized by audio-visual presentation. Hence various audio visual features extracted from video shots are widely used for TV commercial classification.  Indian News channels do not follow any particular news presentation format, have large variability and  dynamic nature presenting a challenging machine learning problem.  Features from 150 Hours of broadcast news videos from 5 different ( 3 Indian and  2 International News channels)  news channels. Viz. CNNIBN, NDTV 24X7, TIMESNOW, BBC and CNN are presented in this dataset.  Videos are recorded at resolution of 720 X 576 at 25 fps  using a DVR and set top box. 3 Indian channels are recorded concurrently while 2 International are recorded together. Feature file preserves the order of occurrence of shots.  Video shots are used as unit for generating instances. Broadcast News videos are segmented into video shots using RGB Colour Histogram matching Between consecutive video frames. From each video shot we have extracted 7 Audio ( viz. Short term energy,  zero crossing rate, Spectral Centroid, spectral Flux, spectral Roll off frequency, fundamental frequency and MFCC Bag of Audio Words) and 5 visual Features ( viz. Video shot length, Screen Text Distribution,  Motion Distribution, Frame Difference Distribution, Edge Change Ratio) from each video shot. Details of each extracted feature are as follows.Audio Features :- In general to attract viewer's attention TV commercials have higher audio amplitude, appropriate background music ( comparatively higher frequencies) as well as sharp transitions from one music to other or music to speech etc. We try to capture these properties by using low level audio features -- Short Time Energy (STE) ,  Zero Crossing Rate (ZCR), Spectral Centroid, Spectral Flux,  Spectral Roll-Off Frequency and Fundamental Frequency.  All of these short term audio features are calculated with audio frame size of 20 msec at 8000Hz sampling Frequency.  The Mean and standard deviation of all audio feature values are calculated over the shot, generating a 2D vector for each feature. The MFCC Bag of Audio Words have been successfully used in several existing speech/audio processing applications. This motivated us to compute the MFCC coefficients along with Delta and Delta-Delta Cepstrum from 150 hours of audio tracks. These coefficients are clustered into 4000 groups which form the Audio words. Each shot is then represented as a  4000 Dimensional Bag of Audio Words by forming the normalized histograms of the MFCC's extracted from 20 ms windows with overlap of 10 ms in the shots. Video Features : Commercial video shots are usually short in length, fast visual transitions with peculiar placement of overlaid text bands. Video Shot Length is directly used as one of the feature. Placement of overlaid text bands is represented by  15 dimensional overlaid Text Distribution. To calculate Text Distribution feature, video frame is divided into a grid of size 5 X 3( 15 grid blocks).  The text distribution feature is obtained by averaging the fraction of text area present in a grid block over all frames of the shot. Motion Distribution, Frame Change Distribution and Edge Change Ratio captures the dynamic nature of the commercial shots. Motion Distribution is obtained by first computing dense optical flow (Horn-Schunk formulation) followed by  construction of a distribution of flow magnitudes over the entire shot with 40 uniformly divided bins in range of [0, 40]. Sudden changes in pixel intensities are grasped by Frame Difference Distribution. Such changes are not registered by optical flow. Thus, Frame Difference Distribution is also computed along with flow magnitude distributions. We obtain the frame difference by averaging absolute frame difference in each of 3 color channels and the distribution is constructed with 32 bins in the range of [0, 255] . Edge Change Ratio Captures the motion of edges between consecutive frames and is defined as ratio of displaced edge pixels to the total number of edge pixels in a frame. We calculate the mean and variance of the ECR over the entire shot. The Feature File is represented in Lib SVM data format and contains approximetly 63% commercial instances( Positives). Dimension index for different Features are as FollowsLabels : - +1/-1 ( Commercials/Non Commercials) FeatureDimension Index in feature FileShot Length1Motion Distribution( Mean and Variance)2 - 3Frame Difference Distribution ( Mean and Variance)4 - 5Short time energy ( Mean and Variance)6 Ã¢â‚¬â€œ 7 ZCR( Mean and Variance)8 - 9Spectral Centroid ( Mean and Variance)10 - 11Spectral Roll off ( Mean and Variance)12 - 13Spectral Flux ( Mean and Variance)14 - 15Fundamental Frequency ( Mean and Variance)16 - 17Motion Distribution ( 40 bins)18 -  58Frame Difference Distribution ( 32 bins)59 - 91Text area distribution (  15 bins Mean  and 15 bins for variance )92 - 122Bag of Audio Words ( 4000 bins)123 -  4123Edge change Ratio ( Mean and Variance)4124 - 4125Key frames for shots can be made available on request."
Twin gas sensor arrays,Twin gas sensor arrays,5 replicates of an 8-MOX gas sensor array were exposed to different gas conditions (4 volatiles at 10 concentration levels each).,Twin+gas+sensor+arrays,https://archive.ics.uci.edu/ml//machine-learning-databases/00361/,https://archive.ics.uci.edu/ml/datasets/Twin+gas+sensor+arrays,"This dataset includes the recordings of five replicates of an 8-sensor array. Each unit holds 8 MOX sensors and integrates custom-designed electronics for sensor operating temperature control and signal acquisition.The same experimental protocol was followed to measure the response of the 5 twin units. Each day, a different unit was tested, which included the presentationof 40 different gas conditions, presented in random order. In particular, the unit under test was exposed to 10 concentration levels of Ethanol, Methane, Ethylene, and Carbon Monoxide.The duration of each experiment was 600 s, and the conductivity of each sensor was acquired at 100Hz.Channel, sensor type (from Figaro), and mean voltage in the heater are as follows: 0: TGS2611 5.65 V1: TGS2612 5.65 V2: TGS2610 5.65 V3: TGS2602 5.65 V4: TGS2611 5.00 V5: TGS2612 5.00 V6: TGS2610 5.00 V7: TGS2602 5.00 VPresented concentration levels are as follows (in ppm):Ethylene: 12.5, 25, 37.5, 50.0, 62.5, 75.0, 87.5, 100.0 , 112.5, 125.0Ethanol: 12.5, 25.0, 37.5, 50.0, 62.5, 75.0, 87.5, 100.0 , 112.5, 125.0Carbon Monoxide: 25.0, 50.0, 75.0, 100.0 , 125.0 ,150.0, 175.0, 200.0, 225.0 , 250.0Methane: 25.0, 50.0, 75.0, 100.0 , 125.0 ,150.0, 175.0, 200.0, 225.0 , 250.0 Days in which each detection platform was tested.Unit 1: 4,10,15,21Unit 2: 1,7,11,16Unit 3: 2,8,14,17Unit 4: 3,9Unit 5: 18,22More information at:J. Fonollosa, L. Fernandez, A. Gutierrez-Galvez, R. Huerta, S. Marco. 'Calibration transfer and drift counteraction in chemical sensor arrays using Direct Standardization'. Sensors and Actuators B: Chemical (2016). [Web Link]The data set can be used exclusively for research purposes. Commercial purposes are fully excluded. ",Computer,"The responses of the sensors are provided in a .txt file for each experiment. File name codes the unit number, gas (Ea: Ethanol, CO: CO, Ey: Ethylene, Me: Methane), concentration (010-100 of the corresponding gas), and repetition. For example, B1_GEa_F040_R2.txt indicates B1 (board 1), Ea (Ethanol), 50 ppm, Repetition 2.Each file includes the elapsed time (in seconds) and the resistance of each sensor (in KOhm). First column is time, and 8 following columns are channels 0-7 as specified before. ","5 replicates of an 8-MOX gas sensor array were exposed to different gas conditions (4 volatiles at 10 concentration levels each).This dataset includes the recordings of five replicates of an 8-sensor array. Each unit holds 8 MOX sensors and integrates custom-designed electronics for sensor operating temperature control and signal acquisition.The same experimental protocol was followed to measure the response of the 5 twin units. Each day, a different unit was tested, which included the presentationof 40 different gas conditions, presented in random order. In particular, the unit under test was exposed to 10 concentration levels of Ethanol, Methane, Ethylene, and Carbon Monoxide.The duration of each experiment was 600 s, and the conductivity of each sensor was acquired at 100Hz.Channel, sensor type (from Figaro), and mean voltage in the heater are as follows: 0: TGS2611 5.65 V1: TGS2612 5.65 V2: TGS2610 5.65 V3: TGS2602 5.65 V4: TGS2611 5.00 V5: TGS2612 5.00 V6: TGS2610 5.00 V7: TGS2602 5.00 VPresented concentration levels are as follows (in ppm):Ethylene: 12.5, 25, 37.5, 50.0, 62.5, 75.0, 87.5, 100.0 , 112.5, 125.0Ethanol: 12.5, 25.0, 37.5, 50.0, 62.5, 75.0, 87.5, 100.0 , 112.5, 125.0Carbon Monoxide: 25.0, 50.0, 75.0, 100.0 , 125.0 ,150.0, 175.0, 200.0, 225.0 , 250.0Methane: 25.0, 50.0, 75.0, 100.0 , 125.0 ,150.0, 175.0, 200.0, 225.0 , 250.0 Days in which each detection platform was tested.Unit 1: 4,10,15,21Unit 2: 1,7,11,16Unit 3: 2,8,14,17Unit 4: 3,9Unit 5: 18,22More information at:J. Fonollosa, L. Fernandez, A. Gutierrez-Galvez, R. Huerta, S. Marco. 'Calibration transfer and drift counteraction in chemical sensor arrays using Direct Standardization'. Sensors and Actuators B: Chemical (2016). [Web Link]The data set can be used exclusively for research purposes. Commercial purposes are fully excluded. The responses of the sensors are provided in a .txt file for each experiment. File name codes the unit number, gas (Ea: Ethanol, CO: CO, Ey: Ethylene, Me: Methane), concentration (010-100 of the corresponding gas), and repetition. For example, B1_GEa_F040_R2.txt indicates B1 (board 1), Ea (Ethanol), 50 ppm, Repetition 2.Each file includes the elapsed time (in seconds) and the resistance of each sensor (in KOhm). First column is time, and 8 following columns are channels 0-7 as specified before. "
Steel Industry Energy Consumption Dataset,Steel Industry Energy Consumption Dataset,"Dataset attributes are lagging and leading current reactive power, the lagging and leading current power factor, carbon dioxide emissions, and load types. Timespan - 1year (365 days)",Steel+Industry+Energy+Consumption+Dataset,https://archive.ics.uci.edu/ml//machine-learning-databases/00618/,https://archive.ics.uci.edu/ml/datasets/Steel+Industry+Energy+Consumption+Dataset," The information gathered is from the DAEWOO Steel Co. Ltd in Gwangyang, South Korea. It produces several types of coils, steel plates, and iron plates. The information on electricity consumption is held in a cloud-based system. The information on energy consumption of the industry is stored on the website of the Korea Electric Power Corporation (pccs.kepco.go.kr), and the perspectives on daily, monthly, and annual data are calculated and shown.",Computer,"Data Variables	                 Type	        MeasurementIndustry Energy Consumption	Continuous	kWhLagging Current reactive power	Continuous	kVarhLeading Current reactive power	Continuous      kVarhtCO2(CO2)	                Continuous	ppmLagging Current power factor	Continuous	%Leading Current Power factor	Continuous	%Number of Seconds from midnight	Continuous	SWeek status	                Categorical	(Weekend (0) or a Weekday(1))Day of week                     Categorical	Sunday, Monday Ã¢â‚¬Â¦. SaturdayLoad Type	                Categorical	Light Load, Medium Load, Maximum Load","Dataset attributes are lagging and leading current reactive power, the lagging and leading current power factor, carbon dioxide emissions, and load types. Timespan - 1year (365 days) The information gathered is from the DAEWOO Steel Co. Ltd in Gwangyang, South Korea. It produces several types of coils, steel plates, and iron plates. The information on electricity consumption is held in a cloud-based system. The information on energy consumption of the industry is stored on the website of the Korea Electric Power Corporation (pccs.kepco.go.kr), and the perspectives on daily, monthly, and annual data are calculated and shown.Data Variables	                 Type	        MeasurementIndustry Energy Consumption	Continuous	kWhLagging Current reactive power	Continuous	kVarhLeading Current reactive power	Continuous      kVarhtCO2(CO2)	                Continuous	ppmLagging Current power factor	Continuous	%Leading Current Power factor	Continuous	%Number of Seconds from midnight	Continuous	SWeek status	                Categorical	(Weekend (0) or a Weekday(1))Day of week                     Categorical	Sunday, Monday Ã¢â‚¬Â¦. SaturdayLoad Type	                Categorical	Light Load, Medium Load, Maximum Load"
UbiqLog (smartphone lifelogging),UbiqLog (smartphone lifelogging),"UbiqLog is the smartphone lifelogging tool that runs on the smartphone of 35 users for about 2 months. 
",UbiqLog+%28smartphone+lifelogging%29,https://archive.ics.uci.edu/ml//machine-learning-databases/00369/,https://archive.ics.uci.edu/ml/datasets/UbiqLog+%28smartphone+lifelogging%29,This is the first smartphone based lifelogging dataset that is going to be available for public use. Please consider that the user of this dataset are obliged NOT to perform any sort of analysis that can harm the privacy of participants. This dataset is not for any privacy related analysis that can re-identify users.The UbiqLog tool is open source and accessible here:  [Web Link],Computer,"With respect to users privacy UbiqLog collects their Calls, SMS headers (no content), App use, WiFi & Bluetooth devices in user's  proximity, geographical location (if available and GPS works), physical activities form Google play API.Data format is in JSON, because there are different sensors and they have different variables. Nevertheless, we have the code for cleaning and converting the data into CSV + smoothing the time. Moreover, we can share our visualization code. Interested individuals could contact the given email address.","UbiqLog is the smartphone lifelogging tool that runs on the smartphone of 35 users for about 2 months. 
This is the first smartphone based lifelogging dataset that is going to be available for public use. Please consider that the user of this dataset are obliged NOT to perform any sort of analysis that can harm the privacy of participants. This dataset is not for any privacy related analysis that can re-identify users.The UbiqLog tool is open source and accessible here:  [Web Link]With respect to users privacy UbiqLog collects their Calls, SMS headers (no content), App use, WiFi & Bluetooth devices in user's  proximity, geographical location (if available and GPS works), physical activities form Google play API.Data format is in JSON, because there are different sensors and they have different variables. Nevertheless, we have the code for cleaning and converting the data into CSV + smoothing the time. Moreover, we can share our visualization code. Interested individuals could contact the given email address."
Spambase,Spambase,Classifying Email as Spam or Non-Spam,Spambase,https://archive.ics.uci.edu/ml//machine-learning-databases/spambase/,https://archive.ics.uci.edu/ml/datasets/Spambase,"The ""spam"" concept is diverse: advertisements for products/web sites, make money fast schemes, chain letters, pornography...	Our collection of spam e-mails came from our postmaster and individuals who had filed spam.  Our collection of non-spam e-mails came from filed work and personal e-mails, and hence the word 'george' and the area code '650' are indicators of non-spam.  These are useful when constructing a personalized spam filter.  One would either have to blind such non-spam indicators or get a very wide collection of non-spam to generate a general purpose spam filter.For background on spam:        Cranor, Lorrie F., LaMacchia, Brian A.  Spam! Communications of the ACM, 41(8):74-83, 1998.   (a) Hewlett-Packard Internal-only Technical Report. External forthcoming.   (b) Determine whether a given email is spam or not.   (c) ~7% misclassification error. False positives (marking good mail as spam) are very undesirable.If we insist on zero false positives in the training/testing set, 20-25% of the spam passed through the filter.",Computer,"The last column of 'spambase.data' denotes whether the e-mail was considered spam (1) or not (0), i.e. unsolicited commercial e-mail.  Most of the attributes indicate whether a particular word or character was frequently occuring in the e-mail.  The run-length attributes (55-57) measure the length of sequences of consecutive capital letters.  For the statistical measures of each attribute, see the end of this file.  Here are the definitions of the attributes:48 continuous real [0,100] attributes of type word_freq_WORD = percentage of words in the e-mail that match WORD, i.e. 100 * (number of times the WORD appears in the e-mail) / total number of words in e-mail.  A ""word"" in this case is any string of alphanumeric characters bounded by non-alphanumeric characters or end-of-string.6 continuous real [0,100] attributes of type char_freq_CHAR] = percentage of characters in the e-mail that match CHAR, i.e. 100 * (number of CHAR occurences) / total characters in e-mail1 continuous real [1,...] attribute of type capital_run_length_average = average length of uninterrupted sequences of capital letters1 continuous integer [1,...] attribute of type capital_run_length_longest = length of longest uninterrupted sequence of capital letters1 continuous integer [1,...] attribute of type capital_run_length_total = sum of length of uninterrupted sequences of capital letters = total number of capital letters in the e-mail1 nominal {0,1} class attribute of type spam= denotes whether the e-mail was considered spam (1) or not (0), i.e. unsolicited commercial e-mail.  ","Classifying Email as Spam or Non-SpamThe ""spam"" concept is diverse: advertisements for products/web sites, make money fast schemes, chain letters, pornography...	Our collection of spam e-mails came from our postmaster and individuals who had filed spam.  Our collection of non-spam e-mails came from filed work and personal e-mails, and hence the word 'george' and the area code '650' are indicators of non-spam.  These are useful when constructing a personalized spam filter.  One would either have to blind such non-spam indicators or get a very wide collection of non-spam to generate a general purpose spam filter.For background on spam:        Cranor, Lorrie F., LaMacchia, Brian A.  Spam! Communications of the ACM, 41(8):74-83, 1998.   (a) Hewlett-Packard Internal-only Technical Report. External forthcoming.   (b) Determine whether a given email is spam or not.   (c) ~7% misclassification error. False positives (marking good mail as spam) are very undesirable.If we insist on zero false positives in the training/testing set, 20-25% of the spam passed through the filter.The last column of 'spambase.data' denotes whether the e-mail was considered spam (1) or not (0), i.e. unsolicited commercial e-mail.  Most of the attributes indicate whether a particular word or character was frequently occuring in the e-mail.  The run-length attributes (55-57) measure the length of sequences of consecutive capital letters.  For the statistical measures of each attribute, see the end of this file.  Here are the definitions of the attributes:48 continuous real [0,100] attributes of type word_freq_WORD = percentage of words in the e-mail that match WORD, i.e. 100 * (number of times the WORD appears in the e-mail) / total number of words in e-mail.  A ""word"" in this case is any string of alphanumeric characters bounded by non-alphanumeric characters or end-of-string.6 continuous real [0,100] attributes of type char_freq_CHAR] = percentage of characters in the e-mail that match CHAR, i.e. 100 * (number of CHAR occurences) / total characters in e-mail1 continuous real [1,...] attribute of type capital_run_length_average = average length of uninterrupted sequences of capital letters1 continuous integer [1,...] attribute of type capital_run_length_longest = length of longest uninterrupted sequence of capital letters1 continuous integer [1,...] attribute of type capital_run_length_total = sum of length of uninterrupted sequences of capital letters = total number of capital letters in the e-mail1 nominal {0,1} class attribute of type spam= denotes whether the e-mail was considered spam (1) or not (0), i.e. unsolicited commercial e-mail.  "
UJI Pen Characters,UJI Pen Characters,Data consists of written characters in a UNIPEN-like format,UJI+Pen+Characters,https://archive.ics.uci.edu/ml//machine-learning-databases/uji-penchars/version1/,https://archive.ics.uci.edu/ml/datasets/UJI+Pen+Characters,"We create a character database by collecting samples from 11 writers.  Each writer contributed with letters (lower and uppercase), digits, and other characters (Spanish diacritics and punctuation marks) that we have not employed in our experiments and are not included in this database version. Two samples have been collected for each pair writer/character, so the total number of samples in this database version is 1364:          11 writers x 2 repetitions x (2x26 letters + 10 digits)The proposed task is a writer-independent one consisting of 11 leaving-one-writer-out tests, so the effective training set size (for each one of the 1364 test samples) is 1240:          10 writers x 2 repetitions x (2x26 letters + 10 digits) Moreover, this classification task is a 35-class one because we have not considered a different class for each different character: each one of the 26 letters is considered as a case-independent class, there are 9 additional clases for non-zero digits, and the zero is included in the same class as o's.This database is available in a UNIPEN-like format, trying to mimic the original Pendigits database. Two versions of that database are available; see folder: [Web Link]The distribution of our database consists of 12 files:          uji.names          One file ""UJIpenchars-wNN"" per writer, where NN = ""01"", ""02""... ""11""The handwriting samples were collected on a Toshiba Portégé M400 Tablet PC using its cordless stylus. Each one of the 11 writers completed 2 non-consecutive sessions. In each session, the corresponding writer was asked to write one exemplar for each character in a fixed set including lowercase letters, uppercase ones, and digits, along with other characters omitted from this database version. The acquisition program shows a set of boxes on the screen, a different one for each required character, and writers are told to write only inside those boxes. If they make a mistake or are unhappy with a character writing, they are instructed to clear the content of the corresponding box by using an on-screen button and try again. Subjects are monitored only when writing their first exemplars and every sample considered OK by its writer was accepted as such.Only X and Y coordinate information was recorded along the strokes by the acquisition program, without, for instance, pressure level values or timing information. Thus, in multi-stroke samples, no information at all was recorded between strokes; however, in this database version we have included a "".DT 100"" line in sample files after each stroke, following the Pendigits database criterion.We have observed that runs of consecutive points with identical coordinates were frequently acquired inside strokes; such runs were preserved in this database version, so each database user must decide whether to avoid them by an appropriate preprocessing step or not.",Computer,"For each sample, you can find:a. The character it represents.b. The class it belongs to.c. The sequence of strokes it consists of.When testing, you are only allowed to read the sequence of strokes of a sample in order to predict its class.For Each Attribute:As said before, this database is available in a UNIPEN-like format, trying to mimic the original Pendigits database.  A definition of UNIPEN format can be found in [Web Link]Regarding the attributes of a sample, you can find them in the file format as follows:a. Character name: Each sample begins with a "".SEGMENT"" line. The last component of that line shows the character name, one out of 62 possibilities. The complete set of possibilities is shown in the first line of each file, a "".LEXICON"" line. Those possibilities are repeated here:""a"" ""b"" ""c"" ""d"" ""e"" ""f"" ""g"" ""h"" ""i"" ""j"" ""k"" ""l"" ""m""""n"" ""o"" ""p"" ""q"" ""r"" ""s"" ""t"" ""u"" ""v"" ""w"" ""x"" ""y"" ""z""""A"" ""B"" ""C"" ""D"" ""E"" ""F"" ""G"" ""H"" ""I"" ""J"" ""K"" ""L"" ""M""""N"" ""O"" ""P"" ""Q"" ""R"" ""S"" ""T"" ""U"" ""V"" ""W"" ""X"" ""Y"" ""Z""""0"" ""1"" ""2"" ""3"" ""4"" ""5"" ""6"" ""7"" ""8"" ""9""b. Class name: The class name of a sample appears in the "".COMMENT"" line that follows its "".SEGMENT"" line. This name is one out of 35 possibilities. In each file, the complete set of possibilities is shown in "".COMMENT"" lines between the "".LEXICON"" line and a "".HIERARCHY"" one. Those class definitions are repeated here:               [A] = { ""a"" , ""A"" }               [B] = { ""b"" , ""B"" }               [C] = { ""c"" , ""C"" }               [D] = { ""d"" , ""D"" }               [E] = { ""e"" , ""E"" }               [F] = { ""f"" , ""F"" }               [G] = { ""g"" , ""G"" }               [H] = { ""h"" , ""H"" }               [I] = { ""i"" , ""I"" }               [J] = { ""j"" , ""J"" }               [K] = { ""k"" , ""K"" }               [L] = { ""l"" , ""L"" }               [M] = { ""m"" , ""M"" }               [N] = { ""n"" , ""N"" }               [O] = { ""o"" , ""O"" , ""0"" }               [P] = { ""p"" , ""P"" }               [Q] = { ""q"" , ""Q"" }               [R] = { ""r"" , ""R"" }               [S] = { ""s"" , ""S"" }               [T] = { ""t"" , ""T"" }               [U] = { ""u"" , ""U"" }               [V] = { ""v"" , ""V"" }               [W] = { ""w"" , ""W"" }               [X] = { ""x"" , ""X"" }               [Y] = { ""y"" , ""Y"" }               [Z] = { ""z"" , ""Z"" }               [1] = { ""1"" }               [2] = { ""2"" }               [3] = { ""3"" }               [4] = { ""4"" }               [5] = { ""5"" }               [6] = { ""6"" }               [7] = { ""7"" }               [8] = { ""8"" }               [9] = { ""9"" }c. Sequence of strokes: After the "".SEGMENT"" and "".COMMENT"" lines of a sample, a sequence of one or more strokes follows until the beginning of a new sample or the end of the file.  Each stroke begins with a "".PEN_DOWN"" line and ends with a sequence "".PEN_UP"", "".DT 100""; in between, a sequence of lines, each one representing X and Y coordinates of a point, where X grows left-to-right and Y grows downwards. Coordinates are integer numbers.","Data consists of written characters in a UNIPEN-like formatWe create a character database by collecting samples from 11 writers.  Each writer contributed with letters (lower and uppercase), digits, and other characters (Spanish diacritics and punctuation marks) that we have not employed in our experiments and are not included in this database version. Two samples have been collected for each pair writer/character, so the total number of samples in this database version is 1364:          11 writers x 2 repetitions x (2x26 letters + 10 digits)The proposed task is a writer-independent one consisting of 11 leaving-one-writer-out tests, so the effective training set size (for each one of the 1364 test samples) is 1240:          10 writers x 2 repetitions x (2x26 letters + 10 digits) Moreover, this classification task is a 35-class one because we have not considered a different class for each different character: each one of the 26 letters is considered as a case-independent class, there are 9 additional clases for non-zero digits, and the zero is included in the same class as o's.This database is available in a UNIPEN-like format, trying to mimic the original Pendigits database. Two versions of that database are available; see folder: [Web Link]The distribution of our database consists of 12 files:          uji.names          One file ""UJIpenchars-wNN"" per writer, where NN = ""01"", ""02""... ""11""The handwriting samples were collected on a Toshiba Portégé M400 Tablet PC using its cordless stylus. Each one of the 11 writers completed 2 non-consecutive sessions. In each session, the corresponding writer was asked to write one exemplar for each character in a fixed set including lowercase letters, uppercase ones, and digits, along with other characters omitted from this database version. The acquisition program shows a set of boxes on the screen, a different one for each required character, and writers are told to write only inside those boxes. If they make a mistake or are unhappy with a character writing, they are instructed to clear the content of the corresponding box by using an on-screen button and try again. Subjects are monitored only when writing their first exemplars and every sample considered OK by its writer was accepted as such.Only X and Y coordinate information was recorded along the strokes by the acquisition program, without, for instance, pressure level values or timing information. Thus, in multi-stroke samples, no information at all was recorded between strokes; however, in this database version we have included a "".DT 100"" line in sample files after each stroke, following the Pendigits database criterion.We have observed that runs of consecutive points with identical coordinates were frequently acquired inside strokes; such runs were preserved in this database version, so each database user must decide whether to avoid them by an appropriate preprocessing step or not.For each sample, you can find:a. The character it represents.b. The class it belongs to.c. The sequence of strokes it consists of.When testing, you are only allowed to read the sequence of strokes of a sample in order to predict its class.For Each Attribute:As said before, this database is available in a UNIPEN-like format, trying to mimic the original Pendigits database.  A definition of UNIPEN format can be found in [Web Link]Regarding the attributes of a sample, you can find them in the file format as follows:a. Character name: Each sample begins with a "".SEGMENT"" line. The last component of that line shows the character name, one out of 62 possibilities. The complete set of possibilities is shown in the first line of each file, a "".LEXICON"" line. Those possibilities are repeated here:""a"" ""b"" ""c"" ""d"" ""e"" ""f"" ""g"" ""h"" ""i"" ""j"" ""k"" ""l"" ""m""""n"" ""o"" ""p"" ""q"" ""r"" ""s"" ""t"" ""u"" ""v"" ""w"" ""x"" ""y"" ""z""""A"" ""B"" ""C"" ""D"" ""E"" ""F"" ""G"" ""H"" ""I"" ""J"" ""K"" ""L"" ""M""""N"" ""O"" ""P"" ""Q"" ""R"" ""S"" ""T"" ""U"" ""V"" ""W"" ""X"" ""Y"" ""Z""""0"" ""1"" ""2"" ""3"" ""4"" ""5"" ""6"" ""7"" ""8"" ""9""b. Class name: The class name of a sample appears in the "".COMMENT"" line that follows its "".SEGMENT"" line. This name is one out of 35 possibilities. In each file, the complete set of possibilities is shown in "".COMMENT"" lines between the "".LEXICON"" line and a "".HIERARCHY"" one. Those class definitions are repeated here:               [A] = { ""a"" , ""A"" }               [B] = { ""b"" , ""B"" }               [C] = { ""c"" , ""C"" }               [D] = { ""d"" , ""D"" }               [E] = { ""e"" , ""E"" }               [F] = { ""f"" , ""F"" }               [G] = { ""g"" , ""G"" }               [H] = { ""h"" , ""H"" }               [I] = { ""i"" , ""I"" }               [J] = { ""j"" , ""J"" }               [K] = { ""k"" , ""K"" }               [L] = { ""l"" , ""L"" }               [M] = { ""m"" , ""M"" }               [N] = { ""n"" , ""N"" }               [O] = { ""o"" , ""O"" , ""0"" }               [P] = { ""p"" , ""P"" }               [Q] = { ""q"" , ""Q"" }               [R] = { ""r"" , ""R"" }               [S] = { ""s"" , ""S"" }               [T] = { ""t"" , ""T"" }               [U] = { ""u"" , ""U"" }               [V] = { ""v"" , ""V"" }               [W] = { ""w"" , ""W"" }               [X] = { ""x"" , ""X"" }               [Y] = { ""y"" , ""Y"" }               [Z] = { ""z"" , ""Z"" }               [1] = { ""1"" }               [2] = { ""2"" }               [3] = { ""3"" }               [4] = { ""4"" }               [5] = { ""5"" }               [6] = { ""6"" }               [7] = { ""7"" }               [8] = { ""8"" }               [9] = { ""9"" }c. Sequence of strokes: After the "".SEGMENT"" and "".COMMENT"" lines of a sample, a sequence of one or more strokes follows until the beginning of a new sample or the end of the file.  Each stroke begins with a "".PEN_DOWN"" line and ends with a sequence "".PEN_UP"", "".DT 100""; in between, a sequence of lines, each one representing X and Y coordinates of a point, where X grows left-to-right and Y grows downwards. Coordinates are integer numbers."
UJI Pen Characters (Version 2),UJI Pen Characters (Version 2),A pen-based database with more than 11k isolated handwritten characters,UJI+Pen+Characters+%28Version+2%29,https://archive.ics.uci.edu/ml//machine-learning-databases/uji-penchars/version2/,https://archive.ics.uci.edu/ml/datasets/UJI+Pen+Characters+%28Version+2%29,We have created the UJIpenchars2 character database by collecting samples from 60 writers at two different sites in two phases: ,Computer,"The file 'ujipenchars2.txt' is a text one with a simple format where all database samples are represented. Because some non-ASCII characters are needed, UTF-8 encoding is employed.In order to describe how attributes are represented in 'ujipenchars2.txt', it is worth explaining the general syntax of the file first. From the higher-level point of view, this file is composed of comment lines and sample representations.A comment line is one beginning with two slashes. In 'ujipenchars2.txt', we have employed comment lines for two purposes:","A pen-based database with more than 11k isolated handwritten charactersWe have created the UJIpenchars2 character database by collecting samples from 60 writers at two different sites in two phases: The file 'ujipenchars2.txt' is a text one with a simple format where all database samples are represented. Because some non-ASCII characters are needed, UTF-8 encoding is employed.In order to describe how attributes are represented in 'ujipenchars2.txt', it is worth explaining the general syntax of the file first. From the higher-level point of view, this file is composed of comment lines and sample representations.A comment line is one beginning with two slashes. In 'ujipenchars2.txt', we have employed comment lines for two purposes:"
Rice Leaf Diseases,Rice Leaf Diseases,"There are three classes/diseases: Bacterial leaf blight, Brown spot, and Leaf smut, each having 40 images. The format of all images is jpg.  ",Rice+Leaf+Diseases,https://archive.ics.uci.edu/ml//machine-learning-databases/00486/,https://archive.ics.uci.edu/ml/datasets/Rice+Leaf+Diseases,"The dataset was created by manually separating infected leaves into different disease classes. We had consulted the farmers and had asked them to provide names of diseases for sample leaves. Farmers had provided names in their native languages (Gujarati) and we identiÃ¯Â¬Â�ed and veriÃ¯Â¬Â�ed English names of those diseases by consulting with experts of agriculture Ã¯Â¬Â�eld.This dataset was used for Detection and ClassiÃ¯Â¬Â�cation of Rice Plant Diseases. As part of the work, the following activities were carried out (1) How to extract various image features (2) which image processing operations can provide needed information (3) which image features can provide substantial input for classification. The survey work is available in IEEE conference paper: A Survey on Detection and Classification of Rice Plant Diseases, available at [Web Link]. A classification model was developed using SVM. The detailed information is available in the published journal article:Detection and classification of rice plant diseases, in Intelligent Decision Technologies, IOS Press, available at [Web Link]",Computer,"Image Format: .jpg, The images were captured with a white background, in direct sunlight. The images were reduced to the desired resolution for processing.","There are three classes/diseases: Bacterial leaf blight, Brown spot, and Leaf smut, each having 40 images. The format of all images is jpg.  The dataset was created by manually separating infected leaves into different disease classes. We had consulted the farmers and had asked them to provide names of diseases for sample leaves. Farmers had provided names in their native languages (Gujarati) and we identiÃ¯Â¬Â�ed and veriÃ¯Â¬Â�ed English names of those diseases by consulting with experts of agriculture Ã¯Â¬Â�eld.This dataset was used for Detection and ClassiÃ¯Â¬Â�cation of Rice Plant Diseases. As part of the work, the following activities were carried out (1) How to extract various image features (2) which image processing operations can provide needed information (3) which image features can provide substantial input for classification. The survey work is available in IEEE conference paper: A Survey on Detection and Classification of Rice Plant Diseases, available at [Web Link]. A classification model was developed using SVM. The detailed information is available in the published journal article:Detection and classification of rice plant diseases, in Intelligent Decision Technologies, IOS Press, available at [Web Link]Image Format: .jpg, The images were captured with a white background, in direct sunlight. The images were reduced to the desired resolution for processing."
Rice (Cammeo and Osmancik),Rice (Cammeo and Osmancik),"A total of 3810 rice grain's images were taken for the two species, processed and feature inferences were made. 7 morphological features were obtained for each grain of rice.",Rice+%28Cammeo+and+Osmancik%29,https://archive.ics.uci.edu/ml//machine-learning-databases/00545/,https://archive.ics.uci.edu/ml/datasets/Rice+%28Cammeo+and+Osmancik%29,"Among  the certified rice grown in TURKEY,  the  Osmancik species, which has a large planting area since 1997 and the Cammeo species grown since 2014 have been selected for the study.  When  looking  at  the  general  characteristics  of  Osmancik species, they have a wide, long, glassy and dull appearance.  When looking at the general characteristics of the Cammeo species, they have wide and long, glassy and dull in appearance.  A total of 3810 rice grain's images were taken for the two species, processed and feature inferences were made. 7 morphological features were obtained for each grain of rice. ",Computer,"1.) Area: Returns  the  number  of  pixels  within  the boundaries of the rice grain.2.) Perimeter: Calculates the circumference by calculating  the  distance  between  pixels around the boundaries of the rice grain.3.) Major Axis Length: The longest line that can be drawn on the rice  grain,  i.e.  the  main  axis  distance, gives.4.) Minor Axis Length: The shortest line that can be drawn on the rice  grain,  i.e.  the  small  axis  distance, gives.5.) Eccentricity: It measures how round the ellipse, which has  the  same  moments  as  the  rice  grain, is.6.) Convex Area: Returns  the  pixel  count  of  the  smallest convex shell of the region formed by the rice grain.7.) Extent: Returns the ratio of the regionformed by the rice grain to the bounding box pixels.8.) Class: Cammeo and Osmancik rices","A total of 3810 rice grain's images were taken for the two species, processed and feature inferences were made. 7 morphological features were obtained for each grain of rice.Among  the certified rice grown in TURKEY,  the  Osmancik species, which has a large planting area since 1997 and the Cammeo species grown since 2014 have been selected for the study.  When  looking  at  the  general  characteristics  of  Osmancik species, they have a wide, long, glassy and dull appearance.  When looking at the general characteristics of the Cammeo species, they have wide and long, glassy and dull in appearance.  A total of 3810 rice grain's images were taken for the two species, processed and feature inferences were made. 7 morphological features were obtained for each grain of rice. 1.) Area: Returns  the  number  of  pixels  within  the boundaries of the rice grain.2.) Perimeter: Calculates the circumference by calculating  the  distance  between  pixels around the boundaries of the rice grain.3.) Major Axis Length: The longest line that can be drawn on the rice  grain,  i.e.  the  main  axis  distance, gives.4.) Minor Axis Length: The shortest line that can be drawn on the rice  grain,  i.e.  the  small  axis  distance, gives.5.) Eccentricity: It measures how round the ellipse, which has  the  same  moments  as  the  rice  grain, is.6.) Convex Area: Returns  the  pixel  count  of  the  smallest convex shell of the region formed by the rice grain.7.) Extent: Returns the ratio of the regionformed by the rice grain to the bounding box pixels.8.) Class: Cammeo and Osmancik rices"
REWEMA,REWEMA,REWEMA (Retrieval of 32-bit Windows Architecture Executables Applied to Malware Analysis) can be used in Artificial intelligence-based antivirus. ,REWEMA,https://archive.ics.uci.edu/ml//machine-learning-databases/00634/,https://archive.ics.uci.edu/ml/datasets/REWEMA,"The extraction of features of executables employs the process of disassembling. Then, the algorithm, referring to the executable, can be studied and later classified by the neural. There are 3136 malicious executables and 3136 other benign executables. Therefore, the REWEMA base is suitable for learning with artificial intelligence, since both classes of executables have the same amount.As for malicious executables, REWEMA is the junction of several malware databases. Virtual plagues were extracted from databases provided by enthusiastic study groups such as Vxheaven and TheZoo. Malwares, contained in REWEMA, are widely used in various malicious activities. In REWEMA, there are Trojan horse, Worm, Constructor, Exploit, HackTool, Hoax, Backdoor, Rootkit, Virus and Spyware. In addition, REWEMA contains Botnets aiming Flooder, CC (command-and-control server), DoS (Denial of Service), IRC (Internet Relay Chat), CF (Click Fraud) and SPAM e-mail.As for benign executables, the acquisition came from benign application repositories such as sourceforge, github and sysinternals. It should be noted that all benign executables were submitted to VirusTotal and all were its benign attested by the main commercial antivirus worldwide. The diagnostics, provided by VirusTotal, corresponding to the benign and malware executables are available in the virtual address of the REWEMA database Ã‚Â¹.1.	REWEMA (Retrieval of 32-bit Windows Architecture Executables Applied to Malware Analysis). [Web Link]. Accessed on Feb 2020",Computer,"1) Application name2) Class (M = malware, B = benign)3) Input Attribute (3-632).Next, the groups of features extracted from the executables investigated are detailed.Ã¢â‚¬Â¢	Histogram of instructions, in assembly, referring to the mnemonic.Ã¢â‚¬Â¢	Number of subroutines invoking TLS (transport layer security).Ã¢â‚¬Â¢	Number of subroutines responsible for exporting data (exports).Ã¢â‚¬Â¢	APIs (application programming interface) used by the executable.Ã¢â‚¬Â¢	Features related to clues that the computer has suffered fragmentation on its hard disk, as well as accumulated invalid boot attempts.Ã¢â‚¬Â¢	Application execution mode. There are two options:software with a graphical interface (GUI); software running on the console.Ã¢â‚¬Â¢	Features related to the operating system. Ã¢â‚¬Â¢	Features related to Windows Registry (Regedit). Ã¢â‚¬Â¢	Features related to spywares such as keyloggers (capture of keyboard information in order to theft of passwords and logins) and screenloggers (screen shot of the victim). Ã¢â‚¬Â¢	Features related to antiforensic digital which are techniques of removal, occultation and subversion of evidences with the goal of reducing the consequences of the results of forensic analyzes. Ã¢â‚¬Â¢	Features related to the creation of GUI (Graphical User Interface) of the suspicious program. Ã¢â‚¬Â¢	Features related to the illicit forensic of the RAM (main memory) of the local system. Ã¢â‚¬Â¢	Features related to network traffic. Ã¢â‚¬Â¢	Features related to utility application programs. ","REWEMA (Retrieval of 32-bit Windows Architecture Executables Applied to Malware Analysis) can be used in Artificial intelligence-based antivirus. The extraction of features of executables employs the process of disassembling. Then, the algorithm, referring to the executable, can be studied and later classified by the neural. There are 3136 malicious executables and 3136 other benign executables. Therefore, the REWEMA base is suitable for learning with artificial intelligence, since both classes of executables have the same amount.As for malicious executables, REWEMA is the junction of several malware databases. Virtual plagues were extracted from databases provided by enthusiastic study groups such as Vxheaven and TheZoo. Malwares, contained in REWEMA, are widely used in various malicious activities. In REWEMA, there are Trojan horse, Worm, Constructor, Exploit, HackTool, Hoax, Backdoor, Rootkit, Virus and Spyware. In addition, REWEMA contains Botnets aiming Flooder, CC (command-and-control server), DoS (Denial of Service), IRC (Internet Relay Chat), CF (Click Fraud) and SPAM e-mail.As for benign executables, the acquisition came from benign application repositories such as sourceforge, github and sysinternals. It should be noted that all benign executables were submitted to VirusTotal and all were its benign attested by the main commercial antivirus worldwide. The diagnostics, provided by VirusTotal, corresponding to the benign and malware executables are available in the virtual address of the REWEMA database Ã‚Â¹.1.	REWEMA (Retrieval of 32-bit Windows Architecture Executables Applied to Malware Analysis). [Web Link]. Accessed on Feb 20201) Application name2) Class (M = malware, B = benign)3) Input Attribute (3-632).Next, the groups of features extracted from the executables investigated are detailed.Ã¢â‚¬Â¢	Histogram of instructions, in assembly, referring to the mnemonic.Ã¢â‚¬Â¢	Number of subroutines invoking TLS (transport layer security).Ã¢â‚¬Â¢	Number of subroutines responsible for exporting data (exports).Ã¢â‚¬Â¢	APIs (application programming interface) used by the executable.Ã¢â‚¬Â¢	Features related to clues that the computer has suffered fragmentation on its hard disk, as well as accumulated invalid boot attempts.Ã¢â‚¬Â¢	Application execution mode. There are two options:software with a graphical interface (GUI); software running on the console.Ã¢â‚¬Â¢	Features related to the operating system. Ã¢â‚¬Â¢	Features related to Windows Registry (Regedit). Ã¢â‚¬Â¢	Features related to spywares such as keyloggers (capture of keyboard information in order to theft of passwords and logins) and screenloggers (screen shot of the victim). Ã¢â‚¬Â¢	Features related to antiforensic digital which are techniques of removal, occultation and subversion of evidences with the goal of reducing the consequences of the results of forensic analyzes. Ã¢â‚¬Â¢	Features related to the creation of GUI (Graphical User Interface) of the suspicious program. Ã¢â‚¬Â¢	Features related to the illicit forensic of the RAM (main memory) of the local system. Ã¢â‚¬Â¢	Features related to network traffic. Ã¢â‚¬Â¢	Features related to utility application programs. "
Reuter_50_50,Reuter_50_50,The dataset is used for authorship identification in online Writeprint which is a new research field of pattern recognition. ,Reuter_50_50,https://archive.ics.uci.edu/ml//machine-learning-databases/00217/,https://archive.ics.uci.edu/ml/datasets/Reuter_50_50,"The dataset is the subset of RCV1. These corpus has already been used in author identification experiments. In the top 50 authors (with respect to total size of articles) were selected. 50 authors of texts labeled with at least one subtopic of the class CCAT(corporate/industrial) were selected.That way, it is attempted to minimize the topic factor in distinguishing among the texts. The training corpus consists of 2,500 texts (50 per author) and the test corpus includes other 2,500 texts (50 per author) non-overlapping with the training texts.",Computer,Attributes of the dataset are character n-grams(n=1-5),"The dataset is used for authorship identification in online Writeprint which is a new research field of pattern recognition. The dataset is the subset of RCV1. These corpus has already been used in author identification experiments. In the top 50 authors (with respect to total size of articles) were selected. 50 authors of texts labeled with at least one subtopic of the class CCAT(corporate/industrial) were selected.That way, it is attempted to minimize the topic factor in distinguishing among the texts. The training corpus consists of 2,500 texts (50 per author) and the test corpus includes other 2,500 texts (50 per author) non-overlapping with the training texts.Attributes of the dataset are character n-grams(n=1-5)"
URL Reputation,URL Reputation,Anonymized 120-day subset of the ICML-09 URL data containing 2.4 million examples and 3.2 million features.,URL+Reputation,https://archive.ics.uci.edu/ml//machine-learning-databases/url/,https://archive.ics.uci.edu/ml/datasets/URL+Reputation,Uncompressing the archive url_svmlight.tar.gz will yield a directory url_svmlight/ containing the following files:    * FeatureTypes --- A text file list of feature indices that correspond to real-valued features.    * DayX.svm (where X is an integer from 0 to 120) --- The data for day X in SVM-light format. A label of +1 corresponds to a malicious URL and -1 corresponds to a benign URL.,Computer,"Attributes are anonymized, but correspond to lexical and host-based features gathered for each URL.","Anonymized 120-day subset of the ICML-09 URL data containing 2.4 million examples and 3.2 million features.Uncompressing the archive url_svmlight.tar.gz will yield a directory url_svmlight/ containing the following files:    * FeatureTypes --- A text file list of feature indices that correspond to real-valued features.    * DayX.svm (where X is an integer from 0 to 120) --- The data for day X in SVM-light format. A label of +1 corresponds to a malicious URL and -1 corresponds to a benign URL.Attributes are anonymized, but correspond to lexical and host-based features gathered for each URL."
PEMS-SF,PEMS-SF,"15 months worth of daily data (440 daily records) that describes the occupancy rate, between 0 and 1, of different car lanes of the San Francisco bay area freeways across time.",PEMS-SF,https://archive.ics.uci.edu/ml//machine-learning-databases/00204/,https://archive.ics.uci.edu/ml/datasets/PEMS-SF,"We have downloaded 15 months worth of daily data from the California Department of Transportation PEMS website, [Web Link], The data describes the occupancyrate, between 0 and 1, of different car lanes of San Francisco bay area freeways. The measurements cover the period from Jan. 1st 2008 to Mar. 30th 2009 and are sampled every 10 minutes. We consider each day in this database as a single time series of dimension 963 (the number of sensors which functioned consistently throughout the studied period) and length 6 x 24=144. We remove public holidays from the dataset, as wellas two days with anomalies (March 8th 2009 and March 9th 2008) where all sensors were muted between 2:00 and 3:00 AM. This results in a database of 440 time series.The task we propose on this dataset is to classify each observed day as the correct day of the week, from Monday to Sunday, e.g. label it with an integer in {1,2,3,4,5,6,7}. I will keep separate copies of this database on my website in a Matlab format. If you use Matlab, it might be more convenient to consider these .mat files directly.Data-Format-------------There are two files for each fold, the data file and the labels file. We have split the 440 time series between train and test folds, but you are of course free to merge them to consider a different cross validation setting.- The PEMS_train textfile has 263 lines. Each line describes a time-series provided as a matrix. The matrix syntax is that of Matlab, e.g. [ a b ; c d] is the matrix with row vectors [a b] and [c d] in that order. Each matrix describes the different occupancies rates (963 lines, one for each station/detector) sampled every 10 minutes during the day (144 columns).- The PEMS_trainlabel text describes, for each day of measurements described above, the day of the week on which the data was sampled, namely an integer between 1 (Mon.) and 7 (Sun.).- PEMS_test and PEMS_testlabels are formatted in the same way, except that there are 173 test instances.- The permutation that I used to shuffle the dataset is given in the randperm file. If you need to rearrange the data so that it follows the calendar order, you should merge train and test samples and reorder them using the inverse permutation of randperm.",Computer,"Each attribute describes the measurement of the occupancy rate (between 0 and 1) of a captor location as recorded by a measuring station, at a given timestamp in time during the day.  The ID of each station is given in the stations_list text file. For more information on the location (GPS, Highway, Direction) of each station please refer to the PEMS website. There are 963 (stations) x 144 (timestamps) =  138.672 attributes for each record.","15 months worth of daily data (440 daily records) that describes the occupancy rate, between 0 and 1, of different car lanes of the San Francisco bay area freeways across time.We have downloaded 15 months worth of daily data from the California Department of Transportation PEMS website, [Web Link], The data describes the occupancyrate, between 0 and 1, of different car lanes of San Francisco bay area freeways. The measurements cover the period from Jan. 1st 2008 to Mar. 30th 2009 and are sampled every 10 minutes. We consider each day in this database as a single time series of dimension 963 (the number of sensors which functioned consistently throughout the studied period) and length 6 x 24=144. We remove public holidays from the dataset, as wellas two days with anomalies (March 8th 2009 and March 9th 2008) where all sensors were muted between 2:00 and 3:00 AM. This results in a database of 440 time series.The task we propose on this dataset is to classify each observed day as the correct day of the week, from Monday to Sunday, e.g. label it with an integer in {1,2,3,4,5,6,7}. I will keep separate copies of this database on my website in a Matlab format. If you use Matlab, it might be more convenient to consider these .mat files directly.Data-Format-------------There are two files for each fold, the data file and the labels file. We have split the 440 time series between train and test folds, but you are of course free to merge them to consider a different cross validation setting.- The PEMS_train textfile has 263 lines. Each line describes a time-series provided as a matrix. The matrix syntax is that of Matlab, e.g. [ a b ; c d] is the matrix with row vectors [a b] and [c d] in that order. Each matrix describes the different occupancies rates (963 lines, one for each station/detector) sampled every 10 minutes during the day (144 columns).- The PEMS_trainlabel text describes, for each day of measurements described above, the day of the week on which the data was sampled, namely an integer between 1 (Mon.) and 7 (Sun.).- PEMS_test and PEMS_testlabels are formatted in the same way, except that there are 173 test instances.- The permutation that I used to shuffle the dataset is given in the randperm file. If you need to rearrange the data so that it follows the calendar order, you should merge train and test samples and reorder them using the inverse permutation of randperm.Each attribute describes the measurement of the occupancy rate (between 0 and 1) of a captor location as recorded by a measuring station, at a given timestamp in time during the day.  The ID of each station is given in the stations_list text file. For more information on the location (GPS, Highway, Direction) of each station please refer to the PEMS website. There are 963 (stations) x 144 (timestamps) =  138.672 attributes for each record."
Pedestrian in Traffic Dataset,Pedestrian in Traffic Dataset,This data-set contains a number of pedestrian tracks recorded from a vehicle driving in a town in southern Germany. The data is particularly well-suited for multi-agent motion prediction tasks.,Pedestrian+in+Traffic+Dataset,https://archive.ics.uci.edu/ml//machine-learning-databases/00536/,https://archive.ics.uci.edu/ml/datasets/Pedestrian+in+Traffic+Dataset,"The raw data was acquired from a vehicle equipped with multiple sensors while driving, for approximately five hours, in an urban area in southern Germany. The sensor set included one mono-RGB camera, one stereo-RGB camera, an inertial measurement system with differential GPS and a lidar system. The preprocessed data available from this repository consists of 45 pedestrian tracks (in world coordinates) together with a semantic map of the static environment. For each track and at each time-step, not only the agent position is provided, but also body and head orientation attributes, as well as the position of all other agents and their type (e.g. car, cyclist, pedestrian etc.). Additional details about the preprocessing pipeline can be found in [1]. More information on the data format is provided in the next section.",Computer,": Pedestrian tracks are stored in the tracks.csv. Each row in such files contains 14 comma-separated attributes, with missing values denoted by Ã¢â‚¬ËœNoneÃ¢â‚¬â„¢. The attributes are in order:Ã¢â‚¬Â¢	oid: unique agent id (int), Ã¢â‚¬Â¢	timestamp: time in seconds (float),Ã¢â‚¬Â¢	x: x component of position vector (float),Ã¢â‚¬Â¢	y: y component of position vector (float),Ã¢â‚¬Â¢	body_roll: roll body angle in degrees (float),Ã¢â‚¬Â¢	body_pitch: pitch body angle in degrees (float),Ã¢â‚¬Â¢	body_yaw: yaw body angle in degrees (float),Ã¢â‚¬Â¢	head_roll: roll head angle in degrees (float),Ã¢â‚¬Â¢	head_pitch: pitch head angle in degrees (float),Ã¢â‚¬Â¢	head_yaw: yaw head angle in degrees (float),Ã¢â‚¬Â¢	other_oid: list of ids of agents currently present in the scene ([list of int]),Ã¢â‚¬Â¢	other_class: list of other agentsÃ¢â‚¬â„¢ class labels ([list of int]),Ã¢â‚¬Â¢	other_x: list of other agentsÃ¢â‚¬â„¢ x coordinates ([list of float]),Ã¢â‚¬Â¢	other_y: list of other agentsÃ¢â‚¬â„¢ y coordinates ([list of float]).Labels used to identify agent types are available in agent_class_label_info.csv.The file semantic_map.png contains a map of the static environment, where semantic labels are color-encoded according to the mapping available in semantic_map_label_info.csv. Information needed to transform between image and world coordinates is stored in the file map2world_info.txt.","This data-set contains a number of pedestrian tracks recorded from a vehicle driving in a town in southern Germany. The data is particularly well-suited for multi-agent motion prediction tasks.The raw data was acquired from a vehicle equipped with multiple sensors while driving, for approximately five hours, in an urban area in southern Germany. The sensor set included one mono-RGB camera, one stereo-RGB camera, an inertial measurement system with differential GPS and a lidar system. The preprocessed data available from this repository consists of 45 pedestrian tracks (in world coordinates) together with a semantic map of the static environment. For each track and at each time-step, not only the agent position is provided, but also body and head orientation attributes, as well as the position of all other agents and their type (e.g. car, cyclist, pedestrian etc.). Additional details about the preprocessing pipeline can be found in [1]. More information on the data format is provided in the next section.: Pedestrian tracks are stored in the tracks.csv. Each row in such files contains 14 comma-separated attributes, with missing values denoted by Ã¢â‚¬ËœNoneÃ¢â‚¬â„¢. The attributes are in order:Ã¢â‚¬Â¢	oid: unique agent id (int), Ã¢â‚¬Â¢	timestamp: time in seconds (float),Ã¢â‚¬Â¢	x: x component of position vector (float),Ã¢â‚¬Â¢	y: y component of position vector (float),Ã¢â‚¬Â¢	body_roll: roll body angle in degrees (float),Ã¢â‚¬Â¢	body_pitch: pitch body angle in degrees (float),Ã¢â‚¬Â¢	body_yaw: yaw body angle in degrees (float),Ã¢â‚¬Â¢	head_roll: roll head angle in degrees (float),Ã¢â‚¬Â¢	head_pitch: pitch head angle in degrees (float),Ã¢â‚¬Â¢	head_yaw: yaw head angle in degrees (float),Ã¢â‚¬Â¢	other_oid: list of ids of agents currently present in the scene ([list of int]),Ã¢â‚¬Â¢	other_class: list of other agentsÃ¢â‚¬â„¢ class labels ([list of int]),Ã¢â‚¬Â¢	other_x: list of other agentsÃ¢â‚¬â„¢ x coordinates ([list of float]),Ã¢â‚¬Â¢	other_y: list of other agentsÃ¢â‚¬â„¢ y coordinates ([list of float]).Labels used to identify agent types are available in agent_class_label_info.csv.The file semantic_map.png contains a map of the static environment, where semantic labels are color-encoded according to the mapping available in semantic_map_label_info.csv. Information needed to transform between image and world coordinates is stored in the file map2world_info.txt."
User Knowledge Modeling,User Knowledge Modeling,It is the real dataset about the students' knowledge status about the subject of Electrical DC Machines. The dataset had been obtained from Ph.D. Thesis.,User+Knowledge+Modeling,https://archive.ics.uci.edu/ml//machine-learning-databases/00257/,https://archive.ics.uci.edu/ml/datasets/User+Knowledge+Modeling," -- The users' knowledge class were classified by the authors      using intuitive knowledge classifier (a hybrid ML technique of k-NN and meta-heuristic exploring methods), k-nearest neighbor algorithm.       See article for more details on how the users' data was collected and evaluated by the user modeling server.	H. T. Kahraman, Sagiroglu, S., Colak, I., Developing intuitive knowledge classifier and modeling of users' domain dependent data in web,         Knowledge Based Systems, vol. 37, pp. 283-295, 2013. ",Computer,"STG (The degree of study time for goal object materails), (input value) SCG (The degree of repetition number of user for goal object materails) (input value) STR (The degree of study time of user for related objects with goal object) (input value) LPR (The exam performance of user for related objects with goal object) (input value) PEG (The exam performance of user for goal objects) (input value) UNS (The knowledge level of user) (target value) Very Low: 50Low:129Middle: 122High 130","It is the real dataset about the students' knowledge status about the subject of Electrical DC Machines. The dataset had been obtained from Ph.D. Thesis. -- The users' knowledge class were classified by the authors      using intuitive knowledge classifier (a hybrid ML technique of k-NN and meta-heuristic exploring methods), k-nearest neighbor algorithm.       See article for more details on how the users' data was collected and evaluated by the user modeling server.	H. T. Kahraman, Sagiroglu, S., Colak, I., Developing intuitive knowledge classifier and modeling of users' domain dependent data in web,         Knowledge Based Systems, vol. 37, pp. 283-295, 2013. STG (The degree of study time for goal object materails), (input value) SCG (The degree of repetition number of user for goal object materails) (input value) STR (The degree of study time of user for related objects with goal object) (input value) LPR (The exam performance of user for related objects with goal object) (input value) PEG (The exam performance of user for goal objects) (input value) UNS (The knowledge level of user) (target value) Very Low: 50Low:129Middle: 122High 130"
Parkinson's Disease Classification,Parkinson's Disease Classification,The data used in this study were gathered from 188 patients with PD (107 men and 81 women) with ages ranging from 33 to 87 (65.1Â±10.9).,Parkinson%27s+Disease+Classification,https://archive.ics.uci.edu/ml//machine-learning-databases/00470/,https://archive.ics.uci.edu/ml/datasets/Parkinson%27s+Disease+Classification,"The data used in this study were gathered from 188 patients with PD (107 men and 81 women) with ages ranging from 33 to 87 (65.1Ã‚Â±10.9) at the Department of Neurology in CerrahpaÃ…Å¸a Faculty of Medicine, Istanbul University. The control group consists of 64 healthy individuals (23 men and 41 women) with ages varying between 41 and 82 (61.1Ã‚Â±8.9). During the data collection process, the microphone is set to 44.1 KHz and following the physicianÃ¢â‚¬â„¢s examination, the sustained phonation of the vowel /a/ was collected from each subject with three repetitions.",Computer,"Various speech signal processing algorithms including Time Frequency Features, Mel Frequency Cepstral Coefficients (MFCCs), Wavelet Transform based Features, Vocal Fold Features and TWQT features have been applied to the speech recordings of Parkinson's Disease (PD) patients to extract clinically useful information for PD assessment.","The data used in this study were gathered from 188 patients with PD (107 men and 81 women) with ages ranging from 33 to 87 (65.1Â±10.9).The data used in this study were gathered from 188 patients with PD (107 men and 81 women) with ages ranging from 33 to 87 (65.1Ã‚Â±10.9) at the Department of Neurology in CerrahpaÃ…Å¸a Faculty of Medicine, Istanbul University. The control group consists of 64 healthy individuals (23 men and 41 women) with ages varying between 41 and 82 (61.1Ã‚Â±8.9). During the data collection process, the microphone is set to 44.1 KHz and following the physicianÃ¢â‚¬â„¢s examination, the sustained phonation of the vowel /a/ was collected from each subject with three repetitions.Various speech signal processing algorithms including Time Frequency Features, Mel Frequency Cepstral Coefficients (MFCCs), Wavelet Transform based Features, Vocal Fold Features and TWQT features have been applied to the speech recordings of Parkinson's Disease (PD) patients to extract clinically useful information for PD assessment."
Parkinson Disease Spiral Drawings Using Digitized Graphics Tablet,Parkinson Disease Spiral Drawings Using Digitized Graphics Tablet,"Handwriting database consists of 62 PWP(People with Parkinson) and 15 healthy individuals. Three types of recordings (Static Spiral Test, Dynamic Spiral Test and Stability Test) are taken.",Parkinson+Disease+Spiral+Drawings+Using+Digitized+Graphics+Tablet,https://archive.ics.uci.edu/ml//machine-learning-databases/00395/,https://archive.ics.uci.edu/ml/datasets/Parkinson+Disease+Spiral+Drawings+Using+Digitized+Graphics+Tablet,"The PD and control handwriting database consists of 62 PWP (People with parkinson) and 15 healthy individuals who appealed at the Department of Neurology in Cerrahpasa Faculty of Medicine, Istanbul University. From all subjects, three types of handwriting recordings (Static Spiral Test (SST), Dynamic Spiral Test (DST) and Stability Test on Certain Point (STCP)) are taken. Also the drawings of spirals belongs to the PWP are included in the dataset as image. Therefore, this dataset can also be used for regression. Handwriting dataset was constructed using Wacom Cintiq 12WX graphics (Hahne et al., 2009) table. It is basically a graphics tablet and LCD monitor rolled into one. It enables to display a PC's screen on its monitor and only interacts with digitized pens. Special software was designed for recording handwriting drawings and testing the coordination of the PD patients using the recordings. The software uses API functions of the device and was developed in C# platform which can be run on Windows systems You can contact with the authors to request the software which is mentioned [1]. In this study, there are three different kinds of tests developed for the data collection via graphics tablet. The first one isthe Static Spiral Test (SST) which is frequently used for clinical research in the literature for different purposes like determining motor performance (Wang et al., 2008), measuring tremor (Pullman, 1998) and diagnosing PD (Saunders et al., 2008). In this test, three wound Archimedean spirals appears on the graphics tablet using the software and patients were asked to retrace the same spiral as much as they can using the digital pen. During the test, the features which are mentioned above and the other data to specify the patient are recorded to the database. The second test is the Dynamic Spiral Test (DST). Unlike SST, Archimedean spiral just appears and disappears in certain time intervals, in other words the Archimedean spiral blinks. This forces the patient to keep the pattern in mind and continue to draw. The purpose of this test is to determine the change in patient's drawing performance and pause times since it is more difficult to retrace the Archimedean spiral in this case. As a result of this test, it is observed that most of the patients continued drawing but nearly all of them lost the pattern. The third test is Stability Test on Certain Point (STCP). In this test, there is a certain red point in the middle of the screen and the subjects are asked to hold the digital pen on the point without touching the screen in a certain time. The purpose of this test is to determine the patient's hand stability or hand tremor level. Further details are contained in the following reference -- if you use this dataset, please cite: 1.Isenkul, M.E.; Sakar, B.E.; Kursun, O. . 'Improved spiral test using digitized graphics tablet for monitoring Parkinson's disease.' The 2nd International Conference on e-Health and Telemedicine (ICEHTM-2014), pp. 171-175, 2014.2.Erdogdu Sakar, B., Isenkul, M., Sakar, C.O., Sertbas, A., Gurgen, F., Delil, S., Apaydin, H., Kursun, O., 'Collection and Analysis of a Parkinson Speech Dataset with Multiple Types of Sound Recordings', IEEE Journal of Biomedical and Health Informatics, vol. 17(4), pp. 828-834, 2013.",Computer,'data' file contains the handwriting dataset. In this file there is two different folder that contains two different groups of handwriting samples which are called PWP (People with Parkinson's) and Healthy.,"Handwriting database consists of 62 PWP(People with Parkinson) and 15 healthy individuals. Three types of recordings (Static Spiral Test, Dynamic Spiral Test and Stability Test) are taken.The PD and control handwriting database consists of 62 PWP (People with parkinson) and 15 healthy individuals who appealed at the Department of Neurology in Cerrahpasa Faculty of Medicine, Istanbul University. From all subjects, three types of handwriting recordings (Static Spiral Test (SST), Dynamic Spiral Test (DST) and Stability Test on Certain Point (STCP)) are taken. Also the drawings of spirals belongs to the PWP are included in the dataset as image. Therefore, this dataset can also be used for regression. Handwriting dataset was constructed using Wacom Cintiq 12WX graphics (Hahne et al., 2009) table. It is basically a graphics tablet and LCD monitor rolled into one. It enables to display a PC's screen on its monitor and only interacts with digitized pens. Special software was designed for recording handwriting drawings and testing the coordination of the PD patients using the recordings. The software uses API functions of the device and was developed in C# platform which can be run on Windows systems You can contact with the authors to request the software which is mentioned [1]. In this study, there are three different kinds of tests developed for the data collection via graphics tablet. The first one isthe Static Spiral Test (SST) which is frequently used for clinical research in the literature for different purposes like determining motor performance (Wang et al., 2008), measuring tremor (Pullman, 1998) and diagnosing PD (Saunders et al., 2008). In this test, three wound Archimedean spirals appears on the graphics tablet using the software and patients were asked to retrace the same spiral as much as they can using the digital pen. During the test, the features which are mentioned above and the other data to specify the patient are recorded to the database. The second test is the Dynamic Spiral Test (DST). Unlike SST, Archimedean spiral just appears and disappears in certain time intervals, in other words the Archimedean spiral blinks. This forces the patient to keep the pattern in mind and continue to draw. The purpose of this test is to determine the change in patient's drawing performance and pause times since it is more difficult to retrace the Archimedean spiral in this case. As a result of this test, it is observed that most of the patients continued drawing but nearly all of them lost the pattern. The third test is Stability Test on Certain Point (STCP). In this test, there is a certain red point in the middle of the screen and the subjects are asked to hold the digital pen on the point without touching the screen in a certain time. The purpose of this test is to determine the patient's hand stability or hand tremor level. Further details are contained in the following reference -- if you use this dataset, please cite: 1.Isenkul, M.E.; Sakar, B.E.; Kursun, O. . 'Improved spiral test using digitized graphics tablet for monitoring Parkinson's disease.' The 2nd International Conference on e-Health and Telemedicine (ICEHTM-2014), pp. 171-175, 2014.2.Erdogdu Sakar, B., Isenkul, M., Sakar, C.O., Sertbas, A., Gurgen, F., Delil, S., Apaydin, H., Kursun, O., 'Collection and Analysis of a Parkinson Speech Dataset with Multiple Types of Sound Recordings', IEEE Journal of Biomedical and Health Informatics, vol. 17(4), pp. 828-834, 2013.'data' file contains the handwriting dataset. In this file there is two different folder that contains two different groups of handwriting samples which are called PWP (People with Parkinson's) and Healthy."
Parking Birmingham,Parking Birmingham,"Data collected from car parks in Birmingham that are operated by NCP from 
Birmingham City Council. UK Open Government Licence (OGL).
https://data.birmingham.gov.uk/dataset/birmingham-parking",Parking+Birmingham,https://archive.ics.uci.edu/ml//machine-learning-databases/00482/,https://archive.ics.uci.edu/ml/datasets/Parking+Birmingham,Occupancy rates (8:00 to 16:30) from 2016/10/04 to 2016/12/19,Computer,SystemCodeNumber: Car park IDCapacity: Car park capacityOccupancy: Car park occupancy rateLastUpdated: Date and Time of the measure,"Data collected from car parks in Birmingham that are operated by NCP from 
Birmingham City Council. UK Open Government Licence (OGL).
https://data.birmingham.gov.uk/dataset/birmingham-parkingOccupancy rates (8:00 to 16:30) from 2016/10/04 to 2016/12/19SystemCodeNumber: Car park IDCapacity: Car park capacityOccupancy: Car park occupancy rateLastUpdated: Date and Time of the measure"
Paper Reviews,Paper Reviews,This sentiment analysis data set contains scientific paper reviews from an international conference on computing and informatics. The task is to predict the orientation or the evaluation of a review.,Paper+Reviews,https://archive.ics.uci.edu/ml//machine-learning-databases/00410/,https://archive.ics.uci.edu/ml/datasets/Paper+Reviews,"The data set consists of paper reviews sent to an international conference mostly in Spanish (some are in English). It has a total of N = 405 instances evaluated with a 5-point scale ('-2': very negative, '-1': negative, '0': neutral, '1': positive, '2': very positive), expressing the reviewer's opinion about the paper and the orientation perceived by a reader who does not know the reviewer's evaluation (more details in the attributes' section). The distribution of the original scores is more uniform in comparison to the revised scores. This difference is assumed to come from a discrepancy between the way the paper is evaluated and the way the review is written by the original reviewer.The data set is stored in JSON format, the structure is as follows:Paper: { papers have an associated timespan and a paper ID, each paper contains some reviews. The reviews have their own ID, the review text, the remarks (which can be empty), the language of the review, its orientation and evaluation.Some relevant statistics (excluding reviews in English and empty reviews):- Number of words:Min: 3 Max: 530 Avg: 88.64 Stdev: 69.76- Number of sentences:Min: 1 Max: 47 Avg: 8.91 Stdev: 7.54",Computer,"1. Timespan (datetime): A date associated with the year of conference, which in turn corresponds with the time the review was written. The data set includes four years of reviews worth of conferences.2. Paper ID (integer):  This number identifies each individual paper from a given conference. The data set has 172 different papers.3. Preliminary decision (label): The preliminary decision of acceptance or rejection of a paper taken by the conference committee.4. Review ID (integer: A serial number identifier for each review as a correlative with respect to each individual paper. (e.g. the second review of some paper would correspond to the number $2$). The data set has a total of 405 reviews. Most papers have 2 reviews each.5. Text (text): Comments and detailed review of the paper. This is read by the authors and the editing commission of the conference. The editors determine if the paper should be published or not depending on the reviews. There are $6$ instances of empty reviews.6. Remarks (text): Additional comments that can be read only by the editing commission of the conference. This is used in conjunction with the previous attribute to determine if the paper should be published. This is an optional attribute. Whenever it is possible it is concatenated at the end of the main body of the review. Some reviews do not have remarks, this is indicated with an empty string ''.7. Language (text): Language corresponding to the review (it may be English or Spanish). In this case the majority of the reviews are in Spanish, with only $17$ instances of English reviews.8. Orientation (integer from -2 to 2): Review classification defined by the authors of this study, according to the 5-point scale previously described, obtained through the authors' systematic judgement of each review. This attribute represents the subjective perception of each review (i.e. how negative or positive the review is perceived when someone reads it).9. Evaluation (integer from -2 to 2): Review classification as defined by the reviewer, according to the 5-point scale previously described. This attribute represents the real evaluation given to the paper, as determined by the reviewers.10. Confidence (integer from 1 to 5): Value describing the confidence of the reviewer, a higher value denotes more confidence, while a lower value indicates less confidence.","This sentiment analysis data set contains scientific paper reviews from an international conference on computing and informatics. The task is to predict the orientation or the evaluation of a review.The data set consists of paper reviews sent to an international conference mostly in Spanish (some are in English). It has a total of N = 405 instances evaluated with a 5-point scale ('-2': very negative, '-1': negative, '0': neutral, '1': positive, '2': very positive), expressing the reviewer's opinion about the paper and the orientation perceived by a reader who does not know the reviewer's evaluation (more details in the attributes' section). The distribution of the original scores is more uniform in comparison to the revised scores. This difference is assumed to come from a discrepancy between the way the paper is evaluated and the way the review is written by the original reviewer.The data set is stored in JSON format, the structure is as follows:Paper: { papers have an associated timespan and a paper ID, each paper contains some reviews. The reviews have their own ID, the review text, the remarks (which can be empty), the language of the review, its orientation and evaluation.Some relevant statistics (excluding reviews in English and empty reviews):- Number of words:Min: 3 Max: 530 Avg: 88.64 Stdev: 69.76- Number of sentences:Min: 1 Max: 47 Avg: 8.91 Stdev: 7.541. Timespan (datetime): A date associated with the year of conference, which in turn corresponds with the time the review was written. The data set includes four years of reviews worth of conferences.2. Paper ID (integer):  This number identifies each individual paper from a given conference. The data set has 172 different papers.3. Preliminary decision (label): The preliminary decision of acceptance or rejection of a paper taken by the conference committee.4. Review ID (integer: A serial number identifier for each review as a correlative with respect to each individual paper. (e.g. the second review of some paper would correspond to the number $2$). The data set has a total of 405 reviews. Most papers have 2 reviews each.5. Text (text): Comments and detailed review of the paper. This is read by the authors and the editing commission of the conference. The editors determine if the paper should be published or not depending on the reviews. There are $6$ instances of empty reviews.6. Remarks (text): Additional comments that can be read only by the editing commission of the conference. This is used in conjunction with the previous attribute to determine if the paper should be published. This is an optional attribute. Whenever it is possible it is concatenated at the end of the main body of the review. Some reviews do not have remarks, this is indicated with an empty string ''.7. Language (text): Language corresponding to the review (it may be English or Spanish). In this case the majority of the reviews are in Spanish, with only $17$ instances of English reviews.8. Orientation (integer from -2 to 2): Review classification defined by the authors of this study, according to the 5-point scale previously described, obtained through the authors' systematic judgement of each review. This attribute represents the subjective perception of each review (i.e. how negative or positive the review is perceived when someone reads it).9. Evaluation (integer from -2 to 2): Review classification as defined by the reviewer, according to the 5-point scale previously described. This attribute represents the real evaluation given to the paper, as determined by the reviewers.10. Confidence (integer from 1 to 5): Value describing the confidence of the reviewer, a higher value denotes more confidence, while a lower value indicates less confidence."
User Profiling and Abusive Language Detection Dataset,User Profiling and Abusive Language Detection Dataset,The user profiling dataset is a collection of abusive users tweets and also their user following and user follower tweets. The Abusive language detection dataset is a collection of abusive tweets.,User+Profiling+and+Abusive+Language+Detection+Dataset,https://archive.ics.uci.edu/ml//machine-learning-databases/00543/,https://archive.ics.uci.edu/ml/datasets/User+Profiling+and+Abusive+Language+Detection+Dataset,"The user profiling dataset is divided into two sets: testing and validation. the testing dataset consists of 16,582 tweets collected from 52 users and the validation dataset which consists of 37.532 tweets collected from 18 users. Each sets contains three different files namely user_data, following_data, and follower_data. The tweets contains samples of five different categories of abusive messages. The account names of users have been anonymized so as not to violate the privacy of any user.the abusive language detection dataset contains 11, 805 instances of five different categories of abusive messages.The dataset has two columns namely labels and tweets. Both datasets are in CSV format. ",Computer,the user profiling datasets are in text format and the abusive language detection dataset is in both numerical (labels) and text (tweet).,"The user profiling dataset is a collection of abusive users tweets and also their user following and user follower tweets. The Abusive language detection dataset is a collection of abusive tweets.The user profiling dataset is divided into two sets: testing and validation. the testing dataset consists of 16,582 tweets collected from 52 users and the validation dataset which consists of 37.532 tweets collected from 18 users. Each sets contains three different files namely user_data, following_data, and follower_data. The tweets contains samples of five different categories of abusive messages. The account names of users have been anonymized so as not to violate the privacy of any user.the abusive language detection dataset contains 11, 805 instances of five different categories of abusive messages.The dataset has two columns namely labels and tweets. Both datasets are in CSV format. the user profiling datasets are in text format and the abusive language detection dataset is in both numerical (labels) and text (tweet)."
PAMAP2 Physical Activity Monitoring,PAMAP2 Physical Activity Monitoring,"The PAMAP2 Physical Activity Monitoring dataset contains data of 18 different physical activities, performed by 9 subjects wearing 3 inertial measurement units and a heart rate monitor.",PAMAP2+Physical+Activity+Monitoring,https://archive.ics.uci.edu/ml//machine-learning-databases/00231/,https://archive.ics.uci.edu/ml/datasets/PAMAP2+Physical+Activity+Monitoring,"The PAMAP2 Physical Activity Monitoring dataset contains data of 18 different physical activities (such as walking, cycling, playing soccer, etc.), performed by 9 subjects wearing 3 inertial measurement units and a heart rate monitor. The dataset can be used for activity recognition and intensity estimation, while developing and applying algorithms of data processing, segmentation, feature extraction and classification.** Sensors **3 Colibri wireless inertial measurement units (IMU):  - sampling frequency: 100Hz  - position of the sensors:       - 1 IMU over the wrist on the dominant arm        - 1 IMU on the chest        - 1 IMU on the dominant side's ankle HR-monitor:  - sampling frequency: ~9Hz** Data collection protocol **Each of the subjects had to follow a protocol, containing 12 different activities. The folder Ã¢â‚¬Å“ProtocolÃ¢â‚¬Â� contains these recordings by subject.Furthermore, some of the subjects also performed a few optional activities. The folder Ã¢â‚¬Å“OptionalÃ¢â‚¬Â� contains these recordings by subject.** Data files **Raw sensory data can be found in space-separated text-files (.dat), 1 data file per subject per session (protocol or optional). Missing values are indicated with NaN. One line in the data files correspond to one timestamped and labeled instance of sensory data. The data files contain 54 columns: each line consists of a timestamp, an activity label (the ground truth) and 52 attributes of raw sensory data.",Computer,"The 54 columns in the data files are organized as follows:  1.		timestamp (s)  2.		activityID (see below for the mapping to the activities)  3.		heart rate (bpm)  4-20.		IMU hand  21-37.	IMU chest  38-54.	IMU ankleThe IMU sensory data contains the following columns:   1.		temperature (Ã‚Â°C)   2-4.		3D-acceleration data (ms-2), scale: Ã‚Â±16g, resolution: 13-bit   5-7.		3D-acceleration data (ms-2), scale: Ã‚Â±6g, resolution: 13-bit  8-10.		3D-gyroscope data (rad/s)   11-13.	3D-magnetometer data (ÃŽÂ¼T)   14-17.	orientation (invalid in this data collection) List of activityIDs and corresponding activities: 1	lying 2	sitting 3	standing 4	walking 5	running 6	cycling 7	Nordic walking 9	watching TV 10	computer work 11	car driving 12	ascending stairs 13	descending stairs 16	vacuum cleaning 17	ironing 18	folding laundry 19	house cleaning 20	playing soccer 24	rope jumping 0	other (transient activities)","The PAMAP2 Physical Activity Monitoring dataset contains data of 18 different physical activities, performed by 9 subjects wearing 3 inertial measurement units and a heart rate monitor.The PAMAP2 Physical Activity Monitoring dataset contains data of 18 different physical activities (such as walking, cycling, playing soccer, etc.), performed by 9 subjects wearing 3 inertial measurement units and a heart rate monitor. The dataset can be used for activity recognition and intensity estimation, while developing and applying algorithms of data processing, segmentation, feature extraction and classification.** Sensors **3 Colibri wireless inertial measurement units (IMU):  - sampling frequency: 100Hz  - position of the sensors:       - 1 IMU over the wrist on the dominant arm        - 1 IMU on the chest        - 1 IMU on the dominant side's ankle HR-monitor:  - sampling frequency: ~9Hz** Data collection protocol **Each of the subjects had to follow a protocol, containing 12 different activities. The folder Ã¢â‚¬Å“ProtocolÃ¢â‚¬Â� contains these recordings by subject.Furthermore, some of the subjects also performed a few optional activities. The folder Ã¢â‚¬Å“OptionalÃ¢â‚¬Â� contains these recordings by subject.** Data files **Raw sensory data can be found in space-separated text-files (.dat), 1 data file per subject per session (protocol or optional). Missing values are indicated with NaN. One line in the data files correspond to one timestamped and labeled instance of sensory data. The data files contain 54 columns: each line consists of a timestamp, an activity label (the ground truth) and 52 attributes of raw sensory data.The 54 columns in the data files are organized as follows:  1.		timestamp (s)  2.		activityID (see below for the mapping to the activities)  3.		heart rate (bpm)  4-20.		IMU hand  21-37.	IMU chest  38-54.	IMU ankleThe IMU sensory data contains the following columns:   1.		temperature (Ã‚Â°C)   2-4.		3D-acceleration data (ms-2), scale: Ã‚Â±16g, resolution: 13-bit   5-7.		3D-acceleration data (ms-2), scale: Ã‚Â±6g, resolution: 13-bit  8-10.		3D-gyroscope data (rad/s)   11-13.	3D-magnetometer data (ÃŽÂ¼T)   14-17.	orientation (invalid in this data collection) List of activityIDs and corresponding activities: 1	lying 2	sitting 3	standing 4	walking 5	running 6	cycling 7	Nordic walking 9	watching TV 10	computer work 11	car driving 12	ascending stairs 13	descending stairs 16	vacuum cleaning 17	ironing 18	folding laundry 19	house cleaning 20	playing soccer 24	rope jumping 0	other (transient activities)"
Page Blocks Classification,Page Blocks Classification,The problem consists of classifying all the blocks of the page layout of a document that has been detected by a segmentation process.,Page+Blocks+Classification,https://archive.ics.uci.edu/ml//machine-learning-databases/page-blocks/,https://archive.ics.uci.edu/ml/datasets/Page+Blocks+Classification,The 5473 examples comes from 54 distinct documents. Each observation concerns one block. All attributes are numeric. Data are in a format readable by C4.5.,Computer,   height:   integer.         | Height of the block.   lenght:   integer.     | Length of the block.    area:     integer.    | Area of the block (height * lenght);   eccen:    continuous.  | Eccentricity of the block (lenght / height);   p_black:  continuous.  | Percentage of black pixels within the block (blackpix / area);   p_and:    continuous.        | Percentage of black pixels after the application of the Run Length Smoothing Algorithm (RLSA) (blackand / area);   mean_tr:  continuous.      | Mean number of white-black transitions (blackpix / wb_trans);   blackpix: integer.    | Total number of black pixels in the original bitmap of the block.   blackand: integer.        | Total number of black pixels in the bitmap of the block after the RLSA.   wb_trans: integer.          | Number of white-black transitions in the original bitmap of the block.,The problem consists of classifying all the blocks of the page layout of a document that has been detected by a segmentation process.The 5473 examples comes from 54 distinct documents. Each observation concerns one block. All attributes are numeric. Data are in a format readable by C4.5.   height:   integer.         | Height of the block.   lenght:   integer.     | Length of the block.    area:     integer.    | Area of the block (height * lenght);   eccen:    continuous.  | Eccentricity of the block (lenght / height);   p_black:  continuous.  | Percentage of black pixels within the block (blackpix / area);   p_and:    continuous.        | Percentage of black pixels after the application of the Run Length Smoothing Algorithm (RLSA) (blackand / area);   mean_tr:  continuous.      | Mean number of white-black transitions (blackpix / wb_trans);   blackpix: integer.    | Total number of black pixels in the original bitmap of the block.   blackand: integer.        | Total number of black pixels in the bitmap of the block after the RLSA.   wb_trans: integer.          | Number of white-black transitions in the original bitmap of the block.
Optical Recognition of Handwritten Digits,Optical Recognition of Handwritten Digits,Two versions of this database available; see folder,Optical+Recognition+of+Handwritten+Digits,https://archive.ics.uci.edu/ml//machine-learning-databases/optdigits/,https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits,"We used preprocessing programs made available by NIST to extract normalized bitmaps of handwritten digits from a preprinted form. From a total of 43 people, 30 contributed to the training set and different 13 to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of 4x4 and the number of on pixels are counted in each block. This generates an input matrix of 8x8 where each element is an integer in the range 0..16. This reduces dimensionality and gives invariance to small distortions.For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G. T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C. L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469, 1994.",Computer,All input attributes are integers in the range 0..16.The last attribute is the class code 0..9,"Two versions of this database available; see folderWe used preprocessing programs made available by NIST to extract normalized bitmaps of handwritten digits from a preprinted form. From a total of 43 people, 30 contributed to the training set and different 13 to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of 4x4 and the number of on pixels are counted in each block. This generates an input matrix of 8x8 where each element is an integer in the range 0..16. This reduces dimensionality and gives invariance to small distortions.For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G. T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C. L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469, 1994.All input attributes are integers in the range 0..16.The last attribute is the class code 0..9"
Optical Interconnection Network ,Optical Interconnection Network ,This dataset contains 640 performance measurements from a simulation of 2-Dimensional Multiprocessor Optical Interconnection Network. ,Optical+Interconnection+Network+,https://archive.ics.uci.edu/ml//machine-learning-databases/00449/,https://archive.ics.uci.edu/ml/datasets/Optical+Interconnection+Network+," All simulations have done under the software named OPNET Modeler. Message passing is used as the communication mechanism in which any processor can submit to the network a point-to-point message destined at any other processor. M/M/1 queue is considered in the calculations which consist of a First-in First-Out buffer with packet arriving randomly according to a Poisson arrival process, and a processor, that retrieves packets from the buffer at a specified service rate. In all simulations, it is assumed that the processor at each node extracts a packet from an input queue, processes it for a period of time and when that period expires, it generates an output data message. The size of each input queue is assumed as infinite. A processor becomes idle only when all its input queues are empty.",Computer,"The summary of the attributes is given below. Please read the paper ([Web Link]) for detailed descriptions of the attributes. Node Number: The number of the nodes in the network. (8x8 or 4x4).Thread Number: The number of threads in each node at the beginning of the simulation.Spatial Distribution: The performance of the network is evaluated using synthetic traffic workloads. Uniform (UN), Hot Region (HR), Bit reverse (BR) and Perfect Shuffle (PS) traffic models have been included.Temporal Distribution: Temporal distribution of packet generation is implemented by independent traffic sources. In our simulations, we utilized clientÃ¢â‚¬â€œserver traffic (i.e., a server node sends packets to respond to the reception of packets from clients) and asynchronous traffic (i.e., initially, all nodes generate traffic independently of the others; as time progresses, traffic generation at the source/destination nodes dependson the receipt of messages from destination/source nodes).T/R: Message transfer time (T ) Uniformly distributed with mean in range from 20 to 100 clock cycles. Thread run time (R) Exponentially distributed with a mean of 100 clock cycles.Processor Utilization: The average processor utilization measures the percent of time that threads are running in the processor.Channel Waiting Time: Average waiting time of a packet at the output channel queue until it is serviced by the channel.Input Waiting Time: Average waiting time of a packet until it is serviced by the processor.Network Response Time: The time between a request message is enqueued at the output channel and the corresponding data message is received in the input queue.Channel Utilization: The percent of time that the channel is busy transferring packets to the network.","This dataset contains 640 performance measurements from a simulation of 2-Dimensional Multiprocessor Optical Interconnection Network.  All simulations have done under the software named OPNET Modeler. Message passing is used as the communication mechanism in which any processor can submit to the network a point-to-point message destined at any other processor. M/M/1 queue is considered in the calculations which consist of a First-in First-Out buffer with packet arriving randomly according to a Poisson arrival process, and a processor, that retrieves packets from the buffer at a specified service rate. In all simulations, it is assumed that the processor at each node extracts a packet from an input queue, processes it for a period of time and when that period expires, it generates an output data message. The size of each input queue is assumed as infinite. A processor becomes idle only when all its input queues are empty.The summary of the attributes is given below. Please read the paper ([Web Link]) for detailed descriptions of the attributes. Node Number: The number of the nodes in the network. (8x8 or 4x4).Thread Number: The number of threads in each node at the beginning of the simulation.Spatial Distribution: The performance of the network is evaluated using synthetic traffic workloads. Uniform (UN), Hot Region (HR), Bit reverse (BR) and Perfect Shuffle (PS) traffic models have been included.Temporal Distribution: Temporal distribution of packet generation is implemented by independent traffic sources. In our simulations, we utilized clientÃ¢â‚¬â€œserver traffic (i.e., a server node sends packets to respond to the reception of packets from clients) and asynchronous traffic (i.e., initially, all nodes generate traffic independently of the others; as time progresses, traffic generation at the source/destination nodes dependson the receipt of messages from destination/source nodes).T/R: Message transfer time (T ) Uniformly distributed with mean in range from 20 to 100 clock cycles. Thread run time (R) Exponentially distributed with a mean of 100 clock cycles.Processor Utilization: The average processor utilization measures the percent of time that threads are running in the processor.Channel Waiting Time: Average waiting time of a packet at the output channel queue until it is serviced by the channel.Input Waiting Time: Average waiting time of a packet until it is serviced by the processor.Network Response Time: The time between a request message is enqueued at the output channel and the corresponding data message is received in the input queue.Channel Utilization: The percent of time that the channel is busy transferring packets to the network."
OPPORTUNITY Activity Recognition,OPPORTUNITY Activity Recognition,"The OPPORTUNITY Dataset for Human Activity Recognition from Wearable, Object, and Ambient Sensors is a dataset devised to benchmark human activity recognition algorithms (classification, automatic data segmentation, sensor fusion, feature extraction, etc).",OPPORTUNITY+Activity+Recognition,https://archive.ics.uci.edu/ml//machine-learning-databases/00226/,https://archive.ics.uci.edu/ml/datasets/OPPORTUNITY+Activity+Recognition,"The OPPORTUNITY Dataset for Human Activity Recognition from Wearable, Object, and Ambient Sensors is a dataset devised to benchmark human activity recognition algorithms (classification, automatic data segmentation, sensor fusion, feature extraction, etc).A subset of this dataset was used for the ""OPPORTUNITY Activity Recognition Challenge"" organized for the 2011 IEEE conf on Systems, Man and Cybernetics Workshop on ""Robust machine learning techniques for human activity recognition"". The dataset comprises the readings of motion sensors recorded while users executed typical daily activities:  * Body-worn sensors: 7 inertial measurement units, 12 3D acceleration sensors, 4 3D localization information  * Object sensors: 12 objects with 3D acceleration and 2D rate of turn  * Ambient sensors: 13 switches and 8 3D acceleration sensors  * Recordings: 4 users, 6 runs per users. Of these, 5 are Activity of Daily Living runs characterized by a natural execution of daily activities. The 6th run is a ""drill"" run, where users execute a scripted sequence of activities.   * Annotations/classes: the activities of the user in the scenario are annotated on different levels: ""modes of locomotion"" classes; low-level actions relating 13 actions to 23 objects; 17 mid-level gesture classes; and 5 high-level activity classes** Recording scenario **The activity recognition environment and scenario has been designed to generate many activity primitives, yet in a realistic manner. Subjects operated in a room simulating a studio flat with a deckchair, a kitchen, doors giving access to the outside, a coffee machine, a table and a chair.We achieved a natural execution of activities by instructing users to follow a high-level script but leaving them free interpretation as how to achieve the high-level goals. We furthermore encouraged them to perform as naturally as possible with all the variations they were used to.For each subject we recorded 6 different runs. Five of them, termed activity of daily living (ADL), followed a given scenario as detailed below. The remaining one, a drill run, was designed to generate a large number of activity instances. The ADL run consists of temporally unfolding situations. In each situation (e.g. preparing sandwich), a large number of action primitives occur (e.g. reach for bread, move to bread cutter, operate bread cutter).* ADL run *The ADL run consists of temporally unfolding situations:    Start: lying on the deckchair, get up    Groom: move in the room, check that all the objects are in the right places in the drawers and on shelves    Relax: go outside and have a walk around the building    Prepare coffee: prepare a coffee with milk and sugar using the coffee machine    Drink coffee: take coffee sips, move around in the environment    Prepare sandwich: include bread, cheese and salami, using the bread cutter and various knifes and plates    Eat sandwich    Cleanup: put objects used to original place or dish washer, cleanup the table    Break: lie on the deckchair* Drill run *The drill run consists of 20 repetitions of the following sequence of activities:    Open then close the fridge    Open then close the dishwasher    Open then close 3 drawers (at different heights)    Open then close door 1    Open then close door 2    Toggle the lights on then off    Clean the table    Drink while standing    Drink while seated** Annotations **The annotations are done on five Ã‚â€˜tracksÃ‚â€™. One track contains modes of locomotion (e.g. sitting, standing, walking). Two other tracks indicate the actions of the left and right hand (e.g. reach, grasp, release), and to which object they apply (e.g. milk, switch, door).The fourth track indicates the high level activities (e.g. prepare sandwich). The high level activities relate to the situations indicated in the description of the ADL runs as follows (in parenthesis the number of the situations indicated above): relaxing (1, 9), early morning (2, 3), coffee time (4, 5), sandwich time (6, 7), cleanup (8).The mid-level gesture annotations is generated automatically from the low-level hand actions. It comprises coarser characterization of the user's activities. For instance the low-level annotations 'reach door' and 'open door' are combined into a single 'open door' mid-level annotation. Here, the mid-level annotations comprise actions of the left and right hand indiscriminately. However, in practice, the users mostly interacted with the environment with their right hand. We recommend to use the mid-level annotations in first attempts to use this dataset.** Applications **This dataset offers a rich playground to assess methods such as, e.g:  * Classification, (semi-) supervised machine learning  * Automatic segmentation  * Unsupervised structure discovery  * Data imputation  * Multi-modal sensor fusion  * Sensor network research  * Transfer learning, multitask learning  * Sensor selection  * Feature extraction  * Classifier calibration and adaptation  * ...** Baseline benchmarks **Baseline benchmarks for the OPPORTUNITY Activity Recognition Challenge subset of the dataset are available in reference [2]. Scripts to replicate the benchmarks are provided in the package.",Computer,"The dataset comprises the readings of motion sensors recorded while users executed typical daily activities. The detailed format is described in the package. The attributes correspond to raw sensor readings. There is a total of 242 attributes.* Body-worn sensors (145 attributes) *The body-worn sensors include 7 inertial measurement units and 12 3D acceleration sensors.The inertial measurement units provide readings of: 3D acceleration, 3D rate of turn, 3D magnetic field, and orientation of the sensor with respect to a world coordinate system in quaternions. Five sensors are on the upper body and two are mounted on the user's shoes.The acceleration sensors provide 3D acceleration. They are mounted on the upper body, hip and leg.Four tags for an ultra-wideband localization system are placed on the left/right front/back side of the shoulder.  * Object sensors (60 attributes) *12 objects are instrumented with wireless sensors measuring 3D acceleration and 2D rate of turn. This allows to detect which objects are used, and possibly also the kind of usage that is made of them.* Ambient sensors (37 attributes) *Ambient sensors include 13 switches and 8 3D acceleration sensors in drawers, kitchen appliances and doors.The reed switches are placed in triplets on the fridge, dishwasher and drawer 2 and drawer 3. They may be used to detect three states of the furniture element: closed, half open, and fully open. The acceleration sensors may allow to assess if an element of furniture is used, and whether it may be opened or closed.","The OPPORTUNITY Dataset for Human Activity Recognition from Wearable, Object, and Ambient Sensors is a dataset devised to benchmark human activity recognition algorithms (classification, automatic data segmentation, sensor fusion, feature extraction, etc).The OPPORTUNITY Dataset for Human Activity Recognition from Wearable, Object, and Ambient Sensors is a dataset devised to benchmark human activity recognition algorithms (classification, automatic data segmentation, sensor fusion, feature extraction, etc).A subset of this dataset was used for the ""OPPORTUNITY Activity Recognition Challenge"" organized for the 2011 IEEE conf on Systems, Man and Cybernetics Workshop on ""Robust machine learning techniques for human activity recognition"". The dataset comprises the readings of motion sensors recorded while users executed typical daily activities:  * Body-worn sensors: 7 inertial measurement units, 12 3D acceleration sensors, 4 3D localization information  * Object sensors: 12 objects with 3D acceleration and 2D rate of turn  * Ambient sensors: 13 switches and 8 3D acceleration sensors  * Recordings: 4 users, 6 runs per users. Of these, 5 are Activity of Daily Living runs characterized by a natural execution of daily activities. The 6th run is a ""drill"" run, where users execute a scripted sequence of activities.   * Annotations/classes: the activities of the user in the scenario are annotated on different levels: ""modes of locomotion"" classes; low-level actions relating 13 actions to 23 objects; 17 mid-level gesture classes; and 5 high-level activity classes** Recording scenario **The activity recognition environment and scenario has been designed to generate many activity primitives, yet in a realistic manner. Subjects operated in a room simulating a studio flat with a deckchair, a kitchen, doors giving access to the outside, a coffee machine, a table and a chair.We achieved a natural execution of activities by instructing users to follow a high-level script but leaving them free interpretation as how to achieve the high-level goals. We furthermore encouraged them to perform as naturally as possible with all the variations they were used to.For each subject we recorded 6 different runs. Five of them, termed activity of daily living (ADL), followed a given scenario as detailed below. The remaining one, a drill run, was designed to generate a large number of activity instances. The ADL run consists of temporally unfolding situations. In each situation (e.g. preparing sandwich), a large number of action primitives occur (e.g. reach for bread, move to bread cutter, operate bread cutter).* ADL run *The ADL run consists of temporally unfolding situations:    Start: lying on the deckchair, get up    Groom: move in the room, check that all the objects are in the right places in the drawers and on shelves    Relax: go outside and have a walk around the building    Prepare coffee: prepare a coffee with milk and sugar using the coffee machine    Drink coffee: take coffee sips, move around in the environment    Prepare sandwich: include bread, cheese and salami, using the bread cutter and various knifes and plates    Eat sandwich    Cleanup: put objects used to original place or dish washer, cleanup the table    Break: lie on the deckchair* Drill run *The drill run consists of 20 repetitions of the following sequence of activities:    Open then close the fridge    Open then close the dishwasher    Open then close 3 drawers (at different heights)    Open then close door 1    Open then close door 2    Toggle the lights on then off    Clean the table    Drink while standing    Drink while seated** Annotations **The annotations are done on five Ã‚â€˜tracksÃ‚â€™. One track contains modes of locomotion (e.g. sitting, standing, walking). Two other tracks indicate the actions of the left and right hand (e.g. reach, grasp, release), and to which object they apply (e.g. milk, switch, door).The fourth track indicates the high level activities (e.g. prepare sandwich). The high level activities relate to the situations indicated in the description of the ADL runs as follows (in parenthesis the number of the situations indicated above): relaxing (1, 9), early morning (2, 3), coffee time (4, 5), sandwich time (6, 7), cleanup (8).The mid-level gesture annotations is generated automatically from the low-level hand actions. It comprises coarser characterization of the user's activities. For instance the low-level annotations 'reach door' and 'open door' are combined into a single 'open door' mid-level annotation. Here, the mid-level annotations comprise actions of the left and right hand indiscriminately. However, in practice, the users mostly interacted with the environment with their right hand. We recommend to use the mid-level annotations in first attempts to use this dataset.** Applications **This dataset offers a rich playground to assess methods such as, e.g:  * Classification, (semi-) supervised machine learning  * Automatic segmentation  * Unsupervised structure discovery  * Data imputation  * Multi-modal sensor fusion  * Sensor network research  * Transfer learning, multitask learning  * Sensor selection  * Feature extraction  * Classifier calibration and adaptation  * ...** Baseline benchmarks **Baseline benchmarks for the OPPORTUNITY Activity Recognition Challenge subset of the dataset are available in reference [2]. Scripts to replicate the benchmarks are provided in the package.The dataset comprises the readings of motion sensors recorded while users executed typical daily activities. The detailed format is described in the package. The attributes correspond to raw sensor readings. There is a total of 242 attributes.* Body-worn sensors (145 attributes) *The body-worn sensors include 7 inertial measurement units and 12 3D acceleration sensors.The inertial measurement units provide readings of: 3D acceleration, 3D rate of turn, 3D magnetic field, and orientation of the sensor with respect to a world coordinate system in quaternions. Five sensors are on the upper body and two are mounted on the user's shoes.The acceleration sensors provide 3D acceleration. They are mounted on the upper body, hip and leg.Four tags for an ultra-wideband localization system are placed on the left/right front/back side of the shoulder.  * Object sensors (60 attributes) *12 objects are instrumented with wireless sensors measuring 3D acceleration and 2D rate of turn. This allows to detect which objects are used, and possibly also the kind of usage that is made of them.* Ambient sensors (37 attributes) *Ambient sensors include 13 switches and 8 3D acceleration sensors in drawers, kitchen appliances and doors.The reed switches are placed in triplets on the fridge, dishwasher and drawer 2 and drawer 3. They may be used to detect three states of the furniture element: closed, half open, and fully open. The acceleration sensors may allow to assess if an element of furniture is used, and whether it may be opened or closed."
OpinRank Review Dataset,OpinRank Review Dataset,"This data set contains user reviews of cars and and hotels collected from Tripadvisor (~259,000 
reviews) and Edmunds (~42,230 reviews).   ",OpinRank+Review+Dataset,https://archive.ics.uci.edu/ml//machine-learning-databases/00205/,https://archive.ics.uci.edu/ml/datasets/OpinRank+Review+Dataset,"Car Reviews-------------Full reviews of cars for model-years 2007, 2008, and 2009-There are about 140-250 cars for each model year-Extracted fields include dates, author names, favorites and the full textual review-Total number of reviews: ~42,230Hotel Reviews---------------Full reviews of hotels in 10 different cities (Dubai, Beijing, London, New York City, New Delhi, San Francisco, Shanghai, Montreal, Las Vegas, Chicago)-There are about 80-700 hotels in each city-Extracted fields include date, review title and the full review-Total number of reviews: ~259,000",Computer,,"This data set contains user reviews of cars and and hotels collected from Tripadvisor (~259,000 
reviews) and Edmunds (~42,230 reviews).   Car Reviews-------------Full reviews of cars for model-years 2007, 2008, and 2009-There are about 140-250 cars for each model year-Extracted fields include dates, author names, favorites and the full textual review-Total number of reviews: ~42,230Hotel Reviews---------------Full reviews of hotels in 10 different cities (Dubai, Beijing, London, New York City, New Delhi, San Francisco, Shanghai, Montreal, Las Vegas, Chicago)-There are about 80-700 hotels in each city-Extracted fields include date, review title and the full review-Total number of reviews: ~259,000nan"
Opinosis Opinion ⁄ Review,Opinosis Opinion ⁄ Review,This dataset contains sentences extracted from user reviews on a given topic. Example topics are â€œperformance of Toyota Camryâ€� and â€œsound quality of ipod nanoâ€�. ,Opinosis+Opinion+%26frasl%3B+Review,https://archive.ics.uci.edu/ml//machine-learning-databases/opinion/,https://archive.ics.uci.edu/ml/datasets/Opinosis+Opinion+%26frasl%3B+Review,"This dataset contains sentences extracted from user reviews on a given topic. Example topics are Ã¢â‚¬Å“performance of Toyota CamryÃ¢â‚¬Â� and Ã¢â‚¬Å“sound quality of ipod nanoÃ¢â‚¬Â�, etc. In total there are 51 such topics  with each topic having approximately 100 sentences (on the average). The reviews were obtained from various sources - Tripadvisor (hotels), Edmunds.com (cars) and Amazon.com (various electronics). The dataset file also comes with gold standard summaries used for the Opinosis summarization paper (see relevant papers). ",Computer,,"This dataset contains sentences extracted from user reviews on a given topic. Example topics are â€œperformance of Toyota Camryâ€� and â€œsound quality of ipod nanoâ€�. This dataset contains sentences extracted from user reviews on a given topic. Example topics are Ã¢â‚¬Å“performance of Toyota CamryÃ¢â‚¬Â� and Ã¢â‚¬Å“sound quality of ipod nanoÃ¢â‚¬Â�, etc. In total there are 51 such topics  with each topic having approximately 100 sentences (on the average). The reviews were obtained from various sources - Tripadvisor (hotels), Edmunds.com (cars) and Amazon.com (various electronics). The dataset file also comes with gold standard summaries used for the Opinosis summarization paper (see relevant papers). nan"
Opinion Corpus for Lebanese Arabic Reviews (OCLAR),Opinion Corpus for Lebanese Arabic Reviews (OCLAR),"Opinion Corpus for Lebanese Arabic Reviews (OCLAR) corpus is utilizable for Arabic sentiment classification on servicesâ€™ reviews, including hotels, restaurants, shops, and others.",Opinion+Corpus+for+Lebanese+Arabic+Reviews+%28OCLAR%29,https://archive.ics.uci.edu/ml//machine-learning-databases/00499/,https://archive.ics.uci.edu/ml/datasets/Opinion+Corpus+for+Lebanese+Arabic+Reviews+%28OCLAR%29,"The researchers of OCLAR Marwan et al. (2019), they gathered Arabic costumer reviews from ([Web Link]) and Zomato website ([Web Link]) on wide scope of domain, including restaurants, hotels, hospitals, local shops, etc. The corpus finally contains 3916 reviews in 5-rating scale. For this research purpose, the positive class considers rating stars from 5 to 3 of 3465 reviews, and the negative class is represented from values of 1 and 2 of about 451 texts.",Computer,1- 3916 text reviews2- 5-rating scale: 1: 303                   2: 148                   3: 418                   4: 734                   5: 2313Positive class includes rating stars from 5 to 3 of 3465 total.Negative class include rating stars from 1 to 2 of 451 total.,"Opinion Corpus for Lebanese Arabic Reviews (OCLAR) corpus is utilizable for Arabic sentiment classification on servicesâ€™ reviews, including hotels, restaurants, shops, and others.The researchers of OCLAR Marwan et al. (2019), they gathered Arabic costumer reviews from ([Web Link]) and Zomato website ([Web Link]) on wide scope of domain, including restaurants, hotels, hospitals, local shops, etc. The corpus finally contains 3916 reviews in 5-rating scale. For this research purpose, the positive class considers rating stars from 5 to 3 of 3465 reviews, and the negative class is represented from values of 1 and 2 of about 451 texts.1- 3916 text reviews2- 5-rating scale: 1: 303                   2: 148                   3: 418                   4: 734                   5: 2313Positive class includes rating stars from 5 to 3 of 3465 total.Negative class include rating stars from 1 to 2 of 451 total."
Perfume Data,Perfume Data,This data consists of odors of 20 different perfumes. Data was obtained by using a handheld odor meter (OMX-GR sensor) per second for 28 seconds period.,Perfume+Data,https://archive.ics.uci.edu/ml//machine-learning-databases/00303/,https://archive.ics.uci.edu/ml/datasets/Perfume+Data,The data set gathered when we were working at project for Bahrain university between 2002 and 2003.,Computer,"The data was obtained from 20 different perfumes by using a handheld odor meter(OMX-GR sensor). Names of these perfumes are: ajayeb, ajmal, amreaj, aood, asgar_ali, bukhoor, burberry, dehenalaod, junaid, kausar, rose, solidmusk, TeaTreeOil, raspberry, RoseMusk, strawberry, constrected2, carolina_herrera, oudh_ma'alattar, constrected1. Each column represent a measurement and there were 28 takes (one each second) ","This data consists of odors of 20 different perfumes. Data was obtained by using a handheld odor meter (OMX-GR sensor) per second for 28 seconds period.The data set gathered when we were working at project for Bahrain university between 2002 and 2003.The data was obtained from 20 different perfumes by using a handheld odor meter(OMX-GR sensor). Names of these perfumes are: ajayeb, ajmal, amreaj, aood, asgar_ali, bukhoor, burberry, dehenalaod, junaid, kausar, rose, solidmusk, TeaTreeOil, raspberry, RoseMusk, strawberry, constrected2, carolina_herrera, oudh_ma'alattar, constrected1. Each column represent a measurement and there were 28 takes (one each second) "
Turkish Headlines Dataset,Turkish Headlines Dataset,"Dataset consists of 7 news type labels. These labels are economy, politics, life, technology, magazine, health, sport. This dataset was created by me via Mynet, Milliyet, etc websites.",Turkish+Headlines+Dataset,https://archive.ics.uci.edu/ml//machine-learning-databases/00614/,https://archive.ics.uci.edu/ml/datasets/Turkish+Headlines+Dataset,"Dataset consists of 7 news type labels. These labels are economy, politics, life, technology, magazine, health, sport. This dataset was created by me via Mynet, Milliyet, etc websites.There are 600 headlines for each label in the dataset . Hence, total headlines count is 4200 for dataset.",Computer,"Attributes are economy, politics, life, technology, magazine, health, sport.","Dataset consists of 7 news type labels. These labels are economy, politics, life, technology, magazine, health, sport. This dataset was created by me via Mynet, Milliyet, etc websites.Dataset consists of 7 news type labels. These labels are economy, politics, life, technology, magazine, health, sport. This dataset was created by me via Mynet, Milliyet, etc websites.There are 600 headlines for each label in the dataset . Hence, total headlines count is 4200 for dataset.Attributes are economy, politics, life, technology, magazine, health, sport."
Person Classification Gait Data,Person Classification Gait Data,"Gait is considered a biometric criterion. Therefore, we tried to classify people with gait analysis with this gait data set.",Person+Classification+Gait+Data,https://archive.ics.uci.edu/ml//machine-learning-databases/00561/,https://archive.ics.uci.edu/ml/datasets/Person+Classification+Gait+Data,"This data set was created by calculating the walking parameters of a total of 16 different volunteers, 7 female and 9 male. The volunteers of 16 volunteers ranged between 20 and 34 years old, and their weight ranged from 53 to 95. In order to calculate each walking parameter, people were asked to walk the 30-meter long course for three rounds. The shared file contains X and Y data. X represents gait data and y represents person information for the relevant sample.",Computer,"Gait Data consists of the following parameters.Basic Parameters (Speed, Variability, Symmetry), Temporary Parameters (Heel Press Time, Cycle Time, Cadence, Posture, Oscillation, Loading, Foot Press, Thrust, Double Support), Spatial Parameters (Step Length, Step Speed, Peak Angle Speed, Maximum Swing Speed, Rotation Angle, Step Angle, Lift Angle, Swing Width, 3D Path Length), Height Parameters (Maximum Heel Height, Maximum Finger Tip Height, Minimum Finger Tip Height)","Gait is considered a biometric criterion. Therefore, we tried to classify people with gait analysis with this gait data set.This data set was created by calculating the walking parameters of a total of 16 different volunteers, 7 female and 9 male. The volunteers of 16 volunteers ranged between 20 and 34 years old, and their weight ranged from 53 to 95. In order to calculate each walking parameter, people were asked to walk the 30-meter long course for three rounds. The shared file contains X and Y data. X represents gait data and y represents person information for the relevant sample.Gait Data consists of the following parameters.Basic Parameters (Speed, Variability, Symmetry), Temporary Parameters (Heel Press Time, Cycle Time, Cadence, Posture, Oscillation, Loading, Foot Press, Thrust, Double Support), Spatial Parameters (Step Length, Step Speed, Peak Angle Speed, Maximum Swing Speed, Rotation Angle, Step Angle, Lift Angle, Swing Width, 3D Path Length), Height Parameters (Maximum Heel Height, Maximum Finger Tip Height, Minimum Finger Tip Height)"
Physical Unclonable Functions,Physical Unclonable Functions,"The dataset is generated from Physical Unclonable Functions (PUFs) simulation, specifically XOR Arbiter PUFs. PUFs are used for authentication purposes. For more info, refer to our paper below.",Physical+Unclonable+Functions,https://archive.ics.uci.edu/ml//machine-learning-databases/00463/,https://archive.ics.uci.edu/ml/datasets/Physical+Unclonable+Functions, ,Computer,There are two datasets generated from k-XOR Arbiter PUFs simulation:  (1) 5-XOR_128bit dataset:  This dataset is generated using 5-XOR arbiters of 128bit stages PUF. It consists of 6 million rows and 129 attributes where the last attribute is the class label (1 or -1). It is divided into two sets: training set (5 million) and testing set (1 million).  (1) 6-XOR_64bit dataset:  This dataset is generated using 6-XOR arbiters of 64bit stages PUF. It consists of 2.4 million rows and 65 attributes where the last attribute is the class label (1 or -1). It is divided into two sets: training set (2 million) and testing set (400K). ,"The dataset is generated from Physical Unclonable Functions (PUFs) simulation, specifically XOR Arbiter PUFs. PUFs are used for authentication purposes. For more info, refer to our paper below. There are two datasets generated from k-XOR Arbiter PUFs simulation:  (1) 5-XOR_128bit dataset:  This dataset is generated using 5-XOR arbiters of 128bit stages PUF. It consists of 6 million rows and 129 attributes where the last attribute is the class label (1 or -1). It is divided into two sets: training set (5 million) and testing set (1 million).  (1) 6-XOR_64bit dataset:  This dataset is generated using 6-XOR arbiters of 64bit stages PUF. It consists of 2.4 million rows and 65 attributes where the last attribute is the class label (1 or -1). It is divided into two sets: training set (2 million) and testing set (400K). "
Ultrasonic flowmeter diagnostics,Ultrasonic flowmeter diagnostics,Fault diagnosis of four liquid ultrasonic flowmeters,Ultrasonic+flowmeter+diagnostics,https://archive.ics.uci.edu/ml//machine-learning-databases/00433/,https://archive.ics.uci.edu/ml/datasets/Ultrasonic+flowmeter+diagnostics,Meter A contains 87 instances of diagnostic parameters for an 8-path liquid ultrasonic flow meter (USM). It has 37 attributes and 2 classes or health states:Class '1' - HealthyClass '2' - Installation effectsMeter B contains 92 instances of diagnostic parameters for a 4-path liquid USM. It has 52 attributes and 3 classes:Class '1' - HealthyClass '2' - Gas injectionClass '3' - WaxingMeter C contains 181 instances of diagnostic parameters for a 4-path liquid USM. It has 44 attributes and 4 classes:Class '1' - HealthyClass '2' - Gas injectionClass '3' - Installation effectsClass '4' - WaxingMeter D contains 180 instances of diagnostic parameters for a 4-path liquid USM. It has 44 attributes and 4 classes:Class '1' - HealthyClass '2' - Gas injectionClass '3' - Installation effectsClass '4' - Waxing,Computer,"All attributes are continuous, with the exception of the class attribute.Meter A(1)        -- Flatness ratio(2)        -- Symmetry(3)        -- Crossflow(4)-(11)   -- Flow velocity in each of the eight paths(12)-(19)  -- Speed of sound in each of the eight paths(20)       -- Average speed of sound in all eight paths(21)-(36)  -- Gain at both ends of each of the eight paths (37)       -- Class attribute or health state of meter: 1,2Meter B(1)       -- Profile factor(2)       -- Symmetry(3)       -- Crossflow(4)       -- Swirl angle(5)-(8)   -- Flow velocity in each of the four paths(9)       -- Average flow velocity in all four paths(10)-(13)  -- Speed of sound in each of the four paths(14)       -- Average speed of sound in all four paths(15)-(22)  -- Signal strength at both ends of each of the four paths (23)-(26)  -- Turbulence in each of the four paths(27)      -- Meter performance(28)-(35) -- Signal quality at both ends of each of the four paths(36)-(43) -- Gain at both ends of each of the four paths(44)-51   -- Transit time at both ends of each of the four paths(52)      -- Class attribute or health state of meter: 1,2,3Meters C and D(1)       -- Profile factor(2)       -- Symmetry(3)       -- Crossflow(4)-(7)   -- Flow velocity in each of the four paths(8)-(11)  -- Speed of sound in each of the four paths(12)-(19) -- Signal strength at both ends of each of the four paths (20)-(27) -- Signal quality at both ends of each of the four paths(28)-(35) -- Gain at both ends of each of the four paths(36)-(43) -- Transit time at both ends of each of the four paths(44)      -- Class attribute or health state of meter: 1,2,3,4    ","Fault diagnosis of four liquid ultrasonic flowmetersMeter A contains 87 instances of diagnostic parameters for an 8-path liquid ultrasonic flow meter (USM). It has 37 attributes and 2 classes or health states:Class '1' - HealthyClass '2' - Installation effectsMeter B contains 92 instances of diagnostic parameters for a 4-path liquid USM. It has 52 attributes and 3 classes:Class '1' - HealthyClass '2' - Gas injectionClass '3' - WaxingMeter C contains 181 instances of diagnostic parameters for a 4-path liquid USM. It has 44 attributes and 4 classes:Class '1' - HealthyClass '2' - Gas injectionClass '3' - Installation effectsClass '4' - WaxingMeter D contains 180 instances of diagnostic parameters for a 4-path liquid USM. It has 44 attributes and 4 classes:Class '1' - HealthyClass '2' - Gas injectionClass '3' - Installation effectsClass '4' - WaxingAll attributes are continuous, with the exception of the class attribute.Meter A(1)        -- Flatness ratio(2)        -- Symmetry(3)        -- Crossflow(4)-(11)   -- Flow velocity in each of the eight paths(12)-(19)  -- Speed of sound in each of the eight paths(20)       -- Average speed of sound in all eight paths(21)-(36)  -- Gain at both ends of each of the eight paths (37)       -- Class attribute or health state of meter: 1,2Meter B(1)       -- Profile factor(2)       -- Symmetry(3)       -- Crossflow(4)       -- Swirl angle(5)-(8)   -- Flow velocity in each of the four paths(9)       -- Average flow velocity in all four paths(10)-(13)  -- Speed of sound in each of the four paths(14)       -- Average speed of sound in all four paths(15)-(22)  -- Signal strength at both ends of each of the four paths (23)-(26)  -- Turbulence in each of the four paths(27)      -- Meter performance(28)-(35) -- Signal quality at both ends of each of the four paths(36)-(43) -- Gain at both ends of each of the four paths(44)-51   -- Transit time at both ends of each of the four paths(52)      -- Class attribute or health state of meter: 1,2,3Meters C and D(1)       -- Profile factor(2)       -- Symmetry(3)       -- Crossflow(4)-(7)   -- Flow velocity in each of the four paths(8)-(11)  -- Speed of sound in each of the four paths(12)-(19) -- Signal strength at both ends of each of the four paths (20)-(27) -- Signal quality at both ends of each of the four paths(28)-(35) -- Gain at both ends of each of the four paths(36)-(43) -- Transit time at both ends of each of the four paths(44)      -- Class attribute or health state of meter: 1,2,3,4    "
Restaurant &amp; consumer data,Restaurant &amp; consumer data,The dataset was obtained from a recommender system prototype. The task was to generate a top-n list of restaurants according to the consumer preferences. ,Restaurant+%26+consumer+data,https://archive.ics.uci.edu/ml//machine-learning-databases/00232/,https://archive.ics.uci.edu/ml/datasets/Restaurant+%26+consumer+data,"Two approaches were tested: a collaborative filter technique and a contextual approach.   (i) The collaborative filter technique used only one file i.e., rating_final.csv that comprises the user, item and rating attributes.     (ii) The contextual approach generated the recommendations using the remaining eight data files.",Computer,"Files, instances and attributesNumber of Files: 9Restaurants1 chefmozaccepts.csv2 chefmozcuisine.csv3 chefmozhours4.csv4 chefmozparking.csv5 geoplaces2.csvConsumers6 usercuisine.csv7 userpayment.csv8 userprofile.csvUser-Item-Rating9 rating_final.csv%--- Description formatFile nameNumber of instancesNumber of attributesattribute: Type, Number of missing values (if any), Number of values [list of values]%--- 1 chefmozaccepts.csvInstances: 1314Attributes: 2placeID: NominalRpayment: Nominal, 12 [cash,VISA,MasterCard-Eurocard,American_Express,bank_debit_cards,checks,Discover,Carte_Blanche,Diners_Club,Visa,Japan_Credit_Bureau,gift_certificates]2 chefmozcuisine.csvInstances: 916Attributes: 2placeID: NominalRcuisine: Nominal, 59 [Afghan,African,American,Armenian,Asian,Bagels,Bakery,Bar,Bar_Pub_Brewery,Barbecue,Brazilian,Breakfast-Brunch,Burgers,Cafe-Coffee_Shop,			Cafeteria,California,Caribbean,Chinese,Contemporary,Continental-European,Deli-Sandwiches,Dessert-Ice_Cream,Diner,Dutch-Belgian,Eastern_European,Ethiopian,Family,Fast_Food,Fine_Dining,French,,Game,German,Greek,Hot_Dogs,			International,Italian,Japanese,Juice,Korean,Latin_American,Mediterranean,Mexican,Mongolian,Organic-Healthy,Persian,			Pizzeria,Polish,Regional,Seafood,Soup,Southern,Southwestern,Spanish,Steaks,Sushi,Thai,Turkish,Vegetarian,Vietnamese]3 chefmozhours4.csvInstances: 2339Attributes: 3placeID: Nominalhours: Nominal, Range:00:00-23:30days:Nominal, 7 [Mon;Tue;Wed;Thu;Fri;Sat;Sun]4 chefmozparking.csvInstances: 702Attributes: 2placeID: Nominalparking_lot:Nominal, 7[public,none,yes,valet_parking,free,street,validated_parking]5 geoplaces2.csvInstances: 130Attributes: 21placeID: Nominallatitude: Numericlongitude: Numericthe_geom_meter: Nominal (Geospatial)name: Nominaladdress: Nominal,Missing: 27city: Nominal, Missing: 18state: Nominal, Missing: 18country: Nominal, Missing: 28fax: Numeric, Missing: 130zip: Nominal,Missing: 74alcohol: Nominal, Values: 3 [No_Alcohol_Served,Wine_Beer,Full_Bar]smoking_area: Nominal, 5 [none,only_at_bar,permitted,section,not_permitted]dress_code:	Nominal, 3 [informal,casual,formal]accessibility: Nominal, 3 [no_accessibility,completely,partially]price: Nominal, 3 [medium,low,high]url: Nominal, Missing: 116Rambience: Nominal, 2 [familiar,quiet]franchise: Nominal, 2 [t,f]area: Nominal, 2 [open,closed]other_services:	Nominal, 3 [none,internet,variety]6 rating_final.csvInstances: 1161Attributes: 5userID: NominalplaceID: Nominalrating: Numeric, 3 [0,1,2]food_rating: Numeric, 3 [0,1,2]service_rating:	Numeric, 3 [0,1,2]7 usercuisine.csvInstances: 330Attributes: 2userID: NominalRcuisine: Nominal, 103 [Afghan,African,American,Armenian,Asian,Australian,Austrian,Bagels,Bakery,Bar,Bar_Pub_Brewery,Barbecue,Basque,Brazilian,Breakfast-Brunch,British,Burgers,Burmese,Cafe-Coffee_Shop,Cafeteria,Cajun-Creole,California,Cambodian,Canadian,Caribbean,Chilean,Chinese,Contemporary,Continental-European,Cuban,Deli-Sandwiches,Dessert-Ice_Cream,Dim_Sum,Diner,Doughnuts,Dutch-Belgian,Eastern_European,Eclectic,Ethiopian,Family,Fast_Food,Filipino,Fine_Dining,French,Fusion,Game,German,Greek,Hawaiian,Hot_Dogs,Hungarian,Indian-Pakistani,Indigenous,Indonesian,International,Irish,Israeli,Italian,Jamaican,Japanese,Juice,Korean,Kosher,Latin_American,Lebanese,Malaysian,Mediterranean,Mexican,Middle_Eastern,Mongolian,Moroccan,North_African,Organic-Healthy,Pacific_Northwest,Pacific_Rim,Persian,Peruvian,Pizzeria,Polish,Polynesian,Portuguese,Regional,Romanian,Russian-Ukrainian,Scandinavian,Seafood,Soup,Southeast_Asian,Southern,Southwestern,Spanish,Steaks,Sushi,Swiss,Tapas,Tea_House,Tex-Mex,Thai,Tibetan,Tunisian,Turkish,Vegetarian,Vietnamese]8 userpayment.csvInstances: 177Attributes: 2userID: NominalUpayment: Nominal, 5 [cash,bank_debit_cards,MasterCard-Eurocard,VISA,American_Express]9 userprofileInstances: 138Attributes: 19userID: Nominallatitude: Numericlongitude: Numericthe_geom_meter: Nominal (Geospatial)smoker: Nominal, Missing: 3, 2 [false,true]drink_level: Nominal, 3 [abstemious,social drinker,casual drinker]dress_preference:Nominal, Missing: 5, 4 [informal,formal,no preference,elegant]ambience: Nominal, Missing: 6, 3 [family,friends,solitary]transport: Nominal, Missing: 7, 3 [on foot,public,car owner]marital_status:	Nominal, Missing: 4, 3 [single,married,widow]hijos: Nominal, Missing: 11, 3 [independent,kids,dependent]birth_year:	Nominalinterest: Nominal, 5 [variety,technology,none,retro,eco-friendly]personality: Nominal, 4 [thrifty-protector,hunter-ostentatious,hard-worker,conformist]religion: Nominal, 5 [none,Catholic,Christian,Mormon,Jewish]activity: Nominal, Missing: 7, 4 [student,professional,unemployed,working-class]color: Nominal, 8 [black,red,blue,green,purple,orange,yellow,white]weight: Numericbudget: Nominal, Missing: 7, 3 [medium,low,high]height: Numeric","The dataset was obtained from a recommender system prototype. The task was to generate a top-n list of restaurants according to the consumer preferences. Two approaches were tested: a collaborative filter technique and a contextual approach.   (i) The collaborative filter technique used only one file i.e., rating_final.csv that comprises the user, item and rating attributes.     (ii) The contextual approach generated the recommendations using the remaining eight data files.Files, instances and attributesNumber of Files: 9Restaurants1 chefmozaccepts.csv2 chefmozcuisine.csv3 chefmozhours4.csv4 chefmozparking.csv5 geoplaces2.csvConsumers6 usercuisine.csv7 userpayment.csv8 userprofile.csvUser-Item-Rating9 rating_final.csv%--- Description formatFile nameNumber of instancesNumber of attributesattribute: Type, Number of missing values (if any), Number of values [list of values]%--- 1 chefmozaccepts.csvInstances: 1314Attributes: 2placeID: NominalRpayment: Nominal, 12 [cash,VISA,MasterCard-Eurocard,American_Express,bank_debit_cards,checks,Discover,Carte_Blanche,Diners_Club,Visa,Japan_Credit_Bureau,gift_certificates]2 chefmozcuisine.csvInstances: 916Attributes: 2placeID: NominalRcuisine: Nominal, 59 [Afghan,African,American,Armenian,Asian,Bagels,Bakery,Bar,Bar_Pub_Brewery,Barbecue,Brazilian,Breakfast-Brunch,Burgers,Cafe-Coffee_Shop,			Cafeteria,California,Caribbean,Chinese,Contemporary,Continental-European,Deli-Sandwiches,Dessert-Ice_Cream,Diner,Dutch-Belgian,Eastern_European,Ethiopian,Family,Fast_Food,Fine_Dining,French,,Game,German,Greek,Hot_Dogs,			International,Italian,Japanese,Juice,Korean,Latin_American,Mediterranean,Mexican,Mongolian,Organic-Healthy,Persian,			Pizzeria,Polish,Regional,Seafood,Soup,Southern,Southwestern,Spanish,Steaks,Sushi,Thai,Turkish,Vegetarian,Vietnamese]3 chefmozhours4.csvInstances: 2339Attributes: 3placeID: Nominalhours: Nominal, Range:00:00-23:30days:Nominal, 7 [Mon;Tue;Wed;Thu;Fri;Sat;Sun]4 chefmozparking.csvInstances: 702Attributes: 2placeID: Nominalparking_lot:Nominal, 7[public,none,yes,valet_parking,free,street,validated_parking]5 geoplaces2.csvInstances: 130Attributes: 21placeID: Nominallatitude: Numericlongitude: Numericthe_geom_meter: Nominal (Geospatial)name: Nominaladdress: Nominal,Missing: 27city: Nominal, Missing: 18state: Nominal, Missing: 18country: Nominal, Missing: 28fax: Numeric, Missing: 130zip: Nominal,Missing: 74alcohol: Nominal, Values: 3 [No_Alcohol_Served,Wine_Beer,Full_Bar]smoking_area: Nominal, 5 [none,only_at_bar,permitted,section,not_permitted]dress_code:	Nominal, 3 [informal,casual,formal]accessibility: Nominal, 3 [no_accessibility,completely,partially]price: Nominal, 3 [medium,low,high]url: Nominal, Missing: 116Rambience: Nominal, 2 [familiar,quiet]franchise: Nominal, 2 [t,f]area: Nominal, 2 [open,closed]other_services:	Nominal, 3 [none,internet,variety]6 rating_final.csvInstances: 1161Attributes: 5userID: NominalplaceID: Nominalrating: Numeric, 3 [0,1,2]food_rating: Numeric, 3 [0,1,2]service_rating:	Numeric, 3 [0,1,2]7 usercuisine.csvInstances: 330Attributes: 2userID: NominalRcuisine: Nominal, 103 [Afghan,African,American,Armenian,Asian,Australian,Austrian,Bagels,Bakery,Bar,Bar_Pub_Brewery,Barbecue,Basque,Brazilian,Breakfast-Brunch,British,Burgers,Burmese,Cafe-Coffee_Shop,Cafeteria,Cajun-Creole,California,Cambodian,Canadian,Caribbean,Chilean,Chinese,Contemporary,Continental-European,Cuban,Deli-Sandwiches,Dessert-Ice_Cream,Dim_Sum,Diner,Doughnuts,Dutch-Belgian,Eastern_European,Eclectic,Ethiopian,Family,Fast_Food,Filipino,Fine_Dining,French,Fusion,Game,German,Greek,Hawaiian,Hot_Dogs,Hungarian,Indian-Pakistani,Indigenous,Indonesian,International,Irish,Israeli,Italian,Jamaican,Japanese,Juice,Korean,Kosher,Latin_American,Lebanese,Malaysian,Mediterranean,Mexican,Middle_Eastern,Mongolian,Moroccan,North_African,Organic-Healthy,Pacific_Northwest,Pacific_Rim,Persian,Peruvian,Pizzeria,Polish,Polynesian,Portuguese,Regional,Romanian,Russian-Ukrainian,Scandinavian,Seafood,Soup,Southeast_Asian,Southern,Southwestern,Spanish,Steaks,Sushi,Swiss,Tapas,Tea_House,Tex-Mex,Thai,Tibetan,Tunisian,Turkish,Vegetarian,Vietnamese]8 userpayment.csvInstances: 177Attributes: 2userID: NominalUpayment: Nominal, 5 [cash,bank_debit_cards,MasterCard-Eurocard,VISA,American_Express]9 userprofileInstances: 138Attributes: 19userID: Nominallatitude: Numericlongitude: Numericthe_geom_meter: Nominal (Geospatial)smoker: Nominal, Missing: 3, 2 [false,true]drink_level: Nominal, 3 [abstemious,social drinker,casual drinker]dress_preference:Nominal, Missing: 5, 4 [informal,formal,no preference,elegant]ambience: Nominal, Missing: 6, 3 [family,friends,solitary]transport: Nominal, Missing: 7, 3 [on foot,public,car owner]marital_status:	Nominal, Missing: 4, 3 [single,married,widow]hijos: Nominal, Missing: 11, 3 [independent,kids,dependent]birth_year:	Nominalinterest: Nominal, 5 [variety,technology,none,retro,eco-friendly]personality: Nominal, 4 [thrifty-protector,hunter-ostentatious,hard-worker,conformist]religion: Nominal, 5 [none,Catholic,Christian,Mormon,Jewish]activity: Nominal, Missing: 7, 4 [student,professional,unemployed,working-class]color: Nominal, 8 [black,red,blue,green,purple,orange,yellow,white]weight: Numericbudget: Nominal, Missing: 7, 3 [medium,low,high]height: Numeric"
Residential Building Data Set,Residential Building Data Set,"Data set includes construction cost, sale prices, project variables, and economic variables corresponding to real estate single-family residential apartments in Tehran, Iran. ",Residential+Building+Data+Set,https://archive.ics.uci.edu/ml//machine-learning-databases/00437/,https://archive.ics.uci.edu/ml/datasets/Residential+Building+Data+Set,See the tab 'Descriptions' in the Excel file.,Computer,"Totally 105: 8 project physical and financial variables, 19 economic variables and indices in 5 time lag numbers (5*19 = 95), and two output variables that are construction costs and sale prices","Data set includes construction cost, sale prices, project variables, and economic variables corresponding to real estate single-family residential apartments in Tehran, Iran. See the tab 'Descriptions' in the Excel file.Totally 105: 8 project physical and financial variables, 19 economic variables and indices in 5 time lag numbers (5*19 = 95), and two output variables that are construction costs and sale prices"
Repeat Consumption Matrices,Repeat Consumption Matrices,"The dataset contains 7 datasets of User - Item matrices, where each entry represents how many times a user consumed an item. Item is used as an umbrella term for various categories.",Repeat+Consumption+Matrices,https://archive.ics.uci.edu/ml//machine-learning-databases/00441/,https://archive.ics.uci.edu/ml/datasets/Repeat+Consumption+Matrices,"There are 7 datasets from Reddit, Twitter, Gowalla and Lastfm.Each matrix contains how many times a user 'consumed' and item. Items can be locations, artists, or subreddits. Details about each dataset are presented below. (In the parenthesis is the number of Users x Items)tw_oc (13k x 11k): tweets with geolocation from Orange County CA area. Items are locations a user visits in this case.tw_ny (30k x 11k): Same as tw_oc but from the New York area.go_sf (2k x 7k): Check-ins from the app Gowalla, from the San Fransisco area. Full dataset here: [Web Link]go_ny (1k x 7k): Same as go_sf, but from the New York area.lastfm (992 x 15k): How many times, a user listened to each artist. Covers 3 years of listening habbits, full dataset here: [Web Link]Ã¢Ë†Â¼ocelma/[Web Link]reddit_top (113k x 21k): How many times a user posted in a subreddit. These are the 130k most active users from 2015 and 20k most subscribed subreddits. This dataset is very large and can take a lot of time to load/use.reddit_sample (20k x 21k): Same as reddit_top, but a sample of 20k users.",Computer,"The attributes represent items (categories) that uses tend to select multiple times. These can be music artists, subreddits or locations on the map.","The dataset contains 7 datasets of User - Item matrices, where each entry represents how many times a user consumed an item. Item is used as an umbrella term for various categories.There are 7 datasets from Reddit, Twitter, Gowalla and Lastfm.Each matrix contains how many times a user 'consumed' and item. Items can be locations, artists, or subreddits. Details about each dataset are presented below. (In the parenthesis is the number of Users x Items)tw_oc (13k x 11k): tweets with geolocation from Orange County CA area. Items are locations a user visits in this case.tw_ny (30k x 11k): Same as tw_oc but from the New York area.go_sf (2k x 7k): Check-ins from the app Gowalla, from the San Fransisco area. Full dataset here: [Web Link]go_ny (1k x 7k): Same as go_sf, but from the New York area.lastfm (992 x 15k): How many times, a user listened to each artist. Covers 3 years of listening habbits, full dataset here: [Web Link]Ã¢Ë†Â¼ocelma/[Web Link]reddit_top (113k x 21k): How many times a user posted in a subreddit. These are the 130k most active users from 2015 and 20k most subscribed subreddits. This dataset is very large and can take a lot of time to load/use.reddit_sample (20k x 21k): Same as reddit_top, but a sample of 20k users.The attributes represent items (categories) that uses tend to select multiple times. These can be music artists, subreddits or locations on the map."
Relative location of CT slices on axial axis,Relative location of CT slices on axial axis,The dataset consists of 384 features extracted from CT images. The class variable is numeric and denotes the relative location of the CT slice on the axial axis of the human body.,Relative+location+of+CT+slices+on+axial+axis,https://archive.ics.uci.edu/ml//machine-learning-databases/00206/,https://archive.ics.uci.edu/ml/datasets/Relative+location+of+CT+slices+on+axial+axis,"The data was retrieved from a set of 53500 CT images from 74 differentpatients (43 male, 31 female).Each CT slice is described by two histograms in polar space.The first histogram describes the location of bone structures in the image,the second the location of air inclusions inside of the body.Both histograms are concatenated to form the final feature vector.Bins that are outside of the image are marked with the value -0.25.The class variable (relative location of an image on the axial axis) wasconstructed by manually annotating up to 10 different distinct landmarks ineach CT Volume with known location. The location of slices in betweenlandmarks was interpolated.",Computer,1. patientId:      Each ID identifies a different patient2. - 241.:         Histogram describing bone structures242. - 385.:       Histogram describing air inclusions386. reference:    Relative location of the image on the axial axis (class	      value). Values are in the range [0; 180] where 0 denotes	      the top of the head and 180 the soles of the feet.,"The dataset consists of 384 features extracted from CT images. The class variable is numeric and denotes the relative location of the CT slice on the axial axis of the human body.The data was retrieved from a set of 53500 CT images from 74 differentpatients (43 male, 31 female).Each CT slice is described by two histograms in polar space.The first histogram describes the location of bone structures in the image,the second the location of air inclusions inside of the body.Both histograms are concatenated to form the final feature vector.Bins that are outside of the image are marked with the value -0.25.The class variable (relative location of an image on the axial axis) wasconstructed by manually annotating up to 10 different distinct landmarks ineach CT Volume with known location. The location of slices in betweenlandmarks was interpolated.1. patientId:      Each ID identifies a different patient2. - 241.:         Histogram describing bone structures242. - 385.:       Histogram describing air inclusions386. reference:    Relative location of the image on the axial axis (class	      value). Values are in the range [0; 180] where 0 denotes	      the top of the head and 180 the soles of the feet."
REJAFADA ,REJAFADA ,"REJAFADA (Retrieval of Jar Files Applied to Dynamic Analysis) aims to be used, as benchmark, to check the quality of  the detection of Jar malware.",REJAFADA+,https://archive.ics.uci.edu/ml//machine-learning-databases/00635/,https://archive.ics.uci.edu/ml/datasets/REJAFADA+,"The REJAFADA (Retrieval of Jar Files Applied to Dynamic Analysis) is a dataset which allows the classification of files with Jar extension between benign and malwares. The REJAFADA is composed of 998 malware Jar files and 998 other benign Jar files. The REJAFADA dataset, consequently, is suitable for learning endowed with AI (Artificial Intelligence), considering that the Jar files presented the same amount in the different classes (malware and benign). The goal is that tendentious classifiers, in relation to a certain class, do not have their success taxes favored.In relation to virtual plagues, REJAFADA extracted malicious Jar files from VirusShare which is a repository of malware samples to provide security researchers, incident responders, forensic analysts, and the morbidly curious access to samples of live malicious code. With respect to benign Jar files, the catalog was given from application repositories such as Java2s.com, and findar.com. All of the benign files have been audited by VirusTotal. Then, the benign Jar files, contained in REJAFADA, had their benevolence attested by the main commercial antiviruses of the world. The obtained results corresponding to the analyses of the benign and malware Jar files, resulting from the VirusTotal audit, are available for consultation at the virtual address of REJAFADA Ã‚Â¹.The features of Jar files originate through the dynamic analysis of suspicious files. Therefore, in our methodology, the malware is executed in order to infect, intentionally, the Java Virtual Machine installed in Windows 7 audited, in real time (dynamic), by the Cuckoo Sandbox.1.	REJAFADA (A  Retrieval of Jar Files Applied to Dynamic Analysis). Available in: [Web Link]. Accessed on  June  2018.",Computer,"1) Application name2) Class (M = malware, B = benign)3) Input Attribute (3-6826).Next, the groups of features are detailedÃ¢â‚¬Â¢	Features related to virtual machines. Ã¢â‚¬Â¢	Features related to malware. Ã¢â‚¬Â¢	Features related to Backdoors.Ã¢â‚¬Â¢	Features related to the banking threats (Trojan horses).Ã¢â‚¬Â¢	Features related to Bitcoin.Ã¢â‚¬Â¢	Features related to bots (machines that perform automatic network tasks, malicious or not, without the knowledge of their owners).Ã¢â‚¬Â¢	Features related to browsers. Ã¢â‚¬Â¢	Features related to Firewall. Ã¢â‚¬Â¢	Features related to cloud computing. Ã¢â‚¬Â¢	Features related to DDoS (Dynamic Danial of Service) attacks. Ã¢â‚¬Â¢	Features that seek to disable features of Windows 7 OS and other utilities. Ã¢â‚¬Â¢	Features associated with network traffic hint windows 7 OS in PCAP format. Ã¢â‚¬Â¢	Features related to DNS servers (Domain Name System, servers responsible for the translation of URL addresses in IP). Ã¢â‚¬Â¢	Features related to native Windows 7 OS programs. Ã¢â‚¬Â¢	Features related to Windows 7 Boot OS. Ã¢â‚¬Â¢	Features related to Windows 7 OS (Regedit).Ã¢â‚¬Â¢	Features related to the use of sandboxes. The digital forensics examines whether the file tried tries to detect whether sandboxes: Cuckoo, Joe, Anubis, Sunbelt, ThreatTrack / GFI / CW or Fortinet are being used, through the presence of their own files.Ã¢â‚¬Â¢	Features related to antivirus. Checks if the file being investigated tries to check for registry keys, in regedit, for Chinese antivirus.Ã¢â‚¬Â¢	Features related to Ransomware (type of malware that by means of encryption, leaves the victim's files unusable, then request a redemption in exchange for the normal use later of the user's files, a redemption usually paid in a non-traceable way, such as bitcoins).Ã¢â‚¬Â¢	Features related to exploit-related features which constitute malware attempting to exploit known or unackaged vulnerabilities, faults or defects in the system or one or more of its components in order to cause unforeseen instabilities and behavior on both your hardware and in your software. Ã¢â‚¬Â¢	Features related to Infostealers, malicious programs that collect confidential information from the affected computer. ","REJAFADA (Retrieval of Jar Files Applied to Dynamic Analysis) aims to be used, as benchmark, to check the quality of  the detection of Jar malware.The REJAFADA (Retrieval of Jar Files Applied to Dynamic Analysis) is a dataset which allows the classification of files with Jar extension between benign and malwares. The REJAFADA is composed of 998 malware Jar files and 998 other benign Jar files. The REJAFADA dataset, consequently, is suitable for learning endowed with AI (Artificial Intelligence), considering that the Jar files presented the same amount in the different classes (malware and benign). The goal is that tendentious classifiers, in relation to a certain class, do not have their success taxes favored.In relation to virtual plagues, REJAFADA extracted malicious Jar files from VirusShare which is a repository of malware samples to provide security researchers, incident responders, forensic analysts, and the morbidly curious access to samples of live malicious code. With respect to benign Jar files, the catalog was given from application repositories such as Java2s.com, and findar.com. All of the benign files have been audited by VirusTotal. Then, the benign Jar files, contained in REJAFADA, had their benevolence attested by the main commercial antiviruses of the world. The obtained results corresponding to the analyses of the benign and malware Jar files, resulting from the VirusTotal audit, are available for consultation at the virtual address of REJAFADA Ã‚Â¹.The features of Jar files originate through the dynamic analysis of suspicious files. Therefore, in our methodology, the malware is executed in order to infect, intentionally, the Java Virtual Machine installed in Windows 7 audited, in real time (dynamic), by the Cuckoo Sandbox.1.	REJAFADA (A  Retrieval of Jar Files Applied to Dynamic Analysis). Available in: [Web Link]. Accessed on  June  2018.1) Application name2) Class (M = malware, B = benign)3) Input Attribute (3-6826).Next, the groups of features are detailedÃ¢â‚¬Â¢	Features related to virtual machines. Ã¢â‚¬Â¢	Features related to malware. Ã¢â‚¬Â¢	Features related to Backdoors.Ã¢â‚¬Â¢	Features related to the banking threats (Trojan horses).Ã¢â‚¬Â¢	Features related to Bitcoin.Ã¢â‚¬Â¢	Features related to bots (machines that perform automatic network tasks, malicious or not, without the knowledge of their owners).Ã¢â‚¬Â¢	Features related to browsers. Ã¢â‚¬Â¢	Features related to Firewall. Ã¢â‚¬Â¢	Features related to cloud computing. Ã¢â‚¬Â¢	Features related to DDoS (Dynamic Danial of Service) attacks. Ã¢â‚¬Â¢	Features that seek to disable features of Windows 7 OS and other utilities. Ã¢â‚¬Â¢	Features associated with network traffic hint windows 7 OS in PCAP format. Ã¢â‚¬Â¢	Features related to DNS servers (Domain Name System, servers responsible for the translation of URL addresses in IP). Ã¢â‚¬Â¢	Features related to native Windows 7 OS programs. Ã¢â‚¬Â¢	Features related to Windows 7 Boot OS. Ã¢â‚¬Â¢	Features related to Windows 7 OS (Regedit).Ã¢â‚¬Â¢	Features related to the use of sandboxes. The digital forensics examines whether the file tried tries to detect whether sandboxes: Cuckoo, Joe, Anubis, Sunbelt, ThreatTrack / GFI / CW or Fortinet are being used, through the presence of their own files.Ã¢â‚¬Â¢	Features related to antivirus. Checks if the file being investigated tries to check for registry keys, in regedit, for Chinese antivirus.Ã¢â‚¬Â¢	Features related to Ransomware (type of malware that by means of encryption, leaves the victim's files unusable, then request a redemption in exchange for the normal use later of the user's files, a redemption usually paid in a non-traceable way, such as bitcoins).Ã¢â‚¬Â¢	Features related to exploit-related features which constitute malware attempting to exploit known or unackaged vulnerabilities, faults or defects in the system or one or more of its components in order to cause unforeseen instabilities and behavior on both your hardware and in your software. Ã¢â‚¬Â¢	Features related to Infostealers, malicious programs that collect confidential information from the affected computer. "
REALDISP Activity Recognition Dataset,REALDISP Activity Recognition Dataset,The REALDISP dataset is devised to evaluate techniques dealing with the effects of sensor displacement in wearable activity recognition as well as to benchmark general activity recognition algorithms ,REALDISP+Activity+Recognition+Dataset,https://archive.ics.uci.edu/ml//machine-learning-databases/00305/,https://archive.ics.uci.edu/ml/datasets/REALDISP+Activity+Recognition+Dataset,"The REALDISP (REAListic sensor DISPlacement) dataset has been originally collected to investigate the effects of sensor displacement in the activity recognition process in real-world settings. It builds on the concept of ideal-placement, self-placement and induced-displacement. The ideal and mutual-displacement conditions represent extreme displacement variants and thus could represent boundary conditions for recognition algorithms. In contrast, self-placement reflects a users perception of how sensors could be attached, e.g., in a sports or lifestyle application. The dataset includes a wide range of physical activities (warm up, cool down and fitness exercises), sensor modalities (acceleration, rate of turn, magnetic field and quaternions) and participants (17 subjects). Apart from investigating sensor displacement, the dataset lend itself for benchmarking activity recognition techniques in ideal conditions.----------------------------------------------------------------------------------------------------------------------Dataset summary:#Activities: 33 #Sensors: 9#Subjects: 17#Scenarios: 3----------------------------------------------------------------------------------------------------------------------ACTIVITY SET:A1: Walking  A2: Jogging  A3: Running  A4: Jump up  A5: Jump front & back  A6: Jump sideways  A7: Jump leg/arms open/closed  A8: Jump rope  A9: Trunk twist (arms outstretched)  A10: Trunk twist (elbows bent)  A11: Waist bends forward  A12: Waist rotation  A13: Waist bends (reach foot with opposite hand)  A14: Reach heels backwards  A15: Lateral bend (10_ to the left + 10_ to the right)A16: Lateral bend with arm up (10_ to the left + 10_ to the right) A17: Repetitive forward stretching A18: Upper trunk and lower body opposite twist A19: Lateral elevation of arms A20: Frontal elevation of arms A21: Frontal hand claps A22: Frontal crossing of arms A23: Shoulders high-amplitude rotation A24: Shoulders low-amplitude rotation A25: Arms inner rotation A26: Knees (alternating) to the breast A27: Heels (alternating) to the backside A28: Knees bending (crouching) A29: Knees (alternating) bending forward A30: Rotation on the knees A31: Rowing A32: Elliptical bike A33: Cycling SENSOR SETUP:Each sensor provides 3D acceleration (accX,accY,accZ), 3D gyro (gyrX,gyrY,gyrZ), 3D magnetic field orientation (magX,magY,magZ) and 4D quaternions (Q1,Q2,Q3,Q4). The sensors are identified according to the body part on which is placed respectively:S1: right lower arm (RLA)S2: right upper arm (RUA)S3: back (BACK)S4: left upper arm (LUA)S5: left lower arm (LLA)S6: right calf (RC)S7: right thigh (RT)S8: left thigh (LT)S9: left calf (LC)SCENARIOS:The dataset contains information for three different scenarios depending on whether the sensors are positioned on predefined positions or placed by the users themselves.- Ideal-placement or the default scenario. The sensors are positioned by the instructor on predefined locations within each body part. The data stemming from this scenario could be considered as the Ã¢â‚¬Å“training setÃ¢â‚¬Â� for supervised activity recognition systems.- Self-placement. The user is asked to position a subset of the sensors themselves on the body parts specified by the instructor, but without providing any hint on how the sensors must be exactly placed. This scenario is devised to investigate some of the variability that may occur in the day-to-day usage of an activity recognition system, involving wearable or self-attached sensors. Normally, the self-placement will lead to on-body sensor setups that differ from the ideal-placement. Nevertheless, this difference may be minimal if the subject places the sensor close to the ideal position.- Induced-displacement. An intentional mispositioning of sensors using rotations and translations with respect to the ideal placement is introduced by the instructor. One of the key interests of including this last scenario is to investigate how the performance of a certain method degrades as the system drifts far from the ideal setup.A complete and illustrated description (including table of activities, sensor setup, etc.) of the dataset is provided in the documentation facilitated along with the dataset. Also, the papers presented in the section Ã¢â‚¬Å“Citation RequestsÃ¢â‚¬Â� provide an insightful description of the dataset and the underlying theory.  ",Computer,"The dataset comprises the readings of motion sensors recorded while users executed typical daily activities. The detailed format is described in the package. The attributes correspond to raw sensor readings. There is a total of 120 attributes:Column 1: Timestamp in secondsColumn 2: Timestamp in microsecondsColumn 3-15: [AccX, AccY, AccZ, GyrX, GyrY, Gyr, GyrZ, MagX, MagY, MagZ, Q1, Q2, Q3, Q4] of sensor S1Column 16-28: [AccX, AccY, AccZ, GyrX, GyrY, Gyr, GyrZ, MagX, MagY, MagZ, Q1, Q2, Q3, Q4] of sensor S2Column 29-41: [AccX, AccY, AccZ, GyrX, GyrY, Gyr, GyrZ, MagX, MagY, MagZ, Q1, Q2, Q3, Q4] of sensor S3Column 42-54: [AccX, AccY, AccZ, GyrX, GyrY, Gyr, GyrZ, MagX, MagY, MagZ, Q1, Q2, Q3, Q4] of sensor S4Column 55-67: [AccX, AccY, AccZ, GyrX, GyrY, Gyr, GyrZ, MagX, MagY, MagZ, Q1, Q2, Q3, Q4] of sensor S5Column 68-80: [AccX, AccY, AccZ, GyrX, GyrY, Gyr, GyrZ, MagX, MagY, MagZ, Q1, Q2, Q3, Q4] of sensor S6Column 91-93: [AccX, AccY, AccZ, GyrX, GyrY, Gyr, GyrZ, MagX, MagY, MagZ, Q1, Q2, Q3, Q4] of sensor S7Column 94-106: [AccX, AccY, AccZ, GyrX, GyrY, Gyr, GyrZ, MagX, MagY, MagZ, Q1, Q2, Q3, Q4] of sensor S8Column 107-119: [AccX, AccY, AccZ, GyrX, GyrY, Gyr, GyrZ, MagX, MagY, MagZ, Q1, Q2, Q3, Q4] of sensor S9Column 120: Label (see activity set)","The REALDISP dataset is devised to evaluate techniques dealing with the effects of sensor displacement in wearable activity recognition as well as to benchmark general activity recognition algorithms The REALDISP (REAListic sensor DISPlacement) dataset has been originally collected to investigate the effects of sensor displacement in the activity recognition process in real-world settings. It builds on the concept of ideal-placement, self-placement and induced-displacement. The ideal and mutual-displacement conditions represent extreme displacement variants and thus could represent boundary conditions for recognition algorithms. In contrast, self-placement reflects a users perception of how sensors could be attached, e.g., in a sports or lifestyle application. The dataset includes a wide range of physical activities (warm up, cool down and fitness exercises), sensor modalities (acceleration, rate of turn, magnetic field and quaternions) and participants (17 subjects). Apart from investigating sensor displacement, the dataset lend itself for benchmarking activity recognition techniques in ideal conditions.----------------------------------------------------------------------------------------------------------------------Dataset summary:#Activities: 33 #Sensors: 9#Subjects: 17#Scenarios: 3----------------------------------------------------------------------------------------------------------------------ACTIVITY SET:A1: Walking  A2: Jogging  A3: Running  A4: Jump up  A5: Jump front & back  A6: Jump sideways  A7: Jump leg/arms open/closed  A8: Jump rope  A9: Trunk twist (arms outstretched)  A10: Trunk twist (elbows bent)  A11: Waist bends forward  A12: Waist rotation  A13: Waist bends (reach foot with opposite hand)  A14: Reach heels backwards  A15: Lateral bend (10_ to the left + 10_ to the right)A16: Lateral bend with arm up (10_ to the left + 10_ to the right) A17: Repetitive forward stretching A18: Upper trunk and lower body opposite twist A19: Lateral elevation of arms A20: Frontal elevation of arms A21: Frontal hand claps A22: Frontal crossing of arms A23: Shoulders high-amplitude rotation A24: Shoulders low-amplitude rotation A25: Arms inner rotation A26: Knees (alternating) to the breast A27: Heels (alternating) to the backside A28: Knees bending (crouching) A29: Knees (alternating) bending forward A30: Rotation on the knees A31: Rowing A32: Elliptical bike A33: Cycling SENSOR SETUP:Each sensor provides 3D acceleration (accX,accY,accZ), 3D gyro (gyrX,gyrY,gyrZ), 3D magnetic field orientation (magX,magY,magZ) and 4D quaternions (Q1,Q2,Q3,Q4). The sensors are identified according to the body part on which is placed respectively:S1: right lower arm (RLA)S2: right upper arm (RUA)S3: back (BACK)S4: left upper arm (LUA)S5: left lower arm (LLA)S6: right calf (RC)S7: right thigh (RT)S8: left thigh (LT)S9: left calf (LC)SCENARIOS:The dataset contains information for three different scenarios depending on whether the sensors are positioned on predefined positions or placed by the users themselves.- Ideal-placement or the default scenario. The sensors are positioned by the instructor on predefined locations within each body part. The data stemming from this scenario could be considered as the Ã¢â‚¬Å“training setÃ¢â‚¬Â� for supervised activity recognition systems.- Self-placement. The user is asked to position a subset of the sensors themselves on the body parts specified by the instructor, but without providing any hint on how the sensors must be exactly placed. This scenario is devised to investigate some of the variability that may occur in the day-to-day usage of an activity recognition system, involving wearable or self-attached sensors. Normally, the self-placement will lead to on-body sensor setups that differ from the ideal-placement. Nevertheless, this difference may be minimal if the subject places the sensor close to the ideal position.- Induced-displacement. An intentional mispositioning of sensors using rotations and translations with respect to the ideal placement is introduced by the instructor. One of the key interests of including this last scenario is to investigate how the performance of a certain method degrades as the system drifts far from the ideal setup.A complete and illustrated description (including table of activities, sensor setup, etc.) of the dataset is provided in the documentation facilitated along with the dataset. Also, the papers presented in the section Ã¢â‚¬Å“Citation RequestsÃ¢â‚¬Â� provide an insightful description of the dataset and the underlying theory.  The dataset comprises the readings of motion sensors recorded while users executed typical daily activities. The detailed format is described in the package. The attributes correspond to raw sensor readings. There is a total of 120 attributes:Column 1: Timestamp in secondsColumn 2: Timestamp in microsecondsColumn 3-15: [AccX, AccY, AccZ, GyrX, GyrY, Gyr, GyrZ, MagX, MagY, MagZ, Q1, Q2, Q3, Q4] of sensor S1Column 16-28: [AccX, AccY, AccZ, GyrX, GyrY, Gyr, GyrZ, MagX, MagY, MagZ, Q1, Q2, Q3, Q4] of sensor S2Column 29-41: [AccX, AccY, AccZ, GyrX, GyrY, Gyr, GyrZ, MagX, MagY, MagZ, Q1, Q2, Q3, Q4] of sensor S3Column 42-54: [AccX, AccY, AccZ, GyrX, GyrY, Gyr, GyrZ, MagX, MagY, MagZ, Q1, Q2, Q3, Q4] of sensor S4Column 55-67: [AccX, AccY, AccZ, GyrX, GyrY, Gyr, GyrZ, MagX, MagY, MagZ, Q1, Q2, Q3, Q4] of sensor S5Column 68-80: [AccX, AccY, AccZ, GyrX, GyrY, Gyr, GyrZ, MagX, MagY, MagZ, Q1, Q2, Q3, Q4] of sensor S6Column 91-93: [AccX, AccY, AccZ, GyrX, GyrY, Gyr, GyrZ, MagX, MagY, MagZ, Q1, Q2, Q3, Q4] of sensor S7Column 94-106: [AccX, AccY, AccZ, GyrX, GyrY, Gyr, GyrZ, MagX, MagY, MagZ, Q1, Q2, Q3, Q4] of sensor S8Column 107-119: [AccX, AccY, AccZ, GyrX, GyrY, Gyr, GyrZ, MagX, MagY, MagZ, Q1, Q2, Q3, Q4] of sensor S9Column 120: Label (see activity set)"
Query Analytics Workloads Dataset,Query Analytics Workloads Dataset,The data-set contains three (3) sets of range/radius query workloads from Gaussian distributions over a real dataset; Each query is associated with aggregate scalar values (count/sum/average).,Query+Analytics+Workloads+Dataset,https://archive.ics.uci.edu/ml//machine-learning-databases/00493/,https://archive.ics.uci.edu/ml/datasets/Query+Analytics+Workloads+Dataset,"The data-set contains three (3) sets of synthetic range and radius query workloads derived from Gaussian distributions over the real dataset in [URL-1]. Each processed query is associated with aggregate scalar values (count, sum, average) over the dataset in [URL-1].[URL-1]: [Web Link]Note: the current dataset is processed data derived after synthetic query analytics workloads over the real-dataset in [URL-1] and does not include any data from [URL-1]",Computer,"[*] The dataset 'Radius Queries' contains records of the format: {'X-coordinate','Y-coordinate', 'R-Radius'}. These queries define a disc over a 2D space with center (X,Y) and radius R in order to investigate the number of crime incidents, the total arrests and the average beat of the disc region (spatial area) defined by each query.   [*] The dataset 'Radius Queries Count' contains records of the format: {'X-coordinate','Y-coordinate', 'R-Radius', 'Count'}. These queries define a disc over a 2D space with center (X,Y) and radius R and the number of crime incidents Count of the disc region (spatial area) defined by each query.[*] The dataset 'Range Queries Aggregates' contains records of the format: {'X-coordinate','Y-coordinate', 'X-range', 'Y-range', 'Count', 'SUM', 'AVG'}. These queries define a rectangle over a 2D space with coordinates/points: X +/- X-range and Y +/- Y-range. The count, sum, and avg is the number of incidents, total arrests and average beat of the rectangle region (spatial area) defined by each query.[*] All datasets are .csvExample of a Range Query with Count, SUM, and AVG: [1159191.2534425869,1894755.9479944962,5225.375665408865,2981.728430851036,96046.0,34927.0,1111.618901359765]where: 'X-coordinate' = 1159191.2534425869, 'Y-coordinate' = 1894755.9479944962, 'X-range' = 5225.375665408865, 'Y-range' = 2981.728430851036, 'Count' = 96046.0, 'SUM' = 34927, 'AVG' = 1111.618901359765.Attribute Information:Attributes:'ID' = serial number of query (optional) 'X-coordinate' = spatial x-coordinate (float) 'Y-coordinate' = spatial y-coordinate (float) 'R-Radius' = spatial radius of a disc (X,Y) for radius query (float) 'X-range' = spatial x-range for range query (float) 'Y-range' = spatial y-range for range query (float) 'Count' = number of crime incidents in the 2D disc (radius queries) or rectangle (range queries)'SUM' = summation of Arrests in the 2D disc (radius queries) or rectangle (range queries)'AVG' = average Beat in the 2D disc (radius queries) or rectangle (range queries)","The data-set contains three (3) sets of range/radius query workloads from Gaussian distributions over a real dataset; Each query is associated with aggregate scalar values (count/sum/average).The data-set contains three (3) sets of synthetic range and radius query workloads derived from Gaussian distributions over the real dataset in [URL-1]. Each processed query is associated with aggregate scalar values (count, sum, average) over the dataset in [URL-1].[URL-1]: [Web Link]Note: the current dataset is processed data derived after synthetic query analytics workloads over the real-dataset in [URL-1] and does not include any data from [URL-1][*] The dataset 'Radius Queries' contains records of the format: {'X-coordinate','Y-coordinate', 'R-Radius'}. These queries define a disc over a 2D space with center (X,Y) and radius R in order to investigate the number of crime incidents, the total arrests and the average beat of the disc region (spatial area) defined by each query.   [*] The dataset 'Radius Queries Count' contains records of the format: {'X-coordinate','Y-coordinate', 'R-Radius', 'Count'}. These queries define a disc over a 2D space with center (X,Y) and radius R and the number of crime incidents Count of the disc region (spatial area) defined by each query.[*] The dataset 'Range Queries Aggregates' contains records of the format: {'X-coordinate','Y-coordinate', 'X-range', 'Y-range', 'Count', 'SUM', 'AVG'}. These queries define a rectangle over a 2D space with coordinates/points: X +/- X-range and Y +/- Y-range. The count, sum, and avg is the number of incidents, total arrests and average beat of the rectangle region (spatial area) defined by each query.[*] All datasets are .csvExample of a Range Query with Count, SUM, and AVG: [1159191.2534425869,1894755.9479944962,5225.375665408865,2981.728430851036,96046.0,34927.0,1111.618901359765]where: 'X-coordinate' = 1159191.2534425869, 'Y-coordinate' = 1894755.9479944962, 'X-range' = 5225.375665408865, 'Y-range' = 2981.728430851036, 'Count' = 96046.0, 'SUM' = 34927, 'AVG' = 1111.618901359765.Attribute Information:Attributes:'ID' = serial number of query (optional) 'X-coordinate' = spatial x-coordinate (float) 'Y-coordinate' = spatial y-coordinate (float) 'R-Radius' = spatial radius of a disc (X,Y) for radius query (float) 'X-range' = spatial x-range for range query (float) 'Y-range' = spatial y-range for range query (float) 'Count' = number of crime incidents in the 2D disc (radius queries) or rectangle (range queries)'SUM' = summation of Arrests in the 2D disc (radius queries) or rectangle (range queries)'AVG' = average Beat in the 2D disc (radius queries) or rectangle (range queries)"
Qualitative_Bankruptcy,Qualitative_Bankruptcy,Predict the Bankruptcy from Qualitative parameters from experts.,Qualitative_Bankruptcy,https://archive.ics.uci.edu/ml//machine-learning-databases/00281/,https://archive.ics.uci.edu/ml/datasets/Qualitative_Bankruptcy,"The parameters which we used for collecting the dataset is referred from the paper 'The discovery of expertsÃ¢â‚¬â„¢ decision rules from qualitative bankruptcy data using genetic algorithms' by Myoung-Jong Kim*, Ingoo Han.",Computer,"Attribute Information: (P=Positive,A-Average,N-negative,B-Bankruptcy,NB-Non-Bankruptcy)      1. Industrial Risk: {P,A,N}     2. Management Risk: {P,A,N}     3. Financial Flexibility: {P,A,N}     4. Credibility: {P,A,N}     5. Competitiveness: {P,A,N}     6. Operating Risk: {P,A,N}     7. Class: {B,NB}","Predict the Bankruptcy from Qualitative parameters from experts.The parameters which we used for collecting the dataset is referred from the paper 'The discovery of expertsÃ¢â‚¬â„¢ decision rules from qualitative bankruptcy data using genetic algorithms' by Myoung-Jong Kim*, Ingoo Han.Attribute Information: (P=Positive,A-Average,N-negative,B-Bankruptcy,NB-Non-Bankruptcy)      1. Industrial Risk: {P,A,N}     2. Management Risk: {P,A,N}     3. Financial Flexibility: {P,A,N}     4. Credibility: {P,A,N}     5. Competitiveness: {P,A,N}     6. Operating Risk: {P,A,N}     7. Class: {B,NB}"
UNIX User Data,UNIX User Data,This file contains 9 sets of sanitized user data drawn from the command histories of 8 UNIX computer users at Purdue over the course of up to 2 years.,UNIX+User+Data,https://archive.ics.uci.edu/ml//machine-learning-databases/UNIX_user_data-mld/,https://archive.ics.uci.edu/ml/datasets/UNIX+User+Data,"This file contains 9 sets of sanitized user data drawn from thecommand histories of 8 UNIX computer users at Purdue over the courseof up to 2 years (USER0 and USER1 were generated by the same person,working on different platforms and different projects).  The data isdrawn from tcsh(1) history files and has been parsed and sanitized toremove filenames, user names, directory structures, web addresses,host names, and other possibly identifying items.  Command names,flags, and shell metacharacters have been preserved.  Additionally,**SOF** and **EOF** tokens have been inserted at the start and end ofshell sessions, respectively.  Sessions are concatenated by date orderand tokens appear in the order issued within the shell session, but notimestamps are included in this data.  For example, the two sessions:",Computer,,"This file contains 9 sets of sanitized user data drawn from the command histories of 8 UNIX computer users at Purdue over the course of up to 2 years.This file contains 9 sets of sanitized user data drawn from thecommand histories of 8 UNIX computer users at Purdue over the courseof up to 2 years (USER0 and USER1 were generated by the same person,working on different platforms and different projects).  The data isdrawn from tcsh(1) history files and has been parsed and sanitized toremove filenames, user names, directory structures, web addresses,host names, and other possibly identifying items.  Command names,flags, and shell metacharacters have been preserved.  Additionally,**SOF** and **EOF** tokens have been inserted at the start and end ofshell sessions, respectively.  Sessions are concatenated by date orderand tokens appear in the order issued within the shell session, but notimestamps are included in this data.  For example, the two sessions:nan"
Unmanned Aerial Vehicle (UAV) Intrusion Detection,Unmanned Aerial Vehicle (UAV) Intrusion Detection,"For UAV identification, each input is an encrypted WiFi traffic record while the output is whether the current traffic is from a UAV or not. Meta-info on attribute relationship is also provided.",Unmanned+Aerial+Vehicle+%28UAV%29+Intrusion+Detection,https://archive.ics.uci.edu/ml//machine-learning-databases/00564/,https://archive.ics.uci.edu/ml/datasets/Unmanned+Aerial+Vehicle+%28UAV%29+Intrusion+Detection,"Beyond traditional classification task, this dataset also contains other meta-information that help enable additional machine learning tasks. For example, this dataset contains the computational generation time for each statistical attributes, which is recorded in the diagonal values of the matrix D. It also contains the computational dependency among different attributes, which is denoted by the incidence matrix H. For example, the computation of standard deviation contains the computation of mean. Detailed information on D and H are as follows:D: kÃƒâ€” 1. The generation runtime for each feature.H: k'Ãƒâ€”k. The incident matrix of the feature computational hypergraph (see the above paper for details). k' is the number of feature computational components and k is the numbe of features.More information is included in the source paper.",Computer,"The raw inputs are the radio frequency time series in two directions: uplink_flow and downlink_flow. Attributes are processed from the raw input, the list of attributes are:1. uplink_size_mean2. uplink_size_median3. uplink_size_MAD4. uplink_size_STD5. uplink_size_Skewness6. uplink_size_Kurtosis7. uplink_size_MAX8. uplink_size_MIN9. uplink_size_MeanSquare10. downlink_size_mean11. downlink_size_median12. downlink_size_MAD13. downlink_size_STD14. downlink_size_Skewness15. downlink_size_Kurtosis16. downlink_size_MAX17. downlink_size_MIN18. downlink_size_MeanSquare19. both_links_size_mean20. both_links_size_median21. both_links_size_MAD22. both_links_size_STD23. both_links_size_Skewness24. both_links_size_Kurtosis25. both_links_size_MAX26. both_links_size_MIN27. both_links_size_MeanSquare28. uplink_interval_mean29. uplink_interval_median30. uplink_interval_MAD31. uplink_interval_STD32. uplink_interval_Skewness33. uplink_interval_Kurtosis34. uplink_interval_MAX35. uplink_interval_MIN36. uplink_interval_MeanSquare37. downlink_interval_mean38. downlink_interval_median39. downlink_interval_MAD40. downlink_interval_STD41. downlink_interval_Skewness42. downlink_interval_Kurtosis43. downlink_interval_MAX44. downlink_interval_MIN45. downlink_interval_MeanSquare46. both_links_interval_mean47. both_links_interval_median48. both_links_interval_MAD49. both_links_interval_STD50. both_links_interval_Skewness51. both_links_interval_Kurtosis52. both_links_interval_MAX53. both_links_interval_MIN54. both_links_interval_MeanSquare55. label","For UAV identification, each input is an encrypted WiFi traffic record while the output is whether the current traffic is from a UAV or not. Meta-info on attribute relationship is also provided.Beyond traditional classification task, this dataset also contains other meta-information that help enable additional machine learning tasks. For example, this dataset contains the computational generation time for each statistical attributes, which is recorded in the diagonal values of the matrix D. It also contains the computational dependency among different attributes, which is denoted by the incidence matrix H. For example, the computation of standard deviation contains the computation of mean. Detailed information on D and H are as follows:D: kÃƒâ€” 1. The generation runtime for each feature.H: k'Ãƒâ€”k. The incident matrix of the feature computational hypergraph (see the above paper for details). k' is the number of feature computational components and k is the numbe of features.More information is included in the source paper.The raw inputs are the radio frequency time series in two directions: uplink_flow and downlink_flow. Attributes are processed from the raw input, the list of attributes are:1. uplink_size_mean2. uplink_size_median3. uplink_size_MAD4. uplink_size_STD5. uplink_size_Skewness6. uplink_size_Kurtosis7. uplink_size_MAX8. uplink_size_MIN9. uplink_size_MeanSquare10. downlink_size_mean11. downlink_size_median12. downlink_size_MAD13. downlink_size_STD14. downlink_size_Skewness15. downlink_size_Kurtosis16. downlink_size_MAX17. downlink_size_MIN18. downlink_size_MeanSquare19. both_links_size_mean20. both_links_size_median21. both_links_size_MAD22. both_links_size_STD23. both_links_size_Skewness24. both_links_size_Kurtosis25. both_links_size_MAX26. both_links_size_MIN27. both_links_size_MeanSquare28. uplink_interval_mean29. uplink_interval_median30. uplink_interval_MAD31. uplink_interval_STD32. uplink_interval_Skewness33. uplink_interval_Kurtosis34. uplink_interval_MAX35. uplink_interval_MIN36. uplink_interval_MeanSquare37. downlink_interval_mean38. downlink_interval_median39. downlink_interval_MAD40. downlink_interval_STD41. downlink_interval_Skewness42. downlink_interval_Kurtosis43. downlink_interval_MAX44. downlink_interval_MIN45. downlink_interval_MeanSquare46. both_links_interval_mean47. both_links_interval_median48. both_links_interval_MAD49. both_links_interval_STD50. both_links_interval_Skewness51. both_links_interval_Kurtosis52. both_links_interval_MAX53. both_links_interval_MIN54. both_links_interval_MeanSquare55. label"
Predict keywords activities in a online social media,Predict keywords activities in a online social media,The data from Twitter was collected during 360 consecutive days. It was done by querying 1497 English keywords sampled from Wikipedia. This dataset is proposed in a Learning to rank setting.,Predict+keywords+activities+in+a+online+social+media,https://archive.ics.uci.edu/ml//machine-learning-databases/00276/,https://archive.ics.uci.edu/ml/datasets/Predict+keywords+activities+in+a+online+social+media,See files and/or [Web Link],Computer,See files and/or [Web Link],The data from Twitter was collected during 360 consecutive days. It was done by querying 1497 English keywords sampled from Wikipedia. This dataset is proposed in a Learning to rank setting.See files and/or [Web Link]See files and/or [Web Link]
PPG-DaLiA,PPG-DaLiA,"PPG-DaLiA contains data from 15 subjects wearing physiological and motion sensors, providing a PPG dataset for motion compensation and heart rate estimation in Daily Life Activities.
	",PPG-DaLiA,https://archive.ics.uci.edu/ml//machine-learning-databases/00495/,https://archive.ics.uci.edu/ml/datasets/PPG-DaLiA,"PPG-DaLiA is a publicly available dataset for PPG-based heart rate estimation. This multimodal dataset features physiological and motion data, recorded from both a wrist- and a chest-worn device, of 15 subjects while performing a wide range of activities under close to real-life conditions. The included ECG data provides heart rate ground truth. The included PPG- and 3D-accelerometer data can be used for heart rate estimation, while compensating for motion artefacts. Details can be found in the dataset's readme-file, as well as in [1].",Computer,"Raw sensor data was recorded with two devices: a chest-worn device (RespiBAN) and a wrist-worn device (Empatica E4).The RespiBAN device provides the following sensor data: electrocardiogram (ECG), respiration, and three-axis acceleration. All signals are sampled at 700 Hz.The Empatica E4 device provides the following sensor data: blood volume pulse (BVP, 64 Hz), electrodermal activity (EDA, 4 Hz), body temperature (4 Hz), and three-axis acceleration (32 Hz).The dataset's readme-file contains all further details with respect to the dataset structure, data format (RespiBAN device, Empatica E4 device, synchronised data), study protocol, ground truth generation, etc.","PPG-DaLiA contains data from 15 subjects wearing physiological and motion sensors, providing a PPG dataset for motion compensation and heart rate estimation in Daily Life Activities.
	PPG-DaLiA is a publicly available dataset for PPG-based heart rate estimation. This multimodal dataset features physiological and motion data, recorded from both a wrist- and a chest-worn device, of 15 subjects while performing a wide range of activities under close to real-life conditions. The included ECG data provides heart rate ground truth. The included PPG- and 3D-accelerometer data can be used for heart rate estimation, while compensating for motion artefacts. Details can be found in the dataset's readme-file, as well as in [1].Raw sensor data was recorded with two devices: a chest-worn device (RespiBAN) and a wrist-worn device (Empatica E4).The RespiBAN device provides the following sensor data: electrocardiogram (ECG), respiration, and three-axis acceleration. All signals are sampled at 700 Hz.The Empatica E4 device provides the following sensor data: blood volume pulse (BVP, 64 Hz), electrodermal activity (EDA, 4 Hz), body temperature (4 Hz), and three-axis acceleration (32 Hz).The dataset's readme-file contains all further details with respect to the dataset structure, data format (RespiBAN device, Empatica E4 device, synchronised data), study protocol, ground truth generation, etc."
"UrbanGB, urban road accidents coordinates labelled by the urban center","UrbanGB, urban road accidents coordinates labelled by the urban center","Coordinates (longitude and latitude) of 360177 road accidents occurred in urban areas in Great Britain, and labelled according to the urban center where they occurred (469 possible labels).",UrbanGB%2C+urban+road+accidents+coordinates+labelled+by+the+urban+center,https://archive.ics.uci.edu/ml//machine-learning-databases/00550/,https://archive.ics.uci.edu/ml/datasets/UrbanGB%2C+urban+road+accidents+coordinates+labelled+by+the+urban+center,"Please see the included README.md file for details on the contents, format and purpose of the dataset, and the procedure used to create it.",Computer,"The input data contains geographical coordinates in the ranges [-5.55599, 1.75834] (longitude) and [50.0797, 57.6956] (latitude). It is advisable to scale the longitude down by a factor of 1.7 for the purpose of geographical clustering.The labels are provided in a separate file (one label per entry, ranging from 1 to 469).The centroids (barycenters of each partition) are also provided, in a separate file.See the included README.md file for further details. ","Coordinates (longitude and latitude) of 360177 road accidents occurred in urban areas in Great Britain, and labelled according to the urban center where they occurred (469 possible labels).Please see the included README.md file for details on the contents, format and purpose of the dataset, and the procedure used to create it.The input data contains geographical coordinates in the ranges [-5.55599, 1.75834] (longitude) and [50.0797, 57.6956] (latitude). It is advisable to scale the longitude down by a factor of 1.7 for the purpose of geographical clustering.The labels are provided in a separate file (one label per entry, ranging from 1 to 469).The centroids (barycenters of each partition) are also provided, in a separate file.See the included README.md file for further details. "
PMU-UD,PMU-UD,"The handwritten dataset was collected from 170 participants with a total of 5,180 numeral patterns. The dataset is named Prince Mohammad Bin Fahd University - Urdu/Arabic Database (PMU-UD). ",PMU-UD,https://archive.ics.uci.edu/ml//machine-learning-databases/00469/,https://archive.ics.uci.edu/ml/datasets/PMU-UD,The dataset contains handwritten Urdu/Arabic numerals from 0 to 9,Computer,The participants were asked to write the numerals from 0-9 five times each. Participants age ranged from 25-55 years old.,"The handwritten dataset was collected from 170 participants with a total of 5,180 numeral patterns. The dataset is named Prince Mohammad Bin Fahd University - Urdu/Arabic Database (PMU-UD). The dataset contains handwritten Urdu/Arabic numerals from 0 to 9The participants were asked to write the numerals from 0-9 five times each. Participants age ranged from 25-55 years old."
Planning Relax,Planning Relax,The dataset concerns with the classification of two mental stages from recorded EEG signals: Planning (during imagination of motor act) and Relax state. ,Planning+Relax,https://archive.ics.uci.edu/ml//machine-learning-databases/00230/,https://archive.ics.uci.edu/ml/datasets/Planning+Relax,"EEG record contains many regular oscillations, which are believed to reflect synchronized rhythmic activity in a group of neurons. Most activity related EEG patterns occur within the following frequency bands. Delta (0.5 Ã¢â‚¬â€œ 4 Hz.), Theta (4 Ã¢â‚¬â€œ 8 Hz), Alpha (8 Ã¢â‚¬â€œ 13 Hz), Beta (13 Ã¢â‚¬â€œ 22 Hz), and Gamma (30 Ã¢â‚¬â€œ 40 Hz). The waves with the frequency of  7 Ã¢â‚¬â€œ 13 Hz over motor processing areas are called mu rhythm and reflect idling activity in motor areas. It is more pronounced when the subjects are at rest and at least a second before subjects initiate voluntary movement, the mu  activity over the hemisphere contralateral to the region moved shows a decrease in amplitude and is called Event Related Desynchronization (ERD).For the current study, EEG data was collected for 5 times on various days from a healthy right-handed subject of 25 years of age. The data was recorded on a Medelec Profile Digital EEG machine. The settings of high frequency filter 50 Hz, low frequency filter 1.6 Hz, notch filter 50 Hz, sensitivity 70 micro volts/mm, and a sampling rate of 256 Hz were used for the basic signal processing. Eight EEG electrodes (C3, C4, P3, P4, F3, F4, T3, and T4) were placed according to the international standard 10-20 system of electrode placement. Bipolar and unipolar EEG was recorded from eight Ag/AgCI scalp electrodes, which were placed 2.5 cm anterior and posterior to the central electrodes C3 and C4 (left and right side of the hemisphere). A1 and A2 are reference electrodes. The reference electrodes are placed on the left and right ears and the ground electrode on the forehead. EOG (Electrooculogram) being a noise artifact, was derived from two electrodes, placed on the outer cantus of left and right eye in order to detect eye movement. These EOG signals are then used to eliminate eye movement artifacts. The subject was asked to lie down comfortably in a relaxed position with eyes closed and advised to minimize eye movements. The EEG was recorded for the relaxed state for 5 minutes. Following this, an audio beep of 60 db and 0.91 sec. duration was given at the start and end of a 5 second epoch where the subject was asked to mentally plan lifting of the right hand thumb. This activity is collected as a 5 second epoch data corresponding to Ã¢â‚¬Ëœmovement imageryÃ¢â‚¬â„¢ state. After a gap of 5 minutes, the same cue is given to repeat the experiment. The whole experiment lasts for approximately 30 minutes, collecting data for 5 trials of 5 second epoch each for normal relaxed state and 5 trials of 5 second epoch each for movement imagery. No actual movement is performed during the session. All data sets were visually checked for artifacts before final selection.",Computer,"Wavelet transform has been applied for feature extraction for EEG classification. However, wavelet transforms pyramidal algorithm work only on approximation coefficients. So it can not identify 7-13 Hz frequency band. We have extended the methodology by applying wavelet packet analysis, which also decompose detail coefficients. Wavelet packet analysis has been used for signal decomposition with equal frequency bandwidth at each level of decomposition, which leads to an equal number of the approximation and detail coefficients. By applying wavelet packet analysis on the original signal, we have obtained twelve wavelet coefficients in the 7-13 Hz frequency band at the 6th level node (6,2). The signal is reconstructed at node (6,2) and its FFT plot gave the frequency band 7-13 Hz as the most discriminating, in conjunction with the wavelet Daubechies#6 (db6).","The dataset concerns with the classification of two mental stages from recorded EEG signals: Planning (during imagination of motor act) and Relax state. EEG record contains many regular oscillations, which are believed to reflect synchronized rhythmic activity in a group of neurons. Most activity related EEG patterns occur within the following frequency bands. Delta (0.5 Ã¢â‚¬â€œ 4 Hz.), Theta (4 Ã¢â‚¬â€œ 8 Hz), Alpha (8 Ã¢â‚¬â€œ 13 Hz), Beta (13 Ã¢â‚¬â€œ 22 Hz), and Gamma (30 Ã¢â‚¬â€œ 40 Hz). The waves with the frequency of  7 Ã¢â‚¬â€œ 13 Hz over motor processing areas are called mu rhythm and reflect idling activity in motor areas. It is more pronounced when the subjects are at rest and at least a second before subjects initiate voluntary movement, the mu  activity over the hemisphere contralateral to the region moved shows a decrease in amplitude and is called Event Related Desynchronization (ERD).For the current study, EEG data was collected for 5 times on various days from a healthy right-handed subject of 25 years of age. The data was recorded on a Medelec Profile Digital EEG machine. The settings of high frequency filter 50 Hz, low frequency filter 1.6 Hz, notch filter 50 Hz, sensitivity 70 micro volts/mm, and a sampling rate of 256 Hz were used for the basic signal processing. Eight EEG electrodes (C3, C4, P3, P4, F3, F4, T3, and T4) were placed according to the international standard 10-20 system of electrode placement. Bipolar and unipolar EEG was recorded from eight Ag/AgCI scalp electrodes, which were placed 2.5 cm anterior and posterior to the central electrodes C3 and C4 (left and right side of the hemisphere). A1 and A2 are reference electrodes. The reference electrodes are placed on the left and right ears and the ground electrode on the forehead. EOG (Electrooculogram) being a noise artifact, was derived from two electrodes, placed on the outer cantus of left and right eye in order to detect eye movement. These EOG signals are then used to eliminate eye movement artifacts. The subject was asked to lie down comfortably in a relaxed position with eyes closed and advised to minimize eye movements. The EEG was recorded for the relaxed state for 5 minutes. Following this, an audio beep of 60 db and 0.91 sec. duration was given at the start and end of a 5 second epoch where the subject was asked to mentally plan lifting of the right hand thumb. This activity is collected as a 5 second epoch data corresponding to Ã¢â‚¬Ëœmovement imageryÃ¢â‚¬â„¢ state. After a gap of 5 minutes, the same cue is given to repeat the experiment. The whole experiment lasts for approximately 30 minutes, collecting data for 5 trials of 5 second epoch each for normal relaxed state and 5 trials of 5 second epoch each for movement imagery. No actual movement is performed during the session. All data sets were visually checked for artifacts before final selection.Wavelet transform has been applied for feature extraction for EEG classification. However, wavelet transforms pyramidal algorithm work only on approximation coefficients. So it can not identify 7-13 Hz frequency band. We have extended the methodology by applying wavelet packet analysis, which also decompose detail coefficients. Wavelet packet analysis has been used for signal decomposition with equal frequency bandwidth at each level of decomposition, which leads to an equal number of the approximation and detail coefficients. By applying wavelet packet analysis on the original signal, we have obtained twelve wavelet coefficients in the 7-13 Hz frequency band at the 6th level node (6,2). The signal is reconstructed at node (6,2) and its FFT plot gave the frequency band 7-13 Hz as the most discriminating, in conjunction with the wavelet Daubechies#6 (db6)."
Pioneer-1 Mobile Robot Data,Pioneer-1 Mobile Robot Data,"This dataset contains time series sensor readings of the Pioneer-1 mobile robot. The data is broken into ""experiences"" in which the robot takes action for some period of time and experiences a control",Pioneer-1+Mobile+Robot+Data,https://archive.ics.uci.edu/ml//machine-learning-databases/pioneer-mld/,https://archive.ics.uci.edu/ml/datasets/Pioneer-1+Mobile+Robot+Data,"The data were collected over a series of specifically designed trials. Our hope was to cover most of the types of sensory interactions that a Pioneer might be reasonably expected to encounter: things like passing by visible objects, pushing visible objects, crashing into walls, etc. Many of these interactions are repeated throughout the dataset.This data was collected to serve as the basis for work in learning and conceptual development. Our first goal was to be able to have the robot cluster these experiences by their dynamics on their own into clusters of experiences with a common outcome.Each data file contains time series data in which each row of data corresponds to a single observation of the sensor array. Included in each row are two additional variables, 'id' and 'description', which indicate the experience number that the observation belongs to, and a description of that experience, respectively. Observations within an experience are taken every 100ms. The data is stored in three text files: one file for experiences in which the Pioneer was moving in a straight line, one in which it was turning in place, and one in which it was raising or lowering its gripper.The description variable is a string of symbols. The string breaks down as follows:""u"" or ""o"" -  unobstructed or obstructed""x.xs""     -  activity lasted x.x secondsactivity   -  the activity and speed, if applicable, i.e. move100 = move forward at 100mm/secvisual     -  objects in the visual array are listed in sequence. ""cAHEAD"" indicates an object visible to channel c directly AHEAD of the Pioneer.[visual.X] -  visual descriptions followed by a '.' and one character indicate that something special happens with the visible object. .V means the object Vanishes from sight during the activity. .D indicates that the object is Discovered (becomes visible) during the activity. .P indicates that the object is pushed. An example: ""u-3.5s-retr-100-aRIGHT.D""  An unobstructed retreat (move) at -100 mm/sec for 3.5 seconds with an object being discovered in channel A.It should be noted that, particularly with respect to the visual channels, the description may not be 100% accurate. Since the visual channels respond to colors that they are trained on (visual a=red, visual b=yellow, visual c=blue), it was possible, but infrequent, for some extraneous object in the environment generated a response in visual channels that were not supposed to show activity in a particular trial.Rows are seperated by carriage returns, columns by commas. ",Computer,"TRIAL-ID	: categorical, the trial id of the experience that the observation belongs toDESCRIPTION	: a symbolic description of the experience designTIME-SECS	: a reading of the Pioneer's internal clock, in secondsBATTERY-LEVEL	: a reading of battery level, in voltsSONAR-0		: sonar depth reading, in mm, of the left (90) pointing sonarSONAR-1		: sonar depth reading, in mm, of a (15) pointing sonarSONAR-2 	: sonar depth reading, in mm, of a (7.5) pointing sonarSONAR-3 	: sonar depth reading, in mm, of a forward (0) pointing sonarSONAR-4 	: sonar depth reading, in mm, of a (-7.5) pointing sonarSONAR-5 	: sonar depth reading, in mm, of a (-15) pointing sonarSONAR-6 	: sonar depth reading, in mm, of a right (-90) pointing sonarHEADING		: heading reading, in degrees, from the robot's ""true north""R-WHEEL-VEL	: right wheel velocity, in mm/secL-WHEEL-VEL	: left wheel velocity, in mm/secTRANS-VEL	: translational velocity, mm/secROT-VEL		: rotational velocity, mm/secR-STALL		: right wheel stall sensor, binary (0/1)L-STALL		: left wheel stall sensor, binary (0/1)ROBOT-STATUS	: robot status, 2.0 = stationary, 3.0 = movingGRIP-STATE	: gripper stateGRIP-FRONT-BEAM : gripper break beam, binary, 1.0 = brokenGRIP-REAR-BEAM	: gripper break beam, binary, 1.0 = brokenGRIP-BUMPER	: gripper bumper, binary, 1.0 = in contactVIS-A-AREA	: area of dominant visible object for channel A, in pixelsVIS-A-X		: X location of object in channel A on image plane, -140 ... 140VIS-A-Y		: Y location of channel A on image planeVIS-A-H		: height of object in channel A on plane, in pixelsVIS-A-W		: width of object in A on image plane, in pixelsVIS-A-DIST	: distance to object in channel A, in mmVIS-B-AREA	: area of dominant visible object for channel B, in pixelsVIS-B-X		: X location of object in channel B on image plane, -140 ... 140VIS-B-Y		: Y location of channel B on image planeVIS-B-H		: height of object in channel B on plane, in pixelsVIS-B-W		: width of object in B on image plane, in pixelsVIS-B-DIST	: distance to object in channel B, in mmVIS-C-AREA	: area of dominant visible object for channel C, in pixelsVIS-C-X		: X location of object in channel C on image plane, -140 ... 140VIS-C-Y		: Y location of channel C on image planeVIS-C-H		: height of object in C on image plane, in pixelsVIS-C-W		: width of object in C on image plane, in pixelsVIS-C-DIST	: distance to object in channel C, in mmFor the visual variables, when there is no visible object, width = 0, height = 0, area = 0, distance = 10000.0, Y = 0, X = 140.0. The sonars report 5201.0 as their maximum distance. ","This dataset contains time series sensor readings of the Pioneer-1 mobile robot. The data is broken into ""experiences"" in which the robot takes action for some period of time and experiences a controlThe data were collected over a series of specifically designed trials. Our hope was to cover most of the types of sensory interactions that a Pioneer might be reasonably expected to encounter: things like passing by visible objects, pushing visible objects, crashing into walls, etc. Many of these interactions are repeated throughout the dataset.This data was collected to serve as the basis for work in learning and conceptual development. Our first goal was to be able to have the robot cluster these experiences by their dynamics on their own into clusters of experiences with a common outcome.Each data file contains time series data in which each row of data corresponds to a single observation of the sensor array. Included in each row are two additional variables, 'id' and 'description', which indicate the experience number that the observation belongs to, and a description of that experience, respectively. Observations within an experience are taken every 100ms. The data is stored in three text files: one file for experiences in which the Pioneer was moving in a straight line, one in which it was turning in place, and one in which it was raising or lowering its gripper.The description variable is a string of symbols. The string breaks down as follows:""u"" or ""o"" -  unobstructed or obstructed""x.xs""     -  activity lasted x.x secondsactivity   -  the activity and speed, if applicable, i.e. move100 = move forward at 100mm/secvisual     -  objects in the visual array are listed in sequence. ""cAHEAD"" indicates an object visible to channel c directly AHEAD of the Pioneer.[visual.X] -  visual descriptions followed by a '.' and one character indicate that something special happens with the visible object. .V means the object Vanishes from sight during the activity. .D indicates that the object is Discovered (becomes visible) during the activity. .P indicates that the object is pushed. An example: ""u-3.5s-retr-100-aRIGHT.D""  An unobstructed retreat (move) at -100 mm/sec for 3.5 seconds with an object being discovered in channel A.It should be noted that, particularly with respect to the visual channels, the description may not be 100% accurate. Since the visual channels respond to colors that they are trained on (visual a=red, visual b=yellow, visual c=blue), it was possible, but infrequent, for some extraneous object in the environment generated a response in visual channels that were not supposed to show activity in a particular trial.Rows are seperated by carriage returns, columns by commas. TRIAL-ID	: categorical, the trial id of the experience that the observation belongs toDESCRIPTION	: a symbolic description of the experience designTIME-SECS	: a reading of the Pioneer's internal clock, in secondsBATTERY-LEVEL	: a reading of battery level, in voltsSONAR-0		: sonar depth reading, in mm, of the left (90) pointing sonarSONAR-1		: sonar depth reading, in mm, of a (15) pointing sonarSONAR-2 	: sonar depth reading, in mm, of a (7.5) pointing sonarSONAR-3 	: sonar depth reading, in mm, of a forward (0) pointing sonarSONAR-4 	: sonar depth reading, in mm, of a (-7.5) pointing sonarSONAR-5 	: sonar depth reading, in mm, of a (-15) pointing sonarSONAR-6 	: sonar depth reading, in mm, of a right (-90) pointing sonarHEADING		: heading reading, in degrees, from the robot's ""true north""R-WHEEL-VEL	: right wheel velocity, in mm/secL-WHEEL-VEL	: left wheel velocity, in mm/secTRANS-VEL	: translational velocity, mm/secROT-VEL		: rotational velocity, mm/secR-STALL		: right wheel stall sensor, binary (0/1)L-STALL		: left wheel stall sensor, binary (0/1)ROBOT-STATUS	: robot status, 2.0 = stationary, 3.0 = movingGRIP-STATE	: gripper stateGRIP-FRONT-BEAM : gripper break beam, binary, 1.0 = brokenGRIP-REAR-BEAM	: gripper break beam, binary, 1.0 = brokenGRIP-BUMPER	: gripper bumper, binary, 1.0 = in contactVIS-A-AREA	: area of dominant visible object for channel A, in pixelsVIS-A-X		: X location of object in channel A on image plane, -140 ... 140VIS-A-Y		: Y location of channel A on image planeVIS-A-H		: height of object in channel A on plane, in pixelsVIS-A-W		: width of object in A on image plane, in pixelsVIS-A-DIST	: distance to object in channel A, in mmVIS-B-AREA	: area of dominant visible object for channel B, in pixelsVIS-B-X		: X location of object in channel B on image plane, -140 ... 140VIS-B-Y		: Y location of channel B on image planeVIS-B-H		: height of object in channel B on plane, in pixelsVIS-B-W		: width of object in B on image plane, in pixelsVIS-B-DIST	: distance to object in channel B, in mmVIS-C-AREA	: area of dominant visible object for channel C, in pixelsVIS-C-X		: X location of object in channel C on image plane, -140 ... 140VIS-C-Y		: Y location of channel C on image planeVIS-C-H		: height of object in C on image plane, in pixelsVIS-C-W		: width of object in C on image plane, in pixelsVIS-C-DIST	: distance to object in channel C, in mmFor the visual variables, when there is no visible object, width = 0, height = 0, area = 0, distance = 10000.0, Y = 0, X = 140.0. The sonars report 5201.0 as their maximum distance. "
Phishing Websites,Phishing Websites,"This dataset collected mainly from: PhishTank archive, MillerSmiles archive, Googleâ€™s searching operators.",Phishing+Websites,https://archive.ics.uci.edu/ml//machine-learning-databases/00327/,https://archive.ics.uci.edu/ml/datasets/Phishing+Websites,"One of the challenges faced by our research was the unavailability of reliable training datasets. In fact this challenge faces any researcher in the field. However, although plenty of articles about predicting phishing websites have been disseminated these days, no reliable training dataset has been published publically, may be because there is no agreement in literature on the definitive features that characterize phishing webpages, hence it is difficult to shape a dataset that covers all possible features. In this dataset, we shed light on the important features that have proved to be sound and effective in predicting phishing websites. In addition, we propose some new features.",Computer,For Further information about the features see the features file in the data folder.,"This dataset collected mainly from: PhishTank archive, MillerSmiles archive, Googleâ€™s searching operators.One of the challenges faced by our research was the unavailability of reliable training datasets. In fact this challenge faces any researcher in the field. However, although plenty of articles about predicting phishing websites have been disseminated these days, no reliable training dataset has been published publically, may be because there is no agreement in literature on the definitive features that characterize phishing webpages, hence it is difficult to shape a dataset that covers all possible features. In this dataset, we shed light on the important features that have proved to be sound and effective in predicting phishing websites. In addition, we propose some new features.For Further information about the features see the features file in the data folder."
Pen-Based Recognition of Handwritten Digits,Pen-Based Recognition of Handwritten Digits,Digit database of 250 samples from 44 writers,Pen-Based+Recognition+of+Handwritten+Digits,https://archive.ics.uci.edu/ml//machine-learning-databases/pendigits/,https://archive.ics.uci.edu/ml/datasets/Pen-Based+Recognition+of+Handwritten+Digits,"We create a digit database by collecting 250 samples from 44 writers. The samples written by 30 writers are used for training, cross-validation and writer dependent testing, and the digits written by the other 14 are used for writer independent testing. This database is also available in the UNIPEN format.We use a WACOM PL-100V pressure sensitive tablet with an integrated LCD display and a cordless stylus. The input and display areas are located in the same place. Attached to the serial port of an Intel 486 based PC, it allows us to collect handwriting samples. The tablet sends $x$ and $y$ tablet coordinates and pressure level values of the pen at fixed time intervals (sampling rate) of 100 miliseconds. These writers are asked to write 250 digits in random order inside boxes of 500 by 500 tablet pixel resolution.  Subject are monitored only during the first entry screens. Each screen contains five boxes with the digits to be written displayed above. Subjects are told to write only inside these boxes.  If they make a mistake or are unhappy with their writing, they are instructed to clear the content of a box by using an on-screen button. The first ten digits are ignored because most writers are not familiar with this type of input devices, but subjects are not aware of this. In our study, we use only ($x, y$) coordinate information. The stylus pressure level values are ignored. First we apply normalization to make our representation invariant to translations and scale distortions. The raw data that we capture from the tablet consist of integer values between 0 and 500 (tablet input box resolution). The new coordinates are such that the coordinate which has the maximum range varies between 0 and 100. Usually $x$ stays in this range, since most characters are taller than they are wide.  In order to train and test our classifiers, we need to represent digits as constant length feature vectors. A commonly used technique leading to good results is resampling the ( x_t, y_t) points. Temporal resampling (points regularly spaced in time) or spatial resampling (points regularly spaced in arc length) can be used here. Raw point data are already regularly spaced in time but the distance between them is variable. Previous research showed that spatial resampling to obtain a constant number of regularly spaced points on the trajectory yields much better performance, because it provides a better alignment between points. Our resampling algorithm uses simple linear interpolation between pairs of points. The resampled digits are represented as a sequence of T points ( x_t, y_t )_{t=1}^T, regularly spaced in arc length, as opposed to the input sequence, which is regularly spaced in time.So, the input vector size is 2*T, two times the number of points resampled. We considered spatial resampling to T=8,12,16 points in our experiments and found that T=8 gave the best trade-off between accuracy and complexity.",Computer,All input attributes are integers in the range 0..100.The last attribute is the class code 0..9,"Digit database of 250 samples from 44 writersWe create a digit database by collecting 250 samples from 44 writers. The samples written by 30 writers are used for training, cross-validation and writer dependent testing, and the digits written by the other 14 are used for writer independent testing. This database is also available in the UNIPEN format.We use a WACOM PL-100V pressure sensitive tablet with an integrated LCD display and a cordless stylus. The input and display areas are located in the same place. Attached to the serial port of an Intel 486 based PC, it allows us to collect handwriting samples. The tablet sends $x$ and $y$ tablet coordinates and pressure level values of the pen at fixed time intervals (sampling rate) of 100 miliseconds. These writers are asked to write 250 digits in random order inside boxes of 500 by 500 tablet pixel resolution.  Subject are monitored only during the first entry screens. Each screen contains five boxes with the digits to be written displayed above. Subjects are told to write only inside these boxes.  If they make a mistake or are unhappy with their writing, they are instructed to clear the content of a box by using an on-screen button. The first ten digits are ignored because most writers are not familiar with this type of input devices, but subjects are not aware of this. In our study, we use only ($x, y$) coordinate information. The stylus pressure level values are ignored. First we apply normalization to make our representation invariant to translations and scale distortions. The raw data that we capture from the tablet consist of integer values between 0 and 500 (tablet input box resolution). The new coordinates are such that the coordinate which has the maximum range varies between 0 and 100. Usually $x$ stays in this range, since most characters are taller than they are wide.  In order to train and test our classifiers, we need to represent digits as constant length feature vectors. A commonly used technique leading to good results is resampling the ( x_t, y_t) points. Temporal resampling (points regularly spaced in time) or spatial resampling (points regularly spaced in arc length) can be used here. Raw point data are already regularly spaced in time but the distance between them is variable. Previous research showed that spatial resampling to obtain a constant number of regularly spaced points on the trajectory yields much better performance, because it provides a better alignment between points. Our resampling algorithm uses simple linear interpolation between pairs of points. The resampled digits are represented as a sequence of T points ( x_t, y_t )_{t=1}^T, regularly spaced in arc length, as opposed to the input sequence, which is regularly spaced in time.So, the input vector size is 2*T, two times the number of points resampled. We considered spatial resampling to T=8,12,16 points in our experiments and found that T=8 gave the best trade-off between accuracy and complexity.All input attributes are integers in the range 0..100.The last attribute is the class code 0..9"
2.4 GHZ Indoor Channel Measurements,2.4 GHZ Indoor Channel Measurements,"Measurement of the S21,consists of 10 sweeps, each sweep contains 601 frequency points with spacing of 0.167MHz to cover a 100MHz band centered at 2.4GHz.",2.4+GHZ+Indoor+Channel+Measurements,https://archive.ics.uci.edu/ml//machine-learning-databases/00480/,https://archive.ics.uci.edu/ml/datasets/2.4+GHZ+Indoor+Channel+Measurements,"Abstract: The frequency domain measurement of the scattering parameter, S21, of the wireless channel was carried out using the ZVB14 Vector Network Analyzer (VNA) from Rhode and Schwartz. The measurement system consists of the VNA, low loss RF cables, and omnidirectional antennas at the transmitter and receiver ends. The transmitter and receiver heights were fixed at 1.5 m. A program script was written for the VNA to measure 10 consecutive sweeps: each sweep contains 601 frequency sample points with spacing of 0.167 MHz to cover a 100 MHz band centered at 2.4 GHz. The settings provided a high time-domain resolution of 10 nsec (inverse of the bandwidth) and a time span of (0.167 MHz) = 5.99 ÃŽÂ¼sec . The measurements were designed to examine the WiFi bands specifically, channels 1, 6, and 11 in the IEEE 802.11 standard. The frequency domain channel measurements were conducted at Khalifa University campus in Sharjah, UAE. The measurements were done in 4 different locations:1- Lab139 (highly cluttered)2- Corridor_rm155 (medium cluttered) [with wall from one side and windows from the   other side].3- Main_Lobby (low cluttered)4- Sports_Hall (open space). Instructions: ---------------------------------------------------------------------------------------------------------------Details of the dataset:The frequency domain measurement of the scattering parameter, S21, of the wireless channel was carried out using the ZVB14 Vector Network Analyzer (VNA) from Rhode and Schwartz. The measurement system consists of the VNA, low loss RF cables, and omnidirectional antennas at the transmitter and receiver ends. The transmitter and receiver heights were fixed at 1.5 m. A program script was written for the VNA to measure 10 consecutive sweeps: each sweep contains 601 frequency sample points with spacing of 0.167 MHz to cover a 100 MHz band centered at 2.4 GHz. The settings provided a high time-domain resolution of 10 nsec (inverse of the bandwidth) and a time span of (0.167 MHz) = 5.99ÃŽÂ¼sec . The measurements were designed to examine the WiFi bands specifically, channels 1, 6, and 11 in the IEEE 802.11 standard. The frequency domain channel measurements were conducted at Khalifa University campus in Sharjah, UAE. The measurements were done in 4 different locations:1- Lab139 (highly cluttered) 2- Corridor_rm155 (medium cluttered) [with wall from one side and windows from the other side].3- Main_Lobby (low cluttered) 4- Sports_Hall (open space).  The layout of the floor plan is shown in Floor_Plan.pdf where the red circle represents the transmitter and the green circle represent the receiver location. The square area was divided into uniform grids with a spacing of one wavelength (12.5 cm) that resulted in a total number of 196 points to capture the small-scale variations. The database was measured under a stationary scenario where there were no movements around the Tx/Rx at the time of measurements. This is achieved since the survey is conducted during low-activity time. This gives a total of 1960 samples because each point has 10 measurements.  In the case of Lab139 there is one set of measurements where the furthest point between the Tx/Rx is 7.1m and then the  receiver will moved across the uniform grid. This gives a total of 1960 points. In the case of Corridor_rm155 there are three set of measurements where the furthest point between Tx/Rx is 7.1m and this gives a total of 1960 points.In the case of Main_Lobby there are three set of measurements where the furthest point between Tx/Rx is 7.1m  and this gives a total of 1960 points. In the case of Sport_Hall there is one set of measurements where the furthest point between the Tx/Rx is 7.1m and this gives a total of 1960 points.  filename format (environment_Tx/Rx(separation)) i.e Corridor_rm155_7.1 : The environment is a narrow corridor with walls from one side and window from the other side and the Tx/Rx maximum separation is 7.1m and as the receiver is moved across the uniform grid it decreases. Each file will Loc_xxxx and this will resemble the location of the receiver and each location have ten measurements. The flow ofnumbers on the uniform grid is shown in Flow_of_Numbering.pdf---------------------------------------------------------------------------------------------------------------------Questions:Feel free to reach me at my email:malhajri '@' mit.edumialhajri1 '@' gmail.com---------------------------------------------------------------------------------------------------------------Citation:If you will use this dataset please cite the following document:1- First paper@inproceedings{alhajri2016classification,  title={Classification of indoor environments based on spatial correlation of rf channel fingerprints},  author={Alhajri, MI and Alsindi, N and Ali, NT and Shubair, RM},  booktitle={Antennas and Propagation (APSURSI), 2016 IEEE International Symposium on},  pages={1447--1448},  year={2016},}2- Second paper@article{alhajri2018classification,  title={Classification of Indoor Environments for IoT Applications: A Machine Learning Approach},  author={AlHajri, Mohamed Ibrahim and Ali, Nazar T and Shubair, Raed M},  journal={IEEE Antennas and Wireless Propagation Letters},  year={2018},  publisher={IEEE}}",Computer,This dataset have 5 attributes:1- Frequency2- Real part of S11 parameter3- Imaginary part of S11 parameter4- Real part of S21 parameter5- Imaginary part of S21 parameter,"Measurement of the S21,consists of 10 sweeps, each sweep contains 601 frequency points with spacing of 0.167MHz to cover a 100MHz band centered at 2.4GHz.Abstract: The frequency domain measurement of the scattering parameter, S21, of the wireless channel was carried out using the ZVB14 Vector Network Analyzer (VNA) from Rhode and Schwartz. The measurement system consists of the VNA, low loss RF cables, and omnidirectional antennas at the transmitter and receiver ends. The transmitter and receiver heights were fixed at 1.5 m. A program script was written for the VNA to measure 10 consecutive sweeps: each sweep contains 601 frequency sample points with spacing of 0.167 MHz to cover a 100 MHz band centered at 2.4 GHz. The settings provided a high time-domain resolution of 10 nsec (inverse of the bandwidth) and a time span of (0.167 MHz) = 5.99 ÃŽÂ¼sec . The measurements were designed to examine the WiFi bands specifically, channels 1, 6, and 11 in the IEEE 802.11 standard. The frequency domain channel measurements were conducted at Khalifa University campus in Sharjah, UAE. The measurements were done in 4 different locations:1- Lab139 (highly cluttered)2- Corridor_rm155 (medium cluttered) [with wall from one side and windows from the   other side].3- Main_Lobby (low cluttered)4- Sports_Hall (open space). Instructions: ---------------------------------------------------------------------------------------------------------------Details of the dataset:The frequency domain measurement of the scattering parameter, S21, of the wireless channel was carried out using the ZVB14 Vector Network Analyzer (VNA) from Rhode and Schwartz. The measurement system consists of the VNA, low loss RF cables, and omnidirectional antennas at the transmitter and receiver ends. The transmitter and receiver heights were fixed at 1.5 m. A program script was written for the VNA to measure 10 consecutive sweeps: each sweep contains 601 frequency sample points with spacing of 0.167 MHz to cover a 100 MHz band centered at 2.4 GHz. The settings provided a high time-domain resolution of 10 nsec (inverse of the bandwidth) and a time span of (0.167 MHz) = 5.99ÃŽÂ¼sec . The measurements were designed to examine the WiFi bands specifically, channels 1, 6, and 11 in the IEEE 802.11 standard. The frequency domain channel measurements were conducted at Khalifa University campus in Sharjah, UAE. The measurements were done in 4 different locations:1- Lab139 (highly cluttered) 2- Corridor_rm155 (medium cluttered) [with wall from one side and windows from the other side].3- Main_Lobby (low cluttered) 4- Sports_Hall (open space).  The layout of the floor plan is shown in Floor_Plan.pdf where the red circle represents the transmitter and the green circle represent the receiver location. The square area was divided into uniform grids with a spacing of one wavelength (12.5 cm) that resulted in a total number of 196 points to capture the small-scale variations. The database was measured under a stationary scenario where there were no movements around the Tx/Rx at the time of measurements. This is achieved since the survey is conducted during low-activity time. This gives a total of 1960 samples because each point has 10 measurements.  In the case of Lab139 there is one set of measurements where the furthest point between the Tx/Rx is 7.1m and then the  receiver will moved across the uniform grid. This gives a total of 1960 points. In the case of Corridor_rm155 there are three set of measurements where the furthest point between Tx/Rx is 7.1m and this gives a total of 1960 points.In the case of Main_Lobby there are three set of measurements where the furthest point between Tx/Rx is 7.1m  and this gives a total of 1960 points. In the case of Sport_Hall there is one set of measurements where the furthest point between the Tx/Rx is 7.1m and this gives a total of 1960 points.  filename format (environment_Tx/Rx(separation)) i.e Corridor_rm155_7.1 : The environment is a narrow corridor with walls from one side and window from the other side and the Tx/Rx maximum separation is 7.1m and as the receiver is moved across the uniform grid it decreases. Each file will Loc_xxxx and this will resemble the location of the receiver and each location have ten measurements. The flow ofnumbers on the uniform grid is shown in Flow_of_Numbering.pdf---------------------------------------------------------------------------------------------------------------------Questions:Feel free to reach me at my email:malhajri '@' mit.edumialhajri1 '@' gmail.com---------------------------------------------------------------------------------------------------------------Citation:If you will use this dataset please cite the following document:1- First paper@inproceedings{alhajri2016classification,  title={Classification of indoor environments based on spatial correlation of rf channel fingerprints},  author={Alhajri, MI and Alsindi, N and Ali, NT and Shubair, RM},  booktitle={Antennas and Propagation (APSURSI), 2016 IEEE International Symposium on},  pages={1447--1448},  year={2016},}2- Second paper@article{alhajri2018classification,  title={Classification of Indoor Environments for IoT Applications: A Machine Learning Approach},  author={AlHajri, Mohamed Ibrahim and Ali, Nazar T and Shubair, Raed M},  journal={IEEE Antennas and Wireless Propagation Letters},  year={2018},  publisher={IEEE}}This dataset have 5 attributes:1- Frequency2- Real part of S11 parameter3- Imaginary part of S11 parameter4- Real part of S21 parameter5- Imaginary part of S21 parameter"
Character Trajectories,Character Trajectories,"Multiple, labelled samples of pen tip trajectories recorded whilst writing individual characters. All samples are from the same writer, for the purposes of primitive extraction. Only characters with a single pen-down segment were considered.",Character+Trajectories,https://archive.ics.uci.edu/ml//machine-learning-databases/character-trajectories/,https://archive.ics.uci.edu/ml/datasets/Character+Trajectories,"The characters here were used for a PhD study on primitive extraction using HMM based models. The data consists of 2858 character samples, contained in the cell array 'mixout'. The struct variable 'consts' contains a field consts.charlabels which provides ennummerated labels for the characters. consts.key provides the key for each label. The data was captured using a WACOM tablet. 3 Dimensions were kept - x, y, and pen tip force. The data has been numerically differentiated and Gaussian smoothed, with a sigma value of 2. Data was captured at 200Hz. The data was normalised with consts.datanorm. Only characters with a single 'PEN-DOWN' segment were considered. Character segmentation was performed using a pen tip force cut-off point. The characters have also been shifted so that their velocity profiles best match the mean of the set.",Computer,"Each character sample is a 3-dimensional pen tip velocity trajectory. This is contained in matrix format, with 3 rows and T columns where T is the length of the character sample.","Multiple, labelled samples of pen tip trajectories recorded whilst writing individual characters. All samples are from the same writer, for the purposes of primitive extraction. Only characters with a single pen-down segment were considered.The characters here were used for a PhD study on primitive extraction using HMM based models. The data consists of 2858 character samples, contained in the cell array 'mixout'. The struct variable 'consts' contains a field consts.charlabels which provides ennummerated labels for the characters. consts.key provides the key for each label. The data was captured using a WACOM tablet. 3 Dimensions were kept - x, y, and pen tip force. The data has been numerically differentiated and Gaussian smoothed, with a sigma value of 2. Data was captured at 200Hz. The data was normalised with consts.datanorm. Only characters with a single 'PEN-DOWN' segment were considered. Character segmentation was performed using a pen tip force cut-off point. The characters have also been shifted so that their velocity profiles best match the mean of the set.Each character sample is a 3-dimensional pen tip velocity trajectory. This is contained in matrix format, with 3 rows and T columns where T is the length of the character sample."
Burst Header Packet (BHP) flooding attack on Optical Burst Switching (OBS) Network,Burst Header Packet (BHP) flooding attack on Optical Burst Switching (OBS) Network,One of the primary challenges in identifying the risks of the Burst Header Packet (BHP) flood attacks in Optical Burst Switching networks (OBS) is the scarcity of reliable historical data.  ,Burst+Header+Packet+%28BHP%29+flooding+attack+on+Optical+Burst+Switching+%28OBS%29+Network,https://archive.ics.uci.edu/ml//machine-learning-databases/00404/,https://archive.ics.uci.edu/ml/datasets/Burst+Header+Packet+%28BHP%29+flooding+attack+on+Optical+Burst+Switching+%28OBS%29+Network,For Further information about the variables see the file in the data folder.,Computer,"1. Node: This is the number of the sending node (numeric).2. Utilized Bandwidth Rate: This is the normalization of Ã¢â‚¬ËœUsed_BandidthÃ¢â‚¬â„¢ (numeric).3. Packet Drop Rate: This is the normalization of Ã¢â‚¬ËœPercentage_Of_Lost_Pcaket_RateÃ¢â‚¬â„¢ (numeric).4. Reserved_Bandwidth: Initial reserved Bandwidth assigned (given) to each node, the user (usr) in the experiments assign these values. (numeric).5. Average_Delay_Time_Per_Sec:  Average Delay Time (per second) for each node. This is (End-to End Delay). (numeric).6. Percentage_Of_Lost_Pcaket_Rate: Percentage of Packets Drop Rate for each node (numeric).7. Percentage_Of_Lost_Byte_Rate: Percentage of Lost Byte Rate for each node (numeric).8. Packet Received Rate: Total received packets (per second) for each node based on Ã¢â‚¬ËœReserved_BandwidthÃ¢â‚¬â„¢ (numeric).9. Used_Bandwidth: This is what each node could reserve from the Ã¢â‚¬ËœReserved_BandwidthÃ¢â‚¬â„¢ (numeric).10. Lost_Bandwidth: The amount of lost Bandwidth by each node from Ã¢â‚¬ËœReserved_BandwidthÃ¢â‚¬â„¢ (numeric).11. Packet Size_Byte: Packets size in Byte assigned specifically for each node to transmit. Note: 60 Byte will be added to the 1440 for the IP Header and the UDP Header ((Data size 1440 Byte) + (IP Header 40 Byte) + (UDP Header 20 Byte)) =1500 Byte (numeric).12. Packet_Transmitted: Total transmitted packets (per second) for each node based on the Ã¢â‚¬ËœReserved_BandwidthÃ¢â‚¬â„¢ (numeric).13. Packet_Received: Total received packets (per second) for each node based on the Ã¢â‚¬ËœReserved_BandwidthÃ¢â‚¬â„¢ (numeric).14. Packet_lost: Total lost packets (per second) for each node, which based on the Ã¢â‚¬ËœLost_BandwidthÃ¢â‚¬â„¢ (numeric).15. Transmitted_Byte: Total transmitted Byte (per second) for each node (numeric).16. Received_Byte: Total received Byte (per second) for each node based on the Ã¢â‚¬ËœReserved_BandwidthÃ¢â‚¬â„¢ (numeric).17. 10-Run-AVG-Drop-Rate: Average packet drop rate for 10 consecutive (run) iterations (numeric).18. 10-Run-AVG-Bandwidth-Use: Average Bandwidth utilized for 10 consecutive (run) iterations (numeric).19. 10-Run-Delay: Average delay time for 10 consecutive (run) iterations (numeric).20. Node Status' {B, NB, P NB}: initial classification of nodes based on Ã¢â‚¬ËœPacket Drop RateÃ¢â‚¬â„¢, Used_Bandwidth and Ã¢â‚¬ËœAverage_Delay_Time_Per_SecÃ¢â‚¬â„¢. B = Behaving, NB = Not Behaving and P NB = Potentially Not Behaving. (Categorical)21. Flood Status: Percentage of flood per node based on Ã¢â‚¬ËœPacket Drop RateÃ¢â‚¬â„¢ Medium and high level of BHP flood attack in case B (numeric).22. Class ' {NB-No Block, Block, No Block, NB-Wait}: The final classification of nodes based on Ã¢â‚¬ËœPacket Drop RateÃ¢â‚¬â„¢, Ã¢â‚¬ËœReserved_BandwidthÃ¢â‚¬â„¢, Ã¢â‚¬ËœIteration #Ã¢â‚¬â„¢, Ã¢â‚¬ËœUsed_BandwidthÃ¢â‚¬â„¢, Ã¢â‚¬ËœPacket Drop RateÃ¢â‚¬â„¢. This is for case B (Categorical ).","One of the primary challenges in identifying the risks of the Burst Header Packet (BHP) flood attacks in Optical Burst Switching networks (OBS) is the scarcity of reliable historical data.  For Further information about the variables see the file in the data folder.1. Node: This is the number of the sending node (numeric).2. Utilized Bandwidth Rate: This is the normalization of Ã¢â‚¬ËœUsed_BandidthÃ¢â‚¬â„¢ (numeric).3. Packet Drop Rate: This is the normalization of Ã¢â‚¬ËœPercentage_Of_Lost_Pcaket_RateÃ¢â‚¬â„¢ (numeric).4. Reserved_Bandwidth: Initial reserved Bandwidth assigned (given) to each node, the user (usr) in the experiments assign these values. (numeric).5. Average_Delay_Time_Per_Sec:  Average Delay Time (per second) for each node. This is (End-to End Delay). (numeric).6. Percentage_Of_Lost_Pcaket_Rate: Percentage of Packets Drop Rate for each node (numeric).7. Percentage_Of_Lost_Byte_Rate: Percentage of Lost Byte Rate for each node (numeric).8. Packet Received Rate: Total received packets (per second) for each node based on Ã¢â‚¬ËœReserved_BandwidthÃ¢â‚¬â„¢ (numeric).9. Used_Bandwidth: This is what each node could reserve from the Ã¢â‚¬ËœReserved_BandwidthÃ¢â‚¬â„¢ (numeric).10. Lost_Bandwidth: The amount of lost Bandwidth by each node from Ã¢â‚¬ËœReserved_BandwidthÃ¢â‚¬â„¢ (numeric).11. Packet Size_Byte: Packets size in Byte assigned specifically for each node to transmit. Note: 60 Byte will be added to the 1440 for the IP Header and the UDP Header ((Data size 1440 Byte) + (IP Header 40 Byte) + (UDP Header 20 Byte)) =1500 Byte (numeric).12. Packet_Transmitted: Total transmitted packets (per second) for each node based on the Ã¢â‚¬ËœReserved_BandwidthÃ¢â‚¬â„¢ (numeric).13. Packet_Received: Total received packets (per second) for each node based on the Ã¢â‚¬ËœReserved_BandwidthÃ¢â‚¬â„¢ (numeric).14. Packet_lost: Total lost packets (per second) for each node, which based on the Ã¢â‚¬ËœLost_BandwidthÃ¢â‚¬â„¢ (numeric).15. Transmitted_Byte: Total transmitted Byte (per second) for each node (numeric).16. Received_Byte: Total received Byte (per second) for each node based on the Ã¢â‚¬ËœReserved_BandwidthÃ¢â‚¬â„¢ (numeric).17. 10-Run-AVG-Drop-Rate: Average packet drop rate for 10 consecutive (run) iterations (numeric).18. 10-Run-AVG-Bandwidth-Use: Average Bandwidth utilized for 10 consecutive (run) iterations (numeric).19. 10-Run-Delay: Average delay time for 10 consecutive (run) iterations (numeric).20. Node Status' {B, NB, P NB}: initial classification of nodes based on Ã¢â‚¬ËœPacket Drop RateÃ¢â‚¬â„¢, Used_Bandwidth and Ã¢â‚¬ËœAverage_Delay_Time_Per_SecÃ¢â‚¬â„¢. B = Behaving, NB = Not Behaving and P NB = Potentially Not Behaving. (Categorical)21. Flood Status: Percentage of flood per node based on Ã¢â‚¬ËœPacket Drop RateÃ¢â‚¬â„¢ Medium and high level of BHP flood attack in case B (numeric).22. Class ' {NB-No Block, Block, No Block, NB-Wait}: The final classification of nodes based on Ã¢â‚¬ËœPacket Drop RateÃ¢â‚¬â„¢, Ã¢â‚¬ËœReserved_BandwidthÃ¢â‚¬â„¢, Ã¢â‚¬ËœIteration #Ã¢â‚¬â„¢, Ã¢â‚¬ËœUsed_BandwidthÃ¢â‚¬â„¢, Ã¢â‚¬ËœPacket Drop RateÃ¢â‚¬â„¢. This is for case B (Categorical )."
Discrete Tone Image Dataset,Discrete Tone Image Dataset,"Discrete Tone Images(DTI)are available which needs to be analyzed in detail. Here, we created this dataset for those who do research in DTI. 
",Discrete+Tone+Image+Dataset,https://archive.ics.uci.edu/ml//machine-learning-databases/00431/,https://archive.ics.uci.edu/ml/datasets/Discrete+Tone+Image+Dataset,This dataset contains a total of 71 images including 11 types of images with its distorted versions. Each and every image has its own uniqueness of discrete tone image properties. ,Computer,Types of Images1.System Generated DTI by setting distinct pixel values 2.Discrete Pixel Logo 3.Business Charts4.Bi-Level 5.Part of Discrete Information from an Continuous ImageColorspace models1.RGB 2.Grayscale 3.Binary Distortion Types1.JPEG2.Gaussian White Noise (GWN)3.Salt and Pepper noise (SP)4.Multiplicative Speckle Noise (MSN)5.Poisson Noise (PN),"Discrete Tone Images(DTI)are available which needs to be analyzed in detail. Here, we created this dataset for those who do research in DTI. 
This dataset contains a total of 71 images including 11 types of images with its distorted versions. Each and every image has its own uniqueness of discrete tone image properties. Types of Images1.System Generated DTI by setting distinct pixel values 2.Discrete Pixel Logo 3.Business Charts4.Bi-Level 5.Part of Discrete Information from an Continuous ImageColorspace models1.RGB 2.Grayscale 3.Binary Distortion Types1.JPEG2.Gaussian White Noise (GWN)3.Salt and Pepper noise (SP)4.Multiplicative Speckle Noise (MSN)5.Poisson Noise (PN)"
Dishonest Internet users Dataset,Dishonest Internet users Dataset,The dataset was used to test an architecture based on a trust model capable to cope with the evaluation of the trustworthiness of users interacting in pervasive environments.,Dishonest+Internet+users+Dataset,https://archive.ics.uci.edu/ml//machine-learning-databases/00453/,https://archive.ics.uci.edu/ml/datasets/Dishonest+Internet+users+Dataset,"In pervasive computing the interacting users are not able to obtain information about the trustworthiness of each other. Thus, unfair users can act maliciously towards others. The proposed solution enables to evaluate the trustworthiness of each user by monitoring the behavior of each other during their interaction on the network. These behaviors are represented by tuples including significant parameters. Based on these tuples, the architecture combines some artificial intelligence-based technologies to implement a decision making system.The tuples are as follows:eij = where:eij - i-th entity interacting with j-th entity.EIDj - j-th entity IdentificationCT - Counting Trust. It is used to count how many trustworthy transactions (belonging to a specific context) occur after the last untrustworthy transaction.CU - Counting Un-trust. It is used to count how many untrustworthy transactions (belonging to a specific context) occur after the last trustworthy transaction.LT - Last Time. It is used to take into account of the date at which the last experience in a specific context took place.TC - Transactions Context. It is used to identify the type of transaction, such as game, e-commerce, social network and others.TS - Trust Score. It  is the score that an entity gives to another entity at the end of each direct interaction.The data set was obtained by a Java simulator which implemented the proposed architecture.It includes data for the three most popular types of attack, namely:- Counting-based attack. The user tries to gain a good reputation by alternating the honest and dishonest behavior.- Time-based attack. User again tries to gain a good reputation by alternating the honest and dishonest behavior, but acts in different time.- Context-based attack. R tries to gain a good reputation by acting honestly for a type of transaction and dishonestly for another one.Because EIDj parameters are not relevant for the decision-making process, only the following parameters were reported in the dataset:- CT- CU- LT- TC- TSBecause, there could be situation in which users have not historical data (tuples) for interacting with another one, it may get data (tuples) from third-parties who previously have had interaction with the inquired user.Nevertheless, the trustworthiness of such third party entities (recommenders) needs to be evaluated also. Indeed, they may act through attacks, such as: Ballot Stuffing (BS), Bad mouthing , and Random opinion (RO).Changing of the TS parameter for a number of rows in the dataset, and in according to a specific attack, allows to obtain different datasets useful for the recommenders trustworthiness evaluation.According to this, the following datasets are also provided:- BM_x%.txt  x is the percentage of unfair recommendations obtained by a BM attack. It ranges from 10 to 50.- BS_x%.txt  x is the percentage of unfair recommendations obtained by a BS attack. It ranges from 10 to 50.- RO_x%.txt  x is the percentage of unfair recommendations obtained by a BM attack. It ranges from 10 to 50.",Computer,"1) CT {CT_range_1, CT_range_2, CT_range_3, CT_range_4}2) CU {CU_range_1, CU_range_2, CU_range_3, CU_range_4}3) LT {LT_range_1, LT_range_2, LT_range_3, LT_range_4}4) TC {sport, game, ECommerce, holiday}5) TS {trustworthy, untrustworthy}The numerical attributes (CT, CU, LT) was discretized.Several of the papers listed below contain detailed descriptions of how these attributes were discretized.","The dataset was used to test an architecture based on a trust model capable to cope with the evaluation of the trustworthiness of users interacting in pervasive environments.In pervasive computing the interacting users are not able to obtain information about the trustworthiness of each other. Thus, unfair users can act maliciously towards others. The proposed solution enables to evaluate the trustworthiness of each user by monitoring the behavior of each other during their interaction on the network. These behaviors are represented by tuples including significant parameters. Based on these tuples, the architecture combines some artificial intelligence-based technologies to implement a decision making system.The tuples are as follows:eij = where:eij - i-th entity interacting with j-th entity.EIDj - j-th entity IdentificationCT - Counting Trust. It is used to count how many trustworthy transactions (belonging to a specific context) occur after the last untrustworthy transaction.CU - Counting Un-trust. It is used to count how many untrustworthy transactions (belonging to a specific context) occur after the last trustworthy transaction.LT - Last Time. It is used to take into account of the date at which the last experience in a specific context took place.TC - Transactions Context. It is used to identify the type of transaction, such as game, e-commerce, social network and others.TS - Trust Score. It  is the score that an entity gives to another entity at the end of each direct interaction.The data set was obtained by a Java simulator which implemented the proposed architecture.It includes data for the three most popular types of attack, namely:- Counting-based attack. The user tries to gain a good reputation by alternating the honest and dishonest behavior.- Time-based attack. User again tries to gain a good reputation by alternating the honest and dishonest behavior, but acts in different time.- Context-based attack. R tries to gain a good reputation by acting honestly for a type of transaction and dishonestly for another one.Because EIDj parameters are not relevant for the decision-making process, only the following parameters were reported in the dataset:- CT- CU- LT- TC- TSBecause, there could be situation in which users have not historical data (tuples) for interacting with another one, it may get data (tuples) from third-parties who previously have had interaction with the inquired user.Nevertheless, the trustworthiness of such third party entities (recommenders) needs to be evaluated also. Indeed, they may act through attacks, such as: Ballot Stuffing (BS), Bad mouthing , and Random opinion (RO).Changing of the TS parameter for a number of rows in the dataset, and in according to a specific attack, allows to obtain different datasets useful for the recommenders trustworthiness evaluation.According to this, the following datasets are also provided:- BM_x%.txt  x is the percentage of unfair recommendations obtained by a BM attack. It ranges from 10 to 50.- BS_x%.txt  x is the percentage of unfair recommendations obtained by a BS attack. It ranges from 10 to 50.- RO_x%.txt  x is the percentage of unfair recommendations obtained by a BM attack. It ranges from 10 to 50.1) CT {CT_range_1, CT_range_2, CT_range_3, CT_range_4}2) CU {CU_range_1, CU_range_2, CU_range_3, CU_range_4}3) LT {LT_range_1, LT_range_2, LT_range_3, LT_range_4}4) TC {sport, game, ECommerce, holiday}5) TS {trustworthy, untrustworthy}The numerical attributes (CT, CU, LT) was discretized.Several of the papers listed below contain detailed descriptions of how these attributes were discretized."
BLOGGER,BLOGGER,"In this paper, we look for to recognize the causes of users tend
to cyber space in Kohkiloye and Boyer Ahmad Province in
Iran",BLOGGER,https://archive.ics.uci.edu/ml//machine-learning-databases/00255/,https://archive.ics.uci.edu/ml/datasets/BLOGGER,"In this paper, we look for to recognize the causes of users tendto cyber space in Kohkiloye and Boyer Ahmad Province inIran. Collecting information to form database is done byquestionnaire. This questionnaire is provided as oral, writtenand also programming of a website which includes an internetquestionnaire and the users can answer the questions as theywish. They entered their used websites, blogs and socialnetworks during the day.After collecting questionnaires, the wed addresses aregathered to get expected results. And finally, their trustfulnessis checked by analyzing their used web pages. As the resultswere same, for getting better and noiseless response, they willput in database",Computer,"We considered the following parameters as questions: age,education, political attitudes, blog topic, and the type of theidentity in internet, the influence of managersÃ¢â‚¬â„¢ inefficiency ontendency, the effect of inefficient media on tendency, theeffects of social and political conditions on tendency andfinally the effect of poverty in the province on tendency. Thenoisy or too detailed data in database makes us far from to getproper and suitable answers of algorithms [8]. We preprocessedthe data and eliminated some non-relevant data.Finally the followings are considered as the main fields whichinclude: education, political caprice, topics, local mediaturnover (LMT) and local, political and social space (LPSS).The collected data are shown in Table 1.In order to get correct answer, we classify bloggers to twogroups: professional bloggers and seasonal (temporary)bloggers. Professional bloggers are those who adopt blog asan effective digital media and interested in digital writing incontinuous time intervals. Seasonal (temporary) bloggersarenÃ¢â‚¬â„¢t professional and follow blogging in discrete timeperiods. In this study, we review the tendency factorsconsidering whether these people are among professionalbloggers (Pro Bloggers, PB) and then, consider the otherfactors according to it.","In this paper, we look for to recognize the causes of users tend
to cyber space in Kohkiloye and Boyer Ahmad Province in
IranIn this paper, we look for to recognize the causes of users tendto cyber space in Kohkiloye and Boyer Ahmad Province inIran. Collecting information to form database is done byquestionnaire. This questionnaire is provided as oral, writtenand also programming of a website which includes an internetquestionnaire and the users can answer the questions as theywish. They entered their used websites, blogs and socialnetworks during the day.After collecting questionnaires, the wed addresses aregathered to get expected results. And finally, their trustfulnessis checked by analyzing their used web pages. As the resultswere same, for getting better and noiseless response, they willput in databaseWe considered the following parameters as questions: age,education, political attitudes, blog topic, and the type of theidentity in internet, the influence of managersÃ¢â‚¬â„¢ inefficiency ontendency, the effect of inefficient media on tendency, theeffects of social and political conditions on tendency andfinally the effect of poverty in the province on tendency. Thenoisy or too detailed data in database makes us far from to getproper and suitable answers of algorithms [8]. We preprocessedthe data and eliminated some non-relevant data.Finally the followings are considered as the main fields whichinclude: education, political caprice, topics, local mediaturnover (LMT) and local, political and social space (LPSS).The collected data are shown in Table 1.In order to get correct answer, we classify bloggers to twogroups: professional bloggers and seasonal (temporary)bloggers. Professional bloggers are those who adopt blog asan effective digital media and interested in digital writing incontinuous time intervals. Seasonal (temporary) bloggersarenÃ¢â‚¬â„¢t professional and follow blogging in discrete timeperiods. In this study, we review the tendency factorsconsidering whether these people are among professionalbloggers (Pro Bloggers, PB) and then, consider the otherfactors according to it."
BLE RSSI Dataset for Indoor localization and Navigation,BLE RSSI Dataset for Indoor localization and Navigation,This dataset contains RSSI readings gathered from an array of Bluetooth Low Energy (BLE) iBeacons in a real-world and operational indoor environment for localization and navigation purposes.,BLE+RSSI+Dataset+for+Indoor+localization+and+Navigation,https://archive.ics.uci.edu/ml//machine-learning-databases/00435/,https://archive.ics.uci.edu/ml/datasets/BLE+RSSI+Dataset+for+Indoor+localization+and+Navigation,"The dataset was created using the RSSI readings of an array of 13 ibeacons in the first floor of Waldo Library, Western Michigan University. Data was collected using iPhone 6S. The dataset contains two sub-datasets: a labeled dataset (1420 instances) and an unlabeled dataset (5191 instances). The recording was performed during the operational hours of the library. For the labeled dataset, the input data contains the location (label column), a timestamp, followed by RSSI readings of 13 iBeacons. RSSI measurements are negative values. Bigger RSSI values indicate closer proximity to a given iBeacon (e.g., RSSI of -65 represent a closer distance to a given iBeacon compared to RSSI of -85). For out-of-range iBeacons, the RSSI is indicated by -200. The locations related to RSSI readings are combined in one column consisting a letter for the column and a number for the row of the position. The attached figure depicts the layout of the iBeacons as well as the arrange of locations.   ",Computer,"location: The location of receiving RSSIs from ibeacons b3001 to b3013; symbolic values showing the column and row of the location on the map (e.g., A01 stands for column A, row 1).Date: Datetime in the format of Ã¢â‚¬Ëœd-m-yyyy hh:mm:ssÃ¢â‚¬â„¢b3001 - b3013: RSSI readings corresponding to the iBeacons; numeric, integers only.","This dataset contains RSSI readings gathered from an array of Bluetooth Low Energy (BLE) iBeacons in a real-world and operational indoor environment for localization and navigation purposes.The dataset was created using the RSSI readings of an array of 13 ibeacons in the first floor of Waldo Library, Western Michigan University. Data was collected using iPhone 6S. The dataset contains two sub-datasets: a labeled dataset (1420 instances) and an unlabeled dataset (5191 instances). The recording was performed during the operational hours of the library. For the labeled dataset, the input data contains the location (label column), a timestamp, followed by RSSI readings of 13 iBeacons. RSSI measurements are negative values. Bigger RSSI values indicate closer proximity to a given iBeacon (e.g., RSSI of -65 represent a closer distance to a given iBeacon compared to RSSI of -85). For out-of-range iBeacons, the RSSI is indicated by -200. The locations related to RSSI readings are combined in one column consisting a letter for the column and a number for the row of the position. The attached figure depicts the layout of the iBeacons as well as the arrange of locations.   location: The location of receiving RSSIs from ibeacons b3001 to b3013; symbolic values showing the column and row of the location on the map (e.g., A01 stands for column A, row 1).Date: Datetime in the format of Ã¢â‚¬Ëœd-m-yyyy hh:mm:ssÃ¢â‚¬â„¢b3001 - b3013: RSSI readings corresponding to the iBeacons; numeric, integers only."
BitcoinHeistRansomwareAddressDataset,BitcoinHeistRansomwareAddressDataset,BitcoinHeist datasets contains address features on the heterogeneous Bitcoin network to identify ransomware payments.,BitcoinHeistRansomwareAddressDataset,https://archive.ics.uci.edu/ml//machine-learning-databases/00526/,https://archive.ics.uci.edu/ml/datasets/BitcoinHeistRansomwareAddressDataset,"We have downloaded and parsed the entire Bitcoin transaction graph from 2009 January to 2018 December. Using a time interval of 24 hours, we extracted daily transactions on the network and formed the Bitcoin graph. We filtered out the network edges that transfer less than B0.3, since ransom amounts are rarely below this threshold.Ransomware addresses are taken from three widely adopted studies: Montreal, Princeton and Padua. Please see the BitcoinHeist article for references.",Computer,"Featuresaddress: String. Bitcoin address.year: Integer. Year.day: Integer. Day of the year. 1 is the first day, 365 is the last day.length: Integer.weight: Float.count: Integer.looped: Integer.neighbors: Integer.income: Integer. Satoshi amount (1 bitcoin = 100 million satoshis).label: Category String. Name of the ransomware family (e.g., Cryptxxx, cryptolocker etc) or white (i.e., not known to be ransomware).Our graph features are designed to quantify specific transaction patterns. Loop is intended to count how many transaction i) split their coins; ii) move these coins in the network by using different paths and finally, and iii) merge them in a single address. Coins at this final address can then be sold and converted to fiat currency. Weight quantifies the merge behavior (i.e., the transaction has more input addresses than output addresses), where coins in multiple addresses are each passed through a succession of merging transactions and accumulated in a final address. Similar to weight, the count feature is designed to quantify the merging pattern. However, the count feature represents information on the number of transactions, whereas the weight feature represents information on the amount (what percent of these transactionsÃ¢â‚¬â„¢ output?) of transactions. Length is designed to quantify mixing rounds on Bitcoin, where transactions receive and distribute similar amounts of coins in multiple rounds with newly created addresses to hide the coin origin.White Bitcoin addresses are capped at 1K per day (Bitcoin has 800K addresses daily).Note that although we are certain about ransomware labels, we do not know if all white addresses are in fact not related to ransomware.When compared to non-ransomware addresses, ransomware addresses exhibit more profound right skewness in distributions of feature values.","BitcoinHeist datasets contains address features on the heterogeneous Bitcoin network to identify ransomware payments.We have downloaded and parsed the entire Bitcoin transaction graph from 2009 January to 2018 December. Using a time interval of 24 hours, we extracted daily transactions on the network and formed the Bitcoin graph. We filtered out the network edges that transfer less than B0.3, since ransom amounts are rarely below this threshold.Ransomware addresses are taken from three widely adopted studies: Montreal, Princeton and Padua. Please see the BitcoinHeist article for references.Featuresaddress: String. Bitcoin address.year: Integer. Year.day: Integer. Day of the year. 1 is the first day, 365 is the last day.length: Integer.weight: Float.count: Integer.looped: Integer.neighbors: Integer.income: Integer. Satoshi amount (1 bitcoin = 100 million satoshis).label: Category String. Name of the ransomware family (e.g., Cryptxxx, cryptolocker etc) or white (i.e., not known to be ransomware).Our graph features are designed to quantify specific transaction patterns. Loop is intended to count how many transaction i) split their coins; ii) move these coins in the network by using different paths and finally, and iii) merge them in a single address. Coins at this final address can then be sold and converted to fiat currency. Weight quantifies the merge behavior (i.e., the transaction has more input addresses than output addresses), where coins in multiple addresses are each passed through a succession of merging transactions and accumulated in a final address. Similar to weight, the count feature is designed to quantify the merging pattern. However, the count feature represents information on the number of transactions, whereas the weight feature represents information on the amount (what percent of these transactionsÃ¢â‚¬â„¢ output?) of transactions. Length is designed to quantify mixing rounds on Bitcoin, where transactions receive and distribute similar amounts of coins in multiple rounds with newly created addresses to hide the coin origin.White Bitcoin addresses are capped at 1K per day (Bitcoin has 800K addresses daily).Note that although we are certain about ransomware labels, we do not know if all white addresses are in fact not related to ransomware.When compared to non-ransomware addresses, ransomware addresses exhibit more profound right skewness in distributions of feature values."
Dresses_Attribute_Sales,Dresses_Attribute_Sales,This dataset contain Attributes of dresses and their recommendations according to their sales.Sales are monitor on the basis of alternate days. ,Dresses_Attribute_Sales,https://archive.ics.uci.edu/ml//machine-learning-databases/00289/,https://archive.ics.uci.edu/ml/datasets/Dresses_Attribute_Sales,"Style,	Price,	Rating,	Size,	Season,	NeckLine,	SleeveLength,	waiseline,	Material,	FabricType,	Decoration,	Pattern, Type,	Recommendation are Attributes in dataset.",Computer,"Style: Bohemia,brief,casual,cute,fashion,flare,novelty,OL,party,sexy,vintage,work.Price:Low,Average,Medium,High,Very-HighRating:1-5Size:S,M,L,XL,Free	Season:Autumn,winter,Spring,SummerNeckLine:O-neck,backless,board-neck,Bowneck,halter,mandarin-collor,open,peterpan-collor,ruffled,scoop,slash-neck,square-collar,sweetheart,turndowncollar,V-neck.SleeveLength:full,half,halfsleeves,butterfly,sleveless,short,threequarter,turndown,nullwaiseline:dropped,empire,natural,princess,null.	Material:wool,cotton,mix etc	FabricType:shafoon,dobby,popline,satin,knitted,jersey,flannel,corduroy etcDecoration:applique,beading,bow,button,cascading,crystal,draped,embroridary,feathers,flowers etcPattern type: solid,animal,dot,leapard etcRecommendation:0,1","This dataset contain Attributes of dresses and their recommendations according to their sales.Sales are monitor on the basis of alternate days. Style,	Price,	Rating,	Size,	Season,	NeckLine,	SleeveLength,	waiseline,	Material,	FabricType,	Decoration,	Pattern, Type,	Recommendation are Attributes in dataset.Style: Bohemia,brief,casual,cute,fashion,flare,novelty,OL,party,sexy,vintage,work.Price:Low,Average,Medium,High,Very-HighRating:1-5Size:S,M,L,XL,Free	Season:Autumn,winter,Spring,SummerNeckLine:O-neck,backless,board-neck,Bowneck,halter,mandarin-collor,open,peterpan-collor,ruffled,scoop,slash-neck,square-collar,sweetheart,turndowncollar,V-neck.SleeveLength:full,half,halfsleeves,butterfly,sleveless,short,threequarter,turndown,nullwaiseline:dropped,empire,natural,princess,null.	Material:wool,cotton,mix etc	FabricType:shafoon,dobby,popline,satin,knitted,jersey,flannel,corduroy etcDecoration:applique,beading,bow,button,cascading,crystal,draped,embroridary,feathers,flowers etcPattern type: solid,animal,dot,leapard etcRecommendation:0,1"
DrivFace,DrivFace,"The DrivFace contains images sequences of subjects while driving in real scenarios. It is composed of 606 samples of 640Ã—480, acquired over different days from 4 drivers with several facial features.",DrivFace,https://archive.ics.uci.edu/ml//machine-learning-databases/00378/,https://archive.ics.uci.edu/ml/datasets/DrivFace,"The DrivFace database contains images sequences of subjects while driving in real scenarios. It is composed of 606 samples of 640Ãƒâ€”480 pixels each, acquired over different days from 4 drivers (2 women and 2 men) with several facial features like glasses and beard.Additional files:drivFace.mat contains the dataset in Matlab (under prtools library) with the driver faces normalised to 80x80 pixels each and their associated gaze direction labels Ã¢â‚¬Å“looking-rightÃ¢â‚¬Â�, Ã¢â‚¬Å“frontalÃ¢â‚¬Â� and  Ã¢â‚¬Å“looking-leftÃ¢â‚¬Â�.",Computer,"The ground truth contains the annotation of the face bounding box and the facial key points (eyes, nose and mouth). A set of labels assigning each image into 3 possible gaze direction classes are given. The first class is the Ã¢â‚¬Å“looking-rightÃ¢â‚¬Â� class and contains the head angles between -45Ã‚Âº and -30Ã‚Âº. The second one is the Ã¢â‚¬Å“frontalÃ¢â‚¬Â� class and contains the head angles between -15Ã‚Âº and 15Ã‚Âº. The last one is the Ã¢â‚¬Å“looking-leftÃ¢â‚¬Â� class and contains the head angles between 30Ã‚Âº and 45Ã‚Âº. Files and scriptsÃ¢â‚¬Â¢ DrivImages.zip has the driver images. The imag's name has the format:    * YearMonthDay_subject_Driv_imNum_HeadPose.jpg i.e. 20130529_01_Driv_011_f .jpg is a frame of the fisrts driver corresponding to the 11 sequence's image and the head pose is frontal.subject = [1:4], imNum = [001:...], HeadPose = lr (looking-right), f (frontal) and lf (looking-left).  Ã¢â‚¬Â¢ drivPoints.txt contains the ground truth in table's format, where the columns have the follow information:    * fileName is the imagen's name into DrivImages.zip    * subject = [1:4]    * imgNum  = int    * label   = [1/2/3] (head pose class that corresponding to [lr/f/lf], respectively)     * ang     = [-45, -30/ -15 0 15/ 30 15] (head pose angle)    * [xF yF wF hF] = face position     * [xRE yRE]     = rigth eye position     * [xLE yL]      = left eye position     * [xN yN]       = Nose position     * [xRM yRM]     = rigth corner of mouth    * [xLM yLM]     = left corner of mouth   Ã¢â‚¬Â¢ read_drivPoints.m is a Matlab function to read the drivPoints file. You can also use:    * Table = readtable('drivPoints.txt');Ã¢â‚¬Â¢ drivFace.mat contains the dataset in Matlab (under prtools library) with the driver faces normalised to 80x80 pixels each and their associated gaze direction labels Ã¢â‚¬Å“looking-rightÃ¢â‚¬Â�, Ã¢â‚¬Å“frontalÃ¢â‚¬Â� and  Ã¢â‚¬Å“looking-leftÃ¢â‚¬Â�.","The DrivFace contains images sequences of subjects while driving in real scenarios. It is composed of 606 samples of 640Ã—480, acquired over different days from 4 drivers with several facial features.The DrivFace database contains images sequences of subjects while driving in real scenarios. It is composed of 606 samples of 640Ãƒâ€”480 pixels each, acquired over different days from 4 drivers (2 women and 2 men) with several facial features like glasses and beard.Additional files:drivFace.mat contains the dataset in Matlab (under prtools library) with the driver faces normalised to 80x80 pixels each and their associated gaze direction labels Ã¢â‚¬Å“looking-rightÃ¢â‚¬Â�, Ã¢â‚¬Å“frontalÃ¢â‚¬Â� and  Ã¢â‚¬Å“looking-leftÃ¢â‚¬Â�.The ground truth contains the annotation of the face bounding box and the facial key points (eyes, nose and mouth). A set of labels assigning each image into 3 possible gaze direction classes are given. The first class is the Ã¢â‚¬Å“looking-rightÃ¢â‚¬Â� class and contains the head angles between -45Ã‚Âº and -30Ã‚Âº. The second one is the Ã¢â‚¬Å“frontalÃ¢â‚¬Â� class and contains the head angles between -15Ã‚Âº and 15Ã‚Âº. The last one is the Ã¢â‚¬Å“looking-leftÃ¢â‚¬Â� class and contains the head angles between 30Ã‚Âº and 45Ã‚Âº. Files and scriptsÃ¢â‚¬Â¢ DrivImages.zip has the driver images. The imag's name has the format:    * YearMonthDay_subject_Driv_imNum_HeadPose.jpg i.e. 20130529_01_Driv_011_f .jpg is a frame of the fisrts driver corresponding to the 11 sequence's image and the head pose is frontal.subject = [1:4], imNum = [001:...], HeadPose = lr (looking-right), f (frontal) and lf (looking-left).  Ã¢â‚¬Â¢ drivPoints.txt contains the ground truth in table's format, where the columns have the follow information:    * fileName is the imagen's name into DrivImages.zip    * subject = [1:4]    * imgNum  = int    * label   = [1/2/3] (head pose class that corresponding to [lr/f/lf], respectively)     * ang     = [-45, -30/ -15 0 15/ 30 15] (head pose angle)    * [xF yF wF hF] = face position     * [xRE yRE]     = rigth eye position     * [xLE yL]      = left eye position     * [xN yN]       = Nose position     * [xRM yRM]     = rigth corner of mouth    * [xLM yLM]     = left corner of mouth   Ã¢â‚¬Â¢ read_drivPoints.m is a Matlab function to read the drivPoints file. You can also use:    * Table = readtable('drivPoints.txt');Ã¢â‚¬Â¢ drivFace.mat contains the dataset in Matlab (under prtools library) with the driver faces normalised to 80x80 pixels each and their associated gaze direction labels Ã¢â‚¬Å“looking-rightÃ¢â‚¬Â�, Ã¢â‚¬Å“frontalÃ¢â‚¬Â� and  Ã¢â‚¬Å“looking-leftÃ¢â‚¬Â�."
Behavior of the urban traffic of the city of Sao Paulo in Brazil,Behavior of the urban traffic of the city of Sao Paulo in Brazil,The database was created with records of behavior of the urban traffic of the city of Sao Paulo in Brazil.,Behavior+of+the+urban+traffic+of+the+city+of+Sao+Paulo+in+Brazil,https://archive.ics.uci.edu/ml//machine-learning-databases/00483/,https://archive.ics.uci.edu/ml/datasets/Behavior+of+the+urban+traffic+of+the+city+of+Sao+Paulo+in+Brazil,"The database was created with records of behavior of the urban traffic of the city of Sao Paulo in Brazil from December 14, 2009 to December 18, 2009 (From Monday to Friday). Registered from 7:00 to 20:00 every 30 minutes. The data set Behavior of the urban traffic of the city of Sao Paulo in Brazil was used in academic research at the Universidade Nove de Julho - Postgraduate Program in Informatics and Knowledge Management.",Computer,"1.	Hour2.	Immobilized bus3.	Broken Truck4.	Vehicle excess5.	Accident victim6.	Running over7.	Fire Vehicles8.	Occurrence involving freight9.	Incident involving dangerous freight10.	Lack of electricity11.	Fire12.	Point of flooding13.	Manifestations14.	Defect in the network of trolleybuses15.	Tree on the road16.	Semaphore off17.	Intermittent Semaphore18.	Slowness in traffic (%) (Target).arff header for Weka: @relation Behavior@attribute Hour {7:00, 7:30, 8:00, 8:30, 9:00, 9:30, 10:00, 10:30, 11:00, 11:30, 12:00, 12:30, 13:00, 13:30, 14:00, 14:30, 15:00, 15:30, 16:00, 16:30, 17:00, 17:30, 18:00, 18:30, 19:00, 19:30, 20:00}@attribute Immobilized_bus INTEGER@attribute Broken_Truck INTEGER@attribute Vehicle_excess INTEGER@attribute Accident_victim INTEGER@attribute Running_over INTEGER@attribute Fire_vehicles INTEGER@attribute Occurrence_involving_freight INTEGER@attribute Incident_involving_dangerous_freight INTEGER@attribute Lack_of_electricity INTEGER@attribute Fire INTEGER@attribute Point_of_flooding INTEGER@attribute Manifestations INTEGER@attribute Defect_in_the_network_of_trolleybuses INTEGER@attribute Tree_on_the_road INTEGER@attribute Semaphore_off INTEGER@attribute Intermittent_Semaphore INTEGER@attribute Slowness_in_traffic_percent REAL","The database was created with records of behavior of the urban traffic of the city of Sao Paulo in Brazil.The database was created with records of behavior of the urban traffic of the city of Sao Paulo in Brazil from December 14, 2009 to December 18, 2009 (From Monday to Friday). Registered from 7:00 to 20:00 every 30 minutes. The data set Behavior of the urban traffic of the city of Sao Paulo in Brazil was used in academic research at the Universidade Nove de Julho - Postgraduate Program in Informatics and Knowledge Management.1.	Hour2.	Immobilized bus3.	Broken Truck4.	Vehicle excess5.	Accident victim6.	Running over7.	Fire Vehicles8.	Occurrence involving freight9.	Incident involving dangerous freight10.	Lack of electricity11.	Fire12.	Point of flooding13.	Manifestations14.	Defect in the network of trolleybuses15.	Tree on the road16.	Semaphore off17.	Intermittent Semaphore18.	Slowness in traffic (%) (Target).arff header for Weka: @relation Behavior@attribute Hour {7:00, 7:30, 8:00, 8:30, 9:00, 9:30, 10:00, 10:30, 11:00, 11:30, 12:00, 12:30, 13:00, 13:30, 14:00, 14:30, 15:00, 15:30, 16:00, 16:30, 17:00, 17:30, 18:00, 18:30, 19:00, 19:30, 20:00}@attribute Immobilized_bus INTEGER@attribute Broken_Truck INTEGER@attribute Vehicle_excess INTEGER@attribute Accident_victim INTEGER@attribute Running_over INTEGER@attribute Fire_vehicles INTEGER@attribute Occurrence_involving_freight INTEGER@attribute Incident_involving_dangerous_freight INTEGER@attribute Lack_of_electricity INTEGER@attribute Fire INTEGER@attribute Point_of_flooding INTEGER@attribute Manifestations INTEGER@attribute Defect_in_the_network_of_trolleybuses INTEGER@attribute Tree_on_the_road INTEGER@attribute Semaphore_off INTEGER@attribute Intermittent_Semaphore INTEGER@attribute Slowness_in_traffic_percent REAL"
BAUM-2,BAUM-2,A multilingual audio-visual affective face database consisting of 1047 video clips of 286 subjects. ,BAUM-2,https://archive.ics.uci.edu/ml//machine-learning-databases/00474/,https://archive.ics.uci.edu/ml/datasets/BAUM-2,"A multilingual audio-visual affective face database consisting of 1047 video clips of 286 subjects. The collected clips simulate real-world conditions by containing various head poses, illumination conditions, accessories, temporary occlusions and subjects with a wide range of ages.In order to download the database please send an e-mail to cigdem.turan '@' connect.polyu.hk or cigdem.erogluerdem '@' gmail.com",Computer,The readme file contains more information about the format of the database. ,"A multilingual audio-visual affective face database consisting of 1047 video clips of 286 subjects. A multilingual audio-visual affective face database consisting of 1047 video clips of 286 subjects. The collected clips simulate real-world conditions by containing various head poses, illumination conditions, accessories, temporary occlusions and subjects with a wide range of ages.In order to download the database please send an e-mail to cigdem.turan '@' connect.polyu.hk or cigdem.erogluerdem '@' gmail.comThe readme file contains more information about the format of the database. "
BAUM-1,BAUM-1,BAUM-1 dataset contains 1184 multimodal facial video clips collected from 31 subjects. The 1184 video clips contain spontaneous facial expressions and speech of 13 emotional and mental states.,BAUM-1,https://archive.ics.uci.edu/ml//machine-learning-databases/00473/,https://archive.ics.uci.edu/ml/datasets/BAUM-1,In order to download the database please send an e-mail to: s.zhalehpour '@' gmail.com orcigdem.erogluerdem '@' gmail.comRelevant information can be found in the readme file. ,Computer,"The dataset contains short video clips in MP4 format. The expressed emotional and mental states consist of happiness, anger, sadness, disgust, fear, surprise, boredom, contempt, confusion, neutral, thinking, concentrating, and bothered. ","BAUM-1 dataset contains 1184 multimodal facial video clips collected from 31 subjects. The 1184 video clips contain spontaneous facial expressions and speech of 13 emotional and mental states.In order to download the database please send an e-mail to: s.zhalehpour '@' gmail.com orcigdem.erogluerdem '@' gmail.comRelevant information can be found in the readme file. The dataset contains short video clips in MP4 format. The expressed emotional and mental states consist of happiness, anger, sadness, disgust, fear, surprise, boredom, contempt, confusion, neutral, thinking, concentrating, and bothered. "
Dry Bean Dataset,Dry Bean Dataset,"Images of 13,611 grains of 7 different registered dry beans were taken with a high-resolution camera. A total of 16 features; 12 dimensions and 4 shape forms, were obtained from the grains.",Dry+Bean+Dataset,https://archive.ics.uci.edu/ml//machine-learning-databases/00602/,https://archive.ics.uci.edu/ml/datasets/Dry+Bean+Dataset,"Seven different types of dry beans were used in this research, taking into account the features such as form, shape, type, and structure by the market situation. A computer vision system was developed to distinguish seven different registered varieties of dry beans with similar features in order to obtain uniform seed classification. For the classification model, images of 13,611 grains of 7 different registered dry beans were taken with a high-resolution camera. Bean images obtained by computer vision system were subjected to segmentation and feature extraction stages, and a total of 16 features; 12 dimensions and 4 shape forms, were obtained from the grains.",Computer,"1.) Area (A): The area of a bean zone and the number of pixels within its boundaries.2.) Perimeter (P): Bean circumference is defined as the length of its border.3.) Major axis length (L): The distance between the ends of the longest line that can be drawn from a bean.4.) Minor axis length (l): The longest line that can be drawn from the bean while standing perpendicular to the main axis.5.) Aspect ratio (K): Defines the relationship between L and l.6.) Eccentricity (Ec): Eccentricity of the ellipse having the same moments as the region.7.) Convex area (C): Number of pixels in the smallest convex polygon that can contain the area of a bean seed.8.) Equivalent diameter (Ed): The diameter of a circle having the same area as a bean seed area.9.) Extent (Ex): The ratio of the pixels in the bounding box to the bean area.10.)Solidity (S): Also known as convexity. The ratio of the pixels in the convex shell to those found in beans.11.)Roundness (R): Calculated with the following formula: (4piA)/(P^2)12.)Compactness (CO): Measures the roundness of an object: Ed/L13.)ShapeFactor1 (SF1)14.)ShapeFactor2 (SF2)15.)ShapeFactor3 (SF3)16.)ShapeFactor4 (SF4)17.)Class (Seker, Barbunya, Bombay, Cali, Dermosan, Horoz and Sira)","Images of 13,611 grains of 7 different registered dry beans were taken with a high-resolution camera. A total of 16 features; 12 dimensions and 4 shape forms, were obtained from the grains.Seven different types of dry beans were used in this research, taking into account the features such as form, shape, type, and structure by the market situation. A computer vision system was developed to distinguish seven different registered varieties of dry beans with similar features in order to obtain uniform seed classification. For the classification model, images of 13,611 grains of 7 different registered dry beans were taken with a high-resolution camera. Bean images obtained by computer vision system were subjected to segmentation and feature extraction stages, and a total of 16 features; 12 dimensions and 4 shape forms, were obtained from the grains.1.) Area (A): The area of a bean zone and the number of pixels within its boundaries.2.) Perimeter (P): Bean circumference is defined as the length of its border.3.) Major axis length (L): The distance between the ends of the longest line that can be drawn from a bean.4.) Minor axis length (l): The longest line that can be drawn from the bean while standing perpendicular to the main axis.5.) Aspect ratio (K): Defines the relationship between L and l.6.) Eccentricity (Ec): Eccentricity of the ellipse having the same moments as the region.7.) Convex area (C): Number of pixels in the smallest convex polygon that can contain the area of a bean seed.8.) Equivalent diameter (Ed): The diameter of a circle having the same area as a bean seed area.9.) Extent (Ex): The ratio of the pixels in the bounding box to the bean area.10.)Solidity (S): Also known as convexity. The ratio of the pixels in the convex shell to those found in beans.11.)Roundness (R): Calculated with the following formula: (4piA)/(P^2)12.)Compactness (CO): Measures the roundness of an object: Ed/L13.)ShapeFactor1 (SF1)14.)ShapeFactor2 (SF2)15.)ShapeFactor3 (SF3)16.)ShapeFactor4 (SF4)17.)Class (Seker, Barbunya, Bombay, Cali, Dermosan, Horoz and Sira)"
DSRC Vehicle Communications,DSRC Vehicle Communications,This set Provides data regarding wireless communications between vehicles and road side units. two separate data sets are provided (normal scenario) and in the presence of attacker (jammer).,DSRC+Vehicle+Communications,https://archive.ics.uci.edu/ml//machine-learning-databases/00415/,https://archive.ics.uci.edu/ml/datasets/DSRC+Vehicle+Communications,Communications were setup based on IEEE 802.11p standards at 5.9Ghz. 10BSM (Basic Service messages) per second. Using Control Channel (Ch172) a 10 Mhz channel. Also Attached a clean version in spreadsheets for each dataset (jammed and normal),Computer,Txnid Transmitted node ID numberRxnid- Received Node Id numberRSS- Received Signal Strength in dbmBER- Packet Error RateRSSI- Received Signal Strength IndicatorSNR- Signal to noise ratio,This set Provides data regarding wireless communications between vehicles and road side units. two separate data sets are provided (normal scenario) and in the presence of attacker (jammer).Communications were setup based on IEEE 802.11p standards at 5.9Ghz. 10BSM (Basic Service messages) per second. Using Control Channel (Ch172) a 10 Mhz channel. Also Attached a clean version in spreadsheets for each dataset (jammed and normal)Txnid Transmitted node ID numberRxnid- Received Node Id numberRSS- Received Signal Strength in dbmBER- Packet Error RateRSSI- Received Signal Strength IndicatorSNR- Signal to noise ratio
Dynamic Features of VirusShare Executables,Dynamic Features of VirusShare Executables,"This dataset contains the dynamic features of 107,888 executables, collected by VirusShare from Nov/2010 to Jul/2014.",Dynamic+Features+of+VirusShare+Executables,https://archive.ics.uci.edu/ml//machine-learning-databases/00413/,https://archive.ics.uci.edu/ml/datasets/Dynamic+Features+of+VirusShare+Executables,"This dataset contains the dynamic features of 107,888 executables, collected by VirusShare from Nov/2010 to Jul/2014. The features were extracted from the artifacts generated by the executables in the Cukoo Sandbox. Please refer to the paper for more details regarding data collection and feature extraction.",Computer,The full set of features is available at [Web Link];,"This dataset contains the dynamic features of 107,888 executables, collected by VirusShare from Nov/2010 to Jul/2014.This dataset contains the dynamic features of 107,888 executables, collected by VirusShare from Nov/2010 to Jul/2014. The features were extracted from the artifacts generated by the executables in the Cukoo Sandbox. Please refer to the paper for more details regarding data collection and feature extraction.The full set of features is available at [Web Link];"
banknote authentication,banknote authentication,Data were extracted from images that were taken for the evaluation of an authentication procedure for banknotes.,banknote+authentication,https://archive.ics.uci.edu/ml//machine-learning-databases/00267/,https://archive.ics.uci.edu/ml/datasets/banknote+authentication,"Data were extracted from images that were taken from genuine and forged banknote-like specimens.  For digitization, an industrial camera usually used for print inspection was used. The final images have 400x 400 pixels. Due to the object lens and distance to the investigated object gray-scale pictures with a resolution of about 660 dpi were gained. Wavelet Transform tool were used to extract features from images.  ",Computer,       1. variance of Wavelet Transformed image (continuous)        2. skewness of Wavelet Transformed image (continuous)       3. curtosis of Wavelet Transformed image (continuous)       4. entropy of image (continuous)       5. class (integer) ,"Data were extracted from images that were taken for the evaluation of an authentication procedure for banknotes.Data were extracted from images that were taken from genuine and forged banknote-like specimens.  For digitization, an industrial camera usually used for print inspection was used. The final images have 400x 400 pixels. Due to the object lens and distance to the investigated object gray-scale pictures with a resolution of about 660 dpi were gained. Wavelet Transform tool were used to extract features from images.         1. variance of Wavelet Transformed image (continuous)        2. skewness of Wavelet Transformed image (continuous)       3. curtosis of Wavelet Transformed image (continuous)       4. entropy of image (continuous)       5. class (integer) "
Early stage diabetes risk prediction dataset.,Early stage diabetes risk prediction dataset.,"This dataset
contains the sign and symptpom data of newly diabetic or would be diabetic patient. ",Early+stage+diabetes+risk+prediction+dataset.,https://archive.ics.uci.edu/ml//machine-learning-databases/00529/,https://archive.ics.uci.edu/ml/datasets/Early+stage+diabetes+risk+prediction+dataset.,"This has been col-lected using direct questionnaires from the patients of Sylhet DiabetesHospital in Sylhet, Bangladesh and approved by a doctor.",Computer,"Age 1.20-65		Sex 1. Male, 2.Female		Polyuria 1.Yes, 2.No.		Polydipsia 1.Yes, 2.No.		sudden weight loss 1.Yes, 2.No.		weakness 1.Yes, 2.No.		Polyphagia 1.Yes, 2.No.		Genital thrush 1.Yes, 2.No.		visual blurring 1.Yes, 2.No.		Itching 1.Yes, 2.No.		Irritability 1.Yes, 2.No.		delayed healing 1.Yes, 2.No.		partial paresis 1.Yes, 2.No.		muscle stiness 1.Yes, 2.No.		Alopecia 1.Yes, 2.No.		Obesity 1.Yes, 2.No.		Class 1.Positive, 2.Negative.		","This dataset
contains the sign and symptpom data of newly diabetic or would be diabetic patient. This has been col-lected using direct questionnaires from the patients of Sylhet DiabetesHospital in Sylhet, Bangladesh and approved by a doctor.Age 1.20-65		Sex 1. Male, 2.Female		Polyuria 1.Yes, 2.No.		Polydipsia 1.Yes, 2.No.		sudden weight loss 1.Yes, 2.No.		weakness 1.Yes, 2.No.		Polyphagia 1.Yes, 2.No.		Genital thrush 1.Yes, 2.No.		visual blurring 1.Yes, 2.No.		Itching 1.Yes, 2.No.		Irritability 1.Yes, 2.No.		delayed healing 1.Yes, 2.No.		partial paresis 1.Yes, 2.No.		muscle stiness 1.Yes, 2.No.		Alopecia 1.Yes, 2.No.		Obesity 1.Yes, 2.No.		Class 1.Positive, 2.Negative.		"
Avila,Avila,"The Avila data set has been extracted from 800 images of the 'Avila Bible', an XII century giant Latin copy of the Bible.  The prediction task consists in associating each pattern to a copyist.",Avila,https://archive.ics.uci.edu/ml//machine-learning-databases/00459/,https://archive.ics.uci.edu/ml/datasets/Avila,"Data have been normalized by using the Z-normalization method and divided into two data sets: a training set containing 10430 samples, and a test set containing the 10437 samples.CLASS DISTRIBUTION (training set)A: 4286B: 5  C: 103 D: 352 E: 1095 F: 1961 G: 446 H: 519I: 831W: 44X: 522 Y: 266",Computer,"F1: intercolumnar distance F2: upper margin F3: lower margin F4: exploitation F5: row number F6: modular ratio F7: interlinear spacing F8: weight F9: peak number F10: modular ratio/ interlinear spacingClass: A, B, C, D, E, F, G, H, I, W, X, Y","The Avila data set has been extracted from 800 images of the 'Avila Bible', an XII century giant Latin copy of the Bible.  The prediction task consists in associating each pattern to a copyist.Data have been normalized by using the Z-normalization method and divided into two data sets: a training set containing 10430 samples, and a test set containing the 10437 samples.CLASS DISTRIBUTION (training set)A: 4286B: 5  C: 103 D: 352 E: 1095 F: 1961 G: 446 H: 519I: 831W: 44X: 522 Y: 266F1: intercolumnar distance F2: upper margin F3: lower margin F4: exploitation F5: row number F6: modular ratio F7: interlinear spacing F8: weight F9: peak number F10: modular ratio/ interlinear spacingClass: A, B, C, D, E, F, G, H, I, W, X, Y"
Buzz in social media ,Buzz in social media ,"This data-set contains examples of buzz events from two different social networks: Twitter, and Tom's Hardware, a forum network focusing on new technology with more conservative dynamics.",Buzz+in+social+media+,https://archive.ics.uci.edu/ml//machine-learning-databases/00248/,https://archive.ics.uci.edu/ml/datasets/Buzz+in+social+media+,Please see [Web Link],Computer,Please see [Web Link],"This data-set contains examples of buzz events from two different social networks: Twitter, and Tom's Hardware, a forum network focusing on new technology with more conservative dynamics.Please see [Web Link]Please see [Web Link]"
Carbon Nanotubes,Carbon Nanotubes,This dataset contains 10721 initial and calculated atomic coordinates of carbon nanotubes.,Carbon+Nanotubes,https://archive.ics.uci.edu/ml//machine-learning-databases/00448/,https://archive.ics.uci.edu/ml/datasets/Carbon+Nanotubes,"CASTEP can simulate a wide range of properties of materials proprieties using density functional theory (DFT). DFT is the most successful method calculates atomic coordinates faster than other mathematical approaches, and it also reaches more accurate results. The dataset is generated with CASTEP using CNT geometry optimization. Many CNTs are simulated in CASTEP, then geometry optimizations are calculated. Initial coordinates of all carbon atoms are generated randomly. Different chiral vectors are used for each CNT simulation. The atom type is selected as carbon, bond length is used as 1.42 AÃ‚Â° (default value). CNT calculation parameters are used as default parameters. To finalize the computation, CASTEP uses a parameter named as elec_energy_tol (electrical energy tolerance) (default 1x10-5 eV) which represents that the change in the total energy from one iteration to the next remains below some tolerance value per atom for a few self-consistent field steps. Initial atomic coordinates (u, v, w), chiral vector (n, m) and calculated atomic coordinates (uÃ¢â‚¬â„¢, vÃ¢â‚¬â„¢, wÃ¢â‚¬â„¢) are obtained from the output files.",Computer,The summary of the attributes is given below. Please read the papers ([Web Link] and [Web Link]) for detailed descriptions of the attributes. Chiral indice n: n parameter of the selected chiral vector.Chiral indice m: n parameter of the selected chiral vector.Initial atomic coordinate u: Randomly generated u parameter of the initial atomic coordinates of all carbon atoms.Initial atomic coordinate v: Randomly generated v parameter of the initial atomic coordinates of all carbon atoms.Initial atomic coordinate w: Randomly generated w parameter of the initial atomic coordinates of all carbon atoms.Calculated atomic coordinate uÃ¢â‚¬â„¢: Calculated uÃ¢â‚¬â„¢ parameter of the atomic coordinates of all carbon atoms.Calculated atomic coordinate vÃ¢â‚¬â„¢: Calculated vÃ¢â‚¬â„¢ parameter of the atomic coordinates of all carbon atoms.Calculated atomic coordinate wÃ¢â‚¬â„¢: Calculated wÃ¢â‚¬â„¢ parameter of the atomic coordinates of all carbon atoms.,"This dataset contains 10721 initial and calculated atomic coordinates of carbon nanotubes.CASTEP can simulate a wide range of properties of materials proprieties using density functional theory (DFT). DFT is the most successful method calculates atomic coordinates faster than other mathematical approaches, and it also reaches more accurate results. The dataset is generated with CASTEP using CNT geometry optimization. Many CNTs are simulated in CASTEP, then geometry optimizations are calculated. Initial coordinates of all carbon atoms are generated randomly. Different chiral vectors are used for each CNT simulation. The atom type is selected as carbon, bond length is used as 1.42 AÃ‚Â° (default value). CNT calculation parameters are used as default parameters. To finalize the computation, CASTEP uses a parameter named as elec_energy_tol (electrical energy tolerance) (default 1x10-5 eV) which represents that the change in the total energy from one iteration to the next remains below some tolerance value per atom for a few self-consistent field steps. Initial atomic coordinates (u, v, w), chiral vector (n, m) and calculated atomic coordinates (uÃ¢â‚¬â„¢, vÃ¢â‚¬â„¢, wÃ¢â‚¬â„¢) are obtained from the output files.The summary of the attributes is given below. Please read the papers ([Web Link] and [Web Link]) for detailed descriptions of the attributes. Chiral indice n: n parameter of the selected chiral vector.Chiral indice m: n parameter of the selected chiral vector.Initial atomic coordinate u: Randomly generated u parameter of the initial atomic coordinates of all carbon atoms.Initial atomic coordinate v: Randomly generated v parameter of the initial atomic coordinates of all carbon atoms.Initial atomic coordinate w: Randomly generated w parameter of the initial atomic coordinates of all carbon atoms.Calculated atomic coordinate uÃ¢â‚¬â„¢: Calculated uÃ¢â‚¬â„¢ parameter of the atomic coordinates of all carbon atoms.Calculated atomic coordinate vÃ¢â‚¬â„¢: Calculated vÃ¢â‚¬â„¢ parameter of the atomic coordinates of all carbon atoms.Calculated atomic coordinate wÃ¢â‚¬â„¢: Calculated wÃ¢â‚¬â„¢ parameter of the atomic coordinates of all carbon atoms."
Devanagari Handwritten Character Dataset,Devanagari Handwritten Character Dataset,This is an image database of Handwritten Devanagari characters. There are 46 classes of characters with 2000 examples each. The dataset is split into training set(85%) and testing set(15%). ,Devanagari+Handwritten+Character+Dataset,https://archive.ics.uci.edu/ml//machine-learning-databases/00389/,https://archive.ics.uci.edu/ml/datasets/Devanagari+Handwritten+Character+Dataset,Data Type: GrayScale Image The image dataset can be used to benchmark classification algorithm for OCR systems. The highest accuracy obtained in the Test set is 98.47%. Model Description is available in the paper [Web Link]More information on the dataset at [Web Link].,Computer,"Image Format: .pngResolution: 32 by 32Actual character is centered within 28 by 28 pixel, padding of 2 pixel is added on all four sides of actual character.","This is an image database of Handwritten Devanagari characters. There are 46 classes of characters with 2000 examples each. The dataset is split into training set(85%) and testing set(15%). Data Type: GrayScale Image The image dataset can be used to benchmark classification algorithm for OCR systems. The highest accuracy obtained in the Test set is 98.47%. Model Description is available in the paper [Web Link]More information on the dataset at [Web Link].Image Format: .pngResolution: 32 by 32Actual character is centered within 28 by 28 pixel, padding of 2 pixel is added on all four sides of actual character."
detection_of_IoT_botnet_attacks_N_BaIoT,detection_of_IoT_botnet_attacks_N_BaIoT,"This dataset addresses the lack of public botnet datasets, especially for the IoT. It suggests *real* traffic data, gathered from 9 commercial IoT devices authentically infected by Mirai and BASHLITE.",detection_of_IoT_botnet_attacks_N_BaIoT,https://archive.ics.uci.edu/ml//machine-learning-databases/00442/,https://archive.ics.uci.edu/ml/datasets/detection_of_IoT_botnet_attacks_N_BaIoT,"(a) Attribute being predicted:-- Originally we aimed at distinguishing between benign and Malicious traffic data by means of anomaly detection techniques.-- However, as the malicious data can be divided into 10 attacks carried by 2 botnets, the dataset can also be used for multi-class classification: 10 classes of attacks, plus 1 class of 'benign'.(b) The study's results:-- For each of the 9 IoT devices we trained and optimized a deep autoencoder on 2/3 of its benign data (i.e., the training set of each device). This was done to capture normal network traffic patterns.-- The test data of each device comprised of the remaining 1/3 of benign data plus all the malicious data. On each test set we applied the respective trained (deep) autoencoder as an anomaly detector. The detection of anomalies (i.e., the cyberattacks launched from each of the above IoT devices) concluded with 100% TPR.",Computer,"-- The following describes each of the features headers:* Stream aggregation:H: Stats summarizing the recent traffic from this packet's host (IP)HH: Stats summarizing the recent traffic going from this packet's host (IP) to the packet's destination host.HpHp: Stats summarizing the recent traffic going from this packet's host+port (IP) to the packet's destination host+port. Example 192.168.4.2:1242 -> 192.168.4.12:80HH_jit: Stats summarizing the jitter of the traffic going from this packet's host (IP) to the packet's destination host.* Time-frame (The decay factor Lambda used in the damped window): How much recent history of the stream is capture in these statisticsL5, L3, L1, ...* The statistics extracted from the packet stream:weight: The weight of the stream (can be viewed as the number of items observed in recent history)mean: ...std: ...radius: The root squared sum of the two streams' variancesmagnitude: The root squared sum of the two streams' means cov: an approximated covariance between  two streamspcc: an approximated covariance between  two streams","This dataset addresses the lack of public botnet datasets, especially for the IoT. It suggests *real* traffic data, gathered from 9 commercial IoT devices authentically infected by Mirai and BASHLITE.(a) Attribute being predicted:-- Originally we aimed at distinguishing between benign and Malicious traffic data by means of anomaly detection techniques.-- However, as the malicious data can be divided into 10 attacks carried by 2 botnets, the dataset can also be used for multi-class classification: 10 classes of attacks, plus 1 class of 'benign'.(b) The study's results:-- For each of the 9 IoT devices we trained and optimized a deep autoencoder on 2/3 of its benign data (i.e., the training set of each device). This was done to capture normal network traffic patterns.-- The test data of each device comprised of the remaining 1/3 of benign data plus all the malicious data. On each test set we applied the respective trained (deep) autoencoder as an anomaly detector. The detection of anomalies (i.e., the cyberattacks launched from each of the above IoT devices) concluded with 100% TPR.-- The following describes each of the features headers:* Stream aggregation:H: Stats summarizing the recent traffic from this packet's host (IP)HH: Stats summarizing the recent traffic going from this packet's host (IP) to the packet's destination host.HpHp: Stats summarizing the recent traffic going from this packet's host+port (IP) to the packet's destination host+port. Example 192.168.4.2:1242 -> 192.168.4.12:80HH_jit: Stats summarizing the jitter of the traffic going from this packet's host (IP) to the packet's destination host.* Time-frame (The decay factor Lambda used in the damped window): How much recent history of the stream is capture in these statisticsL5, L3, L1, ...* The statistics extracted from the packet stream:weight: The weight of the stream (can be viewed as the number of items observed in recent history)mean: ...std: ...radius: The root squared sum of the two streams' variancesmagnitude: The root squared sum of the two streams' means cov: an approximated covariance between  two streamspcc: an approximated covariance between  two streams"
Container Crane Controller Data Set,Container Crane Controller Data Set,A container crane has the function of transporting containers from one point to another point.,Container+Crane+Controller+Data+Set,https://archive.ics.uci.edu/ml//machine-learning-databases/00436/,https://archive.ics.uci.edu/ml/datasets/Container+Crane+Controller+Data+Set,"Two predictive attributes (Speed and Angle) and one attribute target (Power).A container crane has the function of transporting containers from one point to another point. The difficulty of this task lies in the fact that the container is connected to the bridge crane by cables causing an opening angle while the container is being transported, interfering with the operation at high speeds due to oscillation that occurs at the end point, which could cause accidents.",Computer,"Speed of moving Container Crane: low, medium and high (low: 1, 2, 3; medium: 6, 7, 8; high: 9, 10).Angle: large negative angle, small negative angle, angle zero, small positive angle and large positive angle.Power: low, medium and high (low: 0.3; medium: 0.5; high: 0.7).for Weka:@relation Container_Crane_Controller@attribute Speed REAL@attribute Angle REAL@attribute Power REAL@data1.0, -5.0, 0.32.0, 5.0, 0.33.0, -2.0, 0.51.0, 2.0, 0.52.0, 0.0, 0.76.0, -5.0, 0.57.0, 5.0, 0.56.0, -2.0, 0.37.0, 2.0, 0.36.0, 0.0, 0.78.0, -5.0, 0.59.0, 5.0, 0.510.0, -2.0, 0.38.0, 2.0, 0.39.0, 0.0, 0.5","A container crane has the function of transporting containers from one point to another point.Two predictive attributes (Speed and Angle) and one attribute target (Power).A container crane has the function of transporting containers from one point to another point. The difficulty of this task lies in the fact that the container is connected to the bridge crane by cables causing an opening angle while the container is being transported, interfering with the operation at high speeds due to oscillation that occurs at the end point, which could cause accidents.Speed of moving Container Crane: low, medium and high (low: 1, 2, 3; medium: 6, 7, 8; high: 9, 10).Angle: large negative angle, small negative angle, angle zero, small positive angle and large positive angle.Power: low, medium and high (low: 0.3; medium: 0.5; high: 0.7).for Weka:@relation Container_Crane_Controller@attribute Speed REAL@attribute Angle REAL@attribute Power REAL@data1.0, -5.0, 0.32.0, 5.0, 0.33.0, -2.0, 0.51.0, 2.0, 0.52.0, 0.0, 0.76.0, -5.0, 0.57.0, 5.0, 0.56.0, -2.0, 0.37.0, 2.0, 0.36.0, 0.0, 0.78.0, -5.0, 0.59.0, 5.0, 0.510.0, -2.0, 0.38.0, 2.0, 0.39.0, 0.0, 0.5"
Condition monitoring of hydraulic systems,Condition monitoring of hydraulic systems,The data set addresses the condition assessment of a hydraulic test rig based on multi sensor data. Four fault types are superimposed with several severity grades impeding selective quantification.,Condition+monitoring+of+hydraulic+systems,https://archive.ics.uci.edu/ml//machine-learning-databases/00447/,https://archive.ics.uci.edu/ml/datasets/Condition+monitoring+of+hydraulic+systems,"The data set was experimentally obtained with a hydraulic test rig. This test rig consists of a primary working and a secondary cooling-filtration circuit which are connected via the oil tank [1], [2]. The system cyclically repeats constant load cycles (duration 60 seconds) and measures process values such as pressures, volume flows and temperatures while the condition of four hydraulic components (cooler, valve, pump and accumulator) is quantitatively varied. ",Computer,"The data set was experimentally obtained with a hydraulic test rig. This test rig consists of a primary working and a secondary cooling-filtration circuit which are connected via the oil tank [1], [2]. The system cyclically repeats constant load cycles (duration 60 seconds) and measures process values such as pressures, volume flows and temperatures while the condition of four hydraulic components (cooler, valve, pump and accumulator) is quantitatively varied. Attribute Information:The data set contains raw process sensor data (i.e. without feature extraction) which are structured as matrices (tab-delimited) with the rows representing the cycles and the columns the data points within a cycle. The sensors involved are:Sensor		Physical quantity		Unit		Sampling ratePS1		Pressure			bar		100 HzPS2		Pressure			bar		100 HzPS3		Pressure			bar		100 HzPS4		Pressure			bar		100 HzPS5		Pressure			bar		100 HzPS6		Pressure			bar		100 HzEPS1		Motor power			W		100 HzFS1		Volume flow			l/min		10 HzFS2		Volume flow			l/min		10 HzTS1		Temperature			Ã‚Â°C		1 HzTS2		Temperature			Ã‚Â°C		1 HzTS3		Temperature			Ã‚Â°C		1 HzTS4		Temperature			Ã‚Â°C		1 HzVS1		Vibration			mm/s		1 HzCE		Cooling efficiency (virtual)	%		1 HzCP		Cooling power (virtual)		kW		1 HzSE		Efficiency factor		%		1 HzThe target condition values are cycle-wise annotated in Ã¢â‚¬Ëœprofile.txtÃ¢â‚¬Ëœ (tab-delimited). As before, the row number represents the cycle number. The columns are1: Cooler condition / %:	3: close to total failure	20: reduced effifiency	100: full efficiency2: Valve condition / %:	100: optimal switching behavior	90: small lag	80: severe lag	73: close to total failure3: Internal pump leakage:	0: no leakage	1: weak leakage	2: severe leakage4: Hydraulic accumulator / bar:	130: optimal pressure	115: slightly reduced pressure	100: severely reduced pressure	90: close to total failure5: stable flag:	0: conditions were stable	1: static conditions might not have been reached yet","The data set addresses the condition assessment of a hydraulic test rig based on multi sensor data. Four fault types are superimposed with several severity grades impeding selective quantification.The data set was experimentally obtained with a hydraulic test rig. This test rig consists of a primary working and a secondary cooling-filtration circuit which are connected via the oil tank [1], [2]. The system cyclically repeats constant load cycles (duration 60 seconds) and measures process values such as pressures, volume flows and temperatures while the condition of four hydraulic components (cooler, valve, pump and accumulator) is quantitatively varied. The data set was experimentally obtained with a hydraulic test rig. This test rig consists of a primary working and a secondary cooling-filtration circuit which are connected via the oil tank [1], [2]. The system cyclically repeats constant load cycles (duration 60 seconds) and measures process values such as pressures, volume flows and temperatures while the condition of four hydraulic components (cooler, valve, pump and accumulator) is quantitatively varied. Attribute Information:The data set contains raw process sensor data (i.e. without feature extraction) which are structured as matrices (tab-delimited) with the rows representing the cycles and the columns the data points within a cycle. The sensors involved are:Sensor		Physical quantity		Unit		Sampling ratePS1		Pressure			bar		100 HzPS2		Pressure			bar		100 HzPS3		Pressure			bar		100 HzPS4		Pressure			bar		100 HzPS5		Pressure			bar		100 HzPS6		Pressure			bar		100 HzEPS1		Motor power			W		100 HzFS1		Volume flow			l/min		10 HzFS2		Volume flow			l/min		10 HzTS1		Temperature			Ã‚Â°C		1 HzTS2		Temperature			Ã‚Â°C		1 HzTS3		Temperature			Ã‚Â°C		1 HzTS4		Temperature			Ã‚Â°C		1 HzVS1		Vibration			mm/s		1 HzCE		Cooling efficiency (virtual)	%		1 HzCP		Cooling power (virtual)		kW		1 HzSE		Efficiency factor		%		1 HzThe target condition values are cycle-wise annotated in Ã¢â‚¬Ëœprofile.txtÃ¢â‚¬Ëœ (tab-delimited). As before, the row number represents the cycle number. The columns are1: Cooler condition / %:	3: close to total failure	20: reduced effifiency	100: full efficiency2: Valve condition / %:	100: optimal switching behavior	90: small lag	80: severe lag	73: close to total failure3: Internal pump leakage:	0: no leakage	1: weak leakage	2: severe leakage4: Hydraulic accumulator / bar:	130: optimal pressure	115: slightly reduced pressure	100: severely reduced pressure	90: close to total failure5: stable flag:	0: conditions were stable	1: static conditions might not have been reached yet"
Condition Based Maintenance of Naval Propulsion Plants,Condition Based Maintenance of Naval Propulsion Plants,"Data have been generated from a sophisticated simulator of a Gas Turbines (GT), mounted on a Frigate characterized by a COmbined Diesel eLectric And Gas (CODLAG) propulsion plant type.",Condition+Based+Maintenance+of+Naval+Propulsion+Plants,https://archive.ics.uci.edu/ml//machine-learning-databases/00316/,https://archive.ics.uci.edu/ml/datasets/Condition+Based+Maintenance+of+Naval+Propulsion+Plants,"The experiments have been carried out by means of a numerical simulator of a naval vessel (Frigate) characterized by a Gas Turbine (GT) propulsion plant. The different blocks forming the complete simulator (Propeller, Hull, GT, Gear Box and Controller) have been developed and fine tuned over the year on several similar real propulsion plants. In view of these observations the available data are in agreement with a possible real vessel.In this release of the simulator it is also possible to take into account the performance decay over time of the GT components such as GT compressor and turbines.The propulsion system behaviour has been described with this parameters:- Ship speed (linear function of the lever position lp).- Compressor degradation coefficient kMc.- Turbine degradation coefficient kMt.so that each possible degradation state can be described by a combination of this triple (lp,kMt,kMc).The range of decay of compressor and turbine has been sampled with an uniform grid of precision 0.001 so to have a good granularity of representation.In particular for the compressor decay state discretization the kMc coefficient has been investigated in the domain [1; 0.95], and the turbine coefficient in the domain [1; 0.975].Ship speed has been investigated sampling the range of feasible speed from 3 knots to 27 knots with a granularity of representation equal to tree knots.A series of measures (16 features) which indirectly represents of the state of the system subject to performance decay has been acquired and stored in the dataset over the parameter's space.Check the README.txt file for further details about this dataset.",Computer,- A 16-feature vector containing the GT measures at steady state of the physical asset:    Lever position (lp) [ ]    Ship speed (v) [knots]    Gas Turbine (GT) shaft torque (GTT) [kN m]    GT rate of revolutions (GTn) [rpm]    Gas Generator rate of revolutions (GGn) [rpm]    Starboard Propeller Torque (Ts) [kN]    Port Propeller Torque (Tp) [kN]    Hight Pressure (HP) Turbine exit temperature (T48) [C]    GT Compressor inlet air temperature (T1) [C]    GT Compressor outlet air temperature (T2) [C]    HP Turbine exit pressure (P48) [bar]    GT Compressor inlet air pressure (P1) [bar]    GT Compressor outlet air pressure (P2) [bar]    GT exhaust gas pressure (Pexh) [bar]    Turbine Injecton Control (TIC) [%]    Fuel flow (mf) [kg/s]- GT Compressor decay state coefficient- GT Turbine decay state coefficient,"Data have been generated from a sophisticated simulator of a Gas Turbines (GT), mounted on a Frigate characterized by a COmbined Diesel eLectric And Gas (CODLAG) propulsion plant type.The experiments have been carried out by means of a numerical simulator of a naval vessel (Frigate) characterized by a Gas Turbine (GT) propulsion plant. The different blocks forming the complete simulator (Propeller, Hull, GT, Gear Box and Controller) have been developed and fine tuned over the year on several similar real propulsion plants. In view of these observations the available data are in agreement with a possible real vessel.In this release of the simulator it is also possible to take into account the performance decay over time of the GT components such as GT compressor and turbines.The propulsion system behaviour has been described with this parameters:- Ship speed (linear function of the lever position lp).- Compressor degradation coefficient kMc.- Turbine degradation coefficient kMt.so that each possible degradation state can be described by a combination of this triple (lp,kMt,kMc).The range of decay of compressor and turbine has been sampled with an uniform grid of precision 0.001 so to have a good granularity of representation.In particular for the compressor decay state discretization the kMc coefficient has been investigated in the domain [1; 0.95], and the turbine coefficient in the domain [1; 0.975].Ship speed has been investigated sampling the range of feasible speed from 3 knots to 27 knots with a granularity of representation equal to tree knots.A series of measures (16 features) which indirectly represents of the state of the system subject to performance decay has been acquired and stored in the dataset over the parameter's space.Check the README.txt file for further details about this dataset.- A 16-feature vector containing the GT measures at steady state of the physical asset:    Lever position (lp) [ ]    Ship speed (v) [knots]    Gas Turbine (GT) shaft torque (GTT) [kN m]    GT rate of revolutions (GTn) [rpm]    Gas Generator rate of revolutions (GGn) [rpm]    Starboard Propeller Torque (Ts) [kN]    Port Propeller Torque (Tp) [kN]    Hight Pressure (HP) Turbine exit temperature (T48) [C]    GT Compressor inlet air temperature (T1) [C]    GT Compressor outlet air temperature (T2) [C]    HP Turbine exit pressure (P48) [bar]    GT Compressor inlet air pressure (P1) [bar]    GT Compressor outlet air pressure (P2) [bar]    GT exhaust gas pressure (Pexh) [bar]    Turbine Injecton Control (TIC) [%]    Fuel flow (mf) [kg/s]- GT Compressor decay state coefficient- GT Turbine decay state coefficient"
Concrete Slump Test,Concrete Slump Test,"Concrete is a highly complex material. The slump flow of concrete is not only determined by the water content, but that is also influenced by other concrete ingredients.",Concrete+Slump+Test,https://archive.ics.uci.edu/ml//machine-learning-databases/concrete/slump/,https://archive.ics.uci.edu/ml/datasets/Concrete+Slump+Test,"The data set includes 103 data points. There are 7 input variables, and 3 output variables in the data set.The initial data set included 78 data. After several years, we got 25 new data points.",Computer,Input variables (7)(component kg in one M^3 concrete):Cement	Slag	Fly ash	Water	SP	Coarse Aggr.	Fine Aggr.	Output variables (3):SLUMP (cm)	FLOW (cm)	28-day Compressive Strength (Mpa),"Concrete is a highly complex material. The slump flow of concrete is not only determined by the water content, but that is also influenced by other concrete ingredients.The data set includes 103 data points. There are 7 input variables, and 3 output variables in the data set.The initial data set included 78 data. After several years, we got 25 new data points.Input variables (7)(component kg in one M^3 concrete):Cement	Slag	Fly ash	Water	SP	Coarse Aggr.	Fine Aggr.	Output variables (3):SLUMP (cm)	FLOW (cm)	28-day Compressive Strength (Mpa)"
Computer Hardware,Computer Hardware,"Relative CPU Performance Data, described in terms of its cycle time, memory size, etc.",Computer+Hardware,https://archive.ics.uci.edu/ml//machine-learning-databases/cpu-performance/,https://archive.ics.uci.edu/ml/datasets/Computer+Hardware,The estimated relative performance values were estimated by the authors using a linear regression method.  See their article (pp 308-313) for more details on how the relative performance values were set.,Computer,"   1. vendor name: 30       (adviser, amdahl,apollo, basf, bti, burroughs, c.r.d, cambex, cdc, dec,        dg, formation, four-phase, gould, honeywell, hp, ibm, ipl, magnuson,        microdata, nas, ncr, nixdorf, perkin-elmer, prime, siemens, sperry,        sratus, wang)   2. Model Name: many unique symbols   3. MYCT: machine cycle time in nanoseconds (integer)   4. MMIN: minimum main memory in kilobytes (integer)   5. MMAX: maximum main memory in kilobytes (integer)   6. CACH: cache memory in kilobytes (integer)   7. CHMIN: minimum channels in units (integer)   8. CHMAX: maximum channels in units (integer)   9. PRP: published relative performance (integer)  10. ERP: estimated relative performance from the original article (integer)","Relative CPU Performance Data, described in terms of its cycle time, memory size, etc.The estimated relative performance values were estimated by the authors using a linear regression method.  See their article (pp 308-313) for more details on how the relative performance values were set.   1. vendor name: 30       (adviser, amdahl,apollo, basf, bti, burroughs, c.r.d, cambex, cdc, dec,        dg, formation, four-phase, gould, honeywell, hp, ibm, ipl, magnuson,        microdata, nas, ncr, nixdorf, perkin-elmer, prime, siemens, sperry,        sratus, wang)   2. Model Name: many unique symbols   3. MYCT: machine cycle time in nanoseconds (integer)   4. MMIN: minimum main memory in kilobytes (integer)   5. MMAX: maximum main memory in kilobytes (integer)   6. CACH: cache memory in kilobytes (integer)   7. CHMIN: minimum channels in units (integer)   8. CHMAX: maximum channels in units (integer)   9. PRP: published relative performance (integer)  10. ERP: estimated relative performance from the original article (integer)"
Combined Cycle Power Plant,Combined Cycle Power Plant,"The dataset contains 9568 data points collected from a Combined Cycle Power Plant over 6 years (2006-2011), when the plant was set to work with full load. ",Combined+Cycle+Power+Plant,https://archive.ics.uci.edu/ml//machine-learning-databases/00294/,https://archive.ics.uci.edu/ml/datasets/Combined+Cycle+Power+Plant,"The dataset contains 9568 data points collected from a Combined Cycle Power Plant over 6 years (2006-2011), when the power plant was set to work with full load. Features consist of hourly average ambient variables Temperature (T), Ambient Pressure (AP), Relative Humidity (RH) and Exhaust Vacuum (V) to predict the net hourly electrical energy output (EP)  of the plant.A combined cycle power plant (CCPP) is composed of gas turbines (GT), steam turbines (ST) and heat recovery steam generators. In a CCPP, the electricity is generated by gas and steam turbines, which are combined in one cycle, and is transferred from one turbine to another. While the Vacuum is colected from and has effect on the Steam Turbine, he other three of the ambient variables effect the GT performance.For comparability with our baseline studies, and to allow 5x2 fold statistical tests be carried out, we provide the data shuffled five times. For each shuffling 2-fold CV is carried out and the resulting 10 measurements are used for statistical testing.We provide the data both in .ods and in .xlsx formats.",Computer,"Features consist of hourly average ambient variables - Temperature (T) in the range 1.81Â°C and 37.11Â°C,- Ambient Pressure (AP) in the range 992.89-1033.30 milibar,- Relative Humidity (RH) in the range 25.56% to 100.16%- Exhaust Vacuum (V) in teh range 25.36-81.56 cm Hg- Net hourly electrical energy output (EP) 420.26-495.76 MWThe averages are taken from various sensors located around the plant that record the ambient variables every second. The variables are given without normalization. ","The dataset contains 9568 data points collected from a Combined Cycle Power Plant over 6 years (2006-2011), when the plant was set to work with full load. The dataset contains 9568 data points collected from a Combined Cycle Power Plant over 6 years (2006-2011), when the power plant was set to work with full load. Features consist of hourly average ambient variables Temperature (T), Ambient Pressure (AP), Relative Humidity (RH) and Exhaust Vacuum (V) to predict the net hourly electrical energy output (EP)  of the plant.A combined cycle power plant (CCPP) is composed of gas turbines (GT), steam turbines (ST) and heat recovery steam generators. In a CCPP, the electricity is generated by gas and steam turbines, which are combined in one cycle, and is transferred from one turbine to another. While the Vacuum is colected from and has effect on the Steam Turbine, he other three of the ambient variables effect the GT performance.For comparability with our baseline studies, and to allow 5x2 fold statistical tests be carried out, we provide the data shuffled five times. For each shuffling 2-fold CV is carried out and the resulting 10 measurements are used for statistical testing.We provide the data both in .ods and in .xlsx formats.Features consist of hourly average ambient variables - Temperature (T) in the range 1.81Â°C and 37.11Â°C,- Ambient Pressure (AP) in the range 992.89-1033.30 milibar,- Relative Humidity (RH) in the range 25.56% to 100.16%- Exhaust Vacuum (V) in teh range 25.36-81.56 cm Hg- Net hourly electrical energy output (EP) 420.26-495.76 MWThe averages are taken from various sensors located around the plant that record the ambient variables every second. The variables are given without normalization. "
CSM (Conventional and Social Media Movies) Dataset 2014 and 2015,CSM (Conventional and Social Media Movies) Dataset 2014 and 2015,"12 features categorized as conventional and social media features. Both conventional features, collected from movies databases on Web as well as social media features(YouTube,Twitter).",CSM+%28Conventional+and+Social+Media+Movies%29+Dataset+2014+and+2015,https://archive.ics.uci.edu/ml//machine-learning-databases/00424/,https://archive.ics.uci.edu/ml/datasets/CSM+%28Conventional+and+Social+Media+Movies%29+Dataset+2014+and+2015,"Year:2014 and 2015Source: Twitter,YouTube,IMDB",Computer,Provide information about each attribute in your data set.,"12 features categorized as conventional and social media features. Both conventional features, collected from movies databases on Web as well as social media features(YouTube,Twitter).Year:2014 and 2015Source: Twitter,YouTube,IMDBProvide information about each attribute in your data set."
CNNpred: CNN-based stock market prediction using a diverse set of variables,CNNpred: CNN-based stock market prediction using a diverse set of variables,"This dataset contains several daily features of S&P 500, NASDAQ Composite, Dow Jones Industrial Average, RUSSELL 2000, and NYSE Composite from 2010 to 2017.",CNNpred%3A+CNN-based+stock+market+prediction+using+a+diverse+set+of+variables,https://archive.ics.uci.edu/ml//machine-learning-databases/00554/,https://archive.ics.uci.edu/ml/datasets/CNNpred%3A+CNN-based+stock+market+prediction+using+a+diverse+set+of+variables,"It covers features from various categories of technical indicators, futures contracts, price of commodities, important indices of markets around the world, price of major companies in the U.S. market, and treasury bill rates. Sources and thorough description of features have been mentioned in the paper of 'CNNpred: CNN-based stock market prediction using a diverse set of variables'.",Computer,Provide information about each attribute in your data set.,"This dataset contains several daily features of S&P 500, NASDAQ Composite, Dow Jones Industrial Average, RUSSELL 2000, and NYSE Composite from 2010 to 2017.It covers features from various categories of technical indicators, futures contracts, price of commodities, important indices of markets around the world, price of major companies in the U.S. market, and treasury bill rates. Sources and thorough description of features have been mentioned in the paper of 'CNNpred: CNN-based stock market prediction using a diverse set of variables'.Provide information about each attribute in your data set."
EBL Domain Theories,EBL Domain Theories,Assorted small-scale domain theories,EBL+Domain+Theories,https://archive.ics.uci.edu/ml//machine-learning-databases/ebl/,https://archive.ics.uci.edu/ml/datasets/EBL+Domain+Theories,,Computer,,Assorted small-scale domain theoriesnannan
Daily and Sports Activities,Daily and Sports Activities,"The dataset comprises motion sensor data of 19 daily and sports activities each performed by 8 subjects in their own style for 5 minutes. Five Xsens MTx units are used on the torso, arms, and legs.
",Daily+and+Sports+Activities,https://archive.ics.uci.edu/ml//machine-learning-databases/00256/,https://archive.ics.uci.edu/ml/datasets/Daily+and+Sports+Activities,"Brief Description of the Dataset:---------------------------------Each of the 19 activities is performed by eight subjects (4 female, 4 male, between the ages 20 and 30) for 5 minutes.Total signal duration is 5 minutes for each activity of each subject.The subjects are asked to perform the activities in their own style and were not restricted on how the activities should be performed. For this reason, there are inter-subject variations in the speeds and amplitudes of some activities. The activities are performed at the Bilkent University Sports Hall, in the Electrical and Electronics Engineering Building, and in a flat outdoor area on campus. Sensor units are calibrated to acquire data at 25 Hz sampling frequency. The 5-min signals are divided into 5-sec segments so that 480(=60x8) signal segments are obtained for each activity.The 19 activities are: sitting (A1), standing (A2), lying on back and on right side (A3 and A4), ascending and descending stairs (A5 and A6), standing in an elevator still (A7) and moving around in an elevator (A8), walking in a parking lot (A9), walking on a treadmill with a speed of 4 km/h (in flat and 15 deg inclined positions) (A10 and A11),running on a treadmill with a speed of 8 km/h (A12), exercising on a stepper (A13), exercising on a cross trainer (A14), cycling on an exercise bike in horizontal and vertical positions (A15 and A16),rowing (A17), jumping (A18), and playing basketball (A19).File structure:19 activities (a) (in the order given above) 8 subjects   (p)60 segments   (s) 5 units on torso (T), right arm (RA), left arm (LA), right leg (RL), left leg (LL) 9 sensors on each unit (x,y,z accelerometers, x,y,z gyroscopes, x,y,z magnetometers) Folders a01, a02, ..., a19 contain data recorded from the 19 activities.For each activity, the subfolders p1, p2, ..., p8 contain data from each of the 8 subjects.In each subfolder, there are 60 text files s01, s02, ..., s60, one for each segment.In each text file, there are 5 units x 9 sensors = 45 columns and 5 sec x 25 Hz = 125 rows.Each column contains the 125 samples of data acquired from one of the sensors of one of the units over a period of 5 sec.Each row contains data acquired from all of the 45 sensor axes at a particular sampling instant separated by commas.Columns 1-45 correspond to:   T_xacc,  T_yacc,  T_zacc,  T_xgyro, ...,  T_ymag,  T_zmag,RA_xacc, RA_yacc, RA_zacc, RA_xgyro, ..., RA_ymag, RA_zmag,LA_xacc, LA_yacc, LA_zacc, LA_xgyro, ..., LA_ymag, LA_zmag,RL_xacc, RL_yacc, RL_zacc, RL_xgyro, ..., RL_ymag, RL_zmag,LL_xacc, LL_yacc, LL_zacc, LL_xgyro, ..., LL_ymag, LL_zmag.Therefore,columns  1-9  correspond to the sensors in unit 1 (T), columns 10-18 correspond to the sensors in unit 2 (RA), columns 19-27 correspond to the sensors in unit 3 (LA), columns 28-36 correspond to the sensors in unit 4 (RL), columns 37-45 correspond to the sensors in unit 5 (LL). ",Computer,Please see the detailed description above.,"The dataset comprises motion sensor data of 19 daily and sports activities each performed by 8 subjects in their own style for 5 minutes. Five Xsens MTx units are used on the torso, arms, and legs.
Brief Description of the Dataset:---------------------------------Each of the 19 activities is performed by eight subjects (4 female, 4 male, between the ages 20 and 30) for 5 minutes.Total signal duration is 5 minutes for each activity of each subject.The subjects are asked to perform the activities in their own style and were not restricted on how the activities should be performed. For this reason, there are inter-subject variations in the speeds and amplitudes of some activities. The activities are performed at the Bilkent University Sports Hall, in the Electrical and Electronics Engineering Building, and in a flat outdoor area on campus. Sensor units are calibrated to acquire data at 25 Hz sampling frequency. The 5-min signals are divided into 5-sec segments so that 480(=60x8) signal segments are obtained for each activity.The 19 activities are: sitting (A1), standing (A2), lying on back and on right side (A3 and A4), ascending and descending stairs (A5 and A6), standing in an elevator still (A7) and moving around in an elevator (A8), walking in a parking lot (A9), walking on a treadmill with a speed of 4 km/h (in flat and 15 deg inclined positions) (A10 and A11),running on a treadmill with a speed of 8 km/h (A12), exercising on a stepper (A13), exercising on a cross trainer (A14), cycling on an exercise bike in horizontal and vertical positions (A15 and A16),rowing (A17), jumping (A18), and playing basketball (A19).File structure:19 activities (a) (in the order given above) 8 subjects   (p)60 segments   (s) 5 units on torso (T), right arm (RA), left arm (LA), right leg (RL), left leg (LL) 9 sensors on each unit (x,y,z accelerometers, x,y,z gyroscopes, x,y,z magnetometers) Folders a01, a02, ..., a19 contain data recorded from the 19 activities.For each activity, the subfolders p1, p2, ..., p8 contain data from each of the 8 subjects.In each subfolder, there are 60 text files s01, s02, ..., s60, one for each segment.In each text file, there are 5 units x 9 sensors = 45 columns and 5 sec x 25 Hz = 125 rows.Each column contains the 125 samples of data acquired from one of the sensors of one of the units over a period of 5 sec.Each row contains data acquired from all of the 45 sensor axes at a particular sampling instant separated by commas.Columns 1-45 correspond to:   T_xacc,  T_yacc,  T_zacc,  T_xgyro, ...,  T_ymag,  T_zmag,RA_xacc, RA_yacc, RA_zacc, RA_xgyro, ..., RA_ymag, RA_zmag,LA_xacc, LA_yacc, LA_zacc, LA_xgyro, ..., LA_ymag, LA_zmag,RL_xacc, RL_yacc, RL_zacc, RL_xgyro, ..., RL_ymag, RL_zmag,LL_xacc, LL_yacc, LL_zacc, LL_xgyro, ..., LL_ymag, LL_zmag.Therefore,columns  1-9  correspond to the sensors in unit 1 (T), columns 10-18 correspond to the sensors in unit 2 (RA), columns 19-27 correspond to the sensors in unit 3 (LA), columns 28-36 correspond to the sensors in unit 4 (RL), columns 37-45 correspond to the sensors in unit 5 (LL). Please see the detailed description above."
Dataset for ADL Recognition with Wrist-worn Accelerometer,Dataset for ADL Recognition with Wrist-worn Accelerometer,Recordings of 16 volunteers performing 14 Activities of Daily Living (ADL) while carrying a single wrist-worn tri-axial accelerometer.,Dataset+for+ADL+Recognition+with+Wrist-worn+Accelerometer,https://archive.ics.uci.edu/ml//machine-learning-databases/00283/,https://archive.ics.uci.edu/ml/datasets/Dataset+for+ADL+Recognition+with+Wrist-worn+Accelerometer,"The Dataset for ADL Recognition with Wrist-worn Accelerometer is a public collection of labelled accelerometer data recordings to be used for the creation and validation of acceleration models of simple ADL.The Dataset is composed of the recordings of 14 simple ADL (brush_teeth, climb_stairs, comb_hair, descend_stairs, drink_glass, eat_meat, eat_soup, getup_bed, liedown_bed, pour_water, sitdown_chair, standup_chair, use_telephone, walk) perfomed by a total of 16 volunteers.The data are collected by a single tri-axial accelerometer attached to the right-wrist of the volunteer. Accelerometer specifications are detailed in the file MANUAL.TXT inside the Dataset folder.Detailed documentation about the dataset is provided in the files README.TXT and MANUAL.TXT inside the Dataset folder.",Computer,"Each file in the dataset follows the following naming convention:        Accelerometer-[START_TIME]-[ADL]-[VOLUNTEER]where: - [START_TIME]: timestamp of the starting moment of the recording in the format [YYYY-MM-DD-HH-MM-SS] - [HMP]:	 name of the ADL performed in the recorded trial - [VOLUNTEER]:	 identification code of the volunteer performing the recorded motion in the format [gN] where:		  - 'g' indicates the gender of the volunteer (m -> male, f -> female)		  - 'N' indicates the progressive number associated to the volunteerEach record of a file reports: - acceleration along the x axis of the accelerometer - acceleration along the y axis of the accelerometer - acceleration along the z axis of the accelerometer","Recordings of 16 volunteers performing 14 Activities of Daily Living (ADL) while carrying a single wrist-worn tri-axial accelerometer.The Dataset for ADL Recognition with Wrist-worn Accelerometer is a public collection of labelled accelerometer data recordings to be used for the creation and validation of acceleration models of simple ADL.The Dataset is composed of the recordings of 14 simple ADL (brush_teeth, climb_stairs, comb_hair, descend_stairs, drink_glass, eat_meat, eat_soup, getup_bed, liedown_bed, pour_water, sitdown_chair, standup_chair, use_telephone, walk) perfomed by a total of 16 volunteers.The data are collected by a single tri-axial accelerometer attached to the right-wrist of the volunteer. Accelerometer specifications are detailed in the file MANUAL.TXT inside the Dataset folder.Detailed documentation about the dataset is provided in the files README.TXT and MANUAL.TXT inside the Dataset folder.Each file in the dataset follows the following naming convention:        Accelerometer-[START_TIME]-[ADL]-[VOLUNTEER]where: - [START_TIME]: timestamp of the starting moment of the recording in the format [YYYY-MM-DD-HH-MM-SS] - [HMP]:	 name of the ADL performed in the recorded trial - [VOLUNTEER]:	 identification code of the volunteer performing the recorded motion in the format [gN] where:		  - 'g' indicates the gender of the volunteer (m -> male, f -> female)		  - 'N' indicates the progressive number associated to the volunteerEach record of a file reports: - acceleration along the x axis of the accelerometer - acceleration along the y axis of the accelerometer - acceleration along the z axis of the accelerometer"
Dataset for Sensorless Drive Diagnosis,Dataset for Sensorless Drive Diagnosis,Features are extracted from motor current. The motor has intact and defective components. This results in 11 different classes with different conditions. ,Dataset+for+Sensorless+Drive+Diagnosis,https://archive.ics.uci.edu/ml//machine-learning-databases/00325/,https://archive.ics.uci.edu/ml/datasets/Dataset+for+Sensorless+Drive+Diagnosis,"Features are extracted from electric current drive signals. The drive has intact and defective components. This results in 11 different classes with different conditions. Each condition has been measured several times by 12 different operating conditions, this means by different speeds, load moments and load forces. The current signals are measured with a current probe and an oscilloscope on two phases.",Computer,"The Empirical Mode Decomposition (EMD) was used to generate a new database for the generation of features. The first three intrinsic mode functions (IMF) of the two phase currents and their residuals (RES) were used and broken down into sub-sequences. For each of this sub-sequences, the statistical features mean, standard deviation, skewness and kurtosis were calculated.","Features are extracted from motor current. The motor has intact and defective components. This results in 11 different classes with different conditions. Features are extracted from electric current drive signals. The drive has intact and defective components. This results in 11 different classes with different conditions. Each condition has been measured several times by 12 different operating conditions, this means by different speeds, load moments and load forces. The current signals are measured with a current probe and an oscilloscope on two phases.The Empirical Mode Decomposition (EMD) was used to generate a new database for the generation of features. The first three intrinsic mode functions (IMF) of the two phase currents and their residuals (RES) were used and broken down into sub-sequences. For each of this sub-sequences, the statistical features mean, standard deviation, skewness and kurtosis were calculated."
DBWorld e-mails,DBWorld e-mails,It contains 64 e-mails which I have manually collected from DBWorld mailing list. They are classified in: 'announces of conferences' and 'everything else'.,DBWorld+e-mails,https://archive.ics.uci.edu/ml//machine-learning-databases/00219/,https://archive.ics.uci.edu/ml/datasets/DBWorld+e-mails,I collected 64 e-mails from DBWorld newsletter and I used them to train different algorithms in order to classify between 'announces of conferences' and 'everything else'. I used a binary bag-of-words representation with a stopword removal pre-processing task before.,Computer,Each attribute corresponds to a precise word or stem in the entire data set vocabulary (I used bag-of-words representation).,It contains 64 e-mails which I have manually collected from DBWorld mailing list. They are classified in: 'announces of conferences' and 'everything else'.I collected 64 e-mails from DBWorld newsletter and I used them to train different algorithms in order to classify between 'announces of conferences' and 'everything else'. I used a binary bag-of-words representation with a stopword removal pre-processing task before.Each attribute corresponds to a precise word or stem in the entire data set vocabulary (I used bag-of-words representation).
Deepfakes: Medical Image Tamper Detection,Deepfakes: Medical Image Tamper Detection,"Medical deepfakes: CT scans of human lungs, where some have been tampered with cancer added/removed. Can you find them?",Deepfakes%3A+Medical+Image+Tamper+Detection,https://archive.ics.uci.edu/ml//machine-learning-databases/00520/,https://archive.ics.uci.edu/ml/datasets/Deepfakes%3A+Medical+Image+Tamper+Detection,"Attackers have the ability to intercept and add/remove medical evidence in medical imagery with high realism using deep learning. In this dataset we present medical deepfakes: 3D CT scans of human lungs, where some have been tampered with real cancer removed and with fake cancer injected. The objective of this dataset is to distinguish between real and fake cancers, and identify where medical scans have been tampered. Three expert radiologists have evaluated this dataset and could not reliably tell the difference between real and fake cancers, meaning that the fake cancers are realistic and this detection task is very challenging. For more information, please see our paper 'CT-GAN'.The dataset consists of two sets (80 scans and 20 scans). The first 80 were used in a blind trial with the radiologists (they weren't told they were tampered), and the 20 scans were used in an open trial with the radiologists (they were told the truth and asked to identify them). Provided with the scans is a table with the ground truth. For each scan, where a cancer is located (x, y, and z [slice#]) and its classification. A location can be classified as being:True-Benign, (TB): A location that actually has no cancer True-Malicious (TM): A location that has real cancerFalse-Benign (FB): A location that has real cancer, but it was removed.False-Malicious (FM): A location that does not have cancer, but fake cancer was injected there.Access to the dataset is via this link: [Web Link]",Computer,"Each scan is in the medical dicom format, but it can be loaded as a 3D matrix with Python by using the tools provided in our code repository: [Web Link]A scan is basically a series of 512x512 images. The series is usually about 100-300 slices long (the z axis). Cancers can occupy multiple slices along the z-axis.The value at each pixel is the Hounsfield unit (radiodensity) at that location.","Medical deepfakes: CT scans of human lungs, where some have been tampered with cancer added/removed. Can you find them?Attackers have the ability to intercept and add/remove medical evidence in medical imagery with high realism using deep learning. In this dataset we present medical deepfakes: 3D CT scans of human lungs, where some have been tampered with real cancer removed and with fake cancer injected. The objective of this dataset is to distinguish between real and fake cancers, and identify where medical scans have been tampered. Three expert radiologists have evaluated this dataset and could not reliably tell the difference between real and fake cancers, meaning that the fake cancers are realistic and this detection task is very challenging. For more information, please see our paper 'CT-GAN'.The dataset consists of two sets (80 scans and 20 scans). The first 80 were used in a blind trial with the radiologists (they weren't told they were tampered), and the 20 scans were used in an open trial with the radiologists (they were told the truth and asked to identify them). Provided with the scans is a table with the ground truth. For each scan, where a cancer is located (x, y, and z [slice#]) and its classification. A location can be classified as being:True-Benign, (TB): A location that actually has no cancer True-Malicious (TM): A location that has real cancerFalse-Benign (FB): A location that has real cancer, but it was removed.False-Malicious (FM): A location that does not have cancer, but fake cancer was injected there.Access to the dataset is via this link: [Web Link]Each scan is in the medical dicom format, but it can be loaded as a 3D matrix with Python by using the tools provided in our code repository: [Web Link]A scan is basically a series of 512x512 images. The series is usually about 100-300 slices long (the z axis). Cancers can occupy multiple slices along the z-axis.The value at each pixel is the Hounsfield unit (radiodensity) at that location."
DeliciousMIL: A Data Set for Multi-Label Multi-Instance Learning with Instance Labels,DeliciousMIL: A Data Set for Multi-Label Multi-Instance Learning with Instance Labels,"This dataset includes 1) 12234 documents (8251 training, 3983 test) extracted from DeliciousT140 dataset, 2) class labels for all documents, 3) labels for a subset of sentences of the test documents.",DeliciousMIL%3A+A+Data+Set+for+Multi-Label+Multi-Instance+Learning+with+Instance+Labels,https://archive.ics.uci.edu/ml//machine-learning-databases/00418/,https://archive.ics.uci.edu/ml/datasets/DeliciousMIL%3A+A+Data+Set+for+Multi-Label+Multi-Instance+Learning+with+Instance+Labels,"This dataset provides ground-truth class labels to evaluate performance of multi-instance learning models on both instance-level and bag-level label predictions. DeliciousMIL was first used in [1] to evaluate performance of MLTM, a multi-label multi-instance learning method, for document classification and sentence labeling.Multi-instance learning is a special class of weakly supervised machine learning methods where the learner receives a collection of labeled bags each containing multiple instances. A bag is set to have a particular class label if and only if at least one of its instances has that class label.DeliciousMIL consists of a subset of tagged web pages from the social bookmarking site delicious.com. The original web pages were obtained from DeliciousT140 dataset, which was collected by [2] from the delicious.com in June 2008. Users of the website delicious.com bookmarked each page with word tags. From this dataset, we extracted text parts of each web page and chose 20 common tags as class labels. These class labels are:reference, design, programming, internet, computer, web, java, writing, English, grammar, style, language, books, education, philosophy, politics, religion, science, history, and culture.We randomly selected 12234 pages and randomly divided them into 8251 training and 3983 test documents. We also applied Porter stemming and standard stopword removal. Each text document is a bag within a multi-instance learning framework consisting of multiple sentences (instances). The goal is to predict document-level and sentence-level class labels on the test set using a model which is trained given only the document-level class labels in the training set.To evaluate performance of such a model, we have manually labeled 1468 randomly selected sentences from the test documents. Please see [1] for more information. ",Computer,"1) train-data.dat and test-data.dat:These files contain the bag-of-word representation of the training and test documents. Each line is of the form: sentence_1 sentence_2 Ã¢â‚¬Â¦ sentence_{Sd}where Sd is the number of sentences in document d. Each sentence s is in the following format: w_{1s} w_{2s} Ã¢â‚¬Â¦ w_{L_s s}where L_s is the number of words in sentence s, and w_{is} is an integer which indexes the i-th term in sentence s. 2) vocabs.txt: This file contains the list of words used for indexing the document representations in data files. Each line contains: word, index.3) train-label.dat and test-label.dat:Each file contains a D by C binary matrix where D is the number of documents in every file and C=20 is the number of classes. The element b_{dc} is 1 if class c is present in document d and zero otherwise.4) test-sentlabel.dat, labeled_test_sentences.dat:test-sentlabel.dat: This file contains class labels for sentences of the test documents. Each line d is of the form:...where y_{scd} is the binary indicator of class c for sentence s of document d. y_{scd} is 1 if class c present in sentence s and zero otherwise. Note that only 1468 sentences are randomly selected and manually labeled. For the rest of the sentences that are unlabeled, we set y_{scd}=-1. labeled_test_sentences.dat: This file only contains the class labels for the 1468 sentences which are manually labeled. Each line of this file is of the form:d s y_{s1d} y_{s2d} Ã¢â‚¬Â¦ y_{sCd}where d and s are respectively document and sentence indices. 4) labels.txt: This contains the list of all class labels in this dataset. Each line is of the form: label, index.Please see [Web Link] for example python code for reading these files.","This dataset includes 1) 12234 documents (8251 training, 3983 test) extracted from DeliciousT140 dataset, 2) class labels for all documents, 3) labels for a subset of sentences of the test documents.This dataset provides ground-truth class labels to evaluate performance of multi-instance learning models on both instance-level and bag-level label predictions. DeliciousMIL was first used in [1] to evaluate performance of MLTM, a multi-label multi-instance learning method, for document classification and sentence labeling.Multi-instance learning is a special class of weakly supervised machine learning methods where the learner receives a collection of labeled bags each containing multiple instances. A bag is set to have a particular class label if and only if at least one of its instances has that class label.DeliciousMIL consists of a subset of tagged web pages from the social bookmarking site delicious.com. The original web pages were obtained from DeliciousT140 dataset, which was collected by [2] from the delicious.com in June 2008. Users of the website delicious.com bookmarked each page with word tags. From this dataset, we extracted text parts of each web page and chose 20 common tags as class labels. These class labels are:reference, design, programming, internet, computer, web, java, writing, English, grammar, style, language, books, education, philosophy, politics, religion, science, history, and culture.We randomly selected 12234 pages and randomly divided them into 8251 training and 3983 test documents. We also applied Porter stemming and standard stopword removal. Each text document is a bag within a multi-instance learning framework consisting of multiple sentences (instances). The goal is to predict document-level and sentence-level class labels on the test set using a model which is trained given only the document-level class labels in the training set.To evaluate performance of such a model, we have manually labeled 1468 randomly selected sentences from the test documents. Please see [1] for more information. 1) train-data.dat and test-data.dat:These files contain the bag-of-word representation of the training and test documents. Each line is of the form: sentence_1 sentence_2 Ã¢â‚¬Â¦ sentence_{Sd}where Sd is the number of sentences in document d. Each sentence s is in the following format: w_{1s} w_{2s} Ã¢â‚¬Â¦ w_{L_s s}where L_s is the number of words in sentence s, and w_{is} is an integer which indexes the i-th term in sentence s. 2) vocabs.txt: This file contains the list of words used for indexing the document representations in data files. Each line contains: word, index.3) train-label.dat and test-label.dat:Each file contains a D by C binary matrix where D is the number of documents in every file and C=20 is the number of classes. The element b_{dc} is 1 if class c is present in document d and zero otherwise.4) test-sentlabel.dat, labeled_test_sentences.dat:test-sentlabel.dat: This file contains class labels for sentences of the test documents. Each line d is of the form:...where y_{scd} is the binary indicator of class c for sentence s of document d. y_{scd} is 1 if class c present in sentence s and zero otherwise. Note that only 1468 sentences are randomly selected and manually labeled. For the rest of the sentences that are unlabeled, we set y_{scd}=-1. labeled_test_sentences.dat: This file only contains the class labels for the 1468 sentences which are manually labeled. Each line of this file is of the form:d s y_{s1d} y_{s2d} Ã¢â‚¬Â¦ y_{sCd}where d and s are respectively document and sentence indices. 4) labels.txt: This contains the list of all class labels in this dataset. Each line is of the form: label, index.Please see [Web Link] for example python code for reading these files."
Character Font Images,Character Font Images,Character images from scanned and computer generated fonts.,Character+Font+Images,https://archive.ics.uci.edu/ml//machine-learning-databases/00417/,https://archive.ics.uci.edu/ml/datasets/Character+Font+Images,"The data set consists of images from 153 character fonts. Some fonts were scanned from a variety of devices: hand scanners, desktop scanners or cameras.  Other fonts were computer generated.  The .zip file contains .csv, comma delimited files, one for each font.  Each .csv file has a header row with the data set attribute names. The Handprint images differ slightly from the standard MNIST dataset.  ",Computer,"field       Type    Unique  Example          Descriptionfont        string  153    Ã¢â‚¬ËœtimesÃ¢â‚¬â„¢           font familyfontVariant string  248    Ã¢â‚¬Ëœtimes new romanÃ¢â‚¬â„¢ If the font image was from a scanner,                                              the fontVariant is Ã¢â‚¬Å“scannedÃ¢â‚¬Â� otherwise it is the font name.m_label     integer 11597  33 to 65535       The character value, for instance 48 for the digit, Ã¢â‚¬Ëœ0Ã¢â‚¬â„¢strength    real    2      .4                A value 0 to 1, indicating normal or bolditalic      integer 2      1                 A flag, if 1, the image was computer generated with the an italic font.m_top       integer        13                The topmost black pixel row index in the original image from which the image was cutm_left      integer        43                The leftmost black pixel column index in the original image from which the image was cutoriginalH   integer        30                The original height of the image in pixelsoriginalW   integer        36                The original width of the image in pixelsh           integer 1      20                The image height in this sample, always 20w           integer 1      20                The image width in this sample, always 20r0c0        integer        0                 Row 0 Column 0 pixel value, 0 to 255, white is 0, 255 is blackr0c1        integer        255               Row 0, Column 1 pixel value, 0 to 255Ã¢â‚¬Â¦ 397       integer        0                 397 pixel values, 0 to 255r19c19      integer        255               Row 19, Column 19 pixel value, 0 to 255","Character images from scanned and computer generated fonts.The data set consists of images from 153 character fonts. Some fonts were scanned from a variety of devices: hand scanners, desktop scanners or cameras.  Other fonts were computer generated.  The .zip file contains .csv, comma delimited files, one for each font.  Each .csv file has a header row with the data set attribute names. The Handprint images differ slightly from the standard MNIST dataset.  field       Type    Unique  Example          Descriptionfont        string  153    Ã¢â‚¬ËœtimesÃ¢â‚¬â„¢           font familyfontVariant string  248    Ã¢â‚¬Ëœtimes new romanÃ¢â‚¬â„¢ If the font image was from a scanner,                                              the fontVariant is Ã¢â‚¬Å“scannedÃ¢â‚¬Â� otherwise it is the font name.m_label     integer 11597  33 to 65535       The character value, for instance 48 for the digit, Ã¢â‚¬Ëœ0Ã¢â‚¬â„¢strength    real    2      .4                A value 0 to 1, indicating normal or bolditalic      integer 2      1                 A flag, if 1, the image was computer generated with the an italic font.m_top       integer        13                The topmost black pixel row index in the original image from which the image was cutm_left      integer        43                The leftmost black pixel column index in the original image from which the image was cutoriginalH   integer        30                The original height of the image in pixelsoriginalW   integer        36                The original width of the image in pixelsh           integer 1      20                The image height in this sample, always 20w           integer 1      20                The image width in this sample, always 20r0c0        integer        0                 Row 0 Column 0 pixel value, 0 to 255, white is 0, 255 is blackr0c1        integer        255               Row 0, Column 1 pixel value, 0 to 255Ã¢â‚¬Â¦ 397       integer        0                 397 pixel values, 0 to 255r19c19      integer        255               Row 19, Column 19 pixel value, 0 to 255"
Detect Malacious Executable(AntiVirus),Detect Malacious Executable(AntiVirus),I extract features from malacious and non-malacious and create and training dataset to teach svm classifier.Dataset made of unknown executable to detect if it is virus or normal safe executable.,Detect+Malacious+Executable%28AntiVirus%29,https://archive.ics.uci.edu/ml//machine-learning-databases/00355/,https://archive.ics.uci.edu/ml/datasets/Detect+Malacious+Executable%28AntiVirus%29,TRAINING File : I have created training file with 100+ non malacious examples and 250+ malacious samples. NON-MALACIOUS dataset is represented by +1 while MALACIOUS datset     is represented by -1 as label. Based on comparison and analysis I have selected 500 most commonly occuring features in MALACIOUS and NON-MALACIOUS file and compared extracted features of each file with this best features. The file is saved with .train extension.TESTING file: We select a unknown malacious executable and carry out same procedure on it ( however we can put it in any class +1/ -1) cuz svmpredict will any way corretly find it for us. We save this testing file with .test extension. ,Computer,"For best results I have used Hybrid Features ( hexdump and DLL) from an executable. After extracting this features I find out the top 500 hex features and top 13 DLL features which are most commonly occuring and prepare file with best features.Now feature amoung this which are found in individual file is been stated in dataset along with 1 while rest are ignored and feature set ends with -1  ie say ( +1 2:1 5:1 45:1 .............. -1)  so here +1 states a NON-malacious file while 2:1 states 2nd feature exists similarly for 5,45 while features which do not occur are simply ignored.For MALACIOUS executable we write it as ( -1 6:1 56:1 ............ -1)so Attribute which exists is given a  colon 1 ahead of it (:1)  ","I extract features from malacious and non-malacious and create and training dataset to teach svm classifier.Dataset made of unknown executable to detect if it is virus or normal safe executable.TRAINING File : I have created training file with 100+ non malacious examples and 250+ malacious samples. NON-MALACIOUS dataset is represented by +1 while MALACIOUS datset     is represented by -1 as label. Based on comparison and analysis I have selected 500 most commonly occuring features in MALACIOUS and NON-MALACIOUS file and compared extracted features of each file with this best features. The file is saved with .train extension.TESTING file: We select a unknown malacious executable and carry out same procedure on it ( however we can put it in any class +1/ -1) cuz svmpredict will any way corretly find it for us. We save this testing file with .test extension. For best results I have used Hybrid Features ( hexdump and DLL) from an executable. After extracting this features I find out the top 500 hex features and top 13 DLL features which are most commonly occuring and prepare file with best features.Now feature amoung this which are found in individual file is been stated in dataset along with 1 while rest are ignored and feature set ends with -1  ie say ( +1 2:1 5:1 45:1 .............. -1)  so here +1 states a NON-malacious file while 2:1 states 2nd feature exists similarly for 5,45 while features which do not occur are simply ignored.For MALACIOUS executable we write it as ( -1 6:1 56:1 ............ -1)so Attribute which exists is given a  colon 1 ahead of it (:1)  "
Detect Malware Types,Detect Malware Types,Provide a short description of your data set (less than 200 characters).,Detect+Malware+Types,https://archive.ics.uci.edu/ml//machine-learning-databases/00533/,https://archive.ics.uci.edu/ml/datasets/Detect+Malware+Types,"This study seeks to obtain data which will help to address machine learning based malware research gaps. The specific objective of this study is to build a benchmark dataset for Windows operating system API calls of various malware. This is the first study to undertake metamorphic malware to build sequential API calls. It is hoped that this research will contribute to a deeper understanding of how metamorphic malware change their behavior (i.e. API calls) by adding meaningless opcodes with their own dissembler/assembler parts. In our research, we have translated the families produced by each of the software into 8 main malware families: Trojan, Backdoor, Downloader, Worms, Spyware Adware, Dropper, Virus. Table 1 shows the number of malware belonging to malware families in our data set. As you can see in the table, the number of samples of other malware families except AdWare is quite close to each other. There is such a difference because we don't find too much of malware from the adware malware family.",Computer,Various Windows API calls,"Provide a short description of your data set (less than 200 characters).This study seeks to obtain data which will help to address machine learning based malware research gaps. The specific objective of this study is to build a benchmark dataset for Windows operating system API calls of various malware. This is the first study to undertake metamorphic malware to build sequential API calls. It is hoped that this research will contribute to a deeper understanding of how metamorphic malware change their behavior (i.e. API calls) by adding meaningless opcodes with their own dissembler/assembler parts. In our research, we have translated the families produced by each of the software into 8 main malware families: Trojan, Backdoor, Downloader, Worms, Spyware Adware, Dropper, Virus. Table 1 shows the number of malware belonging to malware families in our data set. As you can see in the table, the number of samples of other malware families except AdWare is quite close to each other. There is such a difference because we don't find too much of malware from the adware malware family.Various Windows API calls"
Data for Software Engineering Teamwork Assessment in Education Setting,Data for Software Engineering Teamwork Assessment in Education Setting,"Data include over 100 Team Activity Measures and outcomes (ML classes) obtained from activities of 74 student teams during the creation of final class project in SW Eng. classes  at SFSU, Fulda, FAU",Data+for+Software+Engineering+Teamwork+Assessment+in+Education+Setting,https://archive.ics.uci.edu/ml//machine-learning-databases/00393/,https://archive.ics.uci.edu/ml/datasets/Data+for+Software+Engineering+Teamwork+Assessment+in+Education+Setting,"The data can be used to try to predict student learning in SE teamwork based on observation of their team activity **** README FILE from the submitted data ZIP ****#  San Francisco State University#  Software Engineering Team Assessment and Prediction (SETAP) Project#  Machine Learning Training Data File Version 0.7#  ====================================================================##  Copyright 2000-2017 by San Francisco State University, Dragutin#  Petkovic, and Marc Sosnick-Perez.##  CONTACT#  -------#  Professor Dragutin Petkovic:  petkovic '@' sfsu.edu##  LICENSE#  -------#  This data is released under the Creative Commons Attribution-#  NonCommercial 4.0 International license.  For more information,#  please see#  [Web Link].##  The research that has made this data possible has been funded in#  part by NSF grant NSF-TUES1140172.##  YOUR FEEDBACK IS WELCOME#  ------------------------#  We are interested in how this data is being used.  If you use it in#  a research project, we would like to know how you are using the#  data.  Please contact us at petkovic '@' sfsu.edu.###  FILES INCLUDED IN DISTRIBUTION PACKAGE#  ======================================#  This archive contains the data collected by the SETAP Project.###  More data about the SETAP project, data collection, and description#  and use of machine learning to analyze the data can be found in the#  following paper:##  D. Petkovic, M. Sosnick-Perez, K. Okada, R. Todtenhoefer, S. Huang,#  N. Miglani, A. Vigil: 'Using the Random Forest Classifier to Assess#  and Predict Student Learning of Software Engineering Teamwork'.#  Frontiers in Education FIE 2016, Erie, PA, 2016####  See DATA DESCRIPTION below for more information about the data.  The#  README file (which you are reading) contains project information#  such as data collection techniques, data organization and field#  naming convention.  In addition to the README file, the archive#  contains a number of .csv files.  Each of these CSV files contains#  data aggregated by team from the project (see below), paired with#  that team's outcome for either the process or product component of#  the team's evaluation.  The files are named using the following#  convention:##                  setap[Process|Product]T[1-11].csv##  For example, the file setapProcessT5.csv contains the data for all#  teams for time interval 5, paired with the outcome data for the#  Process component of the team's evaluation.##  Detailed information about the exact format of the .csv file may be#  found in the csv files themselves.###  DATA DESCRIPTION#  ====================================================================#  The following is a detailed description of the data contained in the#  accompanying files.##  INTRODUCTION#  ------------##  The data contained in these files were collected over a period of#  several semesters from students engaged in software engineering#  classes at San Francisco State University (class sections of CSC#  640, CSC 648 and CSC 848).  All students consented to this data#  being shared for research purposes provided no uniquely identifiable#  information was contained in the distributed files.  The information#  was collected through various means, with emphasis being placed on#  the collection of objective, quantifiable information.  For more#  information on the data collection procedures, please see the paper#  referenced above.###  PRIVACY#  -------#  The data contained in this file does not contain any information#  which may be individually traced to a particular student who#  participated in the study.###  BRIEF DESCRIPTION OF DATA SOURCES AND DERIVATIONS#  -------------------------------------------------#  SAMs (Student Activity Measure) are collected for each student team#  member during their participation in a software engineering class.#  Student teams work together on a final class project, and comprise#  5-6 students.  Teams that are made up of students from only one#  school are labeled local teams.  Teams made up of students from more#  than one school are labeled global teams.  SAMs are collected from:#  weekly timecards, instructor observations, and software engineering#  tool usage logs.  SAMs are then aggregated by team and time interval#  (see next section) into TAMs (Team Activity Measure).  Outcomes are#  determined at the end of the semester through evaluation of student#  team work in two categories:  software engineering process (how well#  the team applied best software engineering practices), and software#  engineering product (the quality of the finished product the team#  produced).  Thus for each team, two outcomes are determined, process#  and product, respectively.  Outcomes are classified into two class#  grades, A or F.  A represents teams that are at or above#  expectations, F represents teams that are below expectations or need#  attention.  For more information, please see the paper referenced#  above.##  The SE process and SE product outcomes represent ML training classes#  and are to be considered separately, e.g. one should train ML for SE#  process separately from training for SE product.##  TIME INTERVALS FOR WHICH DATA IS COLLECTED#  ------------------------------------------#  Data collected continuously throughout the semester are aggregated#  into different time intervals for the semester's project reflecting#  different dynamics of teamwork during the class.  Time intervals#  represent time periods in which a milestone was developed by each#  team.  A milestone represents a major deliverable point in the class#  for all student teams.  The milestones are roughly divided into the#  following topics:##            M1 - high level requirements and specs#            M2 - more detailed requirements and specs#            M3 - first prototype#            M4 - beta release#            M5 - final delivery##  Time intervals are combinations of the time in which milestones are#  being produced.  Time intervals are used in research only.##  In addition to time intervals corresponding to milestones, a number#  of time intervals combining multiple T1-T5 time intervals have been#  calculated.  This was done to group student activities into design#  vs. implementation phases which have different dynamics.##  These time intervals are defined as follows:##      Time Interval        Corresponding Milestone Periods in Class#    -----------------    --------------------------------------------#           0               Milestone 0#           1               Milestone 1#           2               Milestone 2#           3               Milestone 3#           4               Milestone 4#           5               Milestone 5#           6               Milestone 1 - Milestone 2 inclusive#           7               Milestone 1 - Milestone 3 inclusive#           8               Milestone 1 - Milestone 4 inclusive#           9               Milestone 1 - Milestone 5 inclusive#          10               Milestone 4 - Milestone 5 inclusive#          11               Milestone 3 - Milestone 5 inclusive####  SETAP PROJECT OVERALL DATA STATISTICS#  ================================================================== #  The following is a set of statistics about the entire dataset which#  may be useful in the configuration of machine learning methods.##  This data was collected only from students at SFSU.  Global teams#  represent only the data from the SFSU student portion of the team.##  GENERAL STATISTICS#  ------------------#                       Number of semesters: 7#                            First semester: Fall 2012#                             Last semester: Fall 2015#                        Number of students: 383#                            Class sections: 18##                    Number of TAM features: 115#         Number of class labels (outcomes): 2##                     Issues closed on time:   202#                        Issues closed late: +  53#                                            -------#                              Total issues:   255##  TEAM COMPOSITION STATISTCS#  --------------------------#      Local Teams:    59#     Global Teams: +  15#                   ------#            Total:    74 Teams##  OUTCOME (CLASSIFICATION) STATISTICS#  -----------------------------------#   Total Outcomes: 74##                Proces               Product#           ------------------  ------------------#  outcome:      A       F           A       F#                49      25          42     32##  TAM FEATURE NAMING CONVENTION#  -----------------------------#  A systematic approach to aggregating and naming TAM features was#  developed.  By using this systematic approach, TAM feature names are#  produced that are human understandable and intuitive and related to#  aggregation method.###  There are a number of base TAM which are then aggregated into#  aggregated TAM.##  BASE TAM#  --------##  General TAM#  -----------#  The following TAMs are collected for each team: Year, semester,#  timeInterval, teamNumber, semesterId, teamMemberCount,#  femaleTeamMembersPercent, teamLeadGender, teamDistribution##  Calculated TAM#  --------------#  For each team, TAM were calculated from SAMs for every time interval#  Ti.  The core TAM variables where for each we compute as applicable:#  count, average, standard deviation over weeks, over students etc.##  TAMs collected by Weekly Time Cards (WTS) TAM#  ---------------------------------------------#  teamMemberResponseCount, meetingHours, inPersonMeetingHours.#  nonCodingDeliverablesHours, codingDeliverablesHours, helpHours,#  globalLeadAdminHours, LeadAdminHoursResponseCount,#  GlobalLeadAdminHoursResponseCount##  TAMs collected  by Tool Logs (TL) TAM#  -------------------------------------#  commitCount, uniqueCommitMessageCount, uniqueCommitMessagePercent,#  CommitMessageLength##  Collected by Instructor Observations (IO) TAMs#  ------------------------------------------------#  issueCount, onTimeIssueCount, lateIssueCount###  AGGREGATED TAM#  --------------##  Several aggregation method and derived variable names for TAMs#  reflect how the core TAM variables were aggregated in final TAM#  measures for each time interval Ti:##  Let VAR be the core TAM variable above. The naming conventions and#  aggregation operators to obtain TAMs for each time interval Ti were#  as follows:##  Total - total sum of VAR in the time interval Ti#  Average - average of VAR in the time interval#  StandardDeviation - SD of variable in time interval#  Count - count of events measured by VAR (e.g. missed#  checkpoints) in time interval#  AverageByWeek - total sum/count of VAR in the time interval#  divided by weeks in time interval#  StandradDeviationByWeek - the standard devation of the weekly#  total of VAR taken over the time interval#  AverageByStudent - total count/sum of VAR in time interval,#  divided by number of students in the team#  StandardDeviation ByStudent - standard deviation of  VAR in the#  time interval, over students in the team###  NULL VALUES#  -----------#  NULL values are used in the training data to indicate that no SAMs#  were recorded in that particular time period, week, or for that#  student.##  Frequently TAM features involving teamLeadHours or globalTeamLead#  hours will result in a NULL for a particular training sample.  For#  local team leads, that usually means that the local team lead did#  not complete any timecard surveys for the aggregation in quesiton.#  While for global team lead TAM features this may also be the case,#  the more usual cause of NULLS in global team lead TAM features comes#  from the fact that most teams are not global, and therefore this#  statistic was not gathered for these teams.##  It is left to the individual researcher to decide how to accomodate#  NULL values, and the data is included in this file.  Though these#  may not be useful for machine learning directly, valuable#  information can be obatined with some processing.##  TAM FEATURES#  ------------#  The following is a list of tam features available in the data files.#  The TAM feature names are listed in the order in which the data#  appear in each training sample, i.e. the first feature corresponds#  to the first column, the second feature corresponds to the second#  column, etc.##  The first sample line in the data section of the data file is not a#  true sample, but consists of TAM feature names, which allows for#  easy import into spreadsheets and for human readability.##  The final two TAM features (columns) are the outcome data for#  process and product, and are the last two columns in each sample#  row.  The training sample data follow the header comment section.###  TAM FEATURE LIST#  ----------------#  year#  semester#  timeInterval#  teamNumber#  semesterId#  teamMemberCount#  femaleTeamMembersPercent#  teamLeadGender#  teamDistribution#  teamMemberResponseCount#  meetingHoursTotal#  meetingHoursAverage#  meetingHoursStandardDeviation#  inPersonMeetingHoursTotal#  inPersonMeetingHoursAverage#  inPersonMeetingHoursStandardDeviation#  nonCodingDeliverablesHoursTotal#  nonCodingDeliverablesHoursAverage#  nonCodingDeliverablesHoursStandardDeviation#  codingDeliverablesHoursTotal#  codingDeliverablesHoursAverage#  codingDeliverablesHoursStandardDeviation#  helpHoursTotal#  helpHoursAverage#  helpHoursStandardDeviation#  leadAdminHoursResponseCount#  leadAdminHoursTotal#  leadAdminHoursAverage#  leadAdminHoursStandardDeviation#  globalLeadAdminHoursResponseCount#  globalLeadAdminHoursTotal#  globalLeadAdminHoursAverage#  globalLeadAdminHoursStandardDeviation#  averageResponsesByWeek#  standardDeviationResponsesByWeek#  averageMeetingHoursTotalByWeek#  standardDeviationMeetingHoursTotalByWeek#  averageMeetingHoursAverageByWeek#  standardDeviationMeetingHoursAverageByWeek#  averageInPersonMeetingHoursTotalByWeek#  standardDeviationInPersonMeetingHoursTotalByWeek#  averageInPersonMeetingHoursAverageByWeek#  standardDeviationInPersonMeetingHoursAverageByWeek#  averageNonCodingDeliverablesHoursTotalByWeek#  standardDeviationNonCodingDeliverablesHoursTotalByWeek#  averageNonCodingDeliverablesHoursAverageByWeek#  standardDeviationNonCodingDeliverablesHoursAverageByWeek#  averageCodingDeliverablesHoursTotalByWeek#  standardDeviationCodingDeliverablesHoursTotalByWeek#  averageCodingDeliverablesHoursAverageByWeek#  standardDeviationCodingDeliverablesHoursAverageByWeek#  averageHelpHoursTotalByWeek#  standardDeviationHelpHoursTotalByWeek#  averageHelpHoursAverageByWeek#  standardDeviationHelpHoursAverageByWeek#  averageLeadAdminHoursResponseCountByWeek#  standardDeviationLeadAdminHoursResponseCountByWeek#  averageLeadAdminHoursTotalByWeek#  standardDeviationLeadAdminHoursTotalByWeek#  averageGlobalLeadAdminHoursResponseCountByWeek#  standardDeviationGlobalLeadAdminHoursResponseCountByWeek#  averageGlobalLeadAdminHoursTotalByWeek#  standardDeviationGlobalLeadAdminHoursTotalByWeek#  averageGlobalLeadAdminHoursAverageByWeek#  standardDeviationGlobalLeadAdminHoursAverageByWeek#  averageResponsesByStudent#  standardDeviationResponsesByStudent#  averageMeetingHoursTotalByStudent#  standardDeviationMeetingHoursTotalByStudent#  averageMeetingHoursAverageByStudent#  standardDeviationMeetingHoursAverageByStudent#  averageInPersonMeetingHoursTotalByStudent#  standardDeviationInPersonMeetingHoursTotalByStudent#  averageInPersonMeetingHoursAverageByStudent#  standardDeviationInPersonMeetingHoursAverageByStudent#  averageNonCodingDeliverablesHoursTotalByStudent#  standardDeviationNonCodingDeliverablesHoursTotalByStudent#  averageNonCodingDeliverablesHoursAverageByStudent#  standardDeviationNonCodingDeliverablesHoursAverageByStudent#  averageCodingDeliverablesHoursTotalByStudent#  standardDeviationCodingDeliverablesHoursTotalByStudent#  averageCodingDeliverablesHoursAverageByStudent#  standardDeviationCodingDeliverablesHoursAverageByStudent#  averageHelpHoursTotalByStudent#  standardDeviationHelpHoursTotalByStudent#  averageHelpHoursAverageByStudent#  standardDeviationHelpHoursAverageByStudent#  commitCount#  uniqueCommitMessageCount#  uniqueCommitMessagePercent#  commitMessageLengthTotal#  commitMessageLengthAverage#  commitMessageLengthStandardDeviation#  averageCommitCountByWeek#  standardDeviationCommitCountByWeek#  averageUniqueCommitMessageCountByWeek#  standardDeviationUniqueCommitMessageCountByWeek#  averageUniqueCommitMessagePercentByWeek#  standardDeviationUniqueCommitMessagePercentByWeek#  averageCommitMessageLengthTotalByWeek#  standardDeviationCommitMessageLengthTotalByWeek#  averageCommitCountByStudent#  standardDeviationCommitCountByStudent#  averageUniqueCommitMessageCountByStudent#  standardDeviationUniqueCommitMessageCountByStudent#  averageUniqueCommitMessagePercentByStudent#  standardDeviationUniqueCommitMessagePercentByStudent#  averageCommitMessageLengthTotalByStudent#  standardDeviationCommitMessageLengthTotalByStudent#  averageCommitMessageLengthAverageByStudent#  standardDeviationCommitMessageLengthAverageByStudent#  averageCommitMessageLengthStandardDeviationByStudent#  issueCount#  onTimeIssueCount#  lateIssueCount#  processLetterGrade#  productLetterGrade",Computer,See above,"Data include over 100 Team Activity Measures and outcomes (ML classes) obtained from activities of 74 student teams during the creation of final class project in SW Eng. classes  at SFSU, Fulda, FAUThe data can be used to try to predict student learning in SE teamwork based on observation of their team activity **** README FILE from the submitted data ZIP ****#  San Francisco State University#  Software Engineering Team Assessment and Prediction (SETAP) Project#  Machine Learning Training Data File Version 0.7#  ====================================================================##  Copyright 2000-2017 by San Francisco State University, Dragutin#  Petkovic, and Marc Sosnick-Perez.##  CONTACT#  -------#  Professor Dragutin Petkovic:  petkovic '@' sfsu.edu##  LICENSE#  -------#  This data is released under the Creative Commons Attribution-#  NonCommercial 4.0 International license.  For more information,#  please see#  [Web Link].##  The research that has made this data possible has been funded in#  part by NSF grant NSF-TUES1140172.##  YOUR FEEDBACK IS WELCOME#  ------------------------#  We are interested in how this data is being used.  If you use it in#  a research project, we would like to know how you are using the#  data.  Please contact us at petkovic '@' sfsu.edu.###  FILES INCLUDED IN DISTRIBUTION PACKAGE#  ======================================#  This archive contains the data collected by the SETAP Project.###  More data about the SETAP project, data collection, and description#  and use of machine learning to analyze the data can be found in the#  following paper:##  D. Petkovic, M. Sosnick-Perez, K. Okada, R. Todtenhoefer, S. Huang,#  N. Miglani, A. Vigil: 'Using the Random Forest Classifier to Assess#  and Predict Student Learning of Software Engineering Teamwork'.#  Frontiers in Education FIE 2016, Erie, PA, 2016####  See DATA DESCRIPTION below for more information about the data.  The#  README file (which you are reading) contains project information#  such as data collection techniques, data organization and field#  naming convention.  In addition to the README file, the archive#  contains a number of .csv files.  Each of these CSV files contains#  data aggregated by team from the project (see below), paired with#  that team's outcome for either the process or product component of#  the team's evaluation.  The files are named using the following#  convention:##                  setap[Process|Product]T[1-11].csv##  For example, the file setapProcessT5.csv contains the data for all#  teams for time interval 5, paired with the outcome data for the#  Process component of the team's evaluation.##  Detailed information about the exact format of the .csv file may be#  found in the csv files themselves.###  DATA DESCRIPTION#  ====================================================================#  The following is a detailed description of the data contained in the#  accompanying files.##  INTRODUCTION#  ------------##  The data contained in these files were collected over a period of#  several semesters from students engaged in software engineering#  classes at San Francisco State University (class sections of CSC#  640, CSC 648 and CSC 848).  All students consented to this data#  being shared for research purposes provided no uniquely identifiable#  information was contained in the distributed files.  The information#  was collected through various means, with emphasis being placed on#  the collection of objective, quantifiable information.  For more#  information on the data collection procedures, please see the paper#  referenced above.###  PRIVACY#  -------#  The data contained in this file does not contain any information#  which may be individually traced to a particular student who#  participated in the study.###  BRIEF DESCRIPTION OF DATA SOURCES AND DERIVATIONS#  -------------------------------------------------#  SAMs (Student Activity Measure) are collected for each student team#  member during their participation in a software engineering class.#  Student teams work together on a final class project, and comprise#  5-6 students.  Teams that are made up of students from only one#  school are labeled local teams.  Teams made up of students from more#  than one school are labeled global teams.  SAMs are collected from:#  weekly timecards, instructor observations, and software engineering#  tool usage logs.  SAMs are then aggregated by team and time interval#  (see next section) into TAMs (Team Activity Measure).  Outcomes are#  determined at the end of the semester through evaluation of student#  team work in two categories:  software engineering process (how well#  the team applied best software engineering practices), and software#  engineering product (the quality of the finished product the team#  produced).  Thus for each team, two outcomes are determined, process#  and product, respectively.  Outcomes are classified into two class#  grades, A or F.  A represents teams that are at or above#  expectations, F represents teams that are below expectations or need#  attention.  For more information, please see the paper referenced#  above.##  The SE process and SE product outcomes represent ML training classes#  and are to be considered separately, e.g. one should train ML for SE#  process separately from training for SE product.##  TIME INTERVALS FOR WHICH DATA IS COLLECTED#  ------------------------------------------#  Data collected continuously throughout the semester are aggregated#  into different time intervals for the semester's project reflecting#  different dynamics of teamwork during the class.  Time intervals#  represent time periods in which a milestone was developed by each#  team.  A milestone represents a major deliverable point in the class#  for all student teams.  The milestones are roughly divided into the#  following topics:##            M1 - high level requirements and specs#            M2 - more detailed requirements and specs#            M3 - first prototype#            M4 - beta release#            M5 - final delivery##  Time intervals are combinations of the time in which milestones are#  being produced.  Time intervals are used in research only.##  In addition to time intervals corresponding to milestones, a number#  of time intervals combining multiple T1-T5 time intervals have been#  calculated.  This was done to group student activities into design#  vs. implementation phases which have different dynamics.##  These time intervals are defined as follows:##      Time Interval        Corresponding Milestone Periods in Class#    -----------------    --------------------------------------------#           0               Milestone 0#           1               Milestone 1#           2               Milestone 2#           3               Milestone 3#           4               Milestone 4#           5               Milestone 5#           6               Milestone 1 - Milestone 2 inclusive#           7               Milestone 1 - Milestone 3 inclusive#           8               Milestone 1 - Milestone 4 inclusive#           9               Milestone 1 - Milestone 5 inclusive#          10               Milestone 4 - Milestone 5 inclusive#          11               Milestone 3 - Milestone 5 inclusive####  SETAP PROJECT OVERALL DATA STATISTICS#  ================================================================== #  The following is a set of statistics about the entire dataset which#  may be useful in the configuration of machine learning methods.##  This data was collected only from students at SFSU.  Global teams#  represent only the data from the SFSU student portion of the team.##  GENERAL STATISTICS#  ------------------#                       Number of semesters: 7#                            First semester: Fall 2012#                             Last semester: Fall 2015#                        Number of students: 383#                            Class sections: 18##                    Number of TAM features: 115#         Number of class labels (outcomes): 2##                     Issues closed on time:   202#                        Issues closed late: +  53#                                            -------#                              Total issues:   255##  TEAM COMPOSITION STATISTCS#  --------------------------#      Local Teams:    59#     Global Teams: +  15#                   ------#            Total:    74 Teams##  OUTCOME (CLASSIFICATION) STATISTICS#  -----------------------------------#   Total Outcomes: 74##                Proces               Product#           ------------------  ------------------#  outcome:      A       F           A       F#                49      25          42     32##  TAM FEATURE NAMING CONVENTION#  -----------------------------#  A systematic approach to aggregating and naming TAM features was#  developed.  By using this systematic approach, TAM feature names are#  produced that are human understandable and intuitive and related to#  aggregation method.###  There are a number of base TAM which are then aggregated into#  aggregated TAM.##  BASE TAM#  --------##  General TAM#  -----------#  The following TAMs are collected for each team: Year, semester,#  timeInterval, teamNumber, semesterId, teamMemberCount,#  femaleTeamMembersPercent, teamLeadGender, teamDistribution##  Calculated TAM#  --------------#  For each team, TAM were calculated from SAMs for every time interval#  Ti.  The core TAM variables where for each we compute as applicable:#  count, average, standard deviation over weeks, over students etc.##  TAMs collected by Weekly Time Cards (WTS) TAM#  ---------------------------------------------#  teamMemberResponseCount, meetingHours, inPersonMeetingHours.#  nonCodingDeliverablesHours, codingDeliverablesHours, helpHours,#  globalLeadAdminHours, LeadAdminHoursResponseCount,#  GlobalLeadAdminHoursResponseCount##  TAMs collected  by Tool Logs (TL) TAM#  -------------------------------------#  commitCount, uniqueCommitMessageCount, uniqueCommitMessagePercent,#  CommitMessageLength##  Collected by Instructor Observations (IO) TAMs#  ------------------------------------------------#  issueCount, onTimeIssueCount, lateIssueCount###  AGGREGATED TAM#  --------------##  Several aggregation method and derived variable names for TAMs#  reflect how the core TAM variables were aggregated in final TAM#  measures for each time interval Ti:##  Let VAR be the core TAM variable above. The naming conventions and#  aggregation operators to obtain TAMs for each time interval Ti were#  as follows:##  Total - total sum of VAR in the time interval Ti#  Average - average of VAR in the time interval#  StandardDeviation - SD of variable in time interval#  Count - count of events measured by VAR (e.g. missed#  checkpoints) in time interval#  AverageByWeek - total sum/count of VAR in the time interval#  divided by weeks in time interval#  StandradDeviationByWeek - the standard devation of the weekly#  total of VAR taken over the time interval#  AverageByStudent - total count/sum of VAR in time interval,#  divided by number of students in the team#  StandardDeviation ByStudent - standard deviation of  VAR in the#  time interval, over students in the team###  NULL VALUES#  -----------#  NULL values are used in the training data to indicate that no SAMs#  were recorded in that particular time period, week, or for that#  student.##  Frequently TAM features involving teamLeadHours or globalTeamLead#  hours will result in a NULL for a particular training sample.  For#  local team leads, that usually means that the local team lead did#  not complete any timecard surveys for the aggregation in quesiton.#  While for global team lead TAM features this may also be the case,#  the more usual cause of NULLS in global team lead TAM features comes#  from the fact that most teams are not global, and therefore this#  statistic was not gathered for these teams.##  It is left to the individual researcher to decide how to accomodate#  NULL values, and the data is included in this file.  Though these#  may not be useful for machine learning directly, valuable#  information can be obatined with some processing.##  TAM FEATURES#  ------------#  The following is a list of tam features available in the data files.#  The TAM feature names are listed in the order in which the data#  appear in each training sample, i.e. the first feature corresponds#  to the first column, the second feature corresponds to the second#  column, etc.##  The first sample line in the data section of the data file is not a#  true sample, but consists of TAM feature names, which allows for#  easy import into spreadsheets and for human readability.##  The final two TAM features (columns) are the outcome data for#  process and product, and are the last two columns in each sample#  row.  The training sample data follow the header comment section.###  TAM FEATURE LIST#  ----------------#  year#  semester#  timeInterval#  teamNumber#  semesterId#  teamMemberCount#  femaleTeamMembersPercent#  teamLeadGender#  teamDistribution#  teamMemberResponseCount#  meetingHoursTotal#  meetingHoursAverage#  meetingHoursStandardDeviation#  inPersonMeetingHoursTotal#  inPersonMeetingHoursAverage#  inPersonMeetingHoursStandardDeviation#  nonCodingDeliverablesHoursTotal#  nonCodingDeliverablesHoursAverage#  nonCodingDeliverablesHoursStandardDeviation#  codingDeliverablesHoursTotal#  codingDeliverablesHoursAverage#  codingDeliverablesHoursStandardDeviation#  helpHoursTotal#  helpHoursAverage#  helpHoursStandardDeviation#  leadAdminHoursResponseCount#  leadAdminHoursTotal#  leadAdminHoursAverage#  leadAdminHoursStandardDeviation#  globalLeadAdminHoursResponseCount#  globalLeadAdminHoursTotal#  globalLeadAdminHoursAverage#  globalLeadAdminHoursStandardDeviation#  averageResponsesByWeek#  standardDeviationResponsesByWeek#  averageMeetingHoursTotalByWeek#  standardDeviationMeetingHoursTotalByWeek#  averageMeetingHoursAverageByWeek#  standardDeviationMeetingHoursAverageByWeek#  averageInPersonMeetingHoursTotalByWeek#  standardDeviationInPersonMeetingHoursTotalByWeek#  averageInPersonMeetingHoursAverageByWeek#  standardDeviationInPersonMeetingHoursAverageByWeek#  averageNonCodingDeliverablesHoursTotalByWeek#  standardDeviationNonCodingDeliverablesHoursTotalByWeek#  averageNonCodingDeliverablesHoursAverageByWeek#  standardDeviationNonCodingDeliverablesHoursAverageByWeek#  averageCodingDeliverablesHoursTotalByWeek#  standardDeviationCodingDeliverablesHoursTotalByWeek#  averageCodingDeliverablesHoursAverageByWeek#  standardDeviationCodingDeliverablesHoursAverageByWeek#  averageHelpHoursTotalByWeek#  standardDeviationHelpHoursTotalByWeek#  averageHelpHoursAverageByWeek#  standardDeviationHelpHoursAverageByWeek#  averageLeadAdminHoursResponseCountByWeek#  standardDeviationLeadAdminHoursResponseCountByWeek#  averageLeadAdminHoursTotalByWeek#  standardDeviationLeadAdminHoursTotalByWeek#  averageGlobalLeadAdminHoursResponseCountByWeek#  standardDeviationGlobalLeadAdminHoursResponseCountByWeek#  averageGlobalLeadAdminHoursTotalByWeek#  standardDeviationGlobalLeadAdminHoursTotalByWeek#  averageGlobalLeadAdminHoursAverageByWeek#  standardDeviationGlobalLeadAdminHoursAverageByWeek#  averageResponsesByStudent#  standardDeviationResponsesByStudent#  averageMeetingHoursTotalByStudent#  standardDeviationMeetingHoursTotalByStudent#  averageMeetingHoursAverageByStudent#  standardDeviationMeetingHoursAverageByStudent#  averageInPersonMeetingHoursTotalByStudent#  standardDeviationInPersonMeetingHoursTotalByStudent#  averageInPersonMeetingHoursAverageByStudent#  standardDeviationInPersonMeetingHoursAverageByStudent#  averageNonCodingDeliverablesHoursTotalByStudent#  standardDeviationNonCodingDeliverablesHoursTotalByStudent#  averageNonCodingDeliverablesHoursAverageByStudent#  standardDeviationNonCodingDeliverablesHoursAverageByStudent#  averageCodingDeliverablesHoursTotalByStudent#  standardDeviationCodingDeliverablesHoursTotalByStudent#  averageCodingDeliverablesHoursAverageByStudent#  standardDeviationCodingDeliverablesHoursAverageByStudent#  averageHelpHoursTotalByStudent#  standardDeviationHelpHoursTotalByStudent#  averageHelpHoursAverageByStudent#  standardDeviationHelpHoursAverageByStudent#  commitCount#  uniqueCommitMessageCount#  uniqueCommitMessagePercent#  commitMessageLengthTotal#  commitMessageLengthAverage#  commitMessageLengthStandardDeviation#  averageCommitCountByWeek#  standardDeviationCommitCountByWeek#  averageUniqueCommitMessageCountByWeek#  standardDeviationUniqueCommitMessageCountByWeek#  averageUniqueCommitMessagePercentByWeek#  standardDeviationUniqueCommitMessagePercentByWeek#  averageCommitMessageLengthTotalByWeek#  standardDeviationCommitMessageLengthTotalByWeek#  averageCommitCountByStudent#  standardDeviationCommitCountByStudent#  averageUniqueCommitMessageCountByStudent#  standardDeviationUniqueCommitMessageCountByStudent#  averageUniqueCommitMessagePercentByStudent#  standardDeviationUniqueCommitMessagePercentByStudent#  averageCommitMessageLengthTotalByStudent#  standardDeviationCommitMessageLengthTotalByStudent#  averageCommitMessageLengthAverageByStudent#  standardDeviationCommitMessageLengthAverageByStudent#  averageCommitMessageLengthStandardDeviationByStudent#  issueCount#  onTimeIssueCount#  lateIssueCount#  processLetterGrade#  productLetterGradeSee above"
Average Localization Error (ALE) in sensor node localization process in WSNs,Average Localization Error (ALE) in sensor node localization process in WSNs,This data set can be used to test any regression-based machine learning algorithm. You can predict the ALE variable using four features.,Average+Localization+Error+%28ALE%29+in+sensor+node+localization+process+in+WSNs,https://archive.ics.uci.edu/ml//machine-learning-databases/00608/,https://archive.ics.uci.edu/ml/datasets/Average+Localization+Error+%28ALE%29+in+sensor+node+localization+process+in+WSNs,"This data contains 6 columns (107x6). The first four columns are features, namely anchor ratio, the transmission range of a sensor, node density (here no. of sensor nodes), and iteration count. The fifth column is ALE (predictand) and the last column is the standard deviation value (you may ignore this column if not interested in the error in ALE). This data set is generated from modified Cuckoo search simulations.Anyone can use this data with proper acknowledgment/citation.",Computer,This data contains four features and one predictand.Features are;1. Anchor ratio2. Transmission range (measured in meters)3. Node density and4. IterationThe predictand is ALE (measured in meters),"This data set can be used to test any regression-based machine learning algorithm. You can predict the ALE variable using four features.This data contains 6 columns (107x6). The first four columns are features, namely anchor ratio, the transmission range of a sensor, node density (here no. of sensor nodes), and iteration count. The fifth column is ALE (predictand) and the last column is the standard deviation value (you may ignore this column if not interested in the error in ALE). This data set is generated from modified Cuckoo search simulations.Anyone can use this data with proper acknowledgment/citation.This data contains four features and one predictand.Features are;1. Anchor ratio2. Transmission range (measured in meters)3. Node density and4. IterationThe predictand is ALE (measured in meters)"
BLE RSSI dataset for Indoor localization,BLE RSSI dataset for Indoor localization,This dataset contains RSSIs obtained on smartphones(Sony Xperia XA1). Signals were transmitted from BLE product called iTAG. Location column denotes the position of iTAG in building's entry.,BLE+RSSI+dataset+for+Indoor+localization,https://archive.ics.uci.edu/ml//machine-learning-databases/00586/,https://archive.ics.uci.edu/ml/datasets/BLE+RSSI+dataset+for+Indoor+localization,"The dataset was collected with help of students. Twelve students were divided to three groups and each student had iTAG device. They walked inside their limited area with activated iTAG. In long corridor, 18.35m x 3m, we denoted 3 areas which illustrate building's entry: inside, in vestibule and outside. Two smartphones, Sony Xperia XA1, received signals. They located at the start and end of 'in vestibule' area, which has length of 2.35m. Collection of RSSIs lasted for 20 minutes.There are two datasets: filtered_rssi and raw_rssi. We used feedback filter to smooth RSSI. Raw RSSIs are actual RSSIs that smartphone got.",Computer,"name - MAC address of iTAGlocationStatus - one of three possible iTAG location: INSIDE, IN_VESTIBULE, OUTSIDEtimestamp - timestamp in millisecondsrssiOne - RSSI on first smartphonerssiTwo - RSSI on second smartphone","This dataset contains RSSIs obtained on smartphones(Sony Xperia XA1). Signals were transmitted from BLE product called iTAG. Location column denotes the position of iTAG in building's entry.The dataset was collected with help of students. Twelve students were divided to three groups and each student had iTAG device. They walked inside their limited area with activated iTAG. In long corridor, 18.35m x 3m, we denoted 3 areas which illustrate building's entry: inside, in vestibule and outside. Two smartphones, Sony Xperia XA1, received signals. They located at the start and end of 'in vestibule' area, which has length of 2.35m. Collection of RSSIs lasted for 20 minutes.There are two datasets: filtered_rssi and raw_rssi. We used feedback filter to smooth RSSI. Raw RSSIs are actual RSSIs that smartphone got.name - MAC address of iTAGlocationStatus - one of three possible iTAG location: INSIDE, IN_VESTIBULE, OUTSIDEtimestamp - timestamp in millisecondsrssiOne - RSSI on first smartphonerssiTwo - RSSI on second smartphone"
COVID-19 Surveillance,COVID-19 Surveillance,Coronavirus Disease (COVID-19) Surveillance.,COVID-19+Surveillance,https://archive.ics.uci.edu/ml//machine-learning-databases/00567/,https://archive.ics.uci.edu/ml/datasets/COVID-19+Surveillance,Guidelines for Prevention and Control of Coronavirus Disease (COVID-19).,Computer,Symptoms of COVID-19,Coronavirus Disease (COVID-19) Surveillance.Guidelines for Prevention and Control of Coronavirus Disease (COVID-19).Symptoms of COVID-19
Educational Process Mining (EPM): A Learning Analytics Data Set,Educational Process Mining (EPM): A Learning Analytics Data Set,Educational Process Mining data set is built from the recordings of 115 subjects' activities through a logging application while learning with an educational simulator.,Educational+Process+Mining+%28EPM%29%3A+A+Learning+Analytics+Data+Set,https://archive.ics.uci.edu/ml//machine-learning-databases/00346/,https://archive.ics.uci.edu/ml/datasets/Educational+Process+Mining+%28EPM%29%3A+A+Learning+Analytics+Data+Set,"The experiments have been carried out with a group of 115 students of first-year, undergraduate Engineering major of the University of Genoa. We carried out this study over a simulation environment named Deeds (Digital Electronics Education and Design Suite) which is used for e-learning in digital electronics. The environment provides learning materials through specialized browsers for the students, and asks them to solve various problems with different levels of difficulty. For more information about the Deeds simulator used for this course look at: [Web Link]and to know more about the exercises contents of each session see 'exercises_info.txt'. Our data set contains the students' time series of activities during six sessions of laboratory sessions of the course of digital electronics. There are 6 folders containing the studentsÃ¢â‚¬â„¢ data per session. Each 'Session' folder contains up to 99 CSV files each dedicated to a specific student log during that session. The number of files in each folder changes due to the number of students present in each session. Each file contains 13 features. See 'features_info.txt' for more details.For the details of activities performed by the students during the course, see 'activities_info.txt'The data set includes the following files:=========================================- 'README.txt'- 'features_info.txt': contains information about the variables used on the feature vector.- 'features.txt': List of all features.- 'activities_info.txt': contains information about the variable 'activity'.- 'activities.txt': list of all activities.- 'exercises_info.txt': contains information about the variable 'exercise'.- 'grades_info.txt': contains information about the grade data.Data: ======- 'Processes': contains the data files from Session 1 to 6.- 'logs.txt': shows information about the log data per student Id. It shows whether a student has a log in each session (0: has no log, 1: has log).- 'final_grades.xlsx': contains the results of the final exam in two sheets.- 'intermediate_grades.xlsx': contains the grades for the students' assignments per session.- 'final_exam.pdf': shows the content of the final exam (original in Italian).- 'final_exam_ENG.pdf': shows the content of the final exam translated in English.Notes: ======For more information about this data set please look at: www.la.smartlab.wsla '@' smartlab.ws",Computer,"The features selected for this data set come from pre-processing of data collected through a logging program. Due to ethical reasons and to ensure the anonymity of our users, we cannot share the original log files, instead, we share the data transformed and cleaned in an appropriate format.The original logs contain the logging data of client system per approximately a second, while the features are calculated in order to be allocated to a particular activity. The features are selected and presented in a suitable format for Process Mining. In this sense, the data is presented per session, per student, and per exercise. Each CSV file belongs to a specific session and a specific student (named by the student Id). Each file contains several exercises of that session presented in 'exercise' feature. Each 'exercise' contains activities, which start-time, end-time, and other features are allocated to that.For further information about each feature, see 'features_info.txt'.","Educational Process Mining data set is built from the recordings of 115 subjects' activities through a logging application while learning with an educational simulator.The experiments have been carried out with a group of 115 students of first-year, undergraduate Engineering major of the University of Genoa. We carried out this study over a simulation environment named Deeds (Digital Electronics Education and Design Suite) which is used for e-learning in digital electronics. The environment provides learning materials through specialized browsers for the students, and asks them to solve various problems with different levels of difficulty. For more information about the Deeds simulator used for this course look at: [Web Link]and to know more about the exercises contents of each session see 'exercises_info.txt'. Our data set contains the students' time series of activities during six sessions of laboratory sessions of the course of digital electronics. There are 6 folders containing the studentsÃ¢â‚¬â„¢ data per session. Each 'Session' folder contains up to 99 CSV files each dedicated to a specific student log during that session. The number of files in each folder changes due to the number of students present in each session. Each file contains 13 features. See 'features_info.txt' for more details.For the details of activities performed by the students during the course, see 'activities_info.txt'The data set includes the following files:=========================================- 'README.txt'- 'features_info.txt': contains information about the variables used on the feature vector.- 'features.txt': List of all features.- 'activities_info.txt': contains information about the variable 'activity'.- 'activities.txt': list of all activities.- 'exercises_info.txt': contains information about the variable 'exercise'.- 'grades_info.txt': contains information about the grade data.Data: ======- 'Processes': contains the data files from Session 1 to 6.- 'logs.txt': shows information about the log data per student Id. It shows whether a student has a log in each session (0: has no log, 1: has log).- 'final_grades.xlsx': contains the results of the final exam in two sheets.- 'intermediate_grades.xlsx': contains the grades for the students' assignments per session.- 'final_exam.pdf': shows the content of the final exam (original in Italian).- 'final_exam_ENG.pdf': shows the content of the final exam translated in English.Notes: ======For more information about this data set please look at: www.la.smartlab.wsla '@' smartlab.wsThe features selected for this data set come from pre-processing of data collected through a logging program. Due to ethical reasons and to ensure the anonymity of our users, we cannot share the original log files, instead, we share the data transformed and cleaned in an appropriate format.The original logs contain the logging data of client system per approximately a second, while the features are calculated in order to be allocated to a particular activity. The features are selected and presented in a suitable format for Process Mining. In this sense, the data is presented per session, per student, and per exercise. Each CSV file belongs to a specific session and a specific student (named by the student Id). Each file contains several exercises of that session presented in 'exercise' feature. Each 'exercise' contains activities, which start-time, end-time, and other features are allocated to that.For further information about each feature, see 'features_info.txt'."
Appliances energy prediction,Appliances energy prediction,Experimental data used to create regression models of appliances energy use in a low energy building.,Appliances+energy+prediction,https://archive.ics.uci.edu/ml//machine-learning-databases/00374/,https://archive.ics.uci.edu/ml/datasets/Appliances+energy+prediction,"The data set is at 10 min for about 4.5 months. The house temperature and humidity conditions were monitored with a ZigBee wireless sensor network. Each wireless node transmitted the temperature and humidity conditions around 3.3 min. Then, the wireless data was averaged for 10 minutes periods. The energy data was logged every 10 minutes with m-bus energy meters. Weather from the nearest airport weather station (Chievres Airport, Belgium) was downloaded from a public data set from Reliable Prognosis (rp5.ru), and merged together with the experimental data sets using the date and time column. Two random variables have been included in the data set for testing the regression models and to filter out non predictive attributes (parameters).For more information about the house, data collection, R scripts and figures, please refer to the paper and to the following github repository:[Web Link]",Computer,"date time year-month-day hour:minute:second Appliances, energy use in Whlights, energy use of light fixtures in the house in WhT1, Temperature in kitchen area, in CelsiusRH_1, Humidity in kitchen area, in %T2, Temperature in living room area, in CelsiusRH_2, Humidity in living room area, in %T3, Temperature in laundry room areaRH_3, Humidity in laundry room area, in %T4, Temperature in office room, in CelsiusRH_4, Humidity in office room, in %T5, Temperature in bathroom, in CelsiusRH_5, Humidity in bathroom, in %T6, Temperature outside the building (north side), in CelsiusRH_6, Humidity outside the building (north side), in %T7, Temperature in ironing room , in CelsiusRH_7, Humidity in ironing room, in %T8, Temperature in teenager room 2, in CelsiusRH_8, Humidity in teenager room 2, in %T9, Temperature in parents room, in CelsiusRH_9, Humidity in parents room, in %To, Temperature outside (from Chievres weather station), in CelsiusPressure (from Chievres weather station), in mm HgRH_out, Humidity outside (from Chievres weather station), in %Wind speed (from Chievres weather station), in m/sVisibility (from Chievres weather station), in kmTdewpoint (from Chievres weather station), Ã‚Â°Crv1, Random variable 1, nondimensionalrv2, Random variable 2, nondimensionalWhere indicated, hourly data (then interpolated) from the nearest airport weather station (Chievres Airport, Belgium) was downloaded from a public data set from Reliable Prognosis, rp5.ru. Permission was obtained from Reliable Prognosis for the distribution of the 4.5 months of weather data.","Experimental data used to create regression models of appliances energy use in a low energy building.The data set is at 10 min for about 4.5 months. The house temperature and humidity conditions were monitored with a ZigBee wireless sensor network. Each wireless node transmitted the temperature and humidity conditions around 3.3 min. Then, the wireless data was averaged for 10 minutes periods. The energy data was logged every 10 minutes with m-bus energy meters. Weather from the nearest airport weather station (Chievres Airport, Belgium) was downloaded from a public data set from Reliable Prognosis (rp5.ru), and merged together with the experimental data sets using the date and time column. Two random variables have been included in the data set for testing the regression models and to filter out non predictive attributes (parameters).For more information about the house, data collection, R scripts and figures, please refer to the paper and to the following github repository:[Web Link]date time year-month-day hour:minute:second Appliances, energy use in Whlights, energy use of light fixtures in the house in WhT1, Temperature in kitchen area, in CelsiusRH_1, Humidity in kitchen area, in %T2, Temperature in living room area, in CelsiusRH_2, Humidity in living room area, in %T3, Temperature in laundry room areaRH_3, Humidity in laundry room area, in %T4, Temperature in office room, in CelsiusRH_4, Humidity in office room, in %T5, Temperature in bathroom, in CelsiusRH_5, Humidity in bathroom, in %T6, Temperature outside the building (north side), in CelsiusRH_6, Humidity outside the building (north side), in %T7, Temperature in ironing room , in CelsiusRH_7, Humidity in ironing room, in %T8, Temperature in teenager room 2, in CelsiusRH_8, Humidity in teenager room 2, in %T9, Temperature in parents room, in CelsiusRH_9, Humidity in parents room, in %To, Temperature outside (from Chievres weather station), in CelsiusPressure (from Chievres weather station), in mm HgRH_out, Humidity outside (from Chievres weather station), in %Wind speed (from Chievres weather station), in m/sVisibility (from Chievres weather station), in kmTdewpoint (from Chievres weather station), Ã‚Â°Crv1, Random variable 1, nondimensionalrv2, Random variable 2, nondimensionalWhere indicated, hourly data (then interpolated) from the nearest airport weather station (Chievres Airport, Belgium) was downloaded from a public data set from Reliable Prognosis, rp5.ru. Permission was obtained from Reliable Prognosis for the distribution of the 4.5 months of weather data."
Activities of Daily Living (ADLs) Recognition Using Binary Sensors,Activities of Daily Living (ADLs) Recognition Using Binary Sensors,"This dataset comprises information regarding the ADLs performed by two users on a daily basis in their 
own homes.  ",Activities+of+Daily+Living+%28ADLs%29+Recognition+Using+Binary+Sensors,https://archive.ics.uci.edu/ml//machine-learning-databases/00271/,https://archive.ics.uci.edu/ml/datasets/Activities+of+Daily+Living+%28ADLs%29+Recognition+Using+Binary+Sensors,"This dataset comprises information regarding the ADLs performed by two users on a daily basis in their own homes. This dataset is composed by two instances of data, each one corresponding to a different user and summing up to 35 days of fully labelled data. Each instance of the dataset is described by three text files, namely: description, sensors events (features), activities of the daily living (labels). Sensor events were recorded using a wireless sensor network and data were labelled manually.",Computer,The features are the sensor events captured for the corresponding Wireless Sensor Network.,"This dataset comprises information regarding the ADLs performed by two users on a daily basis in their 
own homes.  This dataset comprises information regarding the ADLs performed by two users on a daily basis in their own homes. This dataset is composed by two instances of data, each one corresponding to a different user and summing up to 35 days of fully labelled data. Each instance of the dataset is described by three text files, namely: description, sensors events (features), activities of the daily living (labels). Sensor events were recorded using a wireless sensor network and data were labelled manually.The features are the sensor events captured for the corresponding Wireless Sensor Network."
Energy efficiency,Energy efficiency,"This study looked into assessing the heating load and cooling load requirements of buildings (that is, energy efficiency) as a function of building parameters.",Energy+efficiency,https://archive.ics.uci.edu/ml//machine-learning-databases/00242/,https://archive.ics.uci.edu/ml/datasets/Energy+efficiency,"We perform energy analysis using 12 different building shapes simulated in Ecotect. The buildings differ with respect to the glazing area, the glazing area distribution, and the orientation, amongst other parameters. We simulate various settings as functions of the afore-mentioned characteristics to obtain 768 building shapes. The dataset comprises 768 samples and 8 features, aiming to predict two real valued responses. It can also be used as a multi-class classification problem if the response is rounded to the nearest integer.",Computer,"The dataset contains eight attributes (or features, denoted by X1...X8) and two responses (or outcomes, denoted by y1 and y2). The aim is to use the eight features to predict each of the two responses.Specifically:X1	Relative CompactnessX2	Surface AreaX3	Wall AreaX4	Roof AreaX5	Overall HeightX6	OrientationX7	Glazing AreaX8	Glazing Area Distributiony1	Heating Loady2	Cooling Load","This study looked into assessing the heating load and cooling load requirements of buildings (that is, energy efficiency) as a function of building parameters.We perform energy analysis using 12 different building shapes simulated in Ecotect. The buildings differ with respect to the glazing area, the glazing area distribution, and the orientation, amongst other parameters. We simulate various settings as functions of the afore-mentioned characteristics to obtain 768 building shapes. The dataset comprises 768 samples and 8 features, aiming to predict two real valued responses. It can also be used as a multi-class classification problem if the response is rounded to the nearest integer.The dataset contains eight attributes (or features, denoted by X1...X8) and two responses (or outcomes, denoted by y1 and y2). The aim is to use the eight features to predict each of the two responses.Specifically:X1	Relative CompactnessX2	Surface AreaX3	Wall AreaX4	Roof AreaX5	Overall HeightX6	OrientationX7	Glazing AreaX8	Glazing Area Distributiony1	Heating Loady2	Cooling Load"
Artificial Characters,Artificial Characters,Dataset artificially generated by using first order theory which describes structure of ten capital letters of English alphabet,Artificial+Characters,https://archive.ics.uci.edu/ml//machine-learning-databases/artificial-characters/,https://archive.ics.uci.edu/ml/datasets/Artificial+Characters,"This database has been artificially generated by using a first order theory which describes the structure of ten capital letters of the English alphabet and a random choice theorem prover which accounts for etherogeneity in the instances. The capital letters represented are the following: A, C, D, E, F, G, H, L, P, R. Each instance is structured and is described by a set of segments (lines) which resemble the way an automatic program would segment an image. Each instance is stored in a separate file whose format is the following:              CLASS OBJNUM TYPE XX1 YY1 XX2 YY2 SIZE DIAG      where CLASS is an integer number indicating the class as described below, OBJNUM is an integer identifier of a segment (starting from 0) in the instance and the remaining columns represent attribute values. For further details, contact the author.",Computer,"      TYPE: the first attribute describes the type of segment and is always set to the string ""line"". Its C language type is char.      XX1,YY1,XX2,YY2: these attributes contain the initial and final coordinates of a segment in a cartesian plane. Their C language type is int.      SIZE: this is the length of a segment computed by using the geometric distance between two points A(X1,Y1) and B(X2,Y2). Its C language type is float.      DIAG: this is the length of the diagonal of the smallest rectangle which includes the picture of the character. The value of this attribute is the same in each object. Its C language type is float.","Dataset artificially generated by using first order theory which describes structure of ten capital letters of English alphabetThis database has been artificially generated by using a first order theory which describes the structure of ten capital letters of the English alphabet and a random choice theorem prover which accounts for etherogeneity in the instances. The capital letters represented are the following: A, C, D, E, F, G, H, L, P, R. Each instance is structured and is described by a set of segments (lines) which resemble the way an automatic program would segment an image. Each instance is stored in a separate file whose format is the following:              CLASS OBJNUM TYPE XX1 YY1 XX2 YY2 SIZE DIAG      where CLASS is an integer number indicating the class as described below, OBJNUM is an integer identifier of a segment (starting from 0) in the instance and the remaining columns represent attribute values. For further details, contact the author.      TYPE: the first attribute describes the type of segment and is always set to the string ""line"". Its C language type is char.      XX1,YY1,XX2,YY2: these attributes contain the initial and final coordinates of a segment in a cartesian plane. Their C language type is int.      SIZE: this is the length of a segment computed by using the geometric distance between two points A(X1,Y1) and B(X2,Y2). Its C language type is float.      DIAG: this is the length of the diagonal of the smallest rectangle which includes the picture of the character. The value of this attribute is the same in each object. Its C language type is float."
Activity Recognition system based on Multisensor data fusion (AReM),Activity Recognition system based on Multisensor data fusion (AReM),"This dataset contains temporal data from a Wireless Sensor Network worn by an actor performing the activities: bending, cycling, lying down, sitting, standing, walking.",Activity+Recognition+system+based+on+Multisensor+data+fusion+%28AReM%29,https://archive.ics.uci.edu/ml//machine-learning-databases/00366/,https://archive.ics.uci.edu/ml/datasets/Activity+Recognition+system+based+on+Multisensor+data+fusion+%28AReM%29,"This dataset represents a real-life benchmark in the area of Activity Recognition applications, as described in [1]. The classification tasks consist in predicting the activity performed by the user from time-series generated by a Wireless Sensor Network (WSN), according to the EvAAL competition technical annex ([Web Link]). In our activity recognition system we use information coming the implicit alteration of the wireless channel due to the movements of the user. The devices measure the RSS of the beacon packets they exchange among themselves in the WSN [2].We collect RSS data using IRIS nodes embedding a Chipcon AT86RF230 radio subsystem that implements the IEEE 802.15.4 standard and programmed with a TinyOS firmware. They are placed on the userÃ¢â‚¬â„¢s chest and ankles. For the purpose of communications, the beacon packets are exchanged by using a simple virtual token protocol that completes its execution in a time slot of 50 milliseconds. A modified version of the Spin ([Web Link]) token-passing protocol is used to schedule node transmission, in order to prevent packet collisions and maintain high data collection rate. When an anchor is transmitting, all other anchors receive the packet and perform the RSS measurements. The payload of the transmitting packet is the set of RSS values between the transmitting node and the other sensors sampled during the previous cycle.From the raw data we extract time-domain features to compress the time series and slightly remove noise and correlations.We choose an epoch time of 250 milliseconds according to the EVAAL technical annex. In such a time slot we elaborate 5 samples of RSS (sampled at 20 Hz) for each of the three couples of WSN nodes (i.e. Chest-Right Ankle, Chest-Left Ankle, Right Ankle-Left Ankle). The features include the mean value and standard deviation for each reciprocal RSS reading from worn WSN sensors.For each activity 15 temporal sequences of input RSS data are present. The dataset contains 480 sequences, for a total number of 42240 instances.We also consider two kind of bending activity, illustrated in the figure provided (bendingTupe.pdf). The positions of sensor nodes with the related identifiers are shown in figure sensorsPlacement.pdf.",Computer,"For each sequence, data is provided in comma separated value (csv) format. - Input data:Input RSS streams are provided in files named datasetID.csv, where ID is the progressive numeric sequence ID for each repetition of the activity performed. In each file, each row corresponds to a time step measurement (in temporal order) and contains the following information:    avg_rss12, var_rss12, avg_rss13, var_rss13, avg_rss23, var_rss23where avg and var are the mean and variance values over 250 ms of data, respectively.- Target data:Target data is provided as the containing folder name.For each activity, we have the following parameters:# Frequency (Hz): 20# Clock (millisecond): 250# Total duration (seconds): 120","This dataset contains temporal data from a Wireless Sensor Network worn by an actor performing the activities: bending, cycling, lying down, sitting, standing, walking.This dataset represents a real-life benchmark in the area of Activity Recognition applications, as described in [1]. The classification tasks consist in predicting the activity performed by the user from time-series generated by a Wireless Sensor Network (WSN), according to the EvAAL competition technical annex ([Web Link]). In our activity recognition system we use information coming the implicit alteration of the wireless channel due to the movements of the user. The devices measure the RSS of the beacon packets they exchange among themselves in the WSN [2].We collect RSS data using IRIS nodes embedding a Chipcon AT86RF230 radio subsystem that implements the IEEE 802.15.4 standard and programmed with a TinyOS firmware. They are placed on the userÃ¢â‚¬â„¢s chest and ankles. For the purpose of communications, the beacon packets are exchanged by using a simple virtual token protocol that completes its execution in a time slot of 50 milliseconds. A modified version of the Spin ([Web Link]) token-passing protocol is used to schedule node transmission, in order to prevent packet collisions and maintain high data collection rate. When an anchor is transmitting, all other anchors receive the packet and perform the RSS measurements. The payload of the transmitting packet is the set of RSS values between the transmitting node and the other sensors sampled during the previous cycle.From the raw data we extract time-domain features to compress the time series and slightly remove noise and correlations.We choose an epoch time of 250 milliseconds according to the EVAAL technical annex. In such a time slot we elaborate 5 samples of RSS (sampled at 20 Hz) for each of the three couples of WSN nodes (i.e. Chest-Right Ankle, Chest-Left Ankle, Right Ankle-Left Ankle). The features include the mean value and standard deviation for each reciprocal RSS reading from worn WSN sensors.For each activity 15 temporal sequences of input RSS data are present. The dataset contains 480 sequences, for a total number of 42240 instances.We also consider two kind of bending activity, illustrated in the figure provided (bendingTupe.pdf). The positions of sensor nodes with the related identifiers are shown in figure sensorsPlacement.pdf.For each sequence, data is provided in comma separated value (csv) format. - Input data:Input RSS streams are provided in files named datasetID.csv, where ID is the progressive numeric sequence ID for each repetition of the activity performed. In each file, each row corresponds to a time step measurement (in temporal order) and contains the following information:    avg_rss12, var_rss12, avg_rss13, var_rss13, avg_rss23, var_rss23where avg and var are the mean and variance values over 250 ms of data, respectively.- Target data:Target data is provided as the containing folder name.For each activity, we have the following parameters:# Frequency (Hz): 20# Clock (millisecond): 250# Total duration (seconds): 120"
Anonymous Microsoft Web Data,Anonymous Microsoft Web Data,Log of anonymous users of www.microsoft.com; predict areas of the web site a user visited based on data on other areas the user visited.,Anonymous+Microsoft+Web+Data,https://archive.ics.uci.edu/ml//machine-learning-databases/anonymous/,https://archive.ics.uci.edu/ml/datasets/Anonymous+Microsoft+Web+Data,"We created the data by sampling and processing the www.microsoft.com logs. The data records the use of www.microsoft.com by 38000 anonymous, randomly-selected users. For each user, the data lists all the areas of the web site (Vroots) that user visited in a one week timeframe.Users are identified only by a sequential number, for example, User #14988, User #14989, etc. The file contains no personally identifiable information. The 294 Vroots are identified by their title (e.g. ""NetShow for PowerPoint"") and URL (e.g. ""/stream""). The data comes from one week in February, 1998.",Computer,"Each attribute is an area (""vroot"") of the www.microsoft.com web site.The datasets record which Vroots each user visited in a one-week timeframe in Feburary 1998.","Log of anonymous users of www.microsoft.com; predict areas of the web site a user visited based on data on other areas the user visited.We created the data by sampling and processing the www.microsoft.com logs. The data records the use of www.microsoft.com by 38000 anonymous, randomly-selected users. For each user, the data lists all the areas of the web site (Vroots) that user visited in a one week timeframe.Users are identified only by a sequential number, for example, User #14988, User #14989, etc. The file contains no personally identifiable information. The 294 Vroots are identified by their title (e.g. ""NetShow for PowerPoint"") and URL (e.g. ""/stream""). The data comes from one week in February, 1998.Each attribute is an area (""vroot"") of the www.microsoft.com web site.The datasets record which Vroots each user visited in a one-week timeframe in Feburary 1998."
EMG dataset in Lower Limb,EMG dataset in Lower Limb,"3 different exercises: sitting, standing and walking in the muscles: biceps femoris, vastus medialis, rectus femoris and semitendinosus addition to goniometry in the exercises.",EMG+dataset+in+Lower+Limb,https://archive.ics.uci.edu/ml//machine-learning-databases/00278/,https://archive.ics.uci.edu/ml/datasets/EMG+dataset+in+Lower+Limb,"2.	Information database:2.1.	Protocol:22 male subjects , 11 with different knee abnormalities previously diagnosed by a professional. They undergo three movements to analyze the behavior associated with the knee muscle , gait , leg extension from a sitting position , and flexion of the leg up. The acquisition process was conducted with 4 electrodes ( Vastus Medialis , semitendinosus , biceps femoris and rectus femoris ) and the goniometer in the knee .2.2.	InstrumentationDatalog equipment was used MWX8 by Biometrics of 8 digital channels and 4 analog channels , of which 4 for sampling were used SEMG and 1 for goniometry, these data were acquired directly to the computer MWX8 internal storage with microSD card and transmitted in Real-time Datalog software through bluetooth adapter , 14-bit resolution and sampling frequency of 1000Hz .2.3.	Data configuration:The total number of electrodes is 4, corresponding to the time series one for each channel (1 to 4). Each series contains ~ 5 shares or motion repetitions for each subject.",Computer,"Each data file contains 5 columns, organized as follows.Segment	Lower LimbChannel	Ch1	Ch2	Ch3	Ch4	Ch5Muscle	RF	BF	VM	ST	FXColumn	0	1	2	3	4","3 different exercises: sitting, standing and walking in the muscles: biceps femoris, vastus medialis, rectus femoris and semitendinosus addition to goniometry in the exercises.2.	Information database:2.1.	Protocol:22 male subjects , 11 with different knee abnormalities previously diagnosed by a professional. They undergo three movements to analyze the behavior associated with the knee muscle , gait , leg extension from a sitting position , and flexion of the leg up. The acquisition process was conducted with 4 electrodes ( Vastus Medialis , semitendinosus , biceps femoris and rectus femoris ) and the goniometer in the knee .2.2.	InstrumentationDatalog equipment was used MWX8 by Biometrics of 8 digital channels and 4 analog channels , of which 4 for sampling were used SEMG and 1 for goniometry, these data were acquired directly to the computer MWX8 internal storage with microSD card and transmitted in Real-time Datalog software through bluetooth adapter , 14-bit resolution and sampling frequency of 1000Hz .2.3.	Data configuration:The total number of electrodes is 4, corresponding to the time series one for each channel (1 to 4). Each series contains ~ 5 shares or motion repetitions for each subject.Each data file contains 5 columns, organized as follows.Segment	Lower LimbChannel	Ch1	Ch2	Ch3	Ch4	Ch5Muscle	RF	BF	VM	ST	FXColumn	0	1	2	3	4"
APS Failure at Scania Trucks,APS Failure at Scania Trucks,The datasets' positive class consists of component failures for a specific component of the APS system. The negative class consists of trucks with failures for components not related to the APS.,APS+Failure+at+Scania+Trucks,https://archive.ics.uci.edu/ml//machine-learning-databases/00421/,https://archive.ics.uci.edu/ml/datasets/APS+Failure+at+Scania+Trucks,"This file is part of APS Failure and Operational Data for Scania Trucks.Copyright (c) <2016> This program (APS Failure and Operational Data for Scania Trucks) is free software: you can redistribute it and/or modifyit under the terms of the GNU General Public License as published bythe Free Software Foundation, either version 3 of the License, or(at your option) any later version.This program is distributed in the hope that it will be useful,but WITHOUT ANY WARRANTY; without even the implied warranty ofMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See theGNU General Public License for more details.You should have received a copy of the GNU General Public Licensealong with this program.  If not, see <[Web Link]>.------------------------------------------------------------------------1. Title: APS Failure at Scania Trucks2. Source Information   -- Creator: Scania CV AB               VagnmakarvÃƒÂ¤gen 1                151 32 SÃƒÂ¶dertÃƒÂ¤lje                Stockholm               Sweden    -- Donor:   Tony Lindgren (tony '@' dsv.su.se) and Jonas Biteus (jonas.biteus '@' scania.com)   -- Date:    September, 2016 3. Past Usage:   Industrial Challenge 2016 at The 15th International Symposium on Intelligent Data Analysis (IDA)    -- Results:              The top three contestants                                                | Score | Number of Type 1 faults | Number of Type 2 faults     ------------------------------------------------------------------------------------------------------------------------------------     Camila F. Costa and Mario A. Nascimento                                  | 9920  | 542                     | 9     Christopher Gondek, Daniel Hafner and Oliver R. Sampson                  | 10900 | 490                     | 12     Sumeet Garnaik, Sushovan Das, Rama Syamala Sreepada and Bidyut Kr. Patra | 11480 | 398                     | 154. Relevant Information:   -- Introduction     The dataset consists of data collected from heavy Scania      trucks in everyday usage. The system in focus is the      Air Pressure system (APS) which generates pressurised      air that are utilized in various functions in a truck,      such as braking and gear changes. The datasets'      positive class consists of component failures      for a specific component of the APS system.      The negative class consists of trucks with failures      for components not related to the APS. The data consists      of a subset of all available data, selected by experts.    -- Challenge metric       Cost-metric of miss-classification:     Predicted class |      True class       |                     |    pos    |    neg    |     -----------------------------------------      pos            |     -     |  Cost_1   |     -----------------------------------------      neg            |  Cost_2   |     -     |     -----------------------------------------     Cost_1 = 10 and cost_2 = 500     The total cost of a prediction model the sum of 'Cost_1'      multiplied by the number of Instances with type 1 failure      and 'Cost_2' with the number of instances with type 2 failure,      resulting in a 'Total_cost'.     In this case Cost_1 refers to the cost that an unnessecary      check needs to be done by an mechanic at an workshop, while      Cost_2 refer to the cost of missing a faulty truck,      which may cause a breakdown.     Total_cost = Cost_1*No_Instances + Cost_2*No_Instances.5. Number of Instances:      The training set contains 60000 examples in total in which      59000 belong to the negative class and 1000 positive class.      The test set contains 16000 examples. 6. Number of Attributes: 171 7. Attribute Information:   The attribute names of the data have been anonymized for    proprietary reasons. It consists of both single numerical    counters and histograms consisting of bins with different    conditions. Typically the histograms have open-ended    conditions at each end. For example if we measuring    the ambient temperature 'T' then the histogram could    be defined with 4 bins where:    bin 1 collect values for temperature T < -20   bin 2 collect values for temperature T >= -20 and T < 0        bin 3 collect values for temperature T >= 0 and T < 20     bin 4 collect values for temperature T > 20    |  b1  |  b2  |  b3  |  b4  |      -----------------------------          -20     0      20  The attributes are as follows: class, then   anonymized operational data. The operational data have   an identifier and a bin id, like 'Identifier_Bin'.  In total there are 171 attributes, of which 7 are   histogram variabels. Missing values are denoted by 'na'.",Computer,"Attribute Information:   The attribute names of the data have been anonymized for    proprietary reasons. It consists of both single numerical    counters and histograms consisting of bins with different    conditions. Typically the histograms have open-ended    conditions at each end. For example if we measuring    the ambient temperature 'T' then the histogram could    be defined with 4 bins where:    bin 1 collect values for temperature T < -20   bin 2 collect values for temperature T >= -20 and T < 0        bin 3 collect values for temperature T >= 0 and T < 20     bin 4 collect values for temperature T > 20    |  b1  |  b2  |  b3  |  b4  |      -----------------------------          -20     0      20  The attributes are as follows: class, then   anonymized operational data. The operational data have   an identifier and a bin id, like 'Identifier_Bin'.  In total there are 171 attributes, of which 7 are   histogram variabels. Missing values are denoted by 'na'.","The datasets' positive class consists of component failures for a specific component of the APS system. The negative class consists of trucks with failures for components not related to the APS.This file is part of APS Failure and Operational Data for Scania Trucks.Copyright (c) <2016> This program (APS Failure and Operational Data for Scania Trucks) is free software: you can redistribute it and/or modifyit under the terms of the GNU General Public License as published bythe Free Software Foundation, either version 3 of the License, or(at your option) any later version.This program is distributed in the hope that it will be useful,but WITHOUT ANY WARRANTY; without even the implied warranty ofMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See theGNU General Public License for more details.You should have received a copy of the GNU General Public Licensealong with this program.  If not, see <[Web Link]>.------------------------------------------------------------------------1. Title: APS Failure at Scania Trucks2. Source Information   -- Creator: Scania CV AB               VagnmakarvÃƒÂ¤gen 1                151 32 SÃƒÂ¶dertÃƒÂ¤lje                Stockholm               Sweden    -- Donor:   Tony Lindgren (tony '@' dsv.su.se) and Jonas Biteus (jonas.biteus '@' scania.com)   -- Date:    September, 2016 3. Past Usage:   Industrial Challenge 2016 at The 15th International Symposium on Intelligent Data Analysis (IDA)    -- Results:              The top three contestants                                                | Score | Number of Type 1 faults | Number of Type 2 faults     ------------------------------------------------------------------------------------------------------------------------------------     Camila F. Costa and Mario A. Nascimento                                  | 9920  | 542                     | 9     Christopher Gondek, Daniel Hafner and Oliver R. Sampson                  | 10900 | 490                     | 12     Sumeet Garnaik, Sushovan Das, Rama Syamala Sreepada and Bidyut Kr. Patra | 11480 | 398                     | 154. Relevant Information:   -- Introduction     The dataset consists of data collected from heavy Scania      trucks in everyday usage. The system in focus is the      Air Pressure system (APS) which generates pressurised      air that are utilized in various functions in a truck,      such as braking and gear changes. The datasets'      positive class consists of component failures      for a specific component of the APS system.      The negative class consists of trucks with failures      for components not related to the APS. The data consists      of a subset of all available data, selected by experts.    -- Challenge metric       Cost-metric of miss-classification:     Predicted class |      True class       |                     |    pos    |    neg    |     -----------------------------------------      pos            |     -     |  Cost_1   |     -----------------------------------------      neg            |  Cost_2   |     -     |     -----------------------------------------     Cost_1 = 10 and cost_2 = 500     The total cost of a prediction model the sum of 'Cost_1'      multiplied by the number of Instances with type 1 failure      and 'Cost_2' with the number of instances with type 2 failure,      resulting in a 'Total_cost'.     In this case Cost_1 refers to the cost that an unnessecary      check needs to be done by an mechanic at an workshop, while      Cost_2 refer to the cost of missing a faulty truck,      which may cause a breakdown.     Total_cost = Cost_1*No_Instances + Cost_2*No_Instances.5. Number of Instances:      The training set contains 60000 examples in total in which      59000 belong to the negative class and 1000 positive class.      The test set contains 16000 examples. 6. Number of Attributes: 171 7. Attribute Information:   The attribute names of the data have been anonymized for    proprietary reasons. It consists of both single numerical    counters and histograms consisting of bins with different    conditions. Typically the histograms have open-ended    conditions at each end. For example if we measuring    the ambient temperature 'T' then the histogram could    be defined with 4 bins where:    bin 1 collect values for temperature T < -20   bin 2 collect values for temperature T >= -20 and T < 0        bin 3 collect values for temperature T >= 0 and T < 20     bin 4 collect values for temperature T > 20    |  b1  |  b2  |  b3  |  b4  |      -----------------------------          -20     0      20  The attributes are as follows: class, then   anonymized operational data. The operational data have   an identifier and a bin id, like 'Identifier_Bin'.  In total there are 171 attributes, of which 7 are   histogram variabels. Missing values are denoted by 'na'.Attribute Information:   The attribute names of the data have been anonymized for    proprietary reasons. It consists of both single numerical    counters and histograms consisting of bins with different    conditions. Typically the histograms have open-ended    conditions at each end. For example if we measuring    the ambient temperature 'T' then the histogram could    be defined with 4 bins where:    bin 1 collect values for temperature T < -20   bin 2 collect values for temperature T >= -20 and T < 0        bin 3 collect values for temperature T >= 0 and T < 20     bin 4 collect values for temperature T > 20    |  b1  |  b2  |  b3  |  b4  |      -----------------------------          -20     0      20  The attributes are as follows: class, then   anonymized operational data. The operational data have   an identifier and a bin id, like 'Identifier_Bin'.  In total there are 171 attributes, of which 7 are   histogram variabels. Missing values are denoted by 'na'."
Accelerometer,Accelerometer,"Accelerometer data from vibrations of a cooler fan with weights on its blades. It can be used for predictions, classification and other tasks that require vibration analysis, especially in engines.",Accelerometer,https://archive.ics.uci.edu/ml//machine-learning-databases/00611/,https://archive.ics.uci.edu/ml/datasets/Accelerometer,"This dataset was generated for use on 'Prediction of Motor Failure Time Using An Artificial Neural Network' project (DOI: 10.3390/s19194342). A cooler fan with weights on its blades was used to generate vibrations. To this fan cooler was attached an accelerometer to collect the vibration data. With this data, motor failure time predictions were made, using an artificial neural networks. To generate three distinct vibration scenarios, the weights were distributed in three different ways: 1) 'red' - normal configuration: two weight pieces positioned on neighboring blades; 2) 'blue' - perpendicular configuration: two weight pieces positioned on blades forming a 90Ã‚Â° angle; 3) 'green' - opposite configuration: two weight pieces positioned on opposite blades. A schematic diagram can be seen in figure 3 of the paper.Devices used:Akasa AK-FN059 12cm Viper cooling fan (Generate the vibrations)MMA8452Q accelerometer (Measure vibration)Data collection method:17 rotation speeds were set up, ranging from 20% to 100% of the cooler maximum speed at 5% intervals; for the three weight distribution configurations in the cooler blades. Note that the Akasa AK-FN059 cooler has 1900 rpm of max rotation speed.The vibration measurements were collected at a frequency of 20 ms for 1 min for each percentage, generating 3000 records per speed. Thus, in total, 153,000 vibration records were collected from the simulation model.",Computer,"There are 5 attributes in the dataset: wconfid,pctid,x,y and z.wconfid: Weight Configuration ID (1 - 'red' - normal configuration; 2 - 'blue' - perpendicular configuration; 3 - 'green' - opposite configuration)pctid: Cooler Fan RPM Speed Percentage ID (20 means 20%, and so on).x: Accelerometer x value.y: Accelerometer y value.z: Accelerometer z value.","Accelerometer data from vibrations of a cooler fan with weights on its blades. It can be used for predictions, classification and other tasks that require vibration analysis, especially in engines.This dataset was generated for use on 'Prediction of Motor Failure Time Using An Artificial Neural Network' project (DOI: 10.3390/s19194342). A cooler fan with weights on its blades was used to generate vibrations. To this fan cooler was attached an accelerometer to collect the vibration data. With this data, motor failure time predictions were made, using an artificial neural networks. To generate three distinct vibration scenarios, the weights were distributed in three different ways: 1) 'red' - normal configuration: two weight pieces positioned on neighboring blades; 2) 'blue' - perpendicular configuration: two weight pieces positioned on blades forming a 90Ã‚Â° angle; 3) 'green' - opposite configuration: two weight pieces positioned on opposite blades. A schematic diagram can be seen in figure 3 of the paper.Devices used:Akasa AK-FN059 12cm Viper cooling fan (Generate the vibrations)MMA8452Q accelerometer (Measure vibration)Data collection method:17 rotation speeds were set up, ranging from 20% to 100% of the cooler maximum speed at 5% intervals; for the three weight distribution configurations in the cooler blades. Note that the Akasa AK-FN059 cooler has 1900 rpm of max rotation speed.The vibration measurements were collected at a frequency of 20 ms for 1 min for each percentage, generating 3000 records per speed. Thus, in total, 153,000 vibration records were collected from the simulation model.There are 5 attributes in the dataset: wconfid,pctid,x,y and z.wconfid: Weight Configuration ID (1 - 'red' - normal configuration; 2 - 'blue' - perpendicular configuration; 3 - 'green' - opposite configuration)pctid: Cooler Fan RPM Speed Percentage ID (20 means 20%, and so on).x: Accelerometer x value.y: Accelerometer y value.z: Accelerometer z value."
AAAI 2014 Accepted Papers,AAAI 2014 Accepted Papers,"This data set compromises the metadata for the 2014 AAAI conference's accepted papers, including paper titles, authors, abstracts, and keywords of varying granularity.",AAAI+2014+Accepted+Papers,https://archive.ics.uci.edu/ml//machine-learning-databases/00307/,https://archive.ics.uci.edu/ml/datasets/AAAI+2014+Accepted+Papers,CSV format where each row is a paper and each column an attribute.,Computer,"Title: Free text; title of the paperAuthors: Free text; author(s) of the paperGroups: Categorical; author-selected, high-level keyword(s)Keywords: Free text; author-generated keywordsTopics: Free text; author-selected, low-level keywordsAbstracts: Free text; paper abstracts","This data set compromises the metadata for the 2014 AAAI conference's accepted papers, including paper titles, authors, abstracts, and keywords of varying granularity.CSV format where each row is a paper and each column an attribute.Title: Free text; title of the paperAuthors: Free text; author(s) of the paperGroups: Categorical; author-selected, high-level keyword(s)Keywords: Free text; author-generated keywordsTopics: Free text; author-selected, low-level keywordsAbstracts: Free text; paper abstracts"
AAAI 2013 Accepted Papers,AAAI 2013 Accepted Papers,"This data set compromises the metadata for the 2013 AAAI conference's accepted papers (main track only), including paper titles, abstracts, and keywords of varying granularity.",AAAI+2013+Accepted+Papers,https://archive.ics.uci.edu/ml//machine-learning-databases/00314/,https://archive.ics.uci.edu/ml/datasets/AAAI+2013+Accepted+Papers,CSV format where each row is a paper and each column is an attribute.,Computer,"Title: Free text; title of the paperKeywords: Free text; author-generated keywordsTopics: Categorical; author-selected, low-level keywords from conference-provided listHigh-level keywords: Categorical; author-selected, high-level keywords from conference-provided list","This data set compromises the metadata for the 2013 AAAI conference's accepted papers (main track only), including paper titles, abstracts, and keywords of varying granularity.CSV format where each row is a paper and each column is an attribute.Title: Free text; title of the paperKeywords: Free text; author-generated keywordsTopics: Categorical; author-selected, low-level keywords from conference-provided listHigh-level keywords: Categorical; author-selected, high-level keywords from conference-provided list"
Alcohol QCM Sensor Dataset,Alcohol QCM Sensor Dataset,"Five different QCM gas sensors are used, and five different gas measurements (1-octanol, 1-propanol, 2-butanol, 2-propanol and 1-isobutanol) are conducted in each of these sensors.",Alcohol+QCM+Sensor+Dataset,https://archive.ics.uci.edu/ml//machine-learning-databases/00496/,https://archive.ics.uci.edu/ml/datasets/Alcohol+QCM+Sensor+Dataset,"In the dataset there are 5 types of dataset.QCM3, QCM6, QCM7, QCM10, QCM12In each of dataset, There is alcohol classification of five types,1-octanol, 1-propanol, 2-butanol, 2-propanol, 1-isobutanol",Computer,"The gas sample is passed through the sensor in five different concentrations. These concentrations are, Concentration	Air ratio (ml)	Gas ratio (ml)1       0.799	0.2012	0.700	0.3003	0.600	0.4004	0.501	0.4995	0.400	0.600There are two channels in the sensor. One of these circles forms channel 1, and the other forms channel 2. MIP and MP ratios used in the QCM sensors are,Sensor name	MIP ratio	NP ratioQCM3	1	1QCM6	1	0QCM7	1	0.5QCM10	1	2QCM12	0	1","Five different QCM gas sensors are used, and five different gas measurements (1-octanol, 1-propanol, 2-butanol, 2-propanol and 1-isobutanol) are conducted in each of these sensors.In the dataset there are 5 types of dataset.QCM3, QCM6, QCM7, QCM10, QCM12In each of dataset, There is alcohol classification of five types,1-octanol, 1-propanol, 2-butanol, 2-propanol, 1-isobutanolThe gas sample is passed through the sensor in five different concentrations. These concentrations are, Concentration	Air ratio (ml)	Gas ratio (ml)1       0.799	0.2012	0.700	0.3003	0.600	0.4004	0.501	0.4995	0.400	0.600There are two channels in the sensor. One of these circles forms channel 1, and the other forms channel 2. MIP and MP ratios used in the QCM sensors are,Sensor name	MIP ratio	NP ratioQCM3	1	1QCM6	1	0QCM7	1	0.5QCM10	1	2QCM12	0	1"
: Simulated Data set of Iraqi tourism places,: Simulated Data set of Iraqi tourism places,"Simulated Data set of Iraqi tourism places with their position (longitude,latitude)and type of interest for each place",%3A+Simulated+Data+set+of+Iraqi+tourism+places,https://archive.ics.uci.edu/ml//machine-learning-databases/00556/,https://archive.ics.uci.edu/ml/datasets/%3A+Simulated+Data+set+of+Iraqi+tourism+places,"ID:(int)	,City:(text)	Place names(text)	Place names(text),	Latitude:real	Longitude:realA: Adventure(1 or blank), C: Culture(1 or blank), E: Environmental(1 or blank), H: Health(1 or blank), N: Nature(1 or blank), R: Religious(1 or blank), SP: SPort(1 or blank), SH: SHopping(1 or blank), B: Business(1 or blank), L: leisure(1 or blank)",Computer,"ID:place identification	,City:the city of plcae,	Place names(in arabic)	Place names(in english),	Latitude:Latitude of place	Longitude:Longitude of placetype of intrest represented as:A: Adventure, C: Culture, E: Environmental, H: Health, N: Nature, R: Religious, SP: SPort, SH: SHopping, B: Business, L: leisure","Simulated Data set of Iraqi tourism places with their position (longitude,latitude)and type of interest for each placeID:(int)	,City:(text)	Place names(text)	Place names(text),	Latitude:real	Longitude:realA: Adventure(1 or blank), C: Culture(1 or blank), E: Environmental(1 or blank), H: Health(1 or blank), N: Nature(1 or blank), R: Religious(1 or blank), SP: SPort(1 or blank), SH: SHopping(1 or blank), B: Business(1 or blank), L: leisure(1 or blank)ID:place identification	,City:the city of plcae,	Place names(in arabic)	Place names(in english),	Latitude:Latitude of place	Longitude:Longitude of placetype of intrest represented as:A: Adventure, C: Culture, E: Environmental, H: Health, N: Nature, R: Religious, SP: SPort, SH: SHopping, B: Business, L: leisure"
Air quality,Air quality, Contains the responses of a gas multisensor device deployed on the field in an Italian city. ,Air+quality,https://archive.ics.uci.edu/ml//machine-learning-databases/00360/,https://archive.ics.uci.edu/ml/datasets/Air+quality,"The dataset contains 9358 instances of hourly averaged responses from an array of 5 metal oxide chemical sensors embedded in an Air Quality Chemical Multisensor Device. The device was located on the field in a significantly polluted area, at road level,within an Italian city. Data were recorded from March 2004 to February 2005 (one year)representing the longest freely available recordings of on field deployed air quality chemical sensor devices responses. Ground Truth hourly averaged concentrations for CO, Non Metanic Hydrocarbons, Benzene, Total Nitrogen Oxides (NOx) and Nitrogen Dioxide (NO2)  and were provided by a co-located reference certified analyzer. Evidences of cross-sensitivities as well as both concept and sensor drifts are present as described in De Vito et al., Sens. And Act. B, Vol. 129,2,2008 (citation required) eventually affecting sensors concentration estimation capabilities. Missing values are tagged with -200 value.This dataset can be used exclusively for research purposes. Commercial purposes are fully excluded.",Computer,0 Date	(DD/MM/YYYY)1 Time	(HH.MM.SS)2 True hourly averaged concentration CO in mg/m^3  (reference analyzer)3 PT08.S1 (tin oxide)  hourly averaged sensor response (nominally  CO targeted)	4 True hourly averaged overall Non Metanic HydroCarbons concentration in microg/m^3 (reference analyzer)5 True hourly averaged Benzene concentration  in microg/m^3 (reference analyzer)6 PT08.S2 (titania) hourly averaged sensor response (nominally NMHC targeted)	7 True hourly averaged NOx concentration  in ppb (reference analyzer)8 PT08.S3 (tungsten oxide) hourly averaged sensor response (nominally NOx targeted) 9 True hourly averaged NO2 concentration in microg/m^3 (reference analyzer)	10 PT08.S4 (tungsten oxide) hourly averaged sensor response (nominally NO2 targeted)	11 PT08.S5 (indium oxide) hourly averaged sensor response (nominally O3 targeted)12 Temperature in Ã‚Â°C	13 Relative Humidity (%) 	14 AH Absolute Humidity," Contains the responses of a gas multisensor device deployed on the field in an Italian city. The dataset contains 9358 instances of hourly averaged responses from an array of 5 metal oxide chemical sensors embedded in an Air Quality Chemical Multisensor Device. The device was located on the field in a significantly polluted area, at road level,within an Italian city. Data were recorded from March 2004 to February 2005 (one year)representing the longest freely available recordings of on field deployed air quality chemical sensor devices responses. Ground Truth hourly averaged concentrations for CO, Non Metanic Hydrocarbons, Benzene, Total Nitrogen Oxides (NOx) and Nitrogen Dioxide (NO2)  and were provided by a co-located reference certified analyzer. Evidences of cross-sensitivities as well as both concept and sensor drifts are present as described in De Vito et al., Sens. And Act. B, Vol. 129,2,2008 (citation required) eventually affecting sensors concentration estimation capabilities. Missing values are tagged with -200 value.This dataset can be used exclusively for research purposes. Commercial purposes are fully excluded.0 Date	(DD/MM/YYYY)1 Time	(HH.MM.SS)2 True hourly averaged concentration CO in mg/m^3  (reference analyzer)3 PT08.S1 (tin oxide)  hourly averaged sensor response (nominally  CO targeted)	4 True hourly averaged overall Non Metanic HydroCarbons concentration in microg/m^3 (reference analyzer)5 True hourly averaged Benzene concentration  in microg/m^3 (reference analyzer)6 PT08.S2 (titania) hourly averaged sensor response (nominally NMHC targeted)	7 True hourly averaged NOx concentration  in ppb (reference analyzer)8 PT08.S3 (tungsten oxide) hourly averaged sensor response (nominally NOx targeted) 9 True hourly averaged NO2 concentration in microg/m^3 (reference analyzer)	10 PT08.S4 (tungsten oxide) hourly averaged sensor response (nominally NO2 targeted)	11 PT08.S5 (indium oxide) hourly averaged sensor response (nominally O3 targeted)12 Temperature in Ã‚Â°C	13 Relative Humidity (%) 	14 AH Absolute Humidity"
3W dataset,3W dataset,The first realistic and public dataset with rare undesirable real events in oil wells.,3W+dataset,https://archive.ics.uci.edu/ml//machine-learning-databases/00540/,https://archive.ics.uci.edu/ml/datasets/3W+dataset,"To the best of its authors' knowledge, this is the first realistic and public dataset with rare undesirable real events in oil wells that can be readily used as a benchmark dataset for development of machine learning techniques related to inherent difficulties of actual data.More information about the theory behind this dataset is available in the paper 'A realistic and public dataset with rare undesirable real events in oil wells' published in the Journal of Petroleum Science and Engineering ([Web Link]). Specific challenges (benchmarks) that practitioners and researchers can use together with the 3W dataset are defined and proposed in this paper.The 3W dataset consists of 1,984 CSV files structured as follows. Due to the limitation of GitHub, this dataset is kept in 7z files splitted automatically and saved in the data directory. Before using 3W dataset, they must be decompressed. After that, the subdirectory names are the instances' labels. Each file represents one instance. The filename reveals its source. All files are standardized as follow. There are one observation per line and one series per column. Columns are separated by commas and decimals are separated by periods. The first column contains timestamps, the last one reveals the observations' labels, and the other columns are the Multivariate Time Series (MTS) (i.e. the instance itself).The 3W dataset's files are in [Web Link], but we believe that the 3W dataset's publication in the UCI Machine Learning Repository benefits the machine learning community.",Computer,Pressure at the Permanent Downhole Gauge (PDG);Pressure at the Temperature and Pressure Transducer (TPT);Temperature at the TPT;Pressure upstream of the Production Choke (PCK);Temperature downstream of the PCK;Pressure downstream of the Gas Lift Choke (GLCK);Temperature downstream of the GLCK;Gas Lift flow.,"The first realistic and public dataset with rare undesirable real events in oil wells.To the best of its authors' knowledge, this is the first realistic and public dataset with rare undesirable real events in oil wells that can be readily used as a benchmark dataset for development of machine learning techniques related to inherent difficulties of actual data.More information about the theory behind this dataset is available in the paper 'A realistic and public dataset with rare undesirable real events in oil wells' published in the Journal of Petroleum Science and Engineering ([Web Link]). Specific challenges (benchmarks) that practitioners and researchers can use together with the 3W dataset are defined and proposed in this paper.The 3W dataset consists of 1,984 CSV files structured as follows. Due to the limitation of GitHub, this dataset is kept in 7z files splitted automatically and saved in the data directory. Before using 3W dataset, they must be decompressed. After that, the subdirectory names are the instances' labels. Each file represents one instance. The filename reveals its source. All files are standardized as follow. There are one observation per line and one series per column. Columns are separated by commas and decimals are separated by periods. The first column contains timestamps, the last one reveals the observations' labels, and the other columns are the Multivariate Time Series (MTS) (i.e. the instance itself).The 3W dataset's files are in [Web Link], but we believe that the 3W dataset's publication in the UCI Machine Learning Repository benefits the machine learning community.Pressure at the Permanent Downhole Gauge (PDG);Pressure at the Temperature and Pressure Transducer (TPT);Temperature at the TPT;Pressure upstream of the Production Choke (PCK);Temperature downstream of the PCK;Pressure downstream of the Gas Lift Choke (GLCK);Temperature downstream of the GLCK;Gas Lift flow."
Air Quality,Air Quality,Contains the responses of a gas multisensor device deployed on the field in an Italian city. Hourly responses averages are recorded along with gas concentrations references from a certified analyzer. ,Air+Quality,https://archive.ics.uci.edu/ml//machine-learning-databases/00360/,https://archive.ics.uci.edu/ml/datasets/Air+Quality,"The dataset contains 9358 instances of hourly averaged responses from an array of 5 metal oxide chemical sensors embedded in an Air Quality Chemical Multisensor Device. The device was located on the field in a significantly polluted area, at road level,within an Italian city. Data were recorded from March 2004 to February 2005 (one year)representing the longest freely available recordings of on field deployed air quality chemical sensor devices responses. Ground Truth hourly averaged concentrations for CO, Non Metanic Hydrocarbons, Benzene, Total Nitrogen Oxides (NOx) and Nitrogen Dioxide (NO2)  and were provided by a co-located reference certified analyzer. Evidences of cross-sensitivities as well as both concept and sensor drifts are present as described in De Vito et al., Sens. And Act. B, Vol. 129,2,2008 (citation required) eventually affecting sensors concentration estimation capabilities. Missing values are tagged with -200 value.This dataset can be used exclusively for research purposes. Commercial purposes are fully excluded.",Computer,0 Date	(DD/MM/YYYY)1 Time	(HH.MM.SS)2 True hourly averaged concentration CO in mg/m^3  (reference analyzer)3 PT08.S1 (tin oxide)  hourly averaged sensor response (nominally  CO targeted)	4 True hourly averaged overall Non Metanic HydroCarbons concentration in microg/m^3 (reference analyzer)5 True hourly averaged Benzene concentration  in microg/m^3 (reference analyzer)6 PT08.S2 (titania) hourly averaged sensor response (nominally NMHC targeted)	7 True hourly averaged NOx concentration  in ppb (reference analyzer)8 PT08.S3 (tungsten oxide) hourly averaged sensor response (nominally NOx targeted) 9 True hourly averaged NO2 concentration in microg/m^3 (reference analyzer)	10 PT08.S4 (tungsten oxide) hourly averaged sensor response (nominally NO2 targeted)	11 PT08.S5 (indium oxide) hourly averaged sensor response (nominally O3 targeted)12 Temperature in Ã‚Â°C	13 Relative Humidity (%) 	14 AH Absolute Humidity,"Contains the responses of a gas multisensor device deployed on the field in an Italian city. Hourly responses averages are recorded along with gas concentrations references from a certified analyzer. The dataset contains 9358 instances of hourly averaged responses from an array of 5 metal oxide chemical sensors embedded in an Air Quality Chemical Multisensor Device. The device was located on the field in a significantly polluted area, at road level,within an Italian city. Data were recorded from March 2004 to February 2005 (one year)representing the longest freely available recordings of on field deployed air quality chemical sensor devices responses. Ground Truth hourly averaged concentrations for CO, Non Metanic Hydrocarbons, Benzene, Total Nitrogen Oxides (NOx) and Nitrogen Dioxide (NO2)  and were provided by a co-located reference certified analyzer. Evidences of cross-sensitivities as well as both concept and sensor drifts are present as described in De Vito et al., Sens. And Act. B, Vol. 129,2,2008 (citation required) eventually affecting sensors concentration estimation capabilities. Missing values are tagged with -200 value.This dataset can be used exclusively for research purposes. Commercial purposes are fully excluded.0 Date	(DD/MM/YYYY)1 Time	(HH.MM.SS)2 True hourly averaged concentration CO in mg/m^3  (reference analyzer)3 PT08.S1 (tin oxide)  hourly averaged sensor response (nominally  CO targeted)	4 True hourly averaged overall Non Metanic HydroCarbons concentration in microg/m^3 (reference analyzer)5 True hourly averaged Benzene concentration  in microg/m^3 (reference analyzer)6 PT08.S2 (titania) hourly averaged sensor response (nominally NMHC targeted)	7 True hourly averaged NOx concentration  in ppb (reference analyzer)8 PT08.S3 (tungsten oxide) hourly averaged sensor response (nominally NOx targeted) 9 True hourly averaged NO2 concentration in microg/m^3 (reference analyzer)	10 PT08.S4 (tungsten oxide) hourly averaged sensor response (nominally NO2 targeted)	11 PT08.S5 (indium oxide) hourly averaged sensor response (nominally O3 targeted)12 Temperature in Ã‚Â°C	13 Relative Humidity (%) 	14 AH Absolute Humidity"
AI4I 2020 Predictive Maintenance Dataset,AI4I 2020 Predictive Maintenance Dataset,The AI4I 2020 Predictive Maintenance Dataset is a synthetic dataset that reflects real predictive maintenance data encountered in industry.,AI4I+2020+Predictive+Maintenance+Dataset,https://archive.ics.uci.edu/ml//machine-learning-databases/00601/,https://archive.ics.uci.edu/ml/datasets/AI4I+2020+Predictive+Maintenance+Dataset,"Since real predictive maintenance datasets are generally difficult to obtain and in particular difficult to publish, we present and provide a synthetic dataset that reflects real predictive maintenance encountered in industry to the best of our knowledge.",Computer,"The dataset consists of 10 000 data points stored as rows with 14 features in columnsUID: unique identifier ranging from 1 to 10000product ID: consisting of a letter L, M, or H for low (50% of all products), medium (30%) and high (20%) as product quality variants and a variant-specific serial numberair temperature [K]: generated using a random walk process later normalized to a standard deviation of 2 K around 300 Kprocess temperature [K]: generated using a random walk process normalized to a standard deviation of 1 K, added to the air temperature plus 10 K.rotational speed [rpm]: calculated from a power of 2860 W, overlaid with a normally distributed noisetorque [Nm]: torque values are normally distributed around 40 Nm with a Ã�Æ’ = 10 Nm and no negative values. tool wear [min]: The quality variants H/M/L add 5/3/2 minutes of tool wear to the used tool in the process. and a'machine failure' label that indicates, whether the machine has failed in this particular datapoint for any of the following failure modes are true.The machine failure consists of five independent failure modestool wear failure (TWF): the tool will be replaced of fail at a randomly selected tool wear time between 200 Ã¢â‚¬â€œ 240 mins (120 times in our dataset). At this point in time, the tool is replaced 69 times, and fails 51 times (randomly assigned).heat dissipation failure (HDF): heat dissipation causes a process failure, if the difference between air- and process temperature is below 8.6 K and the toolÃ¢â‚¬â„¢s rotational speed is below 1380 rpm. This is the case for 115 data points.power failure (PWF): the product of torque and rotational speed (in rad/s) equals the power required for the process. If this power is below 3500 W or above 9000 W, the process fails, which is the case 95 times in our dataset.overstrain failure (OSF): if the product of tool wear and torque exceeds 11,000 minNm for the L product variant (12,000 M, 13,000 H), the process fails due to overstrain. This is true for 98 datapoints.random failures (RNF): each process has a chance of 0,1 % to fail regardless of its process parameters. This is the case for only 5 datapoints, less than could be expected for 10,000 datapoints in our dataset.If at least one of the above failure modes is true, the process fails and the 'machine failure' label is set to 1. It is therefore not transparent to the machine learning method, which of the failure modes has caused the process to fail ","The AI4I 2020 Predictive Maintenance Dataset is a synthetic dataset that reflects real predictive maintenance data encountered in industry.Since real predictive maintenance datasets are generally difficult to obtain and in particular difficult to publish, we present and provide a synthetic dataset that reflects real predictive maintenance encountered in industry to the best of our knowledge.The dataset consists of 10 000 data points stored as rows with 14 features in columnsUID: unique identifier ranging from 1 to 10000product ID: consisting of a letter L, M, or H for low (50% of all products), medium (30%) and high (20%) as product quality variants and a variant-specific serial numberair temperature [K]: generated using a random walk process later normalized to a standard deviation of 2 K around 300 Kprocess temperature [K]: generated using a random walk process normalized to a standard deviation of 1 K, added to the air temperature plus 10 K.rotational speed [rpm]: calculated from a power of 2860 W, overlaid with a normally distributed noisetorque [Nm]: torque values are normally distributed around 40 Nm with a Ã�Æ’ = 10 Nm and no negative values. tool wear [min]: The quality variants H/M/L add 5/3/2 minutes of tool wear to the used tool in the process. and a'machine failure' label that indicates, whether the machine has failed in this particular datapoint for any of the following failure modes are true.The machine failure consists of five independent failure modestool wear failure (TWF): the tool will be replaced of fail at a randomly selected tool wear time between 200 Ã¢â‚¬â€œ 240 mins (120 times in our dataset). At this point in time, the tool is replaced 69 times, and fails 51 times (randomly assigned).heat dissipation failure (HDF): heat dissipation causes a process failure, if the difference between air- and process temperature is below 8.6 K and the toolÃ¢â‚¬â„¢s rotational speed is below 1380 rpm. This is the case for 115 data points.power failure (PWF): the product of torque and rotational speed (in rad/s) equals the power required for the process. If this power is below 3500 W or above 9000 W, the process fails, which is the case 95 times in our dataset.overstrain failure (OSF): if the product of tool wear and torque exceeds 11,000 minNm for the L product variant (12,000 M, 13,000 H), the process fails due to overstrain. This is true for 98 datapoints.random failures (RNF): each process has a chance of 0,1 % to fail regardless of its process parameters. This is the case for only 5 datapoints, less than could be expected for 10,000 datapoints in our dataset.If at least one of the above failure modes is true, the process fails and the 'machine failure' label is set to 1. It is therefore not transparent to the machine learning method, which of the failure modes has caused the process to fail "
"3D Road Network (North Jutland, Denmark)","3D Road Network (North Jutland, Denmark)",3D road network with highly accurate elevation information (+-20cm) from Denmark used in eco-routing and fuel/Co2-estimation routing algorithms.,3D+Road+Network+%28North+Jutland%2C+Denmark%29,https://archive.ics.uci.edu/ml//machine-learning-databases/00246/,https://archive.ics.uci.edu/ml/datasets/3D+Road+Network+%28North+Jutland%2C+Denmark%29,"This dataset was constructed by adding elevation information to a 2D road network in North Jutland, Denmark (covering a region of 185 x 135 km^2). Elevation values where extracted from a publicly available massive Laser Scan Point Cloud for Denmark (available at : [Web Link] (Bottom-most dataset)). This 3D road network was eventually used for benchmarking various fuel and CO2 estimation algorithms. This dataset can be used by any applications that require to know veryaccurate elevation information of a road network to perform more accurate routing for eco-routing, cyclist routes etc. For the data mining and machine learning community, this dataset can be used as 'ground-truth' validation in spatial mining techniques and satellite image processing. It has no class labels, but can be used in unsupervised learning and regression to guess some missing elevation information for some points on the road. The work was supported by the Reduction project that is funded by the European Comission as FP7-ICT-2011-7 STREP project number 288254.",Computer,"1. OSM_ID: OpenStreetMap ID for each road segment or edge in the graph.2. LONGITUDE: Web Mercaptor (Google format) longitude 3. LATITUDE: Web Mercaptor (Google format) latitude4. ALTITUDE: Height in meters. Note: OSM_ID is the ID assigned by OpenStreetMaps ([Web Link]) to the road segments. Each (long,lat,altitude) point on a road segment (with unique OSM ID) is sorted in the same order as they appear on the road. So a 3D-polyline can be drawn by joining points of each row for each OSM_ID road segment.","3D road network with highly accurate elevation information (+-20cm) from Denmark used in eco-routing and fuel/Co2-estimation routing algorithms.This dataset was constructed by adding elevation information to a 2D road network in North Jutland, Denmark (covering a region of 185 x 135 km^2). Elevation values where extracted from a publicly available massive Laser Scan Point Cloud for Denmark (available at : [Web Link] (Bottom-most dataset)). This 3D road network was eventually used for benchmarking various fuel and CO2 estimation algorithms. This dataset can be used by any applications that require to know veryaccurate elevation information of a road network to perform more accurate routing for eco-routing, cyclist routes etc. For the data mining and machine learning community, this dataset can be used as 'ground-truth' validation in spatial mining techniques and satellite image processing. It has no class labels, but can be used in unsupervised learning and regression to guess some missing elevation information for some points on the road. The work was supported by the Reduction project that is funded by the European Comission as FP7-ICT-2011-7 STREP project number 288254.1. OSM_ID: OpenStreetMap ID for each road segment or edge in the graph.2. LONGITUDE: Web Mercaptor (Google format) longitude 3. LATITUDE: Web Mercaptor (Google format) latitude4. ALTITUDE: Height in meters. Note: OSM_ID is the ID assigned by OpenStreetMaps ([Web Link]) to the road segments. Each (long,lat,altitude) point on a road segment (with unique OSM ID) is sorted in the same order as they appear on the road. So a 3D-polyline can be drawn by joining points of each row for each OSM_ID road segment."
ElectricityLoadDiagrams20112014,ElectricityLoadDiagrams20112014,"This data set contains electricity consumption of 370 points/clients.
",ElectricityLoadDiagrams20112014,https://archive.ics.uci.edu/ml//machine-learning-databases/00321/,https://archive.ics.uci.edu/ml/datasets/ElectricityLoadDiagrams20112014,Data set has no missing values.Values are in kW of each 15 min. To convert values in kWh values must be divided by 4.Each column represent one client. Some clients were created after 2011. In these cases consumption were considered zero.All time labels report to Portuguese hour. However all days present 96 measures (24*4). Every year in March time change day (which has only 23 hours) the values between 1:00 am and 2:00 am are zero for all points. Every year in October time change day (which has 25 hours) the values between 1:00 am and 2:00 am aggregate the consumption of two hours.,Computer,"Data set were saved as txt using csv format, using semi colon (;).First column present date and time as a string with the following format 'yyyy-mm-dd hh:mm:ss'Other columns present float values with consumption in kW","This data set contains electricity consumption of 370 points/clients.
Data set has no missing values.Values are in kW of each 15 min. To convert values in kWh values must be divided by 4.Each column represent one client. Some clients were created after 2011. In these cases consumption were considered zero.All time labels report to Portuguese hour. However all days present 96 measures (24*4). Every year in March time change day (which has only 23 hours) the values between 1:00 am and 2:00 am are zero for all points. Every year in October time change day (which has 25 hours) the values between 1:00 am and 2:00 am aggregate the consumption of two hours.Data set were saved as txt using csv format, using semi colon (;).First column present date and time as a string with the following format 'yyyy-mm-dd hh:mm:ss'Other columns present float values with consumption in kW"
Poker Hand,Poker Hand,Purpose is to predict poker hands,Poker+Hand,https://archive.ics.uci.edu/ml//machine-learning-databases/poker/,https://archive.ics.uci.edu/ml/datasets/Poker+Hand,"Each record is an example of a hand consisting of five playing cards drawn from a standard deck of 52. Each card is described using two attributes (suit and rank), for a total of 10 predictive attributes. There is one Class attribute that describes the ""Poker Hand"". The order of cards is important, which is why there are 480 possible Royal Flush hands as compared to 4 (one for each suit - explained in [Web Link]).",Game,"1) S1 ""Suit of card #1""    Ordinal (1-4) representing {Hearts, Spades, Diamonds, Clubs}2) C1 ""Rank of card #1""    Numerical (1-13) representing (Ace, 2, 3, ... , Queen, King)3) S2 ""Suit of card #2""    Ordinal (1-4) representing {Hearts, Spades, Diamonds, Clubs}4) C2 ""Rank of card #2""    Numerical (1-13) representing (Ace, 2, 3, ... , Queen, King)5) S3 ""Suit of card #3""    Ordinal (1-4) representing {Hearts, Spades, Diamonds, Clubs}6) C3 ""Rank of card #3""    Numerical (1-13) representing (Ace, 2, 3, ... , Queen, King)7) S4 ""Suit of card #4""    Ordinal (1-4) representing {Hearts, Spades, Diamonds, Clubs}8) C4 ""Rank of card #4""    Numerical (1-13) representing (Ace, 2, 3, ... , Queen, King)9) S5 ""Suit of card #5""    Ordinal (1-4) representing {Hearts, Spades, Diamonds, Clubs}10) C5 ""Rank of card 5""    Numerical (1-13) representing (Ace, 2, 3, ... , Queen, King)11) CLASS ""Poker Hand""    Ordinal (0-9)    0: Nothing in hand; not a recognized poker hand     1: One pair; one pair of equal ranks within five cards    2: Two pairs; two pairs of equal ranks within five cards    3: Three of a kind; three equal ranks within five cards    4: Straight; five cards, sequentially ranked with no gaps    5: Flush; five cards with the same suit    6: Full house; pair + different rank three of a kind    7: Four of a kind; four equal ranks within five cards    8: Straight flush; straight + flush    9: Royal flush; {Ace, King, Queen, Jack, Ten} + flush","Purpose is to predict poker handsEach record is an example of a hand consisting of five playing cards drawn from a standard deck of 52. Each card is described using two attributes (suit and rank), for a total of 10 predictive attributes. There is one Class attribute that describes the ""Poker Hand"". The order of cards is important, which is why there are 480 possible Royal Flush hands as compared to 4 (one for each suit - explained in [Web Link]).1) S1 ""Suit of card #1""    Ordinal (1-4) representing {Hearts, Spades, Diamonds, Clubs}2) C1 ""Rank of card #1""    Numerical (1-13) representing (Ace, 2, 3, ... , Queen, King)3) S2 ""Suit of card #2""    Ordinal (1-4) representing {Hearts, Spades, Diamonds, Clubs}4) C2 ""Rank of card #2""    Numerical (1-13) representing (Ace, 2, 3, ... , Queen, King)5) S3 ""Suit of card #3""    Ordinal (1-4) representing {Hearts, Spades, Diamonds, Clubs}6) C3 ""Rank of card #3""    Numerical (1-13) representing (Ace, 2, 3, ... , Queen, King)7) S4 ""Suit of card #4""    Ordinal (1-4) representing {Hearts, Spades, Diamonds, Clubs}8) C4 ""Rank of card #4""    Numerical (1-13) representing (Ace, 2, 3, ... , Queen, King)9) S5 ""Suit of card #5""    Ordinal (1-4) representing {Hearts, Spades, Diamonds, Clubs}10) C5 ""Rank of card 5""    Numerical (1-13) representing (Ace, 2, 3, ... , Queen, King)11) CLASS ""Poker Hand""    Ordinal (0-9)    0: Nothing in hand; not a recognized poker hand     1: One pair; one pair of equal ranks within five cards    2: Two pairs; two pairs of equal ranks within five cards    3: Three of a kind; three equal ranks within five cards    4: Straight; five cards, sequentially ranked with no gaps    5: Flush; five cards with the same suit    6: Full house; pair + different rank three of a kind    7: Four of a kind; four equal ranks within five cards    8: Straight flush; straight + flush    9: Royal flush; {Ace, King, Queen, Jack, Ten} + flush"
Rocket League Skillshots Data Set,Rocket League Skillshots Data Set,"This dataset contains data of players of the game Rocket League, performing different skillshots.",Rocket+League+Skillshots+Data+Set,https://archive.ics.uci.edu/ml//machine-learning-databases/00627/,https://archive.ics.uci.edu/ml/datasets/Rocket+League+Skillshots+Data+Set,"Each skillshot performed is characterized by 18 features, composed of players inputs and in-game metrics, collected at different time, creating a multivariate time serie.You can see what skillshots look like in the github of the project:[Web Link]There are seven classes, -1 representing noise (composed of failed figures and random moves)Note that lengthes of those multivariate timeseries varie, and that sample is not collected at regular time iterval (see paper for more details).Using our pattern mining approach, we obtained an accuracy of 87.6% on a 5-fold stratified cross-validation setup.Classes meaning:-1: noise1: ceiling shot2: power shot3: waving dash5: air dribble6: front flick7: musty flick",Game,"The first line contains the name of each of the 18 features.The format is the following:class_numberBallAcceleration_1, Time_1, ..., jump_1BallAcceleration_2, Time_2, ..., jump_2...BallAcceleration_n, Time_n, ..., jump_nclass_number...","This dataset contains data of players of the game Rocket League, performing different skillshots.Each skillshot performed is characterized by 18 features, composed of players inputs and in-game metrics, collected at different time, creating a multivariate time serie.You can see what skillshots look like in the github of the project:[Web Link]There are seven classes, -1 representing noise (composed of failed figures and random moves)Note that lengthes of those multivariate timeseries varie, and that sample is not collected at regular time iterval (see paper for more details).Using our pattern mining approach, we obtained an accuracy of 87.6% on a 5-fold stratified cross-validation setup.Classes meaning:-1: noise1: ceiling shot2: power shot3: waving dash5: air dribble6: front flick7: musty flickThe first line contains the name of each of the 18 features.The format is the following:class_numberBallAcceleration_1, Time_1, ..., jump_1BallAcceleration_2, Time_2, ..., jump_2...BallAcceleration_n, Time_n, ..., jump_nclass_number..."
Chess (King-Rook vs. King),Chess (King-Rook vs. King),Chess Endgame Database for White King and Rook against Black King (KRK).,Chess+%28King-Rook+vs.+King%29,https://archive.ics.uci.edu/ml//machine-learning-databases/chess/king-rook-vs-king/,https://archive.ics.uci.edu/ml/datasets/Chess+%28King-Rook+vs.+King%29,"An Inductive Logic Programming (ILP) or relational learning framework is assumed (Muggleton, 1992). The learning system is provided with examples of chess positions described only by the coordinates of the pieces on the board. Background knowledge in the form of row and column differences is also supplied. The relations necessary to form a correct and concise classifier for the target concept must be discovered by the learning system (the examples already provide a complete extensional definition). The task is closely related to Quinlan's (1983) application of ID3 to classify White King and Rook against Black King and Knight (KRKN) positions as lost 2-ply or lost 3-ply. The framework is similar in that the example positions supply only low-grade data. An important difference is that additional background predicates of the kind supplied in the KRKN study via hand-crafted attributes are not provided for this KRK domain.Chess endgames are complex domains which are enumerable. Endgame databases are tables of stored game-theoretic values for the enumerated elements (legal positions) of the domain. The game-theoretic values stored denote whether or not positions are won for either side, or include also the depth of win (number of moves) assuming minimax-optimal play. From the point of view of experiments on computer induction such databases provide not only a source of examples but also an oracle (Roycroft, 1986) for testing induced rules. However a chess endgame database differs from, say, a relational database containing details of parts and suppliers in the following important respect. The combinatorics of computing the required game-theoretic values for individual position entries independently would be prohibitive. Therefore all the database entries are generated in a single iterative process using the ``standard backup'' algorithm (Thompson, 1986).A KRK database was described by Clarke (1977). The current database was described and used for machine learning experiments in Bain (1992; 1994). It should be noted that our database is not guaranteed correct, but the class distribution is the same as Clarke's database. In (Bain 1992; 1994) the task was classification of positions in the database as won for white in a fixed number of moves, assuming optimal play by both sides. The problem was structured into separate sub-problems by depth-of-win ordered draw, zero, one, ..., sixteen. When learning depth d all examples at depths > d are used as negatives. Quinlan (1994) applied Foil to learn a complete and correct solution for this task.The typical complexity of induced classifiers in this domain suggest that the task is demanding when background knowledge is restricted.",Game,"   1. White King file (column)   2. White King rank (row)   3. White Rook file   4. White Rook rank   5. Black King file   6. Black King rank   7. optimal depth-of-win for White in 0 to 16 moves, otherwise drawn {draw, zero, one, two, ..., sixteen}.","Chess Endgame Database for White King and Rook against Black King (KRK).An Inductive Logic Programming (ILP) or relational learning framework is assumed (Muggleton, 1992). The learning system is provided with examples of chess positions described only by the coordinates of the pieces on the board. Background knowledge in the form of row and column differences is also supplied. The relations necessary to form a correct and concise classifier for the target concept must be discovered by the learning system (the examples already provide a complete extensional definition). The task is closely related to Quinlan's (1983) application of ID3 to classify White King and Rook against Black King and Knight (KRKN) positions as lost 2-ply or lost 3-ply. The framework is similar in that the example positions supply only low-grade data. An important difference is that additional background predicates of the kind supplied in the KRKN study via hand-crafted attributes are not provided for this KRK domain.Chess endgames are complex domains which are enumerable. Endgame databases are tables of stored game-theoretic values for the enumerated elements (legal positions) of the domain. The game-theoretic values stored denote whether or not positions are won for either side, or include also the depth of win (number of moves) assuming minimax-optimal play. From the point of view of experiments on computer induction such databases provide not only a source of examples but also an oracle (Roycroft, 1986) for testing induced rules. However a chess endgame database differs from, say, a relational database containing details of parts and suppliers in the following important respect. The combinatorics of computing the required game-theoretic values for individual position entries independently would be prohibitive. Therefore all the database entries are generated in a single iterative process using the ``standard backup'' algorithm (Thompson, 1986).A KRK database was described by Clarke (1977). The current database was described and used for machine learning experiments in Bain (1992; 1994). It should be noted that our database is not guaranteed correct, but the class distribution is the same as Clarke's database. In (Bain 1992; 1994) the task was classification of positions in the database as won for white in a fixed number of moves, assuming optimal play by both sides. The problem was structured into separate sub-problems by depth-of-win ordered draw, zero, one, ..., sixteen. When learning depth d all examples at depths > d are used as negatives. Quinlan (1994) applied Foil to learn a complete and correct solution for this task.The typical complexity of induced classifiers in this domain suggest that the task is demanding when background knowledge is restricted.   1. White King file (column)   2. White King rank (row)   3. White Rook file   4. White Rook rank   5. Black King file   6. Black King rank   7. optimal depth-of-win for White in 0 to 16 moves, otherwise drawn {draw, zero, one, two, ..., sixteen}."
Chess (King-Rook vs. King-Knight),Chess (King-Rook vs. King-Knight),Knight Pin Chess End-Game Database Creator,Chess+%28King-Rook+vs.+King-Knight%29,https://archive.ics.uci.edu/ml//machine-learning-databases/chess/king-rook-vs-king-knight/,https://archive.ics.uci.edu/ml/datasets/Chess+%28King-Rook+vs.+King-Knight%29,"The companion file is a Common Lisp demonstration file that generates knight-pin Chess end-game samples.  Start up Lisp and load the file. It generates 100 end-games and writes them to a separate file.  Look at the end of the file to see how to change it so that it will produce more end-games, or use the file for output that you wish.The code is released for experimental, confidential use only. See the end of the file for load-time commands that generate a file of examples in Quinlan's format.Note: this program generates duplicates.  In one run, there were about 370 duplicates in the first 1000 instances (i.e., 630 distinct examples).",Game,"Attribute Summaries:    Class: knight's side is lost in n-ply (n=2, 3, etc)    1. distance from black king to knight: 		    1, 2, >2    2. distance from black king to rook: 			    1, 2, >2    3. distance from black king to white king: 		    1, 2, >2    4. distance from white king to knight: 		    1, 2, >2    5. distance from white king to rook: 			    1, 2, >2    6. distance from rook to knight (ADDED): 		    1, 2, >2    7. board relationship of black king and knight (ADDED):  diag, rect, other    8. board relationship of black king and rook (ADDED):    diag, rect, other    9. board relationship of black king and white king (ADDED): diag,rect,other   10. board relationship of white king and knight (ADDED):  diag, rect, other   11. board relationship of white king and rook (ADDED):    diag, rect, other   12. board relationship of white rook and knight (ADDED):  diag, rect, other   13. type of black king's initial square:		    corner, edge, open   14. type of black knight's initial square (ADDED):	    corner, edge, open   15. type of white king's initial square (ADDED):	    corner, edge, open   16. type of white rook's initial square (ADDED):	    corner, edge, open   17. rook checks black king (OMITTED, always f):	    t, f   18. rook threatens knight (OMITTED, always t):	    t, f   19. knight threatens rook (OMITTED, always f):	    t, f   20. black king, knight, rook in line (OMITTED, always t) t, f   21. black king can move adjacent to knight (OMITTED)	    t, f   22. knight can interpose adjacent to king (OMITTED)	    t, f","Knight Pin Chess End-Game Database CreatorThe companion file is a Common Lisp demonstration file that generates knight-pin Chess end-game samples.  Start up Lisp and load the file. It generates 100 end-games and writes them to a separate file.  Look at the end of the file to see how to change it so that it will produce more end-games, or use the file for output that you wish.The code is released for experimental, confidential use only. See the end of the file for load-time commands that generate a file of examples in Quinlan's format.Note: this program generates duplicates.  In one run, there were about 370 duplicates in the first 1000 instances (i.e., 630 distinct examples).Attribute Summaries:    Class: knight's side is lost in n-ply (n=2, 3, etc)    1. distance from black king to knight: 		    1, 2, >2    2. distance from black king to rook: 			    1, 2, >2    3. distance from black king to white king: 		    1, 2, >2    4. distance from white king to knight: 		    1, 2, >2    5. distance from white king to rook: 			    1, 2, >2    6. distance from rook to knight (ADDED): 		    1, 2, >2    7. board relationship of black king and knight (ADDED):  diag, rect, other    8. board relationship of black king and rook (ADDED):    diag, rect, other    9. board relationship of black king and white king (ADDED): diag,rect,other   10. board relationship of white king and knight (ADDED):  diag, rect, other   11. board relationship of white king and rook (ADDED):    diag, rect, other   12. board relationship of white rook and knight (ADDED):  diag, rect, other   13. type of black king's initial square:		    corner, edge, open   14. type of black knight's initial square (ADDED):	    corner, edge, open   15. type of white king's initial square (ADDED):	    corner, edge, open   16. type of white rook's initial square (ADDED):	    corner, edge, open   17. rook checks black king (OMITTED, always f):	    t, f   18. rook threatens knight (OMITTED, always t):	    t, f   19. knight threatens rook (OMITTED, always f):	    t, f   20. black king, knight, rook in line (OMITTED, always t) t, f   21. black king can move adjacent to knight (OMITTED)	    t, f   22. knight can interpose adjacent to king (OMITTED)	    t, f"
Chess (King-Rook vs. King-Pawn),Chess (King-Rook vs. King-Pawn),King+Rook versus King+Pawn on a7 (usually abbreviated KRKPA7).,Chess+%28King-Rook+vs.+King-Pawn%29,https://archive.ics.uci.edu/ml//machine-learning-databases/chess/king-rook-vs-king-pawn/,https://archive.ics.uci.edu/ml/datasets/Chess+%28King-Rook+vs.+King-Pawn%29,The dataset format is described below.  Note: the format of this database was modified on 2/26/90 to conform with the format of all the other databases in the UCI repository of machine learning databases.,Game,"Classes (2):  -- White-can-win (""won"") and White-cannot-win (""nowin"").I believe that White is deemed to be unable to win if the Black pawn can safely advance.Attributes: see Shapiro's book.","King+Rook versus King+Pawn on a7 (usually abbreviated KRKPA7).The dataset format is described below.  Note: the format of this database was modified on 2/26/90 to conform with the format of all the other databases in the UCI repository of machine learning databases.Classes (2):  -- White-can-win (""won"") and White-cannot-win (""nowin"").I believe that White is deemed to be unable to win if the Black pawn can safely advance.Attributes: see Shapiro's book."
Chess (Domain Theories),Chess (Domain Theories),6 different domain theories for generating legal moves of chess,Chess+%28Domain+Theories%29,https://archive.ics.uci.edu/ml//machine-learning-databases/chess/domain-theories/,https://archive.ics.uci.edu/ml/datasets/Chess+%28Domain+Theories%29,"The six encoding are briefly described below:1) chess_flann_new: Written by flann '@' cs.orst.edu. Employs a geometric representation for states, with each square designated by an X,Y coordinate and square connectivity computed by vectors. Generates legal moves by first generating peusdo moves then eliminating those that result in the moving player being in check.2) chess_flann_wyl: Written by flann '@' cs.orst.edu. Employs a relational representation for states, with each square given a unique name and square connectivity computed by an enumeration of connected relations. Generates legal moves by first generating peusdo moves then eliminating those that result in the moving player being in check.3) chess_russell_wyl: Originally written by Stuart Russell in MRS, translated into prolog by flann '@' cs.orst.edu. Employs a geometric representation for states, with each square designated by an X,Y coordinate and square connectivity computed by vectors. Generates legal moves by determining whether the moving side is in check. If the moving side is in check, moves are generated that destroy the check threat. If the moving side is not in check, moves are generated that do not create a check threat. Note that if the moving side is in check from multiple threats then the domain theory generates incorrect moves.4) chess_vijay_1: Written by vijay '@' cs.orst.edu. Employs a relational representation for states, with each square given a unique name and square connectivity computed by an enumeration of connected relations. Generates legal moves by first generating peusdo moves then eliminating those that result in the moving player being in check.5) chess_vijay_2: Written by vijay '@' cs.orst.edu. Employs a geometric representation for states, with each square designated by an X,Y coordinate and square connectivity computed by vectors. Generates legal moves by first generating peusdo moves then eliminating those that result in the moving player being in check.6) chess_vijay_3: Written by vijay '@' cs.orst.edu. Employs a special linear representation for states, with each square designated by a single number and square connectivity computed by a single delta value. Generates legal moves by first generating peusdo moves then eliminating those that result in the moving player being in check.Each domain theory includes a sample state called state1 that describes the board position illustrated as Figure 4(d) in Flann and Dietterich, ""A study of explanation-based methods for inductive learning"" in Machine Learning, 4 187-226. See file test_domain_theories for an example of loading and running the domain theories.In addition to the domain theories, a file called support_code is included that contains some useful prolog routines. One routine takes a generic chess board description and a domain theory name, and produces a prolog state description suitable for use with the given domain theory. See file test_domain_theories for an example of generating state descriptions.",Game,,"6 different domain theories for generating legal moves of chessThe six encoding are briefly described below:1) chess_flann_new: Written by flann '@' cs.orst.edu. Employs a geometric representation for states, with each square designated by an X,Y coordinate and square connectivity computed by vectors. Generates legal moves by first generating peusdo moves then eliminating those that result in the moving player being in check.2) chess_flann_wyl: Written by flann '@' cs.orst.edu. Employs a relational representation for states, with each square given a unique name and square connectivity computed by an enumeration of connected relations. Generates legal moves by first generating peusdo moves then eliminating those that result in the moving player being in check.3) chess_russell_wyl: Originally written by Stuart Russell in MRS, translated into prolog by flann '@' cs.orst.edu. Employs a geometric representation for states, with each square designated by an X,Y coordinate and square connectivity computed by vectors. Generates legal moves by determining whether the moving side is in check. If the moving side is in check, moves are generated that destroy the check threat. If the moving side is not in check, moves are generated that do not create a check threat. Note that if the moving side is in check from multiple threats then the domain theory generates incorrect moves.4) chess_vijay_1: Written by vijay '@' cs.orst.edu. Employs a relational representation for states, with each square given a unique name and square connectivity computed by an enumeration of connected relations. Generates legal moves by first generating peusdo moves then eliminating those that result in the moving player being in check.5) chess_vijay_2: Written by vijay '@' cs.orst.edu. Employs a geometric representation for states, with each square designated by an X,Y coordinate and square connectivity computed by vectors. Generates legal moves by first generating peusdo moves then eliminating those that result in the moving player being in check.6) chess_vijay_3: Written by vijay '@' cs.orst.edu. Employs a special linear representation for states, with each square designated by a single number and square connectivity computed by a single delta value. Generates legal moves by first generating peusdo moves then eliminating those that result in the moving player being in check.Each domain theory includes a sample state called state1 that describes the board position illustrated as Figure 4(d) in Flann and Dietterich, ""A study of explanation-based methods for inductive learning"" in Machine Learning, 4 187-226. See file test_domain_theories for an example of loading and running the domain theories.In addition to the domain theories, a file called support_code is included that contains some useful prolog routines. One routine takes a generic chess board description and a domain theory name, and produces a prolog state description suitable for use with the given domain theory. See file test_domain_theories for an example of generating state descriptions.nan"
Dota2 Games Results,Dota2 Games Results,Dota 2 is a popular computer game with two teams of 5 players. At the start of the game each player chooses a unique hero with different strengths and weaknesses.,Dota2+Games+Results,https://archive.ics.uci.edu/ml//machine-learning-databases/00367/,https://archive.ics.uci.edu/ml/datasets/Dota2+Games+Results,"Dota 2 is a popular computer game with two teams of 5 players. At the start of the game each player chooses a unique hero with different strengths and weaknesses. The dataset is reasonably sparse as only 10 of 113 possible heroes are chosen in a given game. All games were played in a space of 2 hours on the 13th of August, 2016The data was collected using: [Web Link]",Game,Each row of the dataset is a single game with the following features (in the order in the vector):1. Team won the game (1 or -1)2. Cluster ID (related to location)3. Game mode (eg All Pick)4. Game type (eg. Ranked)5 - end: Each element is an indicator for a hero. Value of 1 indicates that a player from team '1' played as that hero and '-1' for the other team. Hero can be selected by only one player each game. This means that each row has five '1' and five '-1' values.The hero to id mapping can be found here: [Web Link],"Dota 2 is a popular computer game with two teams of 5 players. At the start of the game each player chooses a unique hero with different strengths and weaknesses.Dota 2 is a popular computer game with two teams of 5 players. At the start of the game each player chooses a unique hero with different strengths and weaknesses. The dataset is reasonably sparse as only 10 of 113 possible heroes are chosen in a given game. All games were played in a space of 2 hours on the 13th of August, 2016The data was collected using: [Web Link]Each row of the dataset is a single game with the following features (in the order in the vector):1. Team won the game (1 or -1)2. Cluster ID (related to location)3. Game mode (eg All Pick)4. Game type (eg. Ranked)5 - end: Each element is an indicator for a hero. Value of 1 indicates that a player from team '1' played as that hero and '-1' for the other team. Hero can be selected by only one player each game. This means that each row has five '1' and five '-1' values.The hero to id mapping can be found here: [Web Link]"
Tic-Tac-Toe Endgame,Tic-Tac-Toe Endgame,Binary classification task on possible configurations of tic-tac-toe game,Tic-Tac-Toe+Endgame,https://archive.ics.uci.edu/ml//machine-learning-databases/tic-tac-toe/,https://archive.ics.uci.edu/ml/datasets/Tic-Tac-Toe+Endgame,"This database encodes the complete set of possible board configurations at the end of tic-tac-toe games, where ""x"" is assumed to have played first.  The target concept is ""win for x"" (i.e., true when ""x"" has one of 8 possible ways to create a ""three-in-a-row"").  Interestingly, this raw database gives a stripped-down decision tree algorithm (e.g., ID3) fits.  However, the rule-based CN2 algorithm, the simple IB1 instance-based learning algorithm, and the CITRE feature-constructing decision tree algorithm perform well on it.",Game,"    1. top-left-square: {x,o,b}    2. top-middle-square: {x,o,b}    3. top-right-square: {x,o,b}    4. middle-left-square: {x,o,b}    5. middle-middle-square: {x,o,b}    6. middle-right-square: {x,o,b}    7. bottom-left-square: {x,o,b}    8. bottom-middle-square: {x,o,b}    9. bottom-right-square: {x,o,b}   10. Class: {positive,negative}","Binary classification task on possible configurations of tic-tac-toe gameThis database encodes the complete set of possible board configurations at the end of tic-tac-toe games, where ""x"" is assumed to have played first.  The target concept is ""win for x"" (i.e., true when ""x"" has one of 8 possible ways to create a ""three-in-a-row"").  Interestingly, this raw database gives a stripped-down decision tree algorithm (e.g., ID3) fits.  However, the rule-based CN2 algorithm, the simple IB1 instance-based learning algorithm, and the CITRE feature-constructing decision tree algorithm perform well on it.    1. top-left-square: {x,o,b}    2. top-middle-square: {x,o,b}    3. top-right-square: {x,o,b}    4. middle-left-square: {x,o,b}    5. middle-middle-square: {x,o,b}    6. middle-right-square: {x,o,b}    7. bottom-left-square: {x,o,b}    8. bottom-middle-square: {x,o,b}    9. bottom-right-square: {x,o,b}   10. Class: {positive,negative}"
Othello Domain Theory,Othello Domain Theory,Used in research to generate features for an inductive learning system,Othello+Domain+Theory,https://archive.ics.uci.edu/ml//machine-learning-databases/othello/,https://archive.ics.uci.edu/ml/datasets/Othello+Domain+Theory,"The Code (""othello.theory"") is well documented.",Game,,"Used in research to generate features for an inductive learning systemThe Code (""othello.theory"") is well documented.nan"
Connect-4,Connect-4,Contains connect-4 positions,Connect-4,https://archive.ics.uci.edu/ml//machine-learning-databases/connect-4/,https://archive.ics.uci.edu/ml/datasets/Connect-4,"This database contains all legal 8-ply positions in the game of connect-4 in which neither player has won yet, and in which the next move is not forced.x is the first player; o the second.The outcome class is the game theoretical value for the first player.",Game,"Attribute Information: (x=player x has taken, o=player o has taken, b=blank)The board is numbered like:6 . . . . . . .5 . . . . . . .4 . . . . . . .3 . . . . . . .2 . . . . . . .1 . . . . . . . a b c d e f g    1. a1: {x,o,b}    2. a2: {x,o,b}    3. a3: {x,o,b}    4. a4: {x,o,b}    5. a5: {x,o,b}    6. a6: {x,o,b}    7. b1: {x,o,b}    8. b2: {x,o,b}    9. b3: {x,o,b}   10. b4: {x,o,b}   11. b5: {x,o,b}   12. b6: {x,o,b}   13. c1: {x,o,b}   14. c2: {x,o,b}   15. c3: {x,o,b}   16. c4: {x,o,b}   17. c5: {x,o,b}   18. c6: {x,o,b}   19. d1: {x,o,b}   20. d2: {x,o,b}   21. d3: {x,o,b}   22. d4: {x,o,b}   23. d5: {x,o,b}   24. d6: {x,o,b}   25. e1: {x,o,b}   26. e2: {x,o,b}   27. e3: {x,o,b}   28. e4: {x,o,b}   29. e5: {x,o,b}   30. e6: {x,o,b}   31. f1: {x,o,b}   32. f2: {x,o,b}   33. f3: {x,o,b}   34. f4: {x,o,b}   35. f5: {x,o,b}   36. f6: {x,o,b}   37. g1: {x,o,b}   38. g2: {x,o,b}   39. g3: {x,o,b}   40. g4: {x,o,b}   41. g5: {x,o,b}   42. g6: {x,o,b}   43. Class: {win,loss,draw}","Contains connect-4 positionsThis database contains all legal 8-ply positions in the game of connect-4 in which neither player has won yet, and in which the next move is not forced.x is the first player; o the second.The outcome class is the game theoretical value for the first player.Attribute Information: (x=player x has taken, o=player o has taken, b=blank)The board is numbered like:6 . . . . . . .5 . . . . . . .4 . . . . . . .3 . . . . . . .2 . . . . . . .1 . . . . . . . a b c d e f g    1. a1: {x,o,b}    2. a2: {x,o,b}    3. a3: {x,o,b}    4. a4: {x,o,b}    5. a5: {x,o,b}    6. a6: {x,o,b}    7. b1: {x,o,b}    8. b2: {x,o,b}    9. b3: {x,o,b}   10. b4: {x,o,b}   11. b5: {x,o,b}   12. b6: {x,o,b}   13. c1: {x,o,b}   14. c2: {x,o,b}   15. c3: {x,o,b}   16. c4: {x,o,b}   17. c5: {x,o,b}   18. c6: {x,o,b}   19. d1: {x,o,b}   20. d2: {x,o,b}   21. d3: {x,o,b}   22. d4: {x,o,b}   23. d5: {x,o,b}   24. d6: {x,o,b}   25. e1: {x,o,b}   26. e2: {x,o,b}   27. e3: {x,o,b}   28. e4: {x,o,b}   29. e5: {x,o,b}   30. e6: {x,o,b}   31. f1: {x,o,b}   32. f2: {x,o,b}   33. f3: {x,o,b}   34. f4: {x,o,b}   35. f5: {x,o,b}   36. f6: {x,o,b}   37. g1: {x,o,b}   38. g2: {x,o,b}   39. g3: {x,o,b}   40. g4: {x,o,b}   41. g5: {x,o,b}   42. g6: {x,o,b}   43. Class: {win,loss,draw}"
Basketball dataset,Basketball dataset,"It's data collected from different volunteers that are done in a basketball practice: dribbling, pass, shoot, picking the ball, and holding the ball.",Basketball+dataset,https://archive.ics.uci.edu/ml//machine-learning-databases/00587/,https://archive.ics.uci.edu/ml/datasets/Basketball+dataset,"There are different trials. For which, pass, shoot and pick up the ball have 5. and hold and dribble there are 2. First of all, we gathered the 4 users who were willing to be our test samples. Then, one by one we made them do the following 5 activities: Pass, hold the ball, shoot pick up the ball, and dribble. Each activity had a different way of gathering its corresponding data. For holding the ball, we made the volunteer stand in one place in a holding position. Once ready, we run the app. After 5 seconds we stop it and save the data with the userÃ¢â‚¬â„¢s first initial, the activity and the number of the trial. For this label we did a total of 3 trials for each person.Next we started collecting the data of passing. The volunteer starts with the ball in a holding position. Next we run the app, for which after 3 seconds we tell the volunteer to pass the ball to one of us, once finish we stop the app. For this label we did a total of 5 trails for each person. Then, we collected the data of dribbling. The volunteers start with the ball in holding position. Then, 3 secondsafter we run the app we tell him to dribble and after 5 he started the dribbling we said to stop. Once he stops we go and stop the app. For this label we did a total of 3 trials for each person.Continuing with the activity of shooting, we let the volunteer get ready in a holding position with the ball, and then we run the app. For which, he shoots immediately after we start the application. Once finish, we stop the app. For this label we did a total of 5 trials for each person. Finally, we gather the data of picking the ball. For this data, we just start the app, and after 3 seconds the user picks up the ball, and at the 6 seconds we stop the app gathering this range of data.For this label we did a total of 5 trails for each person. Finally we did a different way of collecting the data. For which one user in a set of time did each activity spontanously. Every time he did an activity we collected the time for which he did it in a chronometer, and in a video all for which started closely at the same time. ",Game,we use acceloremeter measures x y z in ms2 and gyroscope measures r phi theta. for X the data is in g,"It's data collected from different volunteers that are done in a basketball practice: dribbling, pass, shoot, picking the ball, and holding the ball.There are different trials. For which, pass, shoot and pick up the ball have 5. and hold and dribble there are 2. First of all, we gathered the 4 users who were willing to be our test samples. Then, one by one we made them do the following 5 activities: Pass, hold the ball, shoot pick up the ball, and dribble. Each activity had a different way of gathering its corresponding data. For holding the ball, we made the volunteer stand in one place in a holding position. Once ready, we run the app. After 5 seconds we stop it and save the data with the userÃ¢â‚¬â„¢s first initial, the activity and the number of the trial. For this label we did a total of 3 trials for each person.Next we started collecting the data of passing. The volunteer starts with the ball in a holding position. Next we run the app, for which after 3 seconds we tell the volunteer to pass the ball to one of us, once finish we stop the app. For this label we did a total of 5 trails for each person. Then, we collected the data of dribbling. The volunteers start with the ball in holding position. Then, 3 secondsafter we run the app we tell him to dribble and after 5 he started the dribbling we said to stop. Once he stops we go and stop the app. For this label we did a total of 3 trials for each person.Continuing with the activity of shooting, we let the volunteer get ready in a holding position with the ball, and then we run the app. For which, he shoots immediately after we start the application. Once finish, we stop the app. For this label we did a total of 5 trials for each person. Finally, we gather the data of picking the ball. For this data, we just start the app, and after 3 seconds the user picks up the ball, and at the 6 seconds we stop the app gathering this range of data.For this label we did a total of 5 trails for each person. Finally we did a different way of collecting the data. For which one user in a set of time did each activity spontanously. Every time he did an activity we collected the time for which he did it in a chronometer, and in a video all for which started closely at the same time. we use acceloremeter measures x y z in ms2 and gyroscope measures r phi theta. for X the data is in g"
SkillCraft1 Master Table Dataset,SkillCraft1 Master Table Dataset,"This data was used in Thompson et al. (2013). A list of possible game actions is discussed in Thompson, Blair, Chen, & Henrey (2013).",SkillCraft1+Master+Table+Dataset,https://archive.ics.uci.edu/ml//machine-learning-databases/00272/,https://archive.ics.uci.edu/ml/datasets/SkillCraft1+Master+Table+Dataset,"   -- We aggregated screen movements into screen-fixations using a Salvucci & Goldberg (2000) dispersion-threshold algorithm, and defined Perception Action Cycles (PACs) as fixations with at least one action.   -- Time is recorded in terms of timestamps in the StarCraft 2 replay file. When the game is played on 'faster', 1 real-time second is equivalent to roughly 88.5 timestamps.   -- List of possible game actions is discussed in Thompson, Blair, Chen, & Henrey (2013)",Game,"   1. GameID: Unique ID number for each game (integer)   2. LeagueIndex: Bronze, Silver, Gold, Platinum, Diamond, Master, GrandMaster, and Professional leagues coded 1-8 (Ordinal)   3. Age: Age of each player (integer)   4. HoursPerWeek: Reported hours spent playing per week (integer)   5. TotalHours: Reported total hours spent playing (integer)   6. APM: Action per minute (continuous)   7. SelectByHotkeys: Number of unit or building selections made using hotkeys per timestamp (continuous)   8. AssignToHotkeys: Number of units or buildings assigned to hotkeys per timestamp (continuous)   9. UniqueHotkeys: Number of unique hotkeys used per timestamp (continuous)  10. MinimapAttacks: Number of attack actions on minimap per timestamp (continuous)  11. MinimapRightClicks: number of right-clicks on minimap per timestamp (continuous)  12. NumberOfPACs: Number of PACs per timestamp (continuous)  13. GapBetweenPACs: Mean duration in milliseconds between PACs (continuous)  14. ActionLatency: Mean latency from the onset of a PACs to their first action in milliseconds (continuous)  15. ActionsInPAC: Mean number of actions within each PAC (continuous)  16. TotalMapExplored: The number of 24x24 game coordinate grids viewed by the player per timestamp (continuous)  17. WorkersMade: Number of SCVs, drones, and probes trained per timestamp (continuous)  18. UniqueUnitsMade: Unique unites made per timestamp (continuous)  19. ComplexUnitsMade: Number of ghosts, infestors, and high templars trained per timestamp (continuous)  20. ComplexAbilitiesUsed: Abilities requiring specific targeting instructions used per timestamp (continuous)","This data was used in Thompson et al. (2013). A list of possible game actions is discussed in Thompson, Blair, Chen, & Henrey (2013).   -- We aggregated screen movements into screen-fixations using a Salvucci & Goldberg (2000) dispersion-threshold algorithm, and defined Perception Action Cycles (PACs) as fixations with at least one action.   -- Time is recorded in terms of timestamps in the StarCraft 2 replay file. When the game is played on 'faster', 1 real-time second is equivalent to roughly 88.5 timestamps.   -- List of possible game actions is discussed in Thompson, Blair, Chen, & Henrey (2013)   1. GameID: Unique ID number for each game (integer)   2. LeagueIndex: Bronze, Silver, Gold, Platinum, Diamond, Master, GrandMaster, and Professional leagues coded 1-8 (Ordinal)   3. Age: Age of each player (integer)   4. HoursPerWeek: Reported hours spent playing per week (integer)   5. TotalHours: Reported total hours spent playing (integer)   6. APM: Action per minute (continuous)   7. SelectByHotkeys: Number of unit or building selections made using hotkeys per timestamp (continuous)   8. AssignToHotkeys: Number of units or buildings assigned to hotkeys per timestamp (continuous)   9. UniqueHotkeys: Number of unique hotkeys used per timestamp (continuous)  10. MinimapAttacks: Number of attack actions on minimap per timestamp (continuous)  11. MinimapRightClicks: number of right-clicks on minimap per timestamp (continuous)  12. NumberOfPACs: Number of PACs per timestamp (continuous)  13. GapBetweenPACs: Mean duration in milliseconds between PACs (continuous)  14. ActionLatency: Mean latency from the onset of a PACs to their first action in milliseconds (continuous)  15. ActionsInPAC: Mean number of actions within each PAC (continuous)  16. TotalMapExplored: The number of 24x24 game coordinate grids viewed by the player per timestamp (continuous)  17. WorkersMade: Number of SCVs, drones, and probes trained per timestamp (continuous)  18. UniqueUnitsMade: Unique unites made per timestamp (continuous)  19. ComplexUnitsMade: Number of ghosts, infestors, and high templars trained per timestamp (continuous)  20. ComplexAbilitiesUsed: Abilities requiring specific targeting instructions used per timestamp (continuous)"
Post-Operative Patient,Post-Operative Patient,Dataset of patient features,Post-Operative+Patient,https://archive.ics.uci.edu/ml//machine-learning-databases/postoperative-patient-data/,https://archive.ics.uci.edu/ml/datasets/Post-Operative+Patient,"The classification task of this database is to determine where patients in a postoperative recovery area should be sent to next.  Because hypothermia is a significant concern after surgery (Woolery, L. et. al. 1991), the attributes correspond roughly to body temperature measurements.Results:      -- LERS (LEM2): 48% accuracy",Life,"     1. L-CORE (patient's internal temperature in C):              high (> 37), mid (>= 36 and <= 37), low (< 36)     2. L-SURF (patient's surface temperature in C):              high (> 36.5), mid (>= 36.5 and <= 35), low (< 35)     3. L-O2 (oxygen saturation in %):              excellent (>= 98), good (>= 90 and < 98),              fair (>= 80 and < 90), poor (< 80)     4. L-BP (last measurement of blood pressure):              high (> 130/90), mid (<= 130/90 and >= 90/70), low (< 90/70)     5. SURF-STBL (stability of patient's surface temperature):              stable, mod-stable, unstable     6. CORE-STBL (stability of patient's core temperature)              stable, mod-stable, unstable     7. BP-STBL (stability of patient's blood pressure)              stable, mod-stable, unstable     8. COMFORT (patient's perceived comfort at discharge, measured as               an integer between 0 and 20)     9. decision ADM-DECS (discharge decision):              I (patient sent to Intensive Care Unit),              S (patient prepared to go home),              A (patient sent to general hospital floor)","Dataset of patient featuresThe classification task of this database is to determine where patients in a postoperative recovery area should be sent to next.  Because hypothermia is a significant concern after surgery (Woolery, L. et. al. 1991), the attributes correspond roughly to body temperature measurements.Results:      -- LERS (LEM2): 48% accuracy     1. L-CORE (patient's internal temperature in C):              high (> 37), mid (>= 36 and <= 37), low (< 36)     2. L-SURF (patient's surface temperature in C):              high (> 36.5), mid (>= 36.5 and <= 35), low (< 35)     3. L-O2 (oxygen saturation in %):              excellent (>= 98), good (>= 90 and < 98),              fair (>= 80 and < 90), poor (< 80)     4. L-BP (last measurement of blood pressure):              high (> 130/90), mid (<= 130/90 and >= 90/70), low (< 90/70)     5. SURF-STBL (stability of patient's surface temperature):              stable, mod-stable, unstable     6. CORE-STBL (stability of patient's core temperature)              stable, mod-stable, unstable     7. BP-STBL (stability of patient's blood pressure)              stable, mod-stable, unstable     8. COMFORT (patient's perceived comfort at discharge, measured as               an integer between 0 and 20)     9. decision ADM-DECS (discharge decision):              I (patient sent to Intensive Care Unit),              S (patient prepared to go home),              A (patient sent to general hospital floor)"
Cervical cancer (Risk Factors),Cervical cancer (Risk Factors),"This dataset focuses on the prediction of indicators/diagnosis of cervical cancer. The features cover demographic information, habits, and historic medical records.",Cervical+cancer+%28Risk+Factors%29,https://archive.ics.uci.edu/ml//machine-learning-databases/00383/,https://archive.ics.uci.edu/ml/datasets/Cervical+cancer+%28Risk+Factors%29,"The dataset was collected at 'Hospital Universitario de Caracas' in Caracas, Venezuela. The dataset comprises demographic information, habits, and historic medical records of 858 patients. Several patients decided not to answer some of the questions because of privacy concerns (missing values).",Life,(int) Age(int) Number of sexual partners(int) First sexual intercourse (age)(int) Num of pregnancies(bool) Smokes(bool) Smokes (years)(bool) Smokes (packs/year)(bool) Hormonal Contraceptives(int) Hormonal Contraceptives (years)(bool) IUD(int) IUD (years)(bool) STDs(int) STDs (number)(bool) STDs:condylomatosis(bool) STDs:cervical condylomatosis(bool) STDs:vaginal condylomatosis(bool) STDs:vulvo-perineal condylomatosis(bool) STDs:syphilis(bool) STDs:pelvic inflammatory disease(bool) STDs:genital herpes(bool) STDs:molluscum contagiosum(bool) STDs:AIDS(bool) STDs:HIV(bool) STDs:Hepatitis B(bool) STDs:HPV(int) STDs: Number of diagnosis(int) STDs: Time since first diagnosis(int) STDs: Time since last diagnosis(bool) Dx:Cancer(bool) Dx:CIN(bool) Dx:HPV(bool) Dx(bool) Hinselmann: target variable(bool) Schiller: target variable(bool) Cytology: target variable(bool) Biopsy: target variable,"This dataset focuses on the prediction of indicators/diagnosis of cervical cancer. The features cover demographic information, habits, and historic medical records.The dataset was collected at 'Hospital Universitario de Caracas' in Caracas, Venezuela. The dataset comprises demographic information, habits, and historic medical records of 858 patients. Several patients decided not to answer some of the questions because of privacy concerns (missing values).(int) Age(int) Number of sexual partners(int) First sexual intercourse (age)(int) Num of pregnancies(bool) Smokes(bool) Smokes (years)(bool) Smokes (packs/year)(bool) Hormonal Contraceptives(int) Hormonal Contraceptives (years)(bool) IUD(int) IUD (years)(bool) STDs(int) STDs (number)(bool) STDs:condylomatosis(bool) STDs:cervical condylomatosis(bool) STDs:vaginal condylomatosis(bool) STDs:vulvo-perineal condylomatosis(bool) STDs:syphilis(bool) STDs:pelvic inflammatory disease(bool) STDs:genital herpes(bool) STDs:molluscum contagiosum(bool) STDs:AIDS(bool) STDs:HIV(bool) STDs:Hepatitis B(bool) STDs:HPV(int) STDs: Number of diagnosis(int) STDs: Time since first diagnosis(int) STDs: Time since last diagnosis(bool) Dx:Cancer(bool) Dx:CIN(bool) Dx:HPV(bool) Dx(bool) Hinselmann: target variable(bool) Schiller: target variable(bool) Cytology: target variable(bool) Biopsy: target variable"
Activity recognition with healthy older people using a batteryless wearable sensor,Activity recognition with healthy older people using a batteryless wearable sensor,"Sequential motion data from 14 healthy older people aged 66 to 86 years old using a batteryless, wearable sensor on top of their clothing for the recognition of activities in clinical environments.",Activity+recognition+with+healthy+older+people+using+a+batteryless+wearable+sensor,https://archive.ics.uci.edu/ml//machine-learning-databases/00427/,https://archive.ics.uci.edu/ml/datasets/Activity+recognition+with+healthy+older+people+using+a+batteryless+wearable+sensor,"This dataset contains the motion data of 14 healthy older aged between 66 and 86 years old, performed broadly scripted activities using a batteryless, wearable sensor on top of their clothing at sternum level. Data is sparse and noisy due to the use of a passive sensor. Participants were allocated in two clinical room settings (S1 and S2). The setting of S1 (Room1) uses 4 RFID reader antennas around the room (one on ceiling level, and 3 on wall level) for the collection of data, whereas the room setting S2 (Room2) uses 3 RFID reader antennas (two at ceiling level and one at wall level) for the collection of motion data. The activities performed were:  walking to the chair,  sitting on the chair,  getting off the chair,  walking to bed,  lying on bed,  getting off the bed and  walking to the door. Hence the possible class labels assigned for every sensor observation are:- Sitting on bed- Sitting on chair- Lying on bed- Ambulating, where ambulating includes standing, walking around the room. ",Life,"The content of the file is as follows:Comma separated values (CSV) format.Column 1: Time in seconds Column 2: Acceleration reading in G for frontal axisColumn 3: Acceleration reading in G for vertical axisColumn 4: Acceleration reading in G for lateral axisColumn 5: Id of antenna reading sensorColumn 6: Received signal strength indicator (RSSI) Column 7: PhaseColumn 8: FrequencyColumn 9: Label of activity, 1: sit on bed, 2: sit on chair, 3: lying, 4: ambulatingIn addition, gender of participant is included in the last character of file name eg: d1p33F (F:female).","Sequential motion data from 14 healthy older people aged 66 to 86 years old using a batteryless, wearable sensor on top of their clothing for the recognition of activities in clinical environments.This dataset contains the motion data of 14 healthy older aged between 66 and 86 years old, performed broadly scripted activities using a batteryless, wearable sensor on top of their clothing at sternum level. Data is sparse and noisy due to the use of a passive sensor. Participants were allocated in two clinical room settings (S1 and S2). The setting of S1 (Room1) uses 4 RFID reader antennas around the room (one on ceiling level, and 3 on wall level) for the collection of data, whereas the room setting S2 (Room2) uses 3 RFID reader antennas (two at ceiling level and one at wall level) for the collection of motion data. The activities performed were:  walking to the chair,  sitting on the chair,  getting off the chair,  walking to bed,  lying on bed,  getting off the bed and  walking to the door. Hence the possible class labels assigned for every sensor observation are:- Sitting on bed- Sitting on chair- Lying on bed- Ambulating, where ambulating includes standing, walking around the room. The content of the file is as follows:Comma separated values (CSV) format.Column 1: Time in seconds Column 2: Acceleration reading in G for frontal axisColumn 3: Acceleration reading in G for vertical axisColumn 4: Acceleration reading in G for lateral axisColumn 5: Id of antenna reading sensorColumn 6: Received signal strength indicator (RSSI) Column 7: PhaseColumn 8: FrequencyColumn 9: Label of activity, 1: sit on bed, 2: sit on chair, 3: lying, 4: ambulatingIn addition, gender of participant is included in the last character of file name eg: d1p33F (F:female)."
Yeast,Yeast,Predicting the Cellular Localization Sites of Proteins,Yeast,https://archive.ics.uci.edu/ml//machine-learning-databases/yeast/,https://archive.ics.uci.edu/ml/datasets/Yeast,"Predicted Attribute: Localization site of protein. ( non-numeric ).The references below describe a predecessor to this dataset and its development. They also give results (not cross-validated) for classification by a rule-based expert system with that version of the dataset.Reference: ""Expert Sytem for Predicting Protein Localization Sites in Gram-Negative Bacteria"", Kenta Nakai & Minoru Kanehisa,  PROTEINS: Structure, Function, and Genetics 11:95-110, 1991.Reference: ""A Knowledge Base for Predicting Protein Localization Sites in Eukaryotic Cells"", Kenta Nakai & Minoru Kanehisa, Genomics 14:897-911, 1992.",Life,"  1.  Sequence Name: Accession number for the SWISS-PROT database  2.  mcg: McGeoch's method for signal sequence recognition.  3.  gvh: von Heijne's method for signal sequence recognition.  4.  alm: Score of the ALOM membrane spanning region prediction program.  5.  mit: Score of discriminant analysis of the amino acid content of the N-terminal region (20 residues long) of mitochondrial and non-mitochondrial proteins.  6.  erl: Presence of ""HDEL"" substring (thought to act as a signal for retention in the endoplasmic reticulum lumen). Binary attribute.  7.  pox: Peroxisomal targeting signal in the C-terminus.  8.  vac: Score of discriminant analysis of the amino acid content of vacuolar and extracellular proteins.  9.  nuc: Score of discriminant analysis of nuclear localization signals of nuclear and non-nuclear proteins.","Predicting the Cellular Localization Sites of ProteinsPredicted Attribute: Localization site of protein. ( non-numeric ).The references below describe a predecessor to this dataset and its development. They also give results (not cross-validated) for classification by a rule-based expert system with that version of the dataset.Reference: ""Expert Sytem for Predicting Protein Localization Sites in Gram-Negative Bacteria"", Kenta Nakai & Minoru Kanehisa,  PROTEINS: Structure, Function, and Genetics 11:95-110, 1991.Reference: ""A Knowledge Base for Predicting Protein Localization Sites in Eukaryotic Cells"", Kenta Nakai & Minoru Kanehisa, Genomics 14:897-911, 1992.  1.  Sequence Name: Accession number for the SWISS-PROT database  2.  mcg: McGeoch's method for signal sequence recognition.  3.  gvh: von Heijne's method for signal sequence recognition.  4.  alm: Score of the ALOM membrane spanning region prediction program.  5.  mit: Score of discriminant analysis of the amino acid content of the N-terminal region (20 residues long) of mitochondrial and non-mitochondrial proteins.  6.  erl: Presence of ""HDEL"" substring (thought to act as a signal for retention in the endoplasmic reticulum lumen). Binary attribute.  7.  pox: Peroxisomal targeting signal in the C-terminus.  8.  vac: Score of discriminant analysis of the amino acid content of vacuolar and extracellular proteins.  9.  nuc: Score of discriminant analysis of nuclear localization signals of nuclear and non-nuclear proteins."
Parkinsons Telemonitoring,Parkinsons Telemonitoring,Oxford Parkinson's Disease Telemonitoring Dataset,Parkinsons+Telemonitoring,https://archive.ics.uci.edu/ml//machine-learning-databases/parkinsons/telemonitoring/,https://archive.ics.uci.edu/ml/datasets/Parkinsons+Telemonitoring,"This dataset is composed of a range of biomedical voice measurements from 42 people with early-stage Parkinson's disease recruited to a six-month trial of a telemonitoring device for remote symptom progression monitoring. The recordings were automatically captured in the patient's homes.Columns in the table contain subject number, subject age, subject gender, time interval from baseline recruitment date, motor UPDRS, total UPDRS, and 16 biomedical voice measures. Each row corresponds to one of 5,875 voice recording from these individuals. The main aim of the data is to predict the motor and total UPDRS scores ('motor_UPDRS' and 'total_UPDRS') from the 16 voice measures.The data is in ASCII CSV format. The rows of the CSV file contain an instance corresponding to one voice recording. There are around 200 recordings per patient, the subject number of the patient is identified in the first column. For further information or to pass on comments, please contact Athanasios Tsanas (tsanasthanasis '@' gmail.com) or Max Little (littlem '@' physics.ox.ac.uk).Further details are contained in the following reference -- if you use this dataset, please cite:Athanasios Tsanas, Max A. Little, Patrick E. McSharry, Lorraine O. Ramig (2009),'Accurate telemonitoring of Parkinsonâ€™s disease progression by non-invasive speech tests',IEEE Transactions on Biomedical Engineering (to appear).Further details about the biomedical voice measures can be found in:Max A. Little, Patrick E. McSharry, Eric J. Hunter, Lorraine O. Ramig (2009), 'Suitability of dysphonia measurements for telemonitoring of Parkinson's disease', IEEE Transactions on Biomedical Engineering, 56(4):1015-1022",Life,"subject# - Integer that uniquely identifies each subjectage - Subject agesex - Subject gender '0' - male, '1' - femaletest_time - Time since recruitment into the trial. The integer part is the number of days since recruitment. motor_UPDRS - Clinician's motor UPDRS score, linearly interpolatedtotal_UPDRS - Clinician's total UPDRS score, linearly interpolatedJitter(%),Jitter(Abs),Jitter:RAP,Jitter:PPQ5,Jitter:DDP - Several measures of variation in fundamental frequencyShimmer,Shimmer(dB),Shimmer:APQ3,Shimmer:APQ5,Shimmer:APQ11,Shimmer:DDA - Several measures of variation in amplitudeNHR,HNR - Two measures of ratio of noise to tonal components in the voiceRPDE - A nonlinear dynamical complexity measureDFA - Signal fractal scaling exponentPPE - A nonlinear measure of fundamental frequency variation ","Oxford Parkinson's Disease Telemonitoring DatasetThis dataset is composed of a range of biomedical voice measurements from 42 people with early-stage Parkinson's disease recruited to a six-month trial of a telemonitoring device for remote symptom progression monitoring. The recordings were automatically captured in the patient's homes.Columns in the table contain subject number, subject age, subject gender, time interval from baseline recruitment date, motor UPDRS, total UPDRS, and 16 biomedical voice measures. Each row corresponds to one of 5,875 voice recording from these individuals. The main aim of the data is to predict the motor and total UPDRS scores ('motor_UPDRS' and 'total_UPDRS') from the 16 voice measures.The data is in ASCII CSV format. The rows of the CSV file contain an instance corresponding to one voice recording. There are around 200 recordings per patient, the subject number of the patient is identified in the first column. For further information or to pass on comments, please contact Athanasios Tsanas (tsanasthanasis '@' gmail.com) or Max Little (littlem '@' physics.ox.ac.uk).Further details are contained in the following reference -- if you use this dataset, please cite:Athanasios Tsanas, Max A. Little, Patrick E. McSharry, Lorraine O. Ramig (2009),'Accurate telemonitoring of Parkinsonâ€™s disease progression by non-invasive speech tests',IEEE Transactions on Biomedical Engineering (to appear).Further details about the biomedical voice measures can be found in:Max A. Little, Patrick E. McSharry, Eric J. Hunter, Lorraine O. Ramig (2009), 'Suitability of dysphonia measurements for telemonitoring of Parkinson's disease', IEEE Transactions on Biomedical Engineering, 56(4):1015-1022subject# - Integer that uniquely identifies each subjectage - Subject agesex - Subject gender '0' - male, '1' - femaletest_time - Time since recruitment into the trial. The integer part is the number of days since recruitment. motor_UPDRS - Clinician's motor UPDRS score, linearly interpolatedtotal_UPDRS - Clinician's total UPDRS score, linearly interpolatedJitter(%),Jitter(Abs),Jitter:RAP,Jitter:PPQ5,Jitter:DDP - Several measures of variation in fundamental frequencyShimmer,Shimmer(dB),Shimmer:APQ3,Shimmer:APQ5,Shimmer:APQ11,Shimmer:DDA - Several measures of variation in amplitudeNHR,HNR - Two measures of ratio of noise to tonal components in the voiceRPDE - A nonlinear dynamical complexity measureDFA - Signal fractal scaling exponentPPE - A nonlinear measure of fundamental frequency variation "
Primary Tumor,Primary Tumor,From Ljubljana Oncology Institute,Primary+Tumor,https://archive.ics.uci.edu/ml//machine-learning-databases/primary-tumor/,https://archive.ics.uci.edu/ml/datasets/Primary+Tumor,This is one of three domains provided by the Oncology Institutenthat has repeatedly appeared in the machine learning literature.(See also breast-cancer and lymphography.),Life,"--- NOTE: All attribute values in the database have been entered as numeric values corresponding to their index in the list of attribute values for that attribute domain as given below.   1. class: lung, head & neck, esophasus, thyroid, stomach, duoden & sm.int, colon, rectum, anus, salivary glands, pancreas, gallblader, liver, kidney, bladder, testis, prostate, ovary, corpus uteri, cervix uteri, vagina, breast   2. age:   <30, 30-59, >=60   3. sex:   male, female   4. histologic-type: epidermoid, adeno, anaplastic   5. degree-of-diffe: well, fairly, poorly   6. bone: yes, no   7. bone-marrow: yes, no   8. lung: yes, no   9. pleura: yes, no  10. peritoneum: yes, no  11. liver: yes, no  12. brain: yes, no  13. skin: yes, no  14. neck: yes, no  15. supraclavicular: yes, no  16. axillar: yes, no  17. mediastinum: yes, no  18. abdominal: yes, no","From Ljubljana Oncology InstituteThis is one of three domains provided by the Oncology Institutenthat has repeatedly appeared in the machine learning literature.(See also breast-cancer and lymphography.)--- NOTE: All attribute values in the database have been entered as numeric values corresponding to their index in the list of attribute values for that attribute domain as given below.   1. class: lung, head & neck, esophasus, thyroid, stomach, duoden & sm.int, colon, rectum, anus, salivary glands, pancreas, gallblader, liver, kidney, bladder, testis, prostate, ovary, corpus uteri, cervix uteri, vagina, breast   2. age:   <30, 30-59, >=60   3. sex:   male, female   4. histologic-type: epidermoid, adeno, anaplastic   5. degree-of-diffe: well, fairly, poorly   6. bone: yes, no   7. bone-marrow: yes, no   8. lung: yes, no   9. pleura: yes, no  10. peritoneum: yes, no  11. liver: yes, no  12. brain: yes, no  13. skin: yes, no  14. neck: yes, no  15. supraclavicular: yes, no  16. axillar: yes, no  17. mediastinum: yes, no  18. abdominal: yes, no"
Protein Data,Protein Data,Undocumented,Protein+Data,https://archive.ics.uci.edu/ml//machine-learning-databases/undocumented/sigillito/,https://archive.ics.uci.edu/ml/datasets/Protein+Data,,Life,,Undocumentednannan
PubChem Bioassay Data,PubChem Bioassay Data,These highly imbalanced bioassay datasets are from the differing types of screening that can be performed using HTS technology. 21 datasets were created from 12 bioassays.,PubChem+Bioassay+Data,https://archive.ics.uci.edu/ml//machine-learning-databases/00209/,https://archive.ics.uci.edu/ml/datasets/PubChem+Bioassay+Data,"21 bioassay datasets generated from Pubchem. Both Primary and confirmatory bioassays (12 bioassays, 21 mixes)The data is provided in the same train/test split as the original paper. The compound IDs have been provided in separate files in case people wish to generate their own molecular representation. The order of the compound Ids is the same as the data files.Ã¢â‚¬Â¢ AID362 details the results of a primary screening bioassay for Formylpeptide Receptor Ligand Binding University from the New Mexico Center for Molecular Discovery. It is a relatively small dataset with 4279 compounds and with a ratio of 1 active to 70 inactive compounds (1.4% minority class). The compounds were selected on the basis of preliminary virtual screening of approximately 480,000 drug-like small molecules from Chemical Diversity Laboratories.Ã¢â‚¬Â¢ AID456 is a primary screen assay from the Burnham Center for Chemical Genomics for inhibition of TNFa induced VCAM-1 cell surface expression and consists of 9,982 compounds with a ratio of 1 active compound to 368 inactive compounds (0.27% minority). The compounds have been selected for their known drug-like properties and 9,431 meet the Rule of 5 [19].Ã¢â‚¬Â¢ AID688 is the result of a primary screen for Yeast eIF2B from the Penn Center for Molecular Discovery and contains activity information of 27,198 compounds with a ratio of 1 active compound to 108 inactive compounds (0.91% minority). The screen is a reporter-gene assay and 25,656 of the compounds have known drug-like properties.Ã¢â‚¬Â¢ AID604 is a primary screening bioassay for Rho kinase 2 inhibitors from the Scripps Research Institute Molecular Screening Center. The bioassay contains activity information of 59,788 compounds with a ratio of 1 active compound to 281 inactive compounds (1.4%). 57,546 of the compounds have known drug-like properties.Ã¢â‚¬Â¢ AID373 is a primary screen from the Scripps Research Institute Molecular Screening Center for endothelial differentiation, sphingolipid G-protein-coupled receptor, 3. 59,788 compounds were screened with a ratio of 1 active compound to 963 inactive compounds (0.1%). 57,546 of the compounds screened had known drug-like properties.Ã¢â‚¬Â¢ AID746 is a primary screen from the Scripps Research Institute Molecular Screening Center for Mitogen-activated protein kinase. 59,788 compounds were screened with a ratio of 1 active compound to 162 inactive compounds (0.61%). 57,546 of the compounds screened had known drug-like properties.Ã¢â‚¬Â¢ AID687 is the result of a primary screen for coagulation factor XI from the Penn Center for Molecular Discovery and contains activity information of 33,067 compounds with a ratio of 1 active compound to 350 inactive compounds (0.28% minority). 30,353 of the compounds screened had known drug-like properties.Ã¢â‚¬Â¢ AID1608 is a different type of screening assay that was used to identify compounds that prevent HttQ103-induced cell death. National Institute of Neurological Disorders and Stroke Approved Drug Program. The compounds that prevent a release of a certain chemical into the growth medium are labelled as active and the remaining compounds are labelled as having inconclusive activity. AID1608 is a small dataset with 1,033 compounds and a ratio of 1 active to 14 inconclusive compounds (6.58% minority class).Ã¢â‚¬Â¢ AID644 confirmatory screen of AID604Ã¢â‚¬Â¢ AID1284 confirmatory screen of AID746Ã¢â‚¬Â¢ AID439 confirmatory screen of AID373Ã¢â‚¬Â¢ AID721 confirmatory screen of AID746",Life,"Each attribute has been fully described in the Open Access publication. The data is a mixture of boolean, integer and real values. Only 2 class - Active and Inactive. Highly Imbalanced.","These highly imbalanced bioassay datasets are from the differing types of screening that can be performed using HTS technology. 21 datasets were created from 12 bioassays.21 bioassay datasets generated from Pubchem. Both Primary and confirmatory bioassays (12 bioassays, 21 mixes)The data is provided in the same train/test split as the original paper. The compound IDs have been provided in separate files in case people wish to generate their own molecular representation. The order of the compound Ids is the same as the data files.Ã¢â‚¬Â¢ AID362 details the results of a primary screening bioassay for Formylpeptide Receptor Ligand Binding University from the New Mexico Center for Molecular Discovery. It is a relatively small dataset with 4279 compounds and with a ratio of 1 active to 70 inactive compounds (1.4% minority class). The compounds were selected on the basis of preliminary virtual screening of approximately 480,000 drug-like small molecules from Chemical Diversity Laboratories.Ã¢â‚¬Â¢ AID456 is a primary screen assay from the Burnham Center for Chemical Genomics for inhibition of TNFa induced VCAM-1 cell surface expression and consists of 9,982 compounds with a ratio of 1 active compound to 368 inactive compounds (0.27% minority). The compounds have been selected for their known drug-like properties and 9,431 meet the Rule of 5 [19].Ã¢â‚¬Â¢ AID688 is the result of a primary screen for Yeast eIF2B from the Penn Center for Molecular Discovery and contains activity information of 27,198 compounds with a ratio of 1 active compound to 108 inactive compounds (0.91% minority). The screen is a reporter-gene assay and 25,656 of the compounds have known drug-like properties.Ã¢â‚¬Â¢ AID604 is a primary screening bioassay for Rho kinase 2 inhibitors from the Scripps Research Institute Molecular Screening Center. The bioassay contains activity information of 59,788 compounds with a ratio of 1 active compound to 281 inactive compounds (1.4%). 57,546 of the compounds have known drug-like properties.Ã¢â‚¬Â¢ AID373 is a primary screen from the Scripps Research Institute Molecular Screening Center for endothelial differentiation, sphingolipid G-protein-coupled receptor, 3. 59,788 compounds were screened with a ratio of 1 active compound to 963 inactive compounds (0.1%). 57,546 of the compounds screened had known drug-like properties.Ã¢â‚¬Â¢ AID746 is a primary screen from the Scripps Research Institute Molecular Screening Center for Mitogen-activated protein kinase. 59,788 compounds were screened with a ratio of 1 active compound to 162 inactive compounds (0.61%). 57,546 of the compounds screened had known drug-like properties.Ã¢â‚¬Â¢ AID687 is the result of a primary screen for coagulation factor XI from the Penn Center for Molecular Discovery and contains activity information of 33,067 compounds with a ratio of 1 active compound to 350 inactive compounds (0.28% minority). 30,353 of the compounds screened had known drug-like properties.Ã¢â‚¬Â¢ AID1608 is a different type of screening assay that was used to identify compounds that prevent HttQ103-induced cell death. National Institute of Neurological Disorders and Stroke Approved Drug Program. The compounds that prevent a release of a certain chemical into the growth medium are labelled as active and the remaining compounds are labelled as having inconclusive activity. AID1608 is a small dataset with 1,033 compounds and a ratio of 1 active to 14 inconclusive compounds (6.58% minority class).Ã¢â‚¬Â¢ AID644 confirmatory screen of AID604Ã¢â‚¬Â¢ AID1284 confirmatory screen of AID746Ã¢â‚¬Â¢ AID439 confirmatory screen of AID373Ã¢â‚¬Â¢ AID721 confirmatory screen of AID746Each attribute has been fully described in the Open Access publication. The data is a mixture of boolean, integer and real values. Only 2 class - Active and Inactive. Highly Imbalanced."
One-hundred plant species leaves data set,One-hundred plant species leaves data set,"Sixteen samples of leaf each of one-hundred plant species. For each sample, a shape descriptor, fine scale margin and texture histogram are given.",One-hundred+plant+species+leaves+data+set,https://archive.ics.uci.edu/ml//machine-learning-databases/00241/,https://archive.ics.uci.edu/ml/datasets/One-hundred+plant+species+leaves+data+set,"For Each feature, a 64 element vector is given per sample of leaf. These vectors are taken as a contigous descriptors (for shape) or histograms (for texture and margin).",Life,"For Each feature, a 64 element vector is given per sample of leaf. One file for each 64-element feature vectors. Each row begins with the class label. The remaining 64 elements is the feature vector.","Sixteen samples of leaf each of one-hundred plant species. For each sample, a shape descriptor, fine scale margin and texture histogram are given.For Each feature, a 64 element vector is given per sample of leaf. These vectors are taken as a contigous descriptors (for shape) or histograms (for texture and margin).For Each feature, a 64 element vector is given per sample of leaf. One file for each 64-element feature vectors. Each row begins with the class label. The remaining 64 elements is the feature vector."
QSAR Bioconcentration classes dataset,QSAR Bioconcentration classes dataset,"Dataset of manually-curated Bioconcentration factor (BCF, fish) and mechanistic classes for QSAR modeling.",QSAR+Bioconcentration+classes+dataset,https://archive.ics.uci.edu/ml//machine-learning-databases/00510/,https://archive.ics.uci.edu/ml/datasets/QSAR+Bioconcentration+classes+dataset,"A dataset of manually-curated BCF for 779 chemicals was used to determine the mechanisms of bioconcentration, i.e. to predict whether a chemical: (1) is mainly stored within lipid tissues, (2) has additional storage sites (e.g. proteins), or (3) is metabolized/eliminated. Data were randomly split into a training set of 584 compounds (75%) and a test set of 195 compounds (25%), preserving the proportion between the classes. Two QSAR classification trees were developed using CART (Classification and Regression Trees) machine learning technique coupled with Genetic Algorithms. The file contains the selected Dragon descriptors (9) along with CAS, SMILES, experimental BCF, experimental/predicted KOW and mechanistic class (1, 2, 3). Further details on model development and performance along with descriptor definitions and interpretation are provided in the original manuscript (Grisoni et al., 2016).",Life,3 Compound identifiers:- CAS number- Molecular SMILES- Train/test splitting9 molecular descriptors (independent variables)- nHM- piPC09- PCD	- X2Av- MLOGP- ON1V- N-072	- B02[C-N]- F04[C-O]2 experimental responses:- Bioconcentration Factor (BCF) in log units (regression)- Bioaccumulation class (three classes),"Dataset of manually-curated Bioconcentration factor (BCF, fish) and mechanistic classes for QSAR modeling.A dataset of manually-curated BCF for 779 chemicals was used to determine the mechanisms of bioconcentration, i.e. to predict whether a chemical: (1) is mainly stored within lipid tissues, (2) has additional storage sites (e.g. proteins), or (3) is metabolized/eliminated. Data were randomly split into a training set of 584 compounds (75%) and a test set of 195 compounds (25%), preserving the proportion between the classes. Two QSAR classification trees were developed using CART (Classification and Regression Trees) machine learning technique coupled with Genetic Algorithms. The file contains the selected Dragon descriptors (9) along with CAS, SMILES, experimental BCF, experimental/predicted KOW and mechanistic class (1, 2, 3). Further details on model development and performance along with descriptor definitions and interpretation are provided in the original manuscript (Grisoni et al., 2016).3 Compound identifiers:- CAS number- Molecular SMILES- Train/test splitting9 molecular descriptors (independent variables)- nHM- piPC09- PCD	- X2Av- MLOGP- ON1V- N-072	- B02[C-N]- F04[C-O]2 experimental responses:- Bioconcentration Factor (BCF) in log units (regression)- Bioaccumulation class (three classes)"
Cervical Cancer Behavior Risk,Cervical Cancer Behavior Risk,"The dataset contains 19 attributes regarding ca cervix behavior risk with class label is ca_cervix with 1 and 0 as values which means the respondent with and without ca cervix, respectively.",Cervical+Cancer+Behavior+Risk,https://archive.ics.uci.edu/ml//machine-learning-databases/00537/,https://archive.ics.uci.edu/ml/datasets/Cervical+Cancer+Behavior+Risk,Provide all relevant information about your data set.,Life,"This dataset consist of 18 attribute (comes from 8 variables, the name of variables is the first word in each attribute)1) behavior_eating2) behavior_personalHygine3) intention_aggregation4) intention_commitment5) attitude_consistency6) attitude_spontaneity7) norm_significantPerson8) norm_fulfillment9) perception_vulnerability10) perception_severity11) motivation_strength12) motivation_willingness13) socialSupport_emotionality14) socialSupport_appreciation15) socialSupport_instrumental16) empowerment_knowledge17) empowerment_abilities18) empowerment_desires19) ca_cervix (this is class attribute, 1=has cervical cancer, 0=no cervical cancer)","The dataset contains 19 attributes regarding ca cervix behavior risk with class label is ca_cervix with 1 and 0 as values which means the respondent with and without ca cervix, respectively.Provide all relevant information about your data set.This dataset consist of 18 attribute (comes from 8 variables, the name of variables is the first word in each attribute)1) behavior_eating2) behavior_personalHygine3) intention_aggregation4) intention_commitment5) attitude_consistency6) attitude_spontaneity7) norm_significantPerson8) norm_fulfillment9) perception_vulnerability10) perception_severity11) motivation_strength12) motivation_willingness13) socialSupport_emotionality14) socialSupport_appreciation15) socialSupport_instrumental16) empowerment_knowledge17) empowerment_abilities18) empowerment_desires19) ca_cervix (this is class attribute, 1=has cervical cancer, 0=no cervical cancer)"
9mers from cullpdb,9mers from cullpdb,Provide a short description of your data set (less than 200 characters).,9mers+from+cullpdb,https://archive.ics.uci.edu/ml//machine-learning-databases/00609/,https://archive.ics.uci.edu/ml/datasets/9mers+from+cullpdb,"The dataset consists of protein fragments of length nine, called 9mers, derived from  3,733 proteins selected by cullpdb [1]. All proteins have 1) resolution less than 1.6 Ãƒâ€¦ngstrÃƒÂ¶m, 2) R-factor less than 0.25, 3) sequence identity below 20%. In addition, all proteins with identity above 20% to CASP13 targets are removed. All torsion angle-pairs are in the allowed region of the Ramachandran plot (fragments containing outliers were detected by the Ramalyze function of the crystallography software PHENIX [1] and removed). The dataset has Ã¢Ë†Â¼158,000 entries randomly split into train, test, and validation sets with a 60/20/20 split.References:  [1] Wang, G., & Dunbrack, R. L. (2005). PISCES: recent improvements to a PDB sequence culling server. Nucleic acids research, 33(suppl_2), W94-W98.  [2] Liebschner, D., Afonine, P. V., Baker, M. L., BunkÃƒÂ³czi, G., Chen, V. B., Croll, T. I., ... & Adams, P. D. (2019). Macromolecular structure determination using X-rays, neutrons, and electrons: recent developments in Phenix. Acta Crystallographica Section D: Structural Biology, 75(10), 861-877.",Life,"secondary_structure: 9 secondary structure labelsangle1: 9 phi torsion angles ([-pi,pi))angle2: 9 psi torsion angles ([-pi,pi))amino_acids: 9 amino acid labelsMap from aa to index in aa_to_index.csv.Map from secondary structure label to index in secondary_structure_to_index.csv.","Provide a short description of your data set (less than 200 characters).The dataset consists of protein fragments of length nine, called 9mers, derived from  3,733 proteins selected by cullpdb [1]. All proteins have 1) resolution less than 1.6 Ãƒâ€¦ngstrÃƒÂ¶m, 2) R-factor less than 0.25, 3) sequence identity below 20%. In addition, all proteins with identity above 20% to CASP13 targets are removed. All torsion angle-pairs are in the allowed region of the Ramachandran plot (fragments containing outliers were detected by the Ramalyze function of the crystallography software PHENIX [1] and removed). The dataset has Ã¢Ë†Â¼158,000 entries randomly split into train, test, and validation sets with a 60/20/20 split.References:  [1] Wang, G., & Dunbrack, R. L. (2005). PISCES: recent improvements to a PDB sequence culling server. Nucleic acids research, 33(suppl_2), W94-W98.  [2] Liebschner, D., Afonine, P. V., Baker, M. L., BunkÃƒÂ³czi, G., Chen, V. B., Croll, T. I., ... & Adams, P. D. (2019). Macromolecular structure determination using X-rays, neutrons, and electrons: recent developments in Phenix. Acta Crystallographica Section D: Structural Biology, 75(10), 861-877.secondary_structure: 9 secondary structure labelsangle1: 9 phi torsion angles ([-pi,pi))angle2: 9 psi torsion angles ([-pi,pi))amino_acids: 9 amino acid labelsMap from aa to index in aa_to_index.csv.Map from secondary structure label to index in secondary_structure_to_index.csv."
Plants,Plants,Data has been extracted from the USDA plants database. It contains all plants (species and genera) in the database and the states of USA and Canada where they occur.,Plants,https://archive.ics.uci.edu/ml//machine-learning-databases/plants/,https://archive.ics.uci.edu/ml/datasets/Plants,The data is in the transactional form. It contains the Latin names (species or genus) and state abbreviations. ,Life,Each row contains a Latin name (species or genus) and a list of state abbreviations. ,Data has been extracted from the USDA plants database. It contains all plants (species and genera) in the database and the states of USA and Canada where they occur.The data is in the transactional form. It contains the Latin names (species or genus) and state abbreviations. Each row contains a Latin name (species or genus) and a list of state abbreviations. 
Activity recognition using wearable physiological measurements,Activity recognition using wearable physiological measurements,"This dataset contains features from Electrocardiogram (ECG), Thoracic Electrical Bioimpedance (TEB) and the Electrodermal Activity (EDA) for activity recognition.",Activity+recognition+using+wearable+physiological+measurements,https://archive.ics.uci.edu/ml//machine-learning-databases/00552/,https://archive.ics.uci.edu/ml/datasets/Activity+recognition+using+wearable+physiological+measurements,"In order to elicit the different activities, we have used a segment documentary called 'Earth' to induce Neutral Activity. In order to elicit emotional activity, we used a set of segments extracted from several validated movies. Ã¢â‚¬Å“American History X' (1998) by Savoy Pictures, Ã¢â‚¬Å“I am legend' (2007) by Warner Bross, 'Life is beautiful' (1997) by Miramax, and Ã¢â‚¬Å“Cannibal Holocaust' (1980) by F.D. Cinematografica. The mental activity was elicited using a set of games based on mental arithmetic and playing the well-known game Ã¢â‚¬Å“Tetris', used several times to elicit mental activity.The designed activity recognition system had to take a decision every 10 s, and each individual generated 28 time slots of each activity (the database is balanced). Thus, the total number of patterns (decisions) for this analysis was 4480, and each class is composed of 1120 different patterns.In the present analysis, we have used four different activities:-Neutral activity, registered during the last 140 s of the first movie (the documentary). As each individual watched each movie twice, there are 280 s for each individual in the database-Emotional activity, registered during the viewing of the last 70 s of the second and third movies (140 s); therefore, we obtained a total of 280 s per individual.-Mental activity, registered during the last 140 s of both games, producing 280 s in total.-Physical activity registered during the last 280 s of the physical activity stage. To elicit physical load the participant had to go up and down the stairs for five minutes.Each attributed was determined using a 40 s window. Measurements were collected from 40 subjects.",Life,"The first column correspond to the index of the subject. The next 174 attributes are statistics extracted from the ECG signal. The next 151 attributes are features extracted from the TEB signal. The next 104 attributes come from the EDA measured in the arm, and the next 104 ones from the EDA in the hand. The last attribute is the pattern class, that is, the corresponding activity: 1-neutral, 2-emotional, 3-mental and 4-physical. ","This dataset contains features from Electrocardiogram (ECG), Thoracic Electrical Bioimpedance (TEB) and the Electrodermal Activity (EDA) for activity recognition.In order to elicit the different activities, we have used a segment documentary called 'Earth' to induce Neutral Activity. In order to elicit emotional activity, we used a set of segments extracted from several validated movies. Ã¢â‚¬Å“American History X' (1998) by Savoy Pictures, Ã¢â‚¬Å“I am legend' (2007) by Warner Bross, 'Life is beautiful' (1997) by Miramax, and Ã¢â‚¬Å“Cannibal Holocaust' (1980) by F.D. Cinematografica. The mental activity was elicited using a set of games based on mental arithmetic and playing the well-known game Ã¢â‚¬Å“Tetris', used several times to elicit mental activity.The designed activity recognition system had to take a decision every 10 s, and each individual generated 28 time slots of each activity (the database is balanced). Thus, the total number of patterns (decisions) for this analysis was 4480, and each class is composed of 1120 different patterns.In the present analysis, we have used four different activities:-Neutral activity, registered during the last 140 s of the first movie (the documentary). As each individual watched each movie twice, there are 280 s for each individual in the database-Emotional activity, registered during the viewing of the last 70 s of the second and third movies (140 s); therefore, we obtained a total of 280 s per individual.-Mental activity, registered during the last 140 s of both games, producing 280 s in total.-Physical activity registered during the last 280 s of the physical activity stage. To elicit physical load the participant had to go up and down the stairs for five minutes.Each attributed was determined using a 40 s window. Measurements were collected from 40 subjects.The first column correspond to the index of the subject. The next 174 attributes are statistics extracted from the ECG signal. The next 151 attributes are features extracted from the TEB signal. The next 104 attributes come from the EDA measured in the arm, and the next 104 ones from the EDA in the hand. The last attribute is the pattern class, that is, the corresponding activity: 1-neutral, 2-emotional, 3-mental and 4-physical. "
p53 Mutants,p53 Mutants,"The goal is to model mutant p53 transcriptional activity (active vs inactive) based on data extracted from biophysical simulations.
",p53+Mutants,https://archive.ics.uci.edu/ml//machine-learning-databases/p53/,https://archive.ics.uci.edu/ml/datasets/p53+Mutants,"Biophysical models of mutant p53 proteins yield features which can be used to predict p53 transcriptional activity.  All class labels are determined via in vivo assays.K8.data - full dataset, 'K8'The following files are provided in order to reconstruct this historical subsets of this data set:K8.instance.tags - provides the precise p53 mutant tag for each instance in the K8.data, for use with the historical definition files:K1.def - defines instances in the 'K1' set.K2.def - defines instances in the 'K2' set.K3.def - defines instances in the 'K3' set.K4.def - defines instances in the 'K4' set.K5.def - defines instances in the 'K5' set.K6.def - defines instances in the 'K6' set.K7.def - defines instances in the 'K7' set.K8.def - defines instances in the 'K8' (full) set.",Life,"There are a total of 5409 attributes per instance.  Attributes 1-4826 represent 2D electrostatic and surface based features.Attributes 4827-5408 represent 3D distance based features.Attribute 5409 is the class attribute, which is either active or inactive. The class labels are to be interpreted as follows: 'active' represents transcriptonally competent, active p53 whereas the 'inactive' label represents cancerous, inactive p53.  Class labels are determined experimentally.More information is provided in the relevant papers cited.","The goal is to model mutant p53 transcriptional activity (active vs inactive) based on data extracted from biophysical simulations.
Biophysical models of mutant p53 proteins yield features which can be used to predict p53 transcriptional activity.  All class labels are determined via in vivo assays.K8.data - full dataset, 'K8'The following files are provided in order to reconstruct this historical subsets of this data set:K8.instance.tags - provides the precise p53 mutant tag for each instance in the K8.data, for use with the historical definition files:K1.def - defines instances in the 'K1' set.K2.def - defines instances in the 'K2' set.K3.def - defines instances in the 'K3' set.K4.def - defines instances in the 'K4' set.K5.def - defines instances in the 'K5' set.K6.def - defines instances in the 'K6' set.K7.def - defines instances in the 'K7' set.K8.def - defines instances in the 'K8' (full) set.There are a total of 5409 attributes per instance.  Attributes 1-4826 represent 2D electrostatic and surface based features.Attributes 4827-5408 represent 3D distance based features.Attribute 5409 is the class attribute, which is either active or inactive. The class labels are to be interpreted as follows: 'active' represents transcriptonally competent, active p53 whereas the 'inactive' label represents cancerous, inactive p53.  Class labels are determined experimentally.More information is provided in the relevant papers cited."
Fertility,Fertility,"100 volunteers provide a semen sample analyzed according to the WHO 2010 criteria. Sperm concentration are related to socio-demographic data, environmental factors, health status, and life habits",Fertility,https://archive.ics.uci.edu/ml//machine-learning-databases/00244/,https://archive.ics.uci.edu/ml/datasets/Fertility,Provide all relevant information about your data set.,Life,"Season in which the analysis was performed. 	1) winter, 2) spring, 3) Summer, 4) fall. 	(-1, -0.33, 0.33, 1) Age at the time of analysis. 	18-36 	(0, 1) Childish diseases (ie , chicken pox, measles, mumps, polio)	1) yes, 2) no. 	(0, 1) Accident or serious trauma 	1) yes, 2) no. 	(0, 1) Surgical intervention 	1) yes, 2) no. 	(0, 1) High fevers in the last year 	1) less than three months ago, 2) more than three months ago, 3) no. 	(-1, 0, 1) Frequency of alcohol consumption 	1) several times a day, 2) every day, 3) several times a week, 4) once a week, 5) hardly ever or never 	(0, 1) Smoking habit 	1) never, 2) occasional 3) daily. 	(-1, 0, 1) Number of hours spent sitting per day 	ene-16	(0, 1) Output: Diagnosis	normal (N), altered (O)	","100 volunteers provide a semen sample analyzed according to the WHO 2010 criteria. Sperm concentration are related to socio-demographic data, environmental factors, health status, and life habitsProvide all relevant information about your data set.Season in which the analysis was performed. 	1) winter, 2) spring, 3) Summer, 4) fall. 	(-1, -0.33, 0.33, 1) Age at the time of analysis. 	18-36 	(0, 1) Childish diseases (ie , chicken pox, measles, mumps, polio)	1) yes, 2) no. 	(0, 1) Accident or serious trauma 	1) yes, 2) no. 	(0, 1) Surgical intervention 	1) yes, 2) no. 	(0, 1) High fevers in the last year 	1) less than three months ago, 2) more than three months ago, 3) no. 	(-1, 0, 1) Frequency of alcohol consumption 	1) several times a day, 2) every day, 3) several times a week, 4) once a week, 5) hardly ever or never 	(0, 1) Smoking habit 	1) never, 2) occasional 3) daily. 	(-1, 0, 1) Number of hours spent sitting per day 	ene-16	(0, 1) Output: Diagnosis	normal (N), altered (O)	"
Physicochemical Properties of Protein Tertiary Structure,Physicochemical Properties of Protein Tertiary Structure,This is a data set of Physicochemical Properties of Protein Tertiary Structure. The data set is taken from CASP 5-9. There are 45730 decoys and size varying from 0 to 21 armstrong.,Physicochemical+Properties+of+Protein+Tertiary+Structure,https://archive.ics.uci.edu/ml//machine-learning-databases/00265/,https://archive.ics.uci.edu/ml/datasets/Physicochemical+Properties+of+Protein+Tertiary+Structure,Provide all relevant information about your data set.,Life,"RMSD-Size of the residue.F1 - Total surface area.F2 - Non polar exposed area.F3 - Fractional area of exposed non polar residue.F4 - Fractional area of exposed non polar part of residue.F5 - Molecular mass weighted exposed area.F6 - Average deviation from standard exposed area of residue.F7 - Euclidian distance.F8 - Secondary structure penalty.F9 - Spacial Distribution constraints (N,K Value).","This is a data set of Physicochemical Properties of Protein Tertiary Structure. The data set is taken from CASP 5-9. There are 45730 decoys and size varying from 0 to 21 armstrong.Provide all relevant information about your data set.RMSD-Size of the residue.F1 - Total surface area.F2 - Non polar exposed area.F3 - Fractional area of exposed non polar residue.F4 - Fractional area of exposed non polar part of residue.F5 - Molecular mass weighted exposed area.F6 - Average deviation from standard exposed area of residue.F7 - Euclidian distance.F8 - Secondary structure penalty.F9 - Spacial Distribution constraints (N,K Value)."
Codon usage,Codon usage,DNA codon usage frequencies of a large sample of diverse biological organisms from different taxa,Codon+usage,https://archive.ics.uci.edu/ml//machine-learning-databases/00577/,https://archive.ics.uci.edu/ml/datasets/Codon+usage,"We examined codon usage frequencies in the genomic coding DNA of a large sample of diverse organisms from different taxa tabulated in the CUTG database, where we further manually curated and harmonized these existing entries by re-classifying CUTG's bacteria (bct) class into archaea (arc), plasmids (plm), and bacteria proper (keeping with the original label `bct').  The reclassification in the original `bct' domain was simplified by extracting from files `qbxxx.spsum.txt' (where xxx = bct (bacteria), inv (invertebrates), mam (mammals), pln (plants), pri (primates), rod (rodents), vrt (vertebrates)) the different genus names of the entries, and making the classification by genus. There were 514 different genus names.  The different genus categories were checked and relabeled as `arc' where appropriate. In the eubacterial entries, the distinction was made of the bacterial genomes proper (keeping with the original label `bct'), and bacterial plasmids (now labeled `plm').  Following these preprocessing steps, the final dataset file comprises all entries of the CUTG databases qbxxx.spsum.txt in one text file. As detailed above, the qbbct.spsum.txt entries were separated as `bct' (that is, eubacteria), `plm' (plasmids), and `arc' (archaea), a distinction not originally made in the CUTG database.",Life,"Column 1: KingdomColumn 2: DNAtypeColumn 3: SpeciesIDColumn 4: NcodonsColumn 5: SpeciesNameColumns 6-69: codon (header: nucleotide bases; entries: frequency of usage (5 digit floating point number))The 'Kingdom' is a 3-letter code corresponding to `xxx' in the CUTG database name: 'arc'(archaea), 'bct'(bacteria), 'phg'(bacteriophage), 'plm' (plasmid), 'pln' (plant), 'inv' (invertebrate), 'vrt' (vertebrate), 'mam' (mammal), 'rod' (rodent), 'pri' (primate), and 'vrl'(virus) sequence entries.  Note that the CUTG database does not contain 'arc' and 'plm' (these have been manually curated ourselves). The 'DNAtype' is denoted as an integer for the genomic composition in the species: 0-genomic, 1-mitochondrial, 2-chloroplast, 3-cyanelle, 4-plastid, 5-nucleomorph, 6-secondary_endosymbiont, 7-chromoplast, 8-leucoplast, 9-NA, 10-proplastid, 11-apicoplast, and 12-kinetoplast.The species identifier ('SpeciesID') is an integer, which uniquely indicates the entries of an organism. It is an accession identifier for each different species in the original CUTG database, followed by the first item listed in each genome. The number of codons (`Ncodons') is the algebraic sum of the numbers listed for the different codons in an entry of CUTG. Codon frequencies are normalized to the total codon count, hence the number of occurrences divided by 'Ncodons' is the codon frequencies listed in the data file. The species' name ('SpeciesName') is represented in strings purged of `comma' (which are now replaced by `space'). This is a descriptive label of the name of the species for data interpretations. Lastly, the codon frequencies ('codon') including 'UUU', 'UUA', 'UUG', 'CUU', etc., are recorded as floats (with decimals in 5 digits).","DNA codon usage frequencies of a large sample of diverse biological organisms from different taxaWe examined codon usage frequencies in the genomic coding DNA of a large sample of diverse organisms from different taxa tabulated in the CUTG database, where we further manually curated and harmonized these existing entries by re-classifying CUTG's bacteria (bct) class into archaea (arc), plasmids (plm), and bacteria proper (keeping with the original label `bct').  The reclassification in the original `bct' domain was simplified by extracting from files `qbxxx.spsum.txt' (where xxx = bct (bacteria), inv (invertebrates), mam (mammals), pln (plants), pri (primates), rod (rodents), vrt (vertebrates)) the different genus names of the entries, and making the classification by genus. There were 514 different genus names.  The different genus categories were checked and relabeled as `arc' where appropriate. In the eubacterial entries, the distinction was made of the bacterial genomes proper (keeping with the original label `bct'), and bacterial plasmids (now labeled `plm').  Following these preprocessing steps, the final dataset file comprises all entries of the CUTG databases qbxxx.spsum.txt in one text file. As detailed above, the qbbct.spsum.txt entries were separated as `bct' (that is, eubacteria), `plm' (plasmids), and `arc' (archaea), a distinction not originally made in the CUTG database.Column 1: KingdomColumn 2: DNAtypeColumn 3: SpeciesIDColumn 4: NcodonsColumn 5: SpeciesNameColumns 6-69: codon (header: nucleotide bases; entries: frequency of usage (5 digit floating point number))The 'Kingdom' is a 3-letter code corresponding to `xxx' in the CUTG database name: 'arc'(archaea), 'bct'(bacteria), 'phg'(bacteriophage), 'plm' (plasmid), 'pln' (plant), 'inv' (invertebrate), 'vrt' (vertebrate), 'mam' (mammal), 'rod' (rodent), 'pri' (primate), and 'vrl'(virus) sequence entries.  Note that the CUTG database does not contain 'arc' and 'plm' (these have been manually curated ourselves). The 'DNAtype' is denoted as an integer for the genomic composition in the species: 0-genomic, 1-mitochondrial, 2-chloroplast, 3-cyanelle, 4-plastid, 5-nucleomorph, 6-secondary_endosymbiont, 7-chromoplast, 8-leucoplast, 9-NA, 10-proplastid, 11-apicoplast, and 12-kinetoplast.The species identifier ('SpeciesID') is an integer, which uniquely indicates the entries of an organism. It is an accession identifier for each different species in the original CUTG database, followed by the first item listed in each genome. The number of codons (`Ncodons') is the algebraic sum of the numbers listed for the different codons in an entry of CUTG. Codon frequencies are normalized to the total codon count, hence the number of occurrences divided by 'Ncodons' is the codon frequencies listed in the data file. The species' name ('SpeciesName') is represented in strings purged of `comma' (which are now replaced by `space'). This is a descriptive label of the name of the species for data interpretations. Lastly, the codon frequencies ('codon') including 'UUU', 'UUA', 'UUG', 'CUU', etc., are recorded as floats (with decimals in 5 digits)."
Wilt,Wilt,"High-resolution Remote Sensing data set (Quickbird). Small number of training samples of diseased trees, large number for other land cover. Testing data set from stratified random sample of image.",Wilt,https://archive.ics.uci.edu/ml//machine-learning-databases/00285/,https://archive.ics.uci.edu/ml/datasets/Wilt,"This data set contains some training and testing data from a remote sensing study by Johnson et al. (2013) that involved detecting diseased trees in Quickbird imagery. There are few training samples for the 'diseased trees' class (74) and many for 'other land cover' class (4265). The data set consists of image segments, generated by segmenting the pansharpened image. The segments contain spectral information from the Quickbird multispectral image bands and texture information from the panchromatic (Pan) image band. The testing data set is for the row with Ã¢â‚¬Å“Segmentation scale 15Ã¢â‚¬Â� segments and Ã¢â‚¬Å“original multi-spectral imageÃ¢â‚¬Â� Spectral information in Table 2 of the reference (i.e. row 5). Please see the reference below for more information on the data set, and please cite the reference if you use this data set. Enjoy!Filestraining.csv: training data set (4339 image segments)testing.csv: testing data set (500 image segments)",Life,"class: 'w' (diseased trees), 'n' (all other land cover)GLCM_Pan: GLCM mean texture (Pan band)Mean_G: Mean green valueMean_R: Mean red valueMean_NIR: Mean NIR valueSD_Pan: Standard deviation (Pan band)","High-resolution Remote Sensing data set (Quickbird). Small number of training samples of diseased trees, large number for other land cover. Testing data set from stratified random sample of image.This data set contains some training and testing data from a remote sensing study by Johnson et al. (2013) that involved detecting diseased trees in Quickbird imagery. There are few training samples for the 'diseased trees' class (74) and many for 'other land cover' class (4265). The data set consists of image segments, generated by segmenting the pansharpened image. The segments contain spectral information from the Quickbird multispectral image bands and texture information from the panchromatic (Pan) image band. The testing data set is for the row with Ã¢â‚¬Å“Segmentation scale 15Ã¢â‚¬Â� segments and Ã¢â‚¬Å“original multi-spectral imageÃ¢â‚¬Â� Spectral information in Table 2 of the reference (i.e. row 5). Please see the reference below for more information on the data set, and please cite the reference if you use this data set. Enjoy!Filestraining.csv: training data set (4339 image segments)testing.csv: testing data set (500 image segments)class: 'w' (diseased trees), 'n' (all other land cover)GLCM_Pan: GLCM mean texture (Pan band)Mean_G: Mean green valueMean_R: Mean red valueMean_NIR: Mean NIR valueSD_Pan: Standard deviation (Pan band)"
PANDOR,PANDOR,PANDOR is a novel and publicly available dataset for online recommendation provided by Purch (http://www.purch.com/). ,PANDOR,https://archive.ics.uci.edu/ml//machine-learning-databases/00460/,https://archive.ics.uci.edu/ml/datasets/PANDOR,"source, offerId, pageViewId, offerViewId, utcDate, keywords, wasClicked, offerViewCountPerPageView, clickCountPerPageView, userId, productLemmas, productFeatures, url, pageLemmas, pageFeatures# Events: 48,602,664# Users: 5,894,431# Offers: 14,716# Clicks: 337,511# OffersShown: 48,754,927# Max offers shown to 1 user: 2,029# Max clicks done by 1 user: 119Average # Offers Shown to 1 user: 8.271Average # Clicks done by 1 user: 0.057Average # Clicks done by 1 user (if user did at least 1 click): 1.350616661464461 # Events where user did at least 1 click: 4,544,848# Events which have at least 1 page text words: 1,212,170# Events which have at least 1 product Text words: 450,050# Events which have at least 1 keyword: 4,492,544 page text vocabulary size: 9,111product text vocabulary size: 6,016keyword vocabulary size: 543 Out of 9,847 offers, 2,701 offers have at least 1 text word (27.4%)Out of 7,092 pages, 1,990 pages have at least 1 text word (28.1%)",Life,Provide information about each attribute in your data set.,"PANDOR is a novel and publicly available dataset for online recommendation provided by Purch (http://www.purch.com/). source, offerId, pageViewId, offerViewId, utcDate, keywords, wasClicked, offerViewCountPerPageView, clickCountPerPageView, userId, productLemmas, productFeatures, url, pageLemmas, pageFeatures# Events: 48,602,664# Users: 5,894,431# Offers: 14,716# Clicks: 337,511# OffersShown: 48,754,927# Max offers shown to 1 user: 2,029# Max clicks done by 1 user: 119Average # Offers Shown to 1 user: 8.271Average # Clicks done by 1 user: 0.057Average # Clicks done by 1 user (if user did at least 1 click): 1.350616661464461 # Events where user did at least 1 click: 4,544,848# Events which have at least 1 page text words: 1,212,170# Events which have at least 1 product Text words: 450,050# Events which have at least 1 keyword: 4,492,544 page text vocabulary size: 9,111product text vocabulary size: 6,016keyword vocabulary size: 543 Out of 9,847 offers, 2,701 offers have at least 1 text word (27.4%)Out of 7,092 pages, 1,990 pages have at least 1 text word (28.1%)Provide information about each attribute in your data set."
Abalone,Abalone,Predict the age of abalone from physical measurements,Abalone,https://archive.ics.uci.edu/ml//machine-learning-databases/abalone/,https://archive.ics.uci.edu/ml/datasets/Abalone,"Predicting the age of abalone from physical measurements.  The age of abalone is determined by cutting the shell through the cone, staining it, and counting the number of rings through a microscope -- a boring and time-consuming task.  Other measurements, which are easier to obtain, are used to predict the age.  Further information, such as weather patterns and location (hence food availability) may be required to solve the problem.From the original data examples with missing values were removed (the majority having the predicted value missing), and the ranges of the continuous values have been scaled for use with an ANN (by dividing by 200).",Life,"Given is the attribute name, attribute type, the measurement unit and a brief description.  The number of rings is the value to predict: either as a continuous value or as a classification problem.Name / Data Type / Measurement Unit / Description-----------------------------Sex / nominal / -- / M, F, and I (infant)Length / continuous / mm / Longest shell measurementDiameter	/ continuous / mm / perpendicular to lengthHeight / continuous / mm / with meat in shellWhole weight / continuous / grams / whole abaloneShucked weight / continuous	 / grams / weight of meatViscera weight / continuous / grams / gut weight (after bleeding)Shell weight / continuous / grams / after being driedRings / integer / -- / +1.5 gives the age in yearsThe readme file contains attribute statistics.","Predict the age of abalone from physical measurementsPredicting the age of abalone from physical measurements.  The age of abalone is determined by cutting the shell through the cone, staining it, and counting the number of rings through a microscope -- a boring and time-consuming task.  Other measurements, which are easier to obtain, are used to predict the age.  Further information, such as weather patterns and location (hence food availability) may be required to solve the problem.From the original data examples with missing values were removed (the majority having the predicted value missing), and the ranges of the continuous values have been scaled for use with an ANN (by dividing by 200).Given is the attribute name, attribute type, the measurement unit and a brief description.  The number of rings is the value to predict: either as a continuous value or as a classification problem.Name / Data Type / Measurement Unit / Description-----------------------------Sex / nominal / -- / M, F, and I (infant)Length / continuous / mm / Longest shell measurementDiameter	/ continuous / mm / perpendicular to lengthHeight / continuous / mm / with meat in shellWhole weight / continuous / grams / whole abaloneShucked weight / continuous	 / grams / weight of meatViscera weight / continuous / grams / gut weight (after bleeding)Shell weight / continuous / grams / after being driedRings / integer / -- / +1.5 gives the age in yearsThe readme file contains attribute statistics."
Parkinson Dataset with replicated acoustic features ,Parkinson Dataset with replicated acoustic features ,Contains acoustic features extracted from 3 voice recording  replications of the sustained /a/ phonation for each one of the 80 subjects (40 of them with Parkinson's Disease).,Parkinson+Dataset+with+replicated+acoustic+features+,https://archive.ics.uci.edu/ml//machine-learning-databases/00489/,https://archive.ics.uci.edu/ml/datasets/Parkinson+Dataset+with+replicated+acoustic+features+,"Important remarks before using this dataset: 1. Each row can not be used independently, because is one of the three replications of one individual. Nature of data is dependent    for each subject, but independent from one to another subject. So, traditional technique from machine learning can not be applied to this dataset, because those techniques are based on the independent nature of the instances. There are 240 instances but for only 80 subjects, so they are not independent. Techniques as those presented in Naranjo et al. (2016), Naranjo et al. (2017) or other specifically designed can be used. 2. The concept of replication considered here does not match the classical concept of statistical repeated measurements. The term 'replications' refers to the collection of features extracted from voice recordings belonging to the same subject. Since, in this context, features are extracted from multiple consecutive voice recordings from the same subject, in principle, the features should be identical. The imperfections in technology and the own biological variability result in non-identical replicated features that are more similar to one another than features from different subjects. 3. All information about how the dataset was generated is presented in Naranjo et al. (2016). ",Life,"1. ID: Subjects's identifier. 2. Recording: Number of the recording.3. Status: 0=Healthy; 1=PD4. Gender: 0=Man; 1=Woman  5. Pitch local perturbation measures: relative jitter (Jitter_rel), absolute jitter (Jitter_abs), relative average perturbation (Jitter_RAP), and pitch perturbation quotient (Jitter_PPQ).6. Amplitude perturbation measures: local shimmer (Shim_loc), shimmer in dB (Shim_dB), 3-point amplitude perturbation quotient (Shim_APQ3), 5-point amplitude perturbation quotient (Shim_APQ5), and 11-point amplitude perturbation quotient (Shim_APQ11).7. Harmonic-to-noise ratio measures: harmonic-to-noise ratio in the frequency band 0-500 Hz (HNR05), in 0-1500 Hz (HNR15), in 0-2500 Hz (HNR25), in 0-3500 Hz (HNR35), and in 0-3800 Hz (HNR38).8. Mel frequency cepstral coefficient-based spectral measures of order 0 to 12 (MFCC0, MFCC1,..., MFCC12) and their derivatives (Delta0, Delta1,..., Delta12).9. Recurrence period density entropy (RPDE).10. Detrended fluctuation analysis (DFA).11. Pitch period entropy (PPE).12. Glottal-to-noise excitation ratio (GNE).","Contains acoustic features extracted from 3 voice recording  replications of the sustained /a/ phonation for each one of the 80 subjects (40 of them with Parkinson's Disease).Important remarks before using this dataset: 1. Each row can not be used independently, because is one of the three replications of one individual. Nature of data is dependent    for each subject, but independent from one to another subject. So, traditional technique from machine learning can not be applied to this dataset, because those techniques are based on the independent nature of the instances. There are 240 instances but for only 80 subjects, so they are not independent. Techniques as those presented in Naranjo et al. (2016), Naranjo et al. (2017) or other specifically designed can be used. 2. The concept of replication considered here does not match the classical concept of statistical repeated measurements. The term 'replications' refers to the collection of features extracted from voice recordings belonging to the same subject. Since, in this context, features are extracted from multiple consecutive voice recordings from the same subject, in principle, the features should be identical. The imperfections in technology and the own biological variability result in non-identical replicated features that are more similar to one another than features from different subjects. 3. All information about how the dataset was generated is presented in Naranjo et al. (2016). 1. ID: Subjects's identifier. 2. Recording: Number of the recording.3. Status: 0=Healthy; 1=PD4. Gender: 0=Man; 1=Woman  5. Pitch local perturbation measures: relative jitter (Jitter_rel), absolute jitter (Jitter_abs), relative average perturbation (Jitter_RAP), and pitch perturbation quotient (Jitter_PPQ).6. Amplitude perturbation measures: local shimmer (Shim_loc), shimmer in dB (Shim_dB), 3-point amplitude perturbation quotient (Shim_APQ3), 5-point amplitude perturbation quotient (Shim_APQ5), and 11-point amplitude perturbation quotient (Shim_APQ11).7. Harmonic-to-noise ratio measures: harmonic-to-noise ratio in the frequency band 0-500 Hz (HNR05), in 0-1500 Hz (HNR15), in 0-2500 Hz (HNR25), in 0-3500 Hz (HNR35), and in 0-3800 Hz (HNR38).8. Mel frequency cepstral coefficient-based spectral measures of order 0 to 12 (MFCC0, MFCC1,..., MFCC12) and their derivatives (Delta0, Delta1,..., Delta12).9. Recurrence period density entropy (RPDE).10. Detrended fluctuation analysis (DFA).11. Pitch period entropy (PPE).12. Glottal-to-noise excitation ratio (GNE)."
Abscisic Acid Signaling Network,Abscisic Acid Signaling Network,The objective is to determine the set of boolean rules that describe the interactions of the nodes within this plant signaling network.  The dataset includes 300 separate boolean pseudodynamic simulations using an asynchronous update scheme. ,Abscisic+Acid+Signaling+Network,https://archive.ics.uci.edu/ml//machine-learning-databases/abscisic-acid/,https://archive.ics.uci.edu/ml/datasets/Abscisic+Acid+Signaling+Network,"The objective is to determine the set of boolean rules that describe the interactions of the nodes within this plant signaling network. The dataset includes 300 separate boolean pseudodynamic simulations of the true rules, using an asynchronous update scheme. Each of the 300 simulations begin with a randomly generated initial condition, in order to ensure sampling of all of the steady states of the system.  There are a total of 43 nodes in this dataset, with 5 ndoes being constants.The results for 300 separate simulations are included in the dataset.  Each simulation consists of a matrix of 0's and 1's, with 21 rows and 43 columns.  The first row is the randomly generated initial condition for the particular simulation, with the next 20 rows being the output from the boolean pseudodynamics simulation.  Each of the 43 columns represent the transient response of a particular node.  The nodal names are identified at the top of the data file.  A line of asterisks is used to separate the simulations from one another.  An example set of data is included below:***************************101110111010110110110100101000101100001100111000011101111011011011111110110010111010111100011110111110101101100011010001110101010110000111011111010110110001100001111010101011000011101111101011011000110000111101010101100001110111110101101100011000011110101010110000111011111010110110001100001111010101011000011101111101011011000110000111101010101100001110111110101101100011000011110101010110000111011111010110110001100001111010101011000011101111101011011000110000111101010101100001110111110101101100011000011110101010110000111011111010110110001100001111010101011000011101111101011011000110000111101010101100001110111110101101100011000011110101010110000111011111010110110001100001111010101011000011101111101011011000110000111101010101100001110111110101101100011000011110101010110000111011111010110110001100001111010101011000011101111101011011000110000111101010101100001110111110101101100011000011110101010",Life,"Each node can have a value of 0 or 1.  38 of the 43 nodes are allowed to vary, with 5 nodes held constant throughout the simulation.","The objective is to determine the set of boolean rules that describe the interactions of the nodes within this plant signaling network.  The dataset includes 300 separate boolean pseudodynamic simulations using an asynchronous update scheme. The objective is to determine the set of boolean rules that describe the interactions of the nodes within this plant signaling network. The dataset includes 300 separate boolean pseudodynamic simulations of the true rules, using an asynchronous update scheme. Each of the 300 simulations begin with a randomly generated initial condition, in order to ensure sampling of all of the steady states of the system.  There are a total of 43 nodes in this dataset, with 5 ndoes being constants.The results for 300 separate simulations are included in the dataset.  Each simulation consists of a matrix of 0's and 1's, with 21 rows and 43 columns.  The first row is the randomly generated initial condition for the particular simulation, with the next 20 rows being the output from the boolean pseudodynamics simulation.  Each of the 43 columns represent the transient response of a particular node.  The nodal names are identified at the top of the data file.  A line of asterisks is used to separate the simulations from one another.  An example set of data is included below:***************************101110111010110110110100101000101100001100111000011101111011011011111110110010111010111100011110111110101101100011010001110101010110000111011111010110110001100001111010101011000011101111101011011000110000111101010101100001110111110101101100011000011110101010110000111011111010110110001100001111010101011000011101111101011011000110000111101010101100001110111110101101100011000011110101010110000111011111010110110001100001111010101011000011101111101011011000110000111101010101100001110111110101101100011000011110101010110000111011111010110110001100001111010101011000011101111101011011000110000111101010101100001110111110101101100011000011110101010110000111011111010110110001100001111010101011000011101111101011011000110000111101010101100001110111110101101100011000011110101010110000111011111010110110001100001111010101011000011101111101011011000110000111101010101100001110111110101101100011000011110101010Each node can have a value of 0 or 1.  38 of the 43 nodes are allowed to vary, with 5 nodes held constant throughout the simulation."
Parkinson Speech Dataset with  Multiple Types of Sound Recordings,Parkinson Speech Dataset with  Multiple Types of Sound Recordings,"The training data belongs to 20 Parkinson's Disease (PD) patients and 20 healthy subjects. From all subjects, multiple types of sound recordings (26) are taken.",Parkinson+Speech+Dataset+with++Multiple+Types+of+Sound+Recordings,https://archive.ics.uci.edu/ml//machine-learning-databases/00301/,https://archive.ics.uci.edu/ml/datasets/Parkinson+Speech+Dataset+with++Multiple+Types+of+Sound+Recordings,"The PD database consists of training and test files. The training data belongs to 20 PWP (6 female, 14 male) and 20 healthy individuals (10 female, 10 male) who appealed at the Department of Neurology in Cerrahpasa Faculty of Medicine, Istanbul University. From all subjects, multiple types of sound recordings (26 voice samples including sustained vowels, numbers, words and short sentences) are taken.  A group of 26 linear and timeÃ¢â‚¬â€œfrequency based features are extracted from each voice sample. UPDRS ((Unified ParkinsonÃ¢â‚¬â„¢s Disease Rating Scale) score of each patient which is determined by expert physician is also available in this dataset. Therefore, this dataset can also be used for regression.After collecting the training dataset which consists of multiple types of sound recordings and performing our experiments, in line with the obtained findings we continued collecting an independent test set from PWP via the same physicianÃ¢â‚¬â„¢s examination process under the same conditions. During the collection of this dataset, 28 PD patients are asked to say only the sustained vowels 'a' and 'o' three times respectively which makes a total of 168 recordings. The same 26 features are extracted from voice samples of this dataset. This dataset can be used as an independent test set to validate the results obtained on training set.Further details are contained in the following reference -- if you use this dataset, please cite: Erdogdu Sakar, B., Isenkul, M., Sakar, C.O., Sertbas, A., Gurgen, F., Delil, S., Apaydin, H., Kursun,O., 'Collection and Analysis of a Parkinson Speech Dataset with Multiple Types of SoundRecordings', IEEE Journal of Biomedical and Health Informatics, vol. 17(4), pp. 828-834, 2013Training Data File:Each subject has 26 voice samples including sustained vowels, numbers, words and short sentences. The voice samples in the training data file are given in the following order:sample# - corresponding voice samples1: sustained vowel (aaaÃ¢â‚¬Â¦Ã¢â‚¬Â¦)2: sustained vowel (oooÃ¢â‚¬Â¦...)3: sustained vowel (uuuÃ¢â‚¬Â¦...)4-13: numbers from 1 to 1014-17: short sentences18-26: wordsTest Data File:28 PD patients are asked to say only the sustained vowels 'a' and 'o' three times respectively which makes a total of 168 recordings (each subject has 6 voice samples) The voice samples in the test data file are given in the following order:sample# - corresponding voice samples1-3: sustained vowel (aaaÃ¢â‚¬Â¦Ã¢â‚¬Â¦)4-6: sustained vowel (oooÃ¢â‚¬Â¦Ã¢â‚¬Â¦)",Life,"Training Data File:column 1: Subject idcolum 2-27: features features 1-5: Jitter (local),Jitter (local, absolute),Jitter (rap),Jitter (ppq5),Jitter (ddp),features 6-11: Shimmer (local),Shimmer (local, dB),Shimmer (apq3),Shimmer (apq5), Shimmer (apq11),Shimmer (dda),features 12-14: AC,NTH,HTN,features 15-19: Median pitch,Mean pitch,Standard deviation,Minimum pitch,Maximum pitch,features 20-23: Number of pulses,Number of periods,Mean period,Standard deviation of period, features 24-26: Fraction of locally unvoiced frames,Number of voice breaks,Degree of voice breakscolumn 28: UPDRScolumn 29: class informationTest Data File:column 1: Subject idcolum 2-27: features features 1-5: Jitter (local),Jitter (local, absolute),Jitter (rap),Jitter (ppq5),Jitter (ddp),features 6-11: Shimmer (local),Shimmer (local, dB),Shimmer (apq3),Shimmer (apq5), Shimmer (apq11),Shimmer (dda),features 12-14: AC,NTH,HTN,features 15-19: Median pitch,Mean pitch,Standard deviation,Minimum pitch,Maximum pitch,features 20-23: Number of pulses,Number of periods,Mean period,Standard deviation of period,features 24-26: Fraction of locally unvoiced frames,Number of voice breaks,Degree of voice breakscolumn 28: class information","The training data belongs to 20 Parkinson's Disease (PD) patients and 20 healthy subjects. From all subjects, multiple types of sound recordings (26) are taken.The PD database consists of training and test files. The training data belongs to 20 PWP (6 female, 14 male) and 20 healthy individuals (10 female, 10 male) who appealed at the Department of Neurology in Cerrahpasa Faculty of Medicine, Istanbul University. From all subjects, multiple types of sound recordings (26 voice samples including sustained vowels, numbers, words and short sentences) are taken.  A group of 26 linear and timeÃ¢â‚¬â€œfrequency based features are extracted from each voice sample. UPDRS ((Unified ParkinsonÃ¢â‚¬â„¢s Disease Rating Scale) score of each patient which is determined by expert physician is also available in this dataset. Therefore, this dataset can also be used for regression.After collecting the training dataset which consists of multiple types of sound recordings and performing our experiments, in line with the obtained findings we continued collecting an independent test set from PWP via the same physicianÃ¢â‚¬â„¢s examination process under the same conditions. During the collection of this dataset, 28 PD patients are asked to say only the sustained vowels 'a' and 'o' three times respectively which makes a total of 168 recordings. The same 26 features are extracted from voice samples of this dataset. This dataset can be used as an independent test set to validate the results obtained on training set.Further details are contained in the following reference -- if you use this dataset, please cite: Erdogdu Sakar, B., Isenkul, M., Sakar, C.O., Sertbas, A., Gurgen, F., Delil, S., Apaydin, H., Kursun,O., 'Collection and Analysis of a Parkinson Speech Dataset with Multiple Types of SoundRecordings', IEEE Journal of Biomedical and Health Informatics, vol. 17(4), pp. 828-834, 2013Training Data File:Each subject has 26 voice samples including sustained vowels, numbers, words and short sentences. The voice samples in the training data file are given in the following order:sample# - corresponding voice samples1: sustained vowel (aaaÃ¢â‚¬Â¦Ã¢â‚¬Â¦)2: sustained vowel (oooÃ¢â‚¬Â¦...)3: sustained vowel (uuuÃ¢â‚¬Â¦...)4-13: numbers from 1 to 1014-17: short sentences18-26: wordsTest Data File:28 PD patients are asked to say only the sustained vowels 'a' and 'o' three times respectively which makes a total of 168 recordings (each subject has 6 voice samples) The voice samples in the test data file are given in the following order:sample# - corresponding voice samples1-3: sustained vowel (aaaÃ¢â‚¬Â¦Ã¢â‚¬Â¦)4-6: sustained vowel (oooÃ¢â‚¬Â¦Ã¢â‚¬Â¦)Training Data File:column 1: Subject idcolum 2-27: features features 1-5: Jitter (local),Jitter (local, absolute),Jitter (rap),Jitter (ppq5),Jitter (ddp),features 6-11: Shimmer (local),Shimmer (local, dB),Shimmer (apq3),Shimmer (apq5), Shimmer (apq11),Shimmer (dda),features 12-14: AC,NTH,HTN,features 15-19: Median pitch,Mean pitch,Standard deviation,Minimum pitch,Maximum pitch,features 20-23: Number of pulses,Number of periods,Mean period,Standard deviation of period, features 24-26: Fraction of locally unvoiced frames,Number of voice breaks,Degree of voice breakscolumn 28: UPDRScolumn 29: class informationTest Data File:column 1: Subject idcolum 2-27: features features 1-5: Jitter (local),Jitter (local, absolute),Jitter (rap),Jitter (ppq5),Jitter (ddp),features 6-11: Shimmer (local),Shimmer (local, dB),Shimmer (apq3),Shimmer (apq5), Shimmer (apq11),Shimmer (dda),features 12-14: AC,NTH,HTN,features 15-19: Median pitch,Mean pitch,Standard deviation,Minimum pitch,Maximum pitch,features 20-23: Number of pulses,Number of periods,Mean period,Standard deviation of period,features 24-26: Fraction of locally unvoiced frames,Number of voice breaks,Degree of voice breakscolumn 28: class information"
QSAR fish bioconcentration factor (BCF),QSAR fish bioconcentration factor (BCF),Experimental bioconcentration factor (BCF) for 1056 molecules and binary fingeprints (extended connectivity) to be used for QSAR modeling.,QSAR+fish+bioconcentration+factor+%28BCF%29,https://archive.ics.uci.edu/ml//machine-learning-databases/00511/,https://archive.ics.uci.edu/ml/datasets/QSAR+fish+bioconcentration+factor+%28BCF%29,"This dataset contains manually-curated experimental bioconcentration factor (BCF) for 1058 molecules (continuous values). Each row contains a molecule, identified by a CAS number, a name (if available), and a SMILES string. Additionally, the KOW (experimental or predicted) is reported. In this database, you will also find Extended Connectivity Fingerprints (binary vectors of 1024 bits), to be used as independent variables to predict the BCF. You can find additional information in the referenced papers.In case you had questions, please do not hesitate to contact us!",Life,"The provided zip file contains two files.(I) The file 'QSAR BCF KOW' contains the following attributes:1. CAS number (molecule identifier)2. Molecule Name (if not available, marked as 'n.a.')3. SMILES string to identify the 2D molecular structure4. LogKOW: octanol water partitioning coefficient (experimental or predicted, as indicated by the column 'KOW Type'5. KOW Type: indicates whether the logKOW value is experimental or predicted 6. Experimental logBCF (quantitative response): experimental fish bioconcentration factor (logarithm form)(II) The file 'ECFP_1024_m0-2_b2_c.txt' contains the following molecular descriptors (to be used to predict the BCF):- Extended Connectivity Fingerprints (ECFPs): binary descriptors useful to predict the experimental logBCF (computed with Dragon7, default settings --> details specified in the file)Each row corresponds to one molecule, as identified by the SMILES field. The molecules are in the same order as in the previous file. ","Experimental bioconcentration factor (BCF) for 1056 molecules and binary fingeprints (extended connectivity) to be used for QSAR modeling.This dataset contains manually-curated experimental bioconcentration factor (BCF) for 1058 molecules (continuous values). Each row contains a molecule, identified by a CAS number, a name (if available), and a SMILES string. Additionally, the KOW (experimental or predicted) is reported. In this database, you will also find Extended Connectivity Fingerprints (binary vectors of 1024 bits), to be used as independent variables to predict the BCF. You can find additional information in the referenced papers.In case you had questions, please do not hesitate to contact us!The provided zip file contains two files.(I) The file 'QSAR BCF KOW' contains the following attributes:1. CAS number (molecule identifier)2. Molecule Name (if not available, marked as 'n.a.')3. SMILES string to identify the 2D molecular structure4. LogKOW: octanol water partitioning coefficient (experimental or predicted, as indicated by the column 'KOW Type'5. KOW Type: indicates whether the logKOW value is experimental or predicted 6. Experimental logBCF (quantitative response): experimental fish bioconcentration factor (logarithm form)(II) The file 'ECFP_1024_m0-2_b2_c.txt' contains the following molecular descriptors (to be used to predict the BCF):- Extended Connectivity Fingerprints (ECFPs): binary descriptors useful to predict the experimental logBCF (computed with Dragon7, default settings --> details specified in the file)Each row corresponds to one molecule, as identified by the SMILES field. The molecules are in the same order as in the previous file. "
Parkinsons,Parkinsons,Oxford Parkinson's Disease Detection Dataset,Parkinsons,https://archive.ics.uci.edu/ml//machine-learning-databases/parkinsons/,https://archive.ics.uci.edu/ml/datasets/Parkinsons,"This dataset is composed of a range of biomedical voice measurements from 31 people, 23 with Parkinson's disease (PD). Each column in the table is a particular voice measure, and each row corresponds one of 195 voice recording from these individuals (""name"" column). The main aim of the data is to discriminate healthy people from those with PD, according to ""status"" column which is set to 0 for healthy and 1 for PD. The data is in ASCII CSV format. The rows of the CSV file contain an instance corresponding to one voice recording. There are around six recordings per patient, the name of the patient is identified in the first column.For further information or to pass on comments, please contact Max Little (littlem '@' robots.ox.ac.uk).Further details are contained in the following reference -- if you use this dataset, please cite:Max A. Little, Patrick E. McSharry, Eric J. Hunter, Lorraine O. Ramig (2008), 'Suitability of dysphonia measurements for telemonitoring of Parkinson's disease', IEEE Transactions on Biomedical Engineering (to appear).",Life,"Matrix column entries (attributes):name - ASCII subject name and recording numberMDVP:Fo(Hz) - Average vocal fundamental frequencyMDVP:Fhi(Hz) - Maximum vocal fundamental frequencyMDVP:Flo(Hz) - Minimum vocal fundamental frequencyMDVP:Jitter(%),MDVP:Jitter(Abs),MDVP:RAP,MDVP:PPQ,Jitter:DDP - Several measures of variation in fundamental frequencyMDVP:Shimmer,MDVP:Shimmer(dB),Shimmer:APQ3,Shimmer:APQ5,MDVP:APQ,Shimmer:DDA - Several measures of variation in amplitudeNHR,HNR - Two measures of ratio of noise to tonal components in the voicestatus - Health status of the subject (one) - Parkinson's, (zero) - healthyRPDE,D2 - Two nonlinear dynamical complexity measuresDFA - Signal fractal scaling exponentspread1,spread2,PPE - Three nonlinear measures of fundamental frequency variation","Oxford Parkinson's Disease Detection DatasetThis dataset is composed of a range of biomedical voice measurements from 31 people, 23 with Parkinson's disease (PD). Each column in the table is a particular voice measure, and each row corresponds one of 195 voice recording from these individuals (""name"" column). The main aim of the data is to discriminate healthy people from those with PD, according to ""status"" column which is set to 0 for healthy and 1 for PD. The data is in ASCII CSV format. The rows of the CSV file contain an instance corresponding to one voice recording. There are around six recordings per patient, the name of the patient is identified in the first column.For further information or to pass on comments, please contact Max Little (littlem '@' robots.ox.ac.uk).Further details are contained in the following reference -- if you use this dataset, please cite:Max A. Little, Patrick E. McSharry, Eric J. Hunter, Lorraine O. Ramig (2008), 'Suitability of dysphonia measurements for telemonitoring of Parkinson's disease', IEEE Transactions on Biomedical Engineering (to appear).Matrix column entries (attributes):name - ASCII subject name and recording numberMDVP:Fo(Hz) - Average vocal fundamental frequencyMDVP:Fhi(Hz) - Maximum vocal fundamental frequencyMDVP:Flo(Hz) - Minimum vocal fundamental frequencyMDVP:Jitter(%),MDVP:Jitter(Abs),MDVP:RAP,MDVP:PPQ,Jitter:DDP - Several measures of variation in fundamental frequencyMDVP:Shimmer,MDVP:Shimmer(dB),Shimmer:APQ3,Shimmer:APQ5,MDVP:APQ,Shimmer:DDA - Several measures of variation in amplitudeNHR,HNR - Two measures of ratio of noise to tonal components in the voicestatus - Health status of the subject (one) - Parkinson's, (zero) - healthyRPDE,D2 - Two nonlinear dynamical complexity measuresDFA - Signal fractal scaling exponentspread1,spread2,PPE - Three nonlinear measures of fundamental frequency variation"
chipseq,chipseq,"ChIP-seq experiments characterize protein modifications or binding at
specific genomic locations in specific samples. The machine learning
problem in these data is structured binary classification.",chipseq,https://archive.ics.uci.edu/ml//machine-learning-databases/00439/,https://archive.ics.uci.edu/ml/datasets/chipseq,"These data are significant because they are among the first to providelabels that formalize the genome-wide peak detection problem, which isa very important problem for biomedical / epigenomics researchers. These labels can be used to train and test supervisedpeak detection algorithms, as explained below.The data are in problem directories such asdata/<SET>/samples/<GROUP>/<SAMPLE>/problems/<PROBLEM>Each problem directory contains two files, labels.bed (weak labels)and coverage.bedGraph.gz (inputs). Each coverage.bedGraph.gz file represents a vector of non-negativeinteger count data, one entry for each genomic position in a subset ofthe human genome hg19. For exampledata/H3K9me3_TDH_BP/samples/tcell/ERS358697/problems/chr8:48135599-86500000/coverage.bedGraph.gzrepresents a vector defined on all genomic positions from 48135600 to86500000 on chr8 (for a particular tcell sample named ERS358697, inthe H3K9me3_TDH_BP data set). To save disk space the vectors are savedusing a run-length encoding; for example the first three lines of thisfile arechr8	48135599	48135625	0chr8	48135625	48135629	1chr8	48135629	48135632	2which mean that the first 26 entries of the vector are 0, the nextfour entries are 1, and the following three entries are 2. Note thatstart positions are 0-based but end positions are 1-based, so thefirst line means a 0 from all positions from 48135600 to 48135625(excluding the start position 48135599 for which we have noinformation).The goal is to learn a function that takes the coverage.bedGraph.gzfile as input, and outputs a binary classification for every genomicposition. The positive class represents peaks (typically large counts)and the negative class represents background noise (typically smallcounts).Weak labels are given in labels.bed files, each of which indicatesseveral regions of the genome with or without peaks. For example thefiledata/H3K4me3_XJ_immune/samples/bcell/McGill0091/problems/chr1:30028082-103863906/labels.bedcontains the 6 labels below:chr1	33111786	33114894	noPeakschr1	33114941	33116174	peakStartchr1	33116183	33116620	peakEndchr1	33116633	33116755	noPeakschr1	33116834	33118135	peakschr1	33118161	33120163	noPeaksThe four labels are interpreted as follows:noPeaks: all of the predictions in this region should be negative /background noise. For example the first line in the file above meansthat for a vector x_i of count data from i=30028083 to i=103863906,the desired function should predict negative / background noisef(x_i)=0 from i=33111787 to i=33114894. If positive / peaks arepredicted f(x_i)=1 for any i in this region, that is counted as afalse positive label.peakStart: there should be exactly one peak start predicted in thisregion. A peak start is defined as a position i such that a peak ispredicted there f(x_i)=1 but not at the previous positionf(x_{i-1})=0. The exact position is unspecified; any position is fine,as long as there is only one start in the region. Predicting exactlyone peak start in this region results in a true positive. More startsis a false positive, and fewer starts is a false negative. Forexample, [peakStart] 0 0 0 1 1 1 1 -> correct.  0 0 1 1 1 1 1 -> also correct.  0 0 0 0 0 0 0 -> false negative (no peak starts).0 0 1 0 1 1 1 -> flase positive (two peak starts).peakEnd: there should be exactly one peak end predicted in thisregion. A peak end is defined as a position i such that a peak ispredicted there f(x_i)=1 but not at the next position f(x_{i+1})=0.The exact position is unspecified; any position is fine, as long asthere is only one end in the region. Predicting exactly one peak endin this region results in a true positive. More ends is a falsepositive, and fewer ends is a false negative. For example, [ peakEnd ] 1 1 1 1 0 0 0 -> correct.  1 1 1 1 1 0 0 -> also correct.  0 0 0 0 0 0 0 -> false negative (no peak ends).1 1 1 0 1 0 0 -> flase positive (two peak ends).peaks: there should be at least one peak predicted somewhere in thisregion (anywhere is fine). Zero predicted peaks in this region is afalse negative. If there is a predicted peak somewhere in this regionthat is a true positive.For a particular set of predicted peaks f(x), the total number ofincorrect labels (false positives + false negatives) can be computedas an evaluation metric (smaller is better). Typically the peakpredictions are also stored using a run-length encoding; the errorrates can be computed using the reference implementation in R packagePeakError, [Web Link]Receiver Operating Characteristic curves can be computed for a familyof predicted peaks f_lambda(x), where lambda is some significancethreshold, intercept parameter, etc. Compute the TPR and FPR as follows:TPR = (total number of true positives)/(total number of labels that could have a true positive) = (number of correct peaks, peakStart, peakEnd labels)/(number of peaks, peakStart, peakEnd labels)FPR = (total number of false positives)/(total number of labels that could have a false positive) = (number of peakStart/End labels with two or more predicted starts/end + number of noPeaks labels with predicted peaks)/(number of peakStart, peakEnd, and noPeaks labels)Suggested fold ID numbers for four-fold cross-validation experimentscan be found in data/*/folds.csv files. For exampledata/H3K36me3_TDH_[Web Link] containsproblem,foldchr16:8686921-32000000,1chr16:60000-8636921,1chr21:43005559-44632664,2chr14:19050000-107289540,3chr15:29209443-77800000,4which means that problems chr16:8686921-32000000 andchr16:60000-8636921 should be considered fold ID 1,chr21:43005559-44632664 should be considered fold ID 2, etc. Thismeans that for data set H3K36me3_TDH_other, the fold ID 2 consists ofall data indata/H3K36me3_TDH_other/samples/*/*/problems/chr21:43005559-44632664directories.There are several types of learning settings that could be used withthese data. Here are four examples.Unsupervised learning. Train models only using thecoverage.bedGraph.gz files. Only use the labels for evaluation (notfor training model parameters).Supervised learning. Train models only using the coverage.bedGraph.gzand labels.bed files in the train set. Use the labels in the test setto evaluate prediction accuracy.Semi-supervised learning. Train models using the coverage.bedGraph.gzand labels.bed files in the train set. You can additionally use thecoverage.bedGraph.gz files in the test set at training time. Use thelabels in the test set to evaluate prediction accuracy.Multi-task learning. Many data sets come from different experimenttypes, so have different peak patterns. For example H3K4me3_TDH_immuneis a H3K4me3 histone modification (sharp peak pattern) andH3K36me3_TDH_immune is a H3K36me3 histone modification (broad peakpattern). Therefore it is not expected that models should generalizebetween data sets. However there is something common across data setsin that in each data set, the peak / positive class is large values,wheras the noise / negative class is small values. Thereforemulti-task learning may be interesting. To compare a multi-tasklearning model to a single-task learning model, use the suggestedcross-validation fold IDs. For test fold ID 1, train both themulti-task and single-task learning models using all other folds, thenmake predictions on all data with fold ID 1. ",Life,"Each attribute is a non-negative integer representing the number DNA sequence reads that has aligned at that particular region of the genome. Larger values are more likely to be peaks / positive, smaller values are more likely to be noise / negative.","ChIP-seq experiments characterize protein modifications or binding at
specific genomic locations in specific samples. The machine learning
problem in these data is structured binary classification.These data are significant because they are among the first to providelabels that formalize the genome-wide peak detection problem, which isa very important problem for biomedical / epigenomics researchers. These labels can be used to train and test supervisedpeak detection algorithms, as explained below.The data are in problem directories such asdata/<SET>/samples/<GROUP>/<SAMPLE>/problems/<PROBLEM>Each problem directory contains two files, labels.bed (weak labels)and coverage.bedGraph.gz (inputs). Each coverage.bedGraph.gz file represents a vector of non-negativeinteger count data, one entry for each genomic position in a subset ofthe human genome hg19. For exampledata/H3K9me3_TDH_BP/samples/tcell/ERS358697/problems/chr8:48135599-86500000/coverage.bedGraph.gzrepresents a vector defined on all genomic positions from 48135600 to86500000 on chr8 (for a particular tcell sample named ERS358697, inthe H3K9me3_TDH_BP data set). To save disk space the vectors are savedusing a run-length encoding; for example the first three lines of thisfile arechr8	48135599	48135625	0chr8	48135625	48135629	1chr8	48135629	48135632	2which mean that the first 26 entries of the vector are 0, the nextfour entries are 1, and the following three entries are 2. Note thatstart positions are 0-based but end positions are 1-based, so thefirst line means a 0 from all positions from 48135600 to 48135625(excluding the start position 48135599 for which we have noinformation).The goal is to learn a function that takes the coverage.bedGraph.gzfile as input, and outputs a binary classification for every genomicposition. The positive class represents peaks (typically large counts)and the negative class represents background noise (typically smallcounts).Weak labels are given in labels.bed files, each of which indicatesseveral regions of the genome with or without peaks. For example thefiledata/H3K4me3_XJ_immune/samples/bcell/McGill0091/problems/chr1:30028082-103863906/labels.bedcontains the 6 labels below:chr1	33111786	33114894	noPeakschr1	33114941	33116174	peakStartchr1	33116183	33116620	peakEndchr1	33116633	33116755	noPeakschr1	33116834	33118135	peakschr1	33118161	33120163	noPeaksThe four labels are interpreted as follows:noPeaks: all of the predictions in this region should be negative /background noise. For example the first line in the file above meansthat for a vector x_i of count data from i=30028083 to i=103863906,the desired function should predict negative / background noisef(x_i)=0 from i=33111787 to i=33114894. If positive / peaks arepredicted f(x_i)=1 for any i in this region, that is counted as afalse positive label.peakStart: there should be exactly one peak start predicted in thisregion. A peak start is defined as a position i such that a peak ispredicted there f(x_i)=1 but not at the previous positionf(x_{i-1})=0. The exact position is unspecified; any position is fine,as long as there is only one start in the region. Predicting exactlyone peak start in this region results in a true positive. More startsis a false positive, and fewer starts is a false negative. Forexample, [peakStart] 0 0 0 1 1 1 1 -> correct.  0 0 1 1 1 1 1 -> also correct.  0 0 0 0 0 0 0 -> false negative (no peak starts).0 0 1 0 1 1 1 -> flase positive (two peak starts).peakEnd: there should be exactly one peak end predicted in thisregion. A peak end is defined as a position i such that a peak ispredicted there f(x_i)=1 but not at the next position f(x_{i+1})=0.The exact position is unspecified; any position is fine, as long asthere is only one end in the region. Predicting exactly one peak endin this region results in a true positive. More ends is a falsepositive, and fewer ends is a false negative. For example, [ peakEnd ] 1 1 1 1 0 0 0 -> correct.  1 1 1 1 1 0 0 -> also correct.  0 0 0 0 0 0 0 -> false negative (no peak ends).1 1 1 0 1 0 0 -> flase positive (two peak ends).peaks: there should be at least one peak predicted somewhere in thisregion (anywhere is fine). Zero predicted peaks in this region is afalse negative. If there is a predicted peak somewhere in this regionthat is a true positive.For a particular set of predicted peaks f(x), the total number ofincorrect labels (false positives + false negatives) can be computedas an evaluation metric (smaller is better). Typically the peakpredictions are also stored using a run-length encoding; the errorrates can be computed using the reference implementation in R packagePeakError, [Web Link]Receiver Operating Characteristic curves can be computed for a familyof predicted peaks f_lambda(x), where lambda is some significancethreshold, intercept parameter, etc. Compute the TPR and FPR as follows:TPR = (total number of true positives)/(total number of labels that could have a true positive) = (number of correct peaks, peakStart, peakEnd labels)/(number of peaks, peakStart, peakEnd labels)FPR = (total number of false positives)/(total number of labels that could have a false positive) = (number of peakStart/End labels with two or more predicted starts/end + number of noPeaks labels with predicted peaks)/(number of peakStart, peakEnd, and noPeaks labels)Suggested fold ID numbers for four-fold cross-validation experimentscan be found in data/*/folds.csv files. For exampledata/H3K36me3_TDH_[Web Link] containsproblem,foldchr16:8686921-32000000,1chr16:60000-8636921,1chr21:43005559-44632664,2chr14:19050000-107289540,3chr15:29209443-77800000,4which means that problems chr16:8686921-32000000 andchr16:60000-8636921 should be considered fold ID 1,chr21:43005559-44632664 should be considered fold ID 2, etc. Thismeans that for data set H3K36me3_TDH_other, the fold ID 2 consists ofall data indata/H3K36me3_TDH_other/samples/*/*/problems/chr21:43005559-44632664directories.There are several types of learning settings that could be used withthese data. Here are four examples.Unsupervised learning. Train models only using thecoverage.bedGraph.gz files. Only use the labels for evaluation (notfor training model parameters).Supervised learning. Train models only using the coverage.bedGraph.gzand labels.bed files in the train set. Use the labels in the test setto evaluate prediction accuracy.Semi-supervised learning. Train models using the coverage.bedGraph.gzand labels.bed files in the train set. You can additionally use thecoverage.bedGraph.gz files in the test set at training time. Use thelabels in the test set to evaluate prediction accuracy.Multi-task learning. Many data sets come from different experimenttypes, so have different peak patterns. For example H3K4me3_TDH_immuneis a H3K4me3 histone modification (sharp peak pattern) andH3K36me3_TDH_immune is a H3K36me3 histone modification (broad peakpattern). Therefore it is not expected that models should generalizebetween data sets. However there is something common across data setsin that in each data set, the peak / positive class is large values,wheras the noise / negative class is small values. Thereforemulti-task learning may be interesting. To compare a multi-tasklearning model to a single-task learning model, use the suggestedcross-validation fold IDs. For test fold ID 1, train both themulti-task and single-task learning models using all other folds, thenmake predictions on all data with fold ID 1. Each attribute is a non-negative integer representing the number DNA sequence reads that has aligned at that particular region of the genome. Larger values are more likely to be peaks / positive, smaller values are more likely to be noise / negative."
Acute Inflammations,Acute Inflammations,"The data was created by a medical expert as a data set to test the expert system, 
which will perform the presumptive diagnosis of two diseases of the urinary system.
",Acute+Inflammations,https://archive.ics.uci.edu/ml//machine-learning-databases/acute/,https://archive.ics.uci.edu/ml/datasets/Acute+Inflammations,"The main idea of this data set is to prepare the algorithm of the expert system, which will perform the presumptive diagnosis of two diseases of urinary system. It will be the example of diagnosing of the acute inflammations of urinary bladder and acute nephritises. For better understanding of the problem let us consider definitions of both diseases given by medics. Acute inflammation of urinary bladder is characterised by sudden occurrence of pains in the abdomen region and the urination in form of constant urine pushing, micturition pains and sometimes lack of urine keeping. Temperature of the body is rising, however most often not above 38C. The excreted urine is turbid and sometimes bloody. At proper treatment, symptoms decay usually within several days. However, there is inclination to returns. At persons with acute inflammation of urinary bladder, we should expect that the illness will turn into protracted form.Acute nephritis of renal pelvis origin occurs considerably more often at women than at men. It begins with sudden fever, which reaches, and sometimes exceeds 40C. The fever is accompanied by shivers and one- or both-side lumbar pains, which are sometimes very strong. Symptoms of acute inflammation of urinary bladder appear very often. Quite not infrequently there are nausea and vomiting and spread pains of whole abdomen.The data was created by a medical expert as a data set to test the expert system, which will perform the presumptive diagnosis of two diseases of urinary system.  The basis for rules detection was Rough Sets Theory.  Each instance represents an potential patient.The data is in an ASCII file. Attributes are separated by TAB.Each line of the data file starts with a digit which tells the temperature of patient.  -- Attribute lines:       For example, '35,9	no	no	yes	yes	yes	yes	no'       Where:	 '35,9'	Temperature of patient 		 'no'	Occurrence of nausea 		 'no'	Lumbar pain  		 'yes'	Urine pushing (continuous need for urination)  		 'yes'	Micturition pains  	 'yes'	Burning of urethra, itch, swelling of urethra outlet 		 'yes'	decision: Inflammation of urinary bladder  	 'no'	decision: Nephritis of renal pelvis origin ",Life," a1	Temperature of patient  { 35C-42C }	 a2	Occurrence of nausea  { yes, no }	 a3	Lumbar pain  { yes, no }	 a4	Urine pushing (continuous need for urination)  { yes, no }	 a5	Micturition pains  { yes, no }	 a6	Burning of urethra, itch, swelling of urethra outlet  { yes, no }	 d1	decision: Inflammation of urinary bladder  { yes, no }	 d2	decision: Nephritis of renal pelvis origin { yes, no }	","The data was created by a medical expert as a data set to test the expert system, 
which will perform the presumptive diagnosis of two diseases of the urinary system.
The main idea of this data set is to prepare the algorithm of the expert system, which will perform the presumptive diagnosis of two diseases of urinary system. It will be the example of diagnosing of the acute inflammations of urinary bladder and acute nephritises. For better understanding of the problem let us consider definitions of both diseases given by medics. Acute inflammation of urinary bladder is characterised by sudden occurrence of pains in the abdomen region and the urination in form of constant urine pushing, micturition pains and sometimes lack of urine keeping. Temperature of the body is rising, however most often not above 38C. The excreted urine is turbid and sometimes bloody. At proper treatment, symptoms decay usually within several days. However, there is inclination to returns. At persons with acute inflammation of urinary bladder, we should expect that the illness will turn into protracted form.Acute nephritis of renal pelvis origin occurs considerably more often at women than at men. It begins with sudden fever, which reaches, and sometimes exceeds 40C. The fever is accompanied by shivers and one- or both-side lumbar pains, which are sometimes very strong. Symptoms of acute inflammation of urinary bladder appear very often. Quite not infrequently there are nausea and vomiting and spread pains of whole abdomen.The data was created by a medical expert as a data set to test the expert system, which will perform the presumptive diagnosis of two diseases of urinary system.  The basis for rules detection was Rough Sets Theory.  Each instance represents an potential patient.The data is in an ASCII file. Attributes are separated by TAB.Each line of the data file starts with a digit which tells the temperature of patient.  -- Attribute lines:       For example, '35,9	no	no	yes	yes	yes	yes	no'       Where:	 '35,9'	Temperature of patient 		 'no'	Occurrence of nausea 		 'no'	Lumbar pain  		 'yes'	Urine pushing (continuous need for urination)  		 'yes'	Micturition pains  	 'yes'	Burning of urethra, itch, swelling of urethra outlet 		 'yes'	decision: Inflammation of urinary bladder  	 'no'	decision: Nephritis of renal pelvis origin  a1	Temperature of patient  { 35C-42C }	 a2	Occurrence of nausea  { yes, no }	 a3	Lumbar pain  { yes, no }	 a4	Urine pushing (continuous need for urination)  { yes, no }	 a5	Micturition pains  { yes, no }	 a6	Burning of urethra, itch, swelling of urethra outlet  { yes, no }	 d1	decision: Inflammation of urinary bladder  { yes, no }	 d2	decision: Nephritis of renal pelvis origin { yes, no }	"
Autistic Spectrum Disorder Screening Data for Adolescent   ,Autistic Spectrum Disorder Screening Data for Adolescent   ,Autistic Spectrum Disorder Screening Data for Adolescent. This dataset is related to classification and predictive tasks.,Autistic+Spectrum+Disorder+Screening+Data+for+Adolescent+++,https://archive.ics.uci.edu/ml//machine-learning-databases/00420/,https://archive.ics.uci.edu/ml/datasets/Autistic+Spectrum+Disorder+Screening+Data+for+Adolescent+++,See description file ,Life,See description file ,Autistic Spectrum Disorder Screening Data for Adolescent. This dataset is related to classification and predictive tasks.See description file See description file 
Cardiotocography,Cardiotocography,The dataset consists of measurements of fetal heart rate (FHR) and uterine contraction (UC) features on cardiotocograms classified by expert obstetricians.,Cardiotocography,https://archive.ics.uci.edu/ml//machine-learning-databases/00193/,https://archive.ics.uci.edu/ml/datasets/Cardiotocography,"2126 fetal cardiotocograms (CTGs) were automatically processed and the respective diagnostic features measured. The CTGs were also classified by three expert obstetricians and a consensus classification label assigned to each of them. Classification was both with respect to a morphologic pattern (A, B, C. ...) and to a fetal state (N, S, P). Therefore the dataset can be used either for 10-class or 3-class experiments.",Life,LB - FHR baseline (beats per minute)AC - # of accelerations per secondFM - # of fetal movements per secondUC - # of uterine contractions per secondDL - # of light decelerations per secondDS - # of severe decelerations per secondDP - # of prolongued decelerations per secondASTV - percentage of time with abnormal short term variabilityMSTV - mean value of short term variabilityALTV - percentage of time with abnormal long term variabilityMLTV - mean value of long term variabilityWidth - width of FHR histogramMin - minimum of FHR histogramMax - Maximum of FHR histogramNmax - # of histogram peaksNzeros - # of histogram zerosMode - histogram modeMean - histogram meanMedian - histogram medianVariance - histogram varianceTendency - histogram tendencyCLASS - FHR pattern class code (1 to 10) NSP - fetal state class code (N=normal; S=suspect; P=pathologic),"The dataset consists of measurements of fetal heart rate (FHR) and uterine contraction (UC) features on cardiotocograms classified by expert obstetricians.2126 fetal cardiotocograms (CTGs) were automatically processed and the respective diagnostic features measured. The CTGs were also classified by three expert obstetricians and a consensus classification label assigned to each of them. Classification was both with respect to a morphologic pattern (A, B, C. ...) and to a fetal state (N, S, P). Therefore the dataset can be used either for 10-class or 3-class experiments.LB - FHR baseline (beats per minute)AC - # of accelerations per secondFM - # of fetal movements per secondUC - # of uterine contractions per secondDL - # of light decelerations per secondDS - # of severe decelerations per secondDP - # of prolongued decelerations per secondASTV - percentage of time with abnormal short term variabilityMSTV - mean value of short term variabilityALTV - percentage of time with abnormal long term variabilityMLTV - mean value of long term variabilityWidth - width of FHR histogramMin - minimum of FHR histogramMax - Maximum of FHR histogramNmax - # of histogram peaksNzeros - # of histogram zerosMode - histogram modeMean - histogram meanMedian - histogram medianVariance - histogram varianceTendency - histogram tendencyCLASS - FHR pattern class code (1 to 10) NSP - fetal state class code (N=normal; S=suspect; P=pathologic)"
Arcene,Arcene,ARCENE's task is to distinguish cancer versus normal patterns from mass-spectrometric data. This is a two-class classification problem with continuous input variables. This dataset is one of 5 datasets of the NIPS 2003 feature selection challenge.,Arcene,https://archive.ics.uci.edu/ml//machine-learning-databases/arcene/,https://archive.ics.uci.edu/ml/datasets/Arcene,"ARCENE was obtained by merging three mass-spectrometry datasets to obtain enough training and test data for a benchmark. The original features indicate the abundance of proteins in human sera having a given mass value. Based on those features one must separate cancer patients from healthy patients. We added a number of distractor feature called 'probes' having no predictive power. The order of the features and patterns were randomized.ARCENE -- Positive ex. -- Negative ex. -- TotalTraining set -- 44 -- 56 -- 100Validation set -- 44 -- 56 -- 100Test set -- 310 -- 390 -- 700All -- 398 -- 502 -- 900Number of variables/features/attributes:Real: 7000Probes: 3000Total: 10000This dataset is one of five datasets used in the NIPS 2003 feature selection challenge. Our website [Web Link] is still open for post-challenge submissions. Information about other related challenges are found at: [Web Link]. The CLOP package includes sample code to process these data: [Web Link].All details about the preparation of the data are found in our technical report: Design of experiments for the NIPS 2003 variable selection benchmark, Isabelle Guyon, July 2003, [Web Link] (also included in the dataset archive). Such information was made available only after the end of the challenge.The data are split into training, validation, and test set. Target values are provided only for the 2 first sets. Test set performance results are obtained by submitting prediction results to: [Web Link].The data are in the following format:dataname.param: Parameters and statistics about the datadataname.feat: Identities of the features (withheld, to avoid biasing feature selection).dataname_train.data: Training set (a coma delimited regular matrix, patterns in lines, features in columns).dataname_valid.data: Validation set.dataname_test.data: Test set.dataname_train.labels: Labels (truth values of the classes) for training examples.dataname_valid.labels: Validation set labels (withheld during the benchmark, but provided now).dataname_test.labels: Test set labels (withheld, so the data can still be use as a benchmark). ",Life,We do not provide attribute information to avoid biasing the feature selection process. ,"ARCENE's task is to distinguish cancer versus normal patterns from mass-spectrometric data. This is a two-class classification problem with continuous input variables. This dataset is one of 5 datasets of the NIPS 2003 feature selection challenge.ARCENE was obtained by merging three mass-spectrometry datasets to obtain enough training and test data for a benchmark. The original features indicate the abundance of proteins in human sera having a given mass value. Based on those features one must separate cancer patients from healthy patients. We added a number of distractor feature called 'probes' having no predictive power. The order of the features and patterns were randomized.ARCENE -- Positive ex. -- Negative ex. -- TotalTraining set -- 44 -- 56 -- 100Validation set -- 44 -- 56 -- 100Test set -- 310 -- 390 -- 700All -- 398 -- 502 -- 900Number of variables/features/attributes:Real: 7000Probes: 3000Total: 10000This dataset is one of five datasets used in the NIPS 2003 feature selection challenge. Our website [Web Link] is still open for post-challenge submissions. Information about other related challenges are found at: [Web Link]. The CLOP package includes sample code to process these data: [Web Link].All details about the preparation of the data are found in our technical report: Design of experiments for the NIPS 2003 variable selection benchmark, Isabelle Guyon, July 2003, [Web Link] (also included in the dataset archive). Such information was made available only after the end of the challenge.The data are split into training, validation, and test set. Target values are provided only for the 2 first sets. Test set performance results are obtained by submitting prediction results to: [Web Link].The data are in the following format:dataname.param: Parameters and statistics about the datadataname.feat: Identities of the features (withheld, to avoid biasing feature selection).dataname_train.data: Training set (a coma delimited regular matrix, patterns in lines, features in columns).dataname_valid.data: Validation set.dataname_test.data: Test set.dataname_train.labels: Labels (truth values of the classes) for training examples.dataname_valid.labels: Validation set labels (withheld during the benchmark, but provided now).dataname_test.labels: Test set labels (withheld, so the data can still be use as a benchmark). We do not provide attribute information to avoid biasing the feature selection process. "
Shoulder Implant Manufacture Classification,Shoulder Implant Manufacture Classification,The multi-class classification data set consists of 597 de-identified raw images of X-ray scans showing implanted shoulder prostheses from four manufactures. ,Shoulder+Implant+Manufacture+Classification,https://archive.ics.uci.edu/ml//machine-learning-databases/00594/,https://archive.ics.uci.edu/ml/datasets/Shoulder+Implant+Manufacture+Classification,"Images are collected by Maya Stark at BIDAL Lab at SFSU for her MS thesis project. They are from The UW Shoulder Site ([Web Link]), manufacturer websites, and Feeley Lab at UCSF. The original collection included 605 X-ray images. Eight images that appeared to have been taken from the same patient were removed, resulting in the final 597 images. The final set contains 83 images from Cofield, 294 from Depuy, 71 from Tornier, and 149 from Zimmer, offering 4-class classification problem. Class labels are provided as the manufacturer name in file names. ",Life,Images are with 8-bit grayscale and various dimensions in jpeg format. ,"The multi-class classification data set consists of 597 de-identified raw images of X-ray scans showing implanted shoulder prostheses from four manufactures. Images are collected by Maya Stark at BIDAL Lab at SFSU for her MS thesis project. They are from The UW Shoulder Site ([Web Link]), manufacturer websites, and Feeley Lab at UCSF. The original collection included 605 X-ray images. Eight images that appeared to have been taken from the same patient were removed, resulting in the final 597 images. The final set contains 83 images from Cofield, 294 from Depuy, 71 from Tornier, and 149 from Zimmer, offering 4-class classification problem. Class labels are provided as the manufacturer name in file names. Images are with 8-bit grayscale and various dimensions in jpeg format. "
Shoulder Implant X-Ray Manufacturer Classification,Shoulder Implant X-Ray Manufacturer Classification,597 de-identified raw X-ray scans of implanted shoulder prostheses from four manufactures.,Shoulder+Implant+X-Ray+Manufacturer+Classification,https://archive.ics.uci.edu/ml//machine-learning-databases/00517/,https://archive.ics.uci.edu/ml/datasets/Shoulder+Implant+X-Ray+Manufacturer+Classification,"Images were collected by Maya Stark at BIDAL Lab at SFSU for her MS thesis project. They are from The UW Shoulder Site ([Web Link]), manufacturer websites, and Feeley Lab at UCSF. The original collection included 605 X-ray images. Eight images that appeared to have been taken from the same patients were removed, resulting in the final 597 images. The final set contains images from the following manufacturers: 83 from Cofield, 294 from Depuy, 71 from Tornier, and 149 from Zimmer, resulting in a 4-class classification problem. Class labels are provided as the manufacturer name in file names. ",Life,Images are with 8-bit grayscale and various dimensions in jpeg format. ,"597 de-identified raw X-ray scans of implanted shoulder prostheses from four manufactures.Images were collected by Maya Stark at BIDAL Lab at SFSU for her MS thesis project. They are from The UW Shoulder Site ([Web Link]), manufacturer websites, and Feeley Lab at UCSF. The original collection included 605 X-ray images. Eight images that appeared to have been taken from the same patients were removed, resulting in the final 597 images. The final set contains images from the following manufacturers: 83 from Cofield, 294 from Depuy, 71 from Tornier, and 149 from Zimmer, resulting in a 4-class classification problem. Class labels are provided as the manufacturer name in file names. Images are with 8-bit grayscale and various dimensions in jpeg format. "
Arrhythmia,Arrhythmia,Distinguish between the presence and absence of cardiac arrhythmia and classify it in one of the 16 groups.,Arrhythmia,https://archive.ics.uci.edu/ml//machine-learning-databases/arrhythmia/,https://archive.ics.uci.edu/ml/datasets/Arrhythmia,"This database contains 279 attributes, 206 of which are linear valued and the rest are nominal. Concerning the study of H. Altay Guvenir: ""The aim is to distinguish between the presence and absence of cardiac arrhythmia and to classify it in one of the 16 groups. Class 01 refers to 'normal' ECG classes 02 to 15 refers to different classes of arrhythmia and class 16 refers to the rest of unclassified ones. For the time being, there exists a computer program that makes such a classification. However there are differences between the cardiolog's and the programs classification. Taking the cardiolog's as a gold standard we aim to minimise this difference by means of machine learning tools.""The names and id numbers of the patients were recently removed from the database.",Life,"   -- Complete attribute documentation:      1 Age: Age in years , linear      2 Sex: Sex (0 = male; 1 = female) , nominal      3 Height: Height in centimeters , linear      4 Weight: Weight in kilograms , linear      5 QRS duration: Average of QRS duration in msec., linear      6 P-R interval: Average duration between onset of P and Q waves in msec., linear      7 Q-T interval: Average duration between onset of Q and offset of T waves in msec., linear      8 T interval: Average duration of T wave in msec., linear      9 P interval: Average duration of P wave in msec., linear      Vector angles in degrees on front plane of:, linear     10 QRS     11 T     12 P     13 QRST     14 J     15 Heart rate: Number of heart beats per minute ,linear         Of channel DI:      Average width, in msec., of: linear      16 Q wave      17 R wave      18 S wave      19 R' wave, small peak just after R      20 S' wave      21 Number of intrinsic deflections, linear      22 Existence of ragged R wave, nominal      23 Existence of diphasic derivation of R wave, nominal      24 Existence of ragged P wave, nominal      25 Existence of diphasic derivation of P wave, nominal      26 Existence of ragged T wave, nominal      27 Existence of diphasic derivation of T wave, nominal     Of channel DII:       28 .. 39 (similar to 16 .. 27 of channel DI)     Of channels DIII:      40 .. 51     Of channel AVR:      52 .. 63     Of channel AVL:      64 .. 75     Of channel AVF:      76 .. 87     Of channel V1:      88 .. 99     Of channel V2:      100 .. 111     Of channel V3:      112 .. 123     Of channel V4:      124 .. 135     Of channel V5:      136 .. 147     Of channel V6:      148 .. 159     Of channel DI:      Amplitude , * 0.1 milivolt, of      160 JJ wave, linear      161 Q wave, linear      162 R wave, linear      163 S wave, linear      164 R' wave, linear      165 S' wave, linear      166 P wave, linear      167 T wave, linear            168 QRSA , Sum of areas of all segments divided by 10, ( Area= width * height / 2 ), linear      169 QRSTA = QRSA + 0.5 * width of T wave * 0.1 * height of T wave. (If T is diphasic then the bigger segment is considered), linear     Of channel DII:      170 .. 179     Of channel DIII:      180 .. 189     Of channel AVR:      190 .. 199     Of channel AVL:      200 .. 209     Of channel AVF:      210 .. 219     Of channel V1:      220 .. 229     Of channel V2:      230 .. 239     Of channel V3:      240 .. 249     Of channel V4:      250 .. 259     Of channel V5:      260 .. 269     Of channel V6:      270 .. 279","Distinguish between the presence and absence of cardiac arrhythmia and classify it in one of the 16 groups.This database contains 279 attributes, 206 of which are linear valued and the rest are nominal. Concerning the study of H. Altay Guvenir: ""The aim is to distinguish between the presence and absence of cardiac arrhythmia and to classify it in one of the 16 groups. Class 01 refers to 'normal' ECG classes 02 to 15 refers to different classes of arrhythmia and class 16 refers to the rest of unclassified ones. For the time being, there exists a computer program that makes such a classification. However there are differences between the cardiolog's and the programs classification. Taking the cardiolog's as a gold standard we aim to minimise this difference by means of machine learning tools.""The names and id numbers of the patients were recently removed from the database.   -- Complete attribute documentation:      1 Age: Age in years , linear      2 Sex: Sex (0 = male; 1 = female) , nominal      3 Height: Height in centimeters , linear      4 Weight: Weight in kilograms , linear      5 QRS duration: Average of QRS duration in msec., linear      6 P-R interval: Average duration between onset of P and Q waves in msec., linear      7 Q-T interval: Average duration between onset of Q and offset of T waves in msec., linear      8 T interval: Average duration of T wave in msec., linear      9 P interval: Average duration of P wave in msec., linear      Vector angles in degrees on front plane of:, linear     10 QRS     11 T     12 P     13 QRST     14 J     15 Heart rate: Number of heart beats per minute ,linear         Of channel DI:      Average width, in msec., of: linear      16 Q wave      17 R wave      18 S wave      19 R' wave, small peak just after R      20 S' wave      21 Number of intrinsic deflections, linear      22 Existence of ragged R wave, nominal      23 Existence of diphasic derivation of R wave, nominal      24 Existence of ragged P wave, nominal      25 Existence of diphasic derivation of P wave, nominal      26 Existence of ragged T wave, nominal      27 Existence of diphasic derivation of T wave, nominal     Of channel DII:       28 .. 39 (similar to 16 .. 27 of channel DI)     Of channels DIII:      40 .. 51     Of channel AVR:      52 .. 63     Of channel AVL:      64 .. 75     Of channel AVF:      76 .. 87     Of channel V1:      88 .. 99     Of channel V2:      100 .. 111     Of channel V3:      112 .. 123     Of channel V4:      124 .. 135     Of channel V5:      136 .. 147     Of channel V6:      148 .. 159     Of channel DI:      Amplitude , * 0.1 milivolt, of      160 JJ wave, linear      161 Q wave, linear      162 R wave, linear      163 S wave, linear      164 R' wave, linear      165 S' wave, linear      166 P wave, linear      167 T wave, linear            168 QRSA , Sum of areas of all segments divided by 10, ( Area= width * height / 2 ), linear      169 QRSTA = QRSA + 0.5 * width of T wave * 0.1 * height of T wave. (If T is diphasic then the bigger segment is considered), linear     Of channel DII:      170 .. 179     Of channel DIII:      180 .. 189     Of channel AVR:      190 .. 199     Of channel AVL:      200 .. 209     Of channel AVF:      210 .. 219     Of channel V1:      220 .. 229     Of channel V2:      230 .. 239     Of channel V3:      240 .. 249     Of channel V4:      250 .. 259     Of channel V5:      260 .. 269     Of channel V6:      270 .. 279"
Simulated data for survival modelling,Simulated data for survival modelling,"A variety of survival data, with carefully controlled event and censor rates, is available to allow people to develop and test new approaches to survival modelling.",Simulated+data+for+survival+modelling,https://archive.ics.uci.edu/ml//machine-learning-databases/00581/,https://archive.ics.uci.edu/ml/datasets/Simulated+data+for+survival+modelling,"We generated two batches of data, where each batch consists of 20 datasets. For the low dimensional batch, we used 5 predictive parameters, of which 2 were dummy parameters (i.e. had no impact) and three were predictive. For the medium dimension batch, we used 25 predictors, of which 2 were dummy and 23 predictive.In each batch, we varied the event rate from 10% to 70% and the censor rate from 0% to 70% in 20% steps, and used a set population size of 3000.This therefore led to two batches, each of 20 datasets of 3000 subjects.",Life,"For the low dimensional batch:x.0 & Binary: with equal probabilitiesx.1 & Gaussian: ÃŽÂ¼ = 50, Ã�Æ’ = 15x.2 & Uniform: [1,2,3,4]x.3 & Binary: 0.6 chance of 0x.4 & Uniform: [1,2,3]For the medium dimension batch:x.0  & Binary: with equal probabilitiesx.1  & Gaussian: ÃŽÂ¼ = 50, Ã�Æ’ = 15x.2  & Uniform: [1,2,3,4]x.3  & Binary: 0.6 chance of 0x.4  & Uniform: [1,2,3]x.5  & Binary: 0.95 chance of 0x.6  & Binary: 0.9 chance of 0x.7  & Binary: 0.85 chance of 0x.8  & Binary: 0.8 chance of 0x.9  & Binary: 0.75 chance of 0x.10 & Binary: 0.7 chance of 0x.11 & Binary: 0.65 chance of 0x.12 & Binary: 0.6 chance of 0x.13 & Binary: 0.55 chance of 0x.14 & Binary: 0.5 chance of 0x.15 & Binary: 0.5 chance of 0x.16 & Binary: 0.45 chance of 0x.17 & Binary: 0.4 chance of 0x.18 & Binary: 0.35 chance of 0x.19 & Binary: 0.3 chance of 0x.20 & Binary: 0.25 chance of 0x.21 & Binary: 0.2 chance of 0x.22 & Binary: 0.15 chance of 0x.23 & Binary: 0.1 chance of 0x.24 & Binary: 0.05 chance of 0","A variety of survival data, with carefully controlled event and censor rates, is available to allow people to develop and test new approaches to survival modelling.We generated two batches of data, where each batch consists of 20 datasets. For the low dimensional batch, we used 5 predictive parameters, of which 2 were dummy parameters (i.e. had no impact) and three were predictive. For the medium dimension batch, we used 25 predictors, of which 2 were dummy and 23 predictive.In each batch, we varied the event rate from 10% to 70% and the censor rate from 0% to 70% in 20% steps, and used a set population size of 3000.This therefore led to two batches, each of 20 datasets of 3000 subjects.For the low dimensional batch:x.0 & Binary: with equal probabilitiesx.1 & Gaussian: ÃŽÂ¼ = 50, Ã�Æ’ = 15x.2 & Uniform: [1,2,3,4]x.3 & Binary: 0.6 chance of 0x.4 & Uniform: [1,2,3]For the medium dimension batch:x.0  & Binary: with equal probabilitiesx.1  & Gaussian: ÃŽÂ¼ = 50, Ã�Æ’ = 15x.2  & Uniform: [1,2,3,4]x.3  & Binary: 0.6 chance of 0x.4  & Uniform: [1,2,3]x.5  & Binary: 0.95 chance of 0x.6  & Binary: 0.9 chance of 0x.7  & Binary: 0.85 chance of 0x.8  & Binary: 0.8 chance of 0x.9  & Binary: 0.75 chance of 0x.10 & Binary: 0.7 chance of 0x.11 & Binary: 0.65 chance of 0x.12 & Binary: 0.6 chance of 0x.13 & Binary: 0.55 chance of 0x.14 & Binary: 0.5 chance of 0x.15 & Binary: 0.5 chance of 0x.16 & Binary: 0.45 chance of 0x.17 & Binary: 0.4 chance of 0x.18 & Binary: 0.35 chance of 0x.19 & Binary: 0.3 chance of 0x.20 & Binary: 0.25 chance of 0x.21 & Binary: 0.2 chance of 0x.22 & Binary: 0.15 chance of 0x.23 & Binary: 0.1 chance of 0x.24 & Binary: 0.05 chance of 0"
Simulated Falls and Daily Living Activities Data Set,Simulated Falls and Daily Living Activities Data Set,"20 falls and 16 daily living activities were performed by 17 volunteers with 5 repetitions while wearing 6 sensors (3.060 instances) that attached to their head, chest, waist, wrist, thigh and ankle.",Simulated+Falls+and+Daily+Living+Activities+Data+Set,https://archive.ics.uci.edu/ml//machine-learning-databases/00455/,https://archive.ics.uci.edu/ml/datasets/Simulated+Falls+and+Daily+Living+Activities+Data+Set,Provide all relevant information about your data set.,Life,Provide information about each attribute in your data set.,"20 falls and 16 daily living activities were performed by 17 volunteers with 5 repetitions while wearing 6 sensors (3.060 instances) that attached to their head, chest, waist, wrist, thigh and ankle.Provide all relevant information about your data set.Provide information about each attribute in your data set."
Audiology (Original),Audiology (Original),Nominal audiology dataset from Baylor,Audiology+%28Original%29,https://archive.ics.uci.edu/ml//machine-learning-databases/audiology/,https://archive.ics.uci.edu/ml/datasets/Audiology+%28Original%29,"This database does NOT use a standard set of attributes per instance.Contact Ray Bareiss (rbareiss '@' uunet.uucp ?) for more information.Domain expert: Professor Craig Wier of the University of Texas, Austin.",Life,"(all attributes are nominally valued)   1. case identifier.   2. classification (24 classes)   3. List of case features      -- format: form f(v) should be read as ""feature f has value v""","Nominal audiology dataset from BaylorThis database does NOT use a standard set of attributes per instance.Contact Ray Bareiss (rbareiss '@' uunet.uucp ?) for more information.Domain expert: Professor Craig Wier of the University of Texas, Austin.(all attributes are nominally valued)   1. case identifier.   2. classification (24 classes)   3. List of case features      -- format: form f(v) should be read as ""feature f has value v"""
Audiology (Standardized),Audiology (Standardized),Standardized version of the original audiology database,Audiology+%28Standardized%29,https://archive.ics.uci.edu/ml//machine-learning-databases/audiology/,https://archive.ics.uci.edu/ml/datasets/Audiology+%28Standardized%29,"This database is a standardized version of the original audiology database (see audiology.* in this directory).  The non-standard set of attributes have been converted to a standard set of attributes according to the rules that follow.* Each property that appears anywhere in the original .data or .test file has been represented as a separate attribute in this file.* A property such as age_gt_60 is represented as a boolean attribute with values f and t.* In most cases, a property of the form x(y) is represented as a discrete attribute x() whose possible values are the various y's; air() is an example.  There are two exceptions:** when only one value of y appears anywhere, e.g. static(normal). In this case, x_y appears as a boolean attribute.** when one case can have two or more values of x, e.g. history(..). All possible values of history are treated as separate boolean attributes.* Since boolean attributes only appear as positive conditions, each boolean attribute is assumed to be false unless noted as true.  The value of multi-value discrete attributes taken as unknown (""?"") unless a value is specified.* The original case identifications, p1 to p200 in the .data file and t1 to t26 in the .test file, have been added as a unique identifier attribute. [Note: in the original .data file, p165 has a repeated specification of o_ar_c(normal); p166 has repeated specification of speech(normal) and conflicting values air(moderate) and air(mild).  No other problems with the original data were noted.]",Life,"   age_gt_60:		     f, t.   air():		     mild,moderate,severe,normal,profound.   airBoneGap:		     f, t.   ar_c():		     normal,elevated,absent.   ar_u():		     normal,absent,elevated.   bone():		     mild,moderate,normal,unmeasured.   boneAbnormal:	     f, t.   bser():		     normal,degraded.   history_buzzing:	     f, t.   history_dizziness:	     f, t.   history_fluctuating:	     f, t.   history_fullness:	     f, t.   history_heredity:	     f, t.   history_nausea:	     f, t.   history_noise:	     f, t.   history_recruitment:	     f, t.   history_ringing:	     f, t.   history_roaring:	     f, t.   history_vomiting:	     f, t.   late_wave_poor:	     f, t.   m_at_2k:		     f, t.   m_cond_lt_1k:	     f, t.   m_gt_1k:		     f, t.   m_m_gt_2k:		     f, t.   m_m_sn:		     f, t.   m_m_sn_gt_1k:	     f, t.   m_m_sn_gt_2k:	     f, t.   m_m_sn_gt_500:	     f, t.   m_p_sn_gt_2k:	     f, t.   m_s_gt_500:		     f, t.   m_s_sn:		     f, t.   m_s_sn_gt_1k:	     f, t.   m_s_sn_gt_2k:	     f, t.   m_s_sn_gt_3k:	     f, t.   m_s_sn_gt_4k:	     f, t.   m_sn_2_3k:		     f, t.   m_sn_gt_1k:		     f, t.   m_sn_gt_2k:		     f, t.   m_sn_gt_3k:		     f, t.   m_sn_gt_4k:		     f, t.   m_sn_gt_500:		     f, t.   m_sn_gt_6k:		     f, t.   m_sn_lt_1k:		     f, t.    m_sn_lt_2k:		     f, t.   m_sn_lt_3k:		     f, t.   middle_wave_poor:	     f, t.   mod_gt_4k:		     f, t.   mod_mixed:		     f, t.   mod_s_mixed:		     f, t.   mod_s_sn_gt_500:	     f, t.   mod_sn:		     f, t.   mod_sn_gt_1k:	     f, t.   mod_sn_gt_2k:	     f, t.   mod_sn_gt_3k:	     f, t.   mod_sn_gt_4k:	     f, t.   mod_sn_gt_500:	     f, t.   notch_4k:		     f, t.   notch_at_4k:		     f, t.   o_ar_c():		     normal,elevated,absent.   o_ar_u():		     normal,absent,elevated.   s_sn_gt_1k:		     f, t.   s_sn_gt_2k:		     f, t.   s_sn_gt_4k:		     f, t.   speech():		     normal,good,very_good,very_poor,poor,unmeasured.   static_normal:	     f, t.   tymp():		     a,as,b,ad,c.   viith_nerve_signs:        f, t.   wave_V_delayed:	     f, t.   waveform_ItoV_prolonged:  f, t.   indentifier               (unique for each instance)   class:                                               cochlear_unknown,mixed_cochlear_age_fixation,poss_central                             mixed_cochlear_age_otitis_media,mixed_poss_noise_om,                             cochlear_age,normal_ear,cochlear_poss_noise,cochlear_age_and_noise,                             acoustic_neuroma,mixed_cochlear_unk_ser_om,conductive_discontinuity,                             retrocochlear_unknown,conductive_fixation,bells_palsy,                             cochlear_noise_and_heredity,mixed_cochlear_unk_fixation,                             otitis_media,possible_menieres,possible_brainstem_disorder,                             cochlear_age_plus_poss_menieres,mixed_cochlear_age_s_om,                             mixed_cochlear_unk_discontinuity,mixed_poss_central_om","Standardized version of the original audiology databaseThis database is a standardized version of the original audiology database (see audiology.* in this directory).  The non-standard set of attributes have been converted to a standard set of attributes according to the rules that follow.* Each property that appears anywhere in the original .data or .test file has been represented as a separate attribute in this file.* A property such as age_gt_60 is represented as a boolean attribute with values f and t.* In most cases, a property of the form x(y) is represented as a discrete attribute x() whose possible values are the various y's; air() is an example.  There are two exceptions:** when only one value of y appears anywhere, e.g. static(normal). In this case, x_y appears as a boolean attribute.** when one case can have two or more values of x, e.g. history(..). All possible values of history are treated as separate boolean attributes.* Since boolean attributes only appear as positive conditions, each boolean attribute is assumed to be false unless noted as true.  The value of multi-value discrete attributes taken as unknown (""?"") unless a value is specified.* The original case identifications, p1 to p200 in the .data file and t1 to t26 in the .test file, have been added as a unique identifier attribute. [Note: in the original .data file, p165 has a repeated specification of o_ar_c(normal); p166 has repeated specification of speech(normal) and conflicting values air(moderate) and air(mild).  No other problems with the original data were noted.]   age_gt_60:		     f, t.   air():		     mild,moderate,severe,normal,profound.   airBoneGap:		     f, t.   ar_c():		     normal,elevated,absent.   ar_u():		     normal,absent,elevated.   bone():		     mild,moderate,normal,unmeasured.   boneAbnormal:	     f, t.   bser():		     normal,degraded.   history_buzzing:	     f, t.   history_dizziness:	     f, t.   history_fluctuating:	     f, t.   history_fullness:	     f, t.   history_heredity:	     f, t.   history_nausea:	     f, t.   history_noise:	     f, t.   history_recruitment:	     f, t.   history_ringing:	     f, t.   history_roaring:	     f, t.   history_vomiting:	     f, t.   late_wave_poor:	     f, t.   m_at_2k:		     f, t.   m_cond_lt_1k:	     f, t.   m_gt_1k:		     f, t.   m_m_gt_2k:		     f, t.   m_m_sn:		     f, t.   m_m_sn_gt_1k:	     f, t.   m_m_sn_gt_2k:	     f, t.   m_m_sn_gt_500:	     f, t.   m_p_sn_gt_2k:	     f, t.   m_s_gt_500:		     f, t.   m_s_sn:		     f, t.   m_s_sn_gt_1k:	     f, t.   m_s_sn_gt_2k:	     f, t.   m_s_sn_gt_3k:	     f, t.   m_s_sn_gt_4k:	     f, t.   m_sn_2_3k:		     f, t.   m_sn_gt_1k:		     f, t.   m_sn_gt_2k:		     f, t.   m_sn_gt_3k:		     f, t.   m_sn_gt_4k:		     f, t.   m_sn_gt_500:		     f, t.   m_sn_gt_6k:		     f, t.   m_sn_lt_1k:		     f, t.    m_sn_lt_2k:		     f, t.   m_sn_lt_3k:		     f, t.   middle_wave_poor:	     f, t.   mod_gt_4k:		     f, t.   mod_mixed:		     f, t.   mod_s_mixed:		     f, t.   mod_s_sn_gt_500:	     f, t.   mod_sn:		     f, t.   mod_sn_gt_1k:	     f, t.   mod_sn_gt_2k:	     f, t.   mod_sn_gt_3k:	     f, t.   mod_sn_gt_4k:	     f, t.   mod_sn_gt_500:	     f, t.   notch_4k:		     f, t.   notch_at_4k:		     f, t.   o_ar_c():		     normal,elevated,absent.   o_ar_u():		     normal,absent,elevated.   s_sn_gt_1k:		     f, t.   s_sn_gt_2k:		     f, t.   s_sn_gt_4k:		     f, t.   speech():		     normal,good,very_good,very_poor,poor,unmeasured.   static_normal:	     f, t.   tymp():		     a,as,b,ad,c.   viith_nerve_signs:        f, t.   wave_V_delayed:	     f, t.   waveform_ItoV_prolonged:  f, t.   indentifier               (unique for each instance)   class:                                               cochlear_unknown,mixed_cochlear_age_fixation,poss_central                             mixed_cochlear_age_otitis_media,mixed_poss_noise_om,                             cochlear_age,normal_ear,cochlear_poss_noise,cochlear_age_and_noise,                             acoustic_neuroma,mixed_cochlear_unk_ser_om,conductive_discontinuity,                             retrocochlear_unknown,conductive_fixation,bells_palsy,                             cochlear_noise_and_heredity,mixed_cochlear_unk_fixation,                             otitis_media,possible_menieres,possible_brainstem_disorder,                             cochlear_age_plus_poss_menieres,mixed_cochlear_age_s_om,                             mixed_cochlear_unk_discontinuity,mixed_poss_central_om"
Bar Crawl: Detecting Heavy Drinking,Bar Crawl: Detecting Heavy Drinking,Accelerometer and transdermal alcohol content data from a college bar crawl. Used to predict heavy drinking episodes via mobile data.,Bar+Crawl%3A+Detecting+Heavy+Drinking,https://archive.ics.uci.edu/ml//machine-learning-databases/00515/,https://archive.ics.uci.edu/ml/datasets/Bar+Crawl%3A+Detecting+Heavy+Drinking,"Relevant Information:    All data is fully anonymized.    Data was originally collected from 19 participants, but the TAC readings of 6 participants were deemed unusable by SCRAM [1]. The data included is from the remaining 13 participants.       Accelerometer data was collected from smartphones at a sampling rate of 40Hz (file: all_accelerometer_data_pids_13.csv). The file contains 5 columns: a timestamp, a participant ID, and a sample from each axis of the accelerometer. Data was collected from a mix of 11 iPhones and 2 Android phones as noted in phone_types.csv. TAC data was collected using SCRAM [2] ankle bracelets and was collected at 30 minute intervals. The raw TAC readings are in the raw_tac directory. TAC readings which are more readily usable for processing are in clean_tac directory and have two columns: a timestamp and TAC reading. The cleaned TAC readings: (1) were processed with a zero-phase low-pass filter to smooth noise without shifting phase; (2) were shifted backwards by 45 minutes so the labels more closely match the true intoxication of the participant (since alcohol takes about 45 minutes to exit through the skin.) Please see the above referenced study for more details on how the data was processed ([Web Link]).    1 - [Web Link]    2 - J. Robert Zettl. The determination of blood alcohol concentration by transdermal measurement. [Web Link], 2002.Number of Instances:    Accelerometer readings: 14,057,567    TAC readings: 715    Participants: 13Number of Attributes:    - Time series: 3 axes of accelerometer data (columns x, y, z in all_accelerometer_data_pids_13.csv)    - Static: 1 phone-type feature (in phone_types.csv)    - Target: 1 time series of TAC for each of the 13 participants (in clean_tac directory).For Each Attribute:    (Main)    all_accelerometer_data_pids_13.csv:        time: integer, unix timestamp, milliseconds        pid: symbolic, 13 categories listed in pids.txt         x: continuous, time-series        y: continuous, time-series        z: continuous, time-series    clean_tac/*.csv:        timestamp: integer, unix timestamp, seconds        TAC_Reading: continuous, time-series    phone_type.csv:        pid: symbolic, 13 categories listed in pids.txt         phonetype: symbolic, 2 categories (iPhone, Android)        (Other)    raw/*.xlsx:        TAC Level: continuous, time-series        IR Voltage: continuous, time-series        Temperature: continuous, time-series        Time: datetime        Date: datetimeMissing Attribute Values:NoneTarget Distribution:    TAC is measured in g/dl where 0.08 is the legal limit for intoxication while driving    Mean TAC: 0.065 +/- 0.182    Max TAC: 0.443    TAC Inner Quartiles: 0.002, 0.029, 0.092    Mean Time-to-last-drink: 16.1 +/- 6.9 hrs",Life,Provide information about each attribute in your data set.,"Accelerometer and transdermal alcohol content data from a college bar crawl. Used to predict heavy drinking episodes via mobile data.Relevant Information:    All data is fully anonymized.    Data was originally collected from 19 participants, but the TAC readings of 6 participants were deemed unusable by SCRAM [1]. The data included is from the remaining 13 participants.       Accelerometer data was collected from smartphones at a sampling rate of 40Hz (file: all_accelerometer_data_pids_13.csv). The file contains 5 columns: a timestamp, a participant ID, and a sample from each axis of the accelerometer. Data was collected from a mix of 11 iPhones and 2 Android phones as noted in phone_types.csv. TAC data was collected using SCRAM [2] ankle bracelets and was collected at 30 minute intervals. The raw TAC readings are in the raw_tac directory. TAC readings which are more readily usable for processing are in clean_tac directory and have two columns: a timestamp and TAC reading. The cleaned TAC readings: (1) were processed with a zero-phase low-pass filter to smooth noise without shifting phase; (2) were shifted backwards by 45 minutes so the labels more closely match the true intoxication of the participant (since alcohol takes about 45 minutes to exit through the skin.) Please see the above referenced study for more details on how the data was processed ([Web Link]).    1 - [Web Link]    2 - J. Robert Zettl. The determination of blood alcohol concentration by transdermal measurement. [Web Link], 2002.Number of Instances:    Accelerometer readings: 14,057,567    TAC readings: 715    Participants: 13Number of Attributes:    - Time series: 3 axes of accelerometer data (columns x, y, z in all_accelerometer_data_pids_13.csv)    - Static: 1 phone-type feature (in phone_types.csv)    - Target: 1 time series of TAC for each of the 13 participants (in clean_tac directory).For Each Attribute:    (Main)    all_accelerometer_data_pids_13.csv:        time: integer, unix timestamp, milliseconds        pid: symbolic, 13 categories listed in pids.txt         x: continuous, time-series        y: continuous, time-series        z: continuous, time-series    clean_tac/*.csv:        timestamp: integer, unix timestamp, seconds        TAC_Reading: continuous, time-series    phone_type.csv:        pid: symbolic, 13 categories listed in pids.txt         phonetype: symbolic, 2 categories (iPhone, Android)        (Other)    raw/*.xlsx:        TAC Level: continuous, time-series        IR Voltage: continuous, time-series        Temperature: continuous, time-series        Time: datetime        Date: datetimeMissing Attribute Values:NoneTarget Distribution:    TAC is measured in g/dl where 0.08 is the legal limit for intoxication while driving    Mean TAC: 0.065 +/- 0.182    Max TAC: 0.443    TAC Inner Quartiles: 0.002, 0.029, 0.092    Mean Time-to-last-drink: 16.1 +/- 6.9 hrsProvide information about each attribute in your data set."
Sepsis survival minimal clinical records,Sepsis survival minimal clinical records,"This dataset collection contains minimal health records of 110,204 admissions (primary cohort), 19,051 admissions (study cohort), and 137 admissions (validation cohort) of patients who had sepsis. 
",Sepsis+survival+minimal+clinical+records,https://archive.ics.uci.edu/ml//machine-learning-databases/00628/,https://archive.ics.uci.edu/ml/datasets/Sepsis+survival+minimal+clinical+records,"Primary cohort from Norway:4 features for 110,204 patient admissionsfile: 's41598-020-73558-3_sepsis_survival_primary_cohort.csv'Study cohort (subset of the primary cohort) from Norway:4 features for 19,051 patient admissionsfile: 's41598-020-73558-3_sepsis_survival_study_cohort.csv'Validation cohort from South Korea:4 features for 137 patientsfile: 's41598-020-73558-3_sepsis_survival_validation_cohort.csv'A detailed description of the datasets can be found in the Datasets section of the following article: Davide Chicco, Giuseppe Jurman, Ã¢â‚¬Å“Survival prediction of patients with sepsis from age, sex, and septic episode number aloneÃ¢â‚¬Â�. Scientific Reports 10, 17156 (2020). [Web Link] ",Life,"Four (4) clinical features:- age_years: integer- sex_0male_1female: binary- episode_number: integer- hospital_outcome_1alive_0dead: booleanA detailed description of the datasets features can be found in the Datasets section of the following article: Davide Chicco, Giuseppe Jurman, Ã¢â‚¬Å“Survival prediction of patients with sepsis from age, sex, and septic episode number aloneÃ¢â‚¬Â�. Scientific Reports 10, 17156 (2020). [Web Link] ","This dataset collection contains minimal health records of 110,204 admissions (primary cohort), 19,051 admissions (study cohort), and 137 admissions (validation cohort) of patients who had sepsis. 
Primary cohort from Norway:4 features for 110,204 patient admissionsfile: 's41598-020-73558-3_sepsis_survival_primary_cohort.csv'Study cohort (subset of the primary cohort) from Norway:4 features for 19,051 patient admissionsfile: 's41598-020-73558-3_sepsis_survival_study_cohort.csv'Validation cohort from South Korea:4 features for 137 patientsfile: 's41598-020-73558-3_sepsis_survival_validation_cohort.csv'A detailed description of the datasets can be found in the Datasets section of the following article: Davide Chicco, Giuseppe Jurman, Ã¢â‚¬Å“Survival prediction of patients with sepsis from age, sex, and septic episode number aloneÃ¢â‚¬Â�. Scientific Reports 10, 17156 (2020). [Web Link] Four (4) clinical features:- age_years: integer- sex_0male_1female: binary- episode_number: integer- hospital_outcome_1alive_0dead: booleanA detailed description of the datasets features can be found in the Datasets section of the following article: Davide Chicco, Giuseppe Jurman, Ã¢â‚¬Å“Survival prediction of patients with sepsis from age, sex, and septic episode number aloneÃ¢â‚¬Â�. Scientific Reports 10, 17156 (2020). [Web Link] "
Smartphone-Based Recognition of Human Activities and Postural Transitions,Smartphone-Based Recognition of Human Activities and Postural Transitions,"Activity recognition data set built from the recordings of 30 subjects performing basic activities and postural transitions while carrying a waist-mounted smartphone with embedded inertial sensors.
",Smartphone-Based+Recognition+of+Human+Activities+and+Postural+Transitions,https://archive.ics.uci.edu/ml//machine-learning-databases/00341/,https://archive.ics.uci.edu/ml/datasets/Smartphone-Based+Recognition+of+Human+Activities+and+Postural+Transitions,"The experiments were carried out with a group of 30 volunteers within an age bracket of 19-48 years. They performed a protocol of activities composed of six basic activities: three static postures (standing, sitting, lying) and three dynamic activities (walking, walking downstairs and walking upstairs). The experiment also included postural transitions that occurred between the static postures. These are: stand-to-sit, sit-to-stand, sit-to-lie, lie-to-sit, stand-to-lie, and lie-to-stand. All the participants were wearing a smartphone (Samsung Galaxy S II) on the waist during the experiment execution. We captured 3-axial linear acceleration and 3-axial angular velocity at a constant rate of 50Hz using the embedded accelerometer and gyroscope of the device. The experiments were video-recorded to label the data manually. The obtained dataset was randomly partitioned into two sets, where 70% of the volunteers was selected for generating the training data and 30% the test data. The sensor signals (accelerometer and gyroscope) were pre-processed by applying noise filters and then sampled in fixed-width sliding windows of 2.56 sec and 50% overlap (128 readings/window). The sensor acceleration signal, which has gravitational and body motion components, was separated using a Butterworth low-pass filter into body acceleration and gravity. The gravitational force is assumed to have only low frequency components, therefore a filter with 0.3 Hz cutoff frequency was used. From each window, a vector of 561 features was obtained by calculating variables from the time and frequency domain. See 'features_info.txt' for more details. This dataset is an updated version of the UCI Human Activity Recognition Using smartphones Dataset that can be found at: [Web Link]This version provides the original raw inertial signals from the smartphone sensors, instead of the ones pre-processed into windows which were provided in version 1. This change was done in order to be able to make online tests with the raw data. Moreover, the activity labels were updated in order to include postural transitions that were not part of the previous version of the dataset. ",Life,"The dataset is then divided in two parts and they can be used separately.  1. Inertial sensor data - Raw triaxial signals from the accelerometer and gyroscope of all the trials with with participants. - The labels of all the performed activities.  2. Records of activity windows. Each one composed of:- A 561-feature vector with time and frequency domain variables. - Its associated activity label. - An identifier of the subject who carried out the experiment.The dataset includes the following files:=========================================- 'README.txt'- '[Web Link]': The raw triaxial acceleration signal for the experiment number XX and associated to the user number YY. Every row is one acceleration sample (three axis) captured at a frequency of 50Hz. - '[Web Link]': The raw triaxial angular speed signal for the experiment number XX and associated to the user number YY. Every row is one angular velocity sample (three axis) captured at a frequency of 50Hz. - '[Web Link]': include all the activity labels available for the dataset (1 per row).    Column 1: experiment number ID,    Column 2: user number ID,    Column 3: activity number ID    Column 4: Label start point (in number of signal log samples (recorded at 50Hz))   Column 5: Label end point (in number of signal log samples)- 'features_info.txt': Shows information about the variables used on the feature vector.- 'features.txt': List of all features.- 'activity_labels.txt': Links the activity ID with their activity name.- '[Web Link]': Training set.- '[Web Link]': Training labels.- '[Web Link]': Test set.- '[Web Link]': Test labels.- '[Web Link]': Each row identifies the subject who performed the activity for each window sample. Its range is from 1 to 30. - '[Web Link]': Each row identifies the subject who performed the activity for each window sample. Its range is from 1 to 30. Notes: ======- Features are normalized and bounded within [-1,1].- Each feature vector is a row on the 'X' and 'y' files.- The units used for the accelerations (total and body) are 'g's (gravity of earth -> 9.80665 m/seg2).- The gyroscope units are rad/seg.- A video of the experiment including an example of the 6 recorded activities with one of the participants can be seen in the following link: [Web Link]For more information about this dataset please contact har '@' smartlab.ws or check our website www.smartlab.ws","Activity recognition data set built from the recordings of 30 subjects performing basic activities and postural transitions while carrying a waist-mounted smartphone with embedded inertial sensors.
The experiments were carried out with a group of 30 volunteers within an age bracket of 19-48 years. They performed a protocol of activities composed of six basic activities: three static postures (standing, sitting, lying) and three dynamic activities (walking, walking downstairs and walking upstairs). The experiment also included postural transitions that occurred between the static postures. These are: stand-to-sit, sit-to-stand, sit-to-lie, lie-to-sit, stand-to-lie, and lie-to-stand. All the participants were wearing a smartphone (Samsung Galaxy S II) on the waist during the experiment execution. We captured 3-axial linear acceleration and 3-axial angular velocity at a constant rate of 50Hz using the embedded accelerometer and gyroscope of the device. The experiments were video-recorded to label the data manually. The obtained dataset was randomly partitioned into two sets, where 70% of the volunteers was selected for generating the training data and 30% the test data. The sensor signals (accelerometer and gyroscope) were pre-processed by applying noise filters and then sampled in fixed-width sliding windows of 2.56 sec and 50% overlap (128 readings/window). The sensor acceleration signal, which has gravitational and body motion components, was separated using a Butterworth low-pass filter into body acceleration and gravity. The gravitational force is assumed to have only low frequency components, therefore a filter with 0.3 Hz cutoff frequency was used. From each window, a vector of 561 features was obtained by calculating variables from the time and frequency domain. See 'features_info.txt' for more details. This dataset is an updated version of the UCI Human Activity Recognition Using smartphones Dataset that can be found at: [Web Link]This version provides the original raw inertial signals from the smartphone sensors, instead of the ones pre-processed into windows which were provided in version 1. This change was done in order to be able to make online tests with the raw data. Moreover, the activity labels were updated in order to include postural transitions that were not part of the previous version of the dataset. The dataset is then divided in two parts and they can be used separately.  1. Inertial sensor data - Raw triaxial signals from the accelerometer and gyroscope of all the trials with with participants. - The labels of all the performed activities.  2. Records of activity windows. Each one composed of:- A 561-feature vector with time and frequency domain variables. - Its associated activity label. - An identifier of the subject who carried out the experiment.The dataset includes the following files:=========================================- 'README.txt'- '[Web Link]': The raw triaxial acceleration signal for the experiment number XX and associated to the user number YY. Every row is one acceleration sample (three axis) captured at a frequency of 50Hz. - '[Web Link]': The raw triaxial angular speed signal for the experiment number XX and associated to the user number YY. Every row is one angular velocity sample (three axis) captured at a frequency of 50Hz. - '[Web Link]': include all the activity labels available for the dataset (1 per row).    Column 1: experiment number ID,    Column 2: user number ID,    Column 3: activity number ID    Column 4: Label start point (in number of signal log samples (recorded at 50Hz))   Column 5: Label end point (in number of signal log samples)- 'features_info.txt': Shows information about the variables used on the feature vector.- 'features.txt': List of all features.- 'activity_labels.txt': Links the activity ID with their activity name.- '[Web Link]': Training set.- '[Web Link]': Training labels.- '[Web Link]': Test set.- '[Web Link]': Test labels.- '[Web Link]': Each row identifies the subject who performed the activity for each window sample. Its range is from 1 to 30. - '[Web Link]': Each row identifies the subject who performed the activity for each window sample. Its range is from 1 to 30. Notes: ======- Features are normalized and bounded within [-1,1].- Each feature vector is a row on the 'X' and 'y' files.- The units used for the accelerations (total and body) are 'g's (gravity of earth -> 9.80665 m/seg2).- The gyroscope units are rad/seg.- A video of the experiment including an example of the 6 recorded activities with one of the participants can be seen in the following link: [Web Link]For more information about this dataset please contact har '@' smartlab.ws or check our website www.smartlab.ws"
Somerville Happiness Survey,Somerville Happiness Survey,A data extract of a non-federal dataset posted here https://catalog.data.gov/dataset/somerville-happiness-survey-responses-2011-2013-2015,Somerville+Happiness+Survey,https://archive.ics.uci.edu/ml//machine-learning-databases/00479/,https://archive.ics.uci.edu/ml/datasets/Somerville+Happiness+Survey,It is a case of supervised learning with the use of Receiver Operating Characteristic (ROC) to select the minimal set of attributes preserving or increasing predictability of the data. ,Life,D = decision attribute (D) with values 0 (unhappy) and 1 (happy)X1 = the availability of information about the city servicesX2 = the cost of housingX3 = the overall quality of public schoolsX4 = your trust in the local policeX5 = the maintenance of streets and sidewalks X6 = the availability of social community eventsAttributes X1 to X6 have values 1 to 5.,A data extract of a non-federal dataset posted here https://catalog.data.gov/dataset/somerville-happiness-survey-responses-2011-2013-2015It is a case of supervised learning with the use of Receiver Operating Characteristic (ROC) to select the minimal set of attributes preserving or increasing predictability of the data. D = decision attribute (D) with values 0 (unhappy) and 1 (happy)X1 = the availability of information about the city servicesX2 = the cost of housingX3 = the overall quality of public schoolsX4 = your trust in the local policeX5 = the maintenance of streets and sidewalks X6 = the availability of social community eventsAttributes X1 to X6 have values 1 to 5.
Soybean (Large),Soybean (Large),Michalski's famous soybean disease database,Soybean+%28Large%29,https://archive.ics.uci.edu/ml//machine-learning-databases/soybean/,https://archive.ics.uci.edu/ml/datasets/Soybean+%28Large%29,"There are 19 classes, only the first 15 of which have been used in prior work. The folklore seems to be that the last four classes are unjustified by the data since they have so few examples. There are 35 categorical attributes, some nominal and some ordered.  The value ""dna'' means does not apply.  The values for attributes are encoded numerically, with the first value encoded as ""0,'' the second as ""1,'' and so forth.  An unknown values is encoded as ""?''.",Life,"    -- 19 Classes     diaporthe-stem-canker, charcoal-rot, rhizoctonia-root-rot,     phytophthora-rot, brown-stem-rot, powdery-mildew,     downy-mildew, brown-spot, bacterial-blight,     bacterial-pustule, purple-seed-stain, anthracnose,     phyllosticta-leaf-spot, alternarialeaf-spot,     frog-eye-leaf-spot, diaporthe-pod-&-stem-blight,     cyst-nematode, 2-4-d-injury, herbicide-injury.	    1. date:		april,may,june,july,august,september,october,?.    2. plant-stand:	normal,lt-normal,?.    3. precip:		lt-norm,norm,gt-norm,?.    4. temp:		lt-norm,norm,gt-norm,?.    5. hail:		yes,no,?.    6. crop-hist:	diff-lst-year,same-lst-yr,same-lst-two-yrs,                        same-lst-sev-yrs,?.    7. area-damaged:	scattered,low-areas,upper-areas,whole-field,?.    8. severity:	minor,pot-severe,severe,?.    9. seed-tmt:	none,fungicide,other,?.   10. germination:	90-100%,80-89%,lt-80%,?.   11. plant-growth:	norm,abnorm,?.   12. leaves:		norm,abnorm.   13. leafspots-halo:	absent,yellow-halos,no-yellow-halos,?.   14. leafspots-marg:	w-s-marg,no-w-s-marg,dna,?.   15. leafspot-size:	lt-1/8,gt-1/8,dna,?.   16. leaf-shread:	absent,present,?.   17. leaf-malf:	absent,present,?.   18. leaf-mild:	absent,upper-surf,lower-surf,?.   19. stem:		norm,abnorm,?.   20. lodging:    	yes,no,?.   21. stem-cankers:	absent,below-soil,above-soil,above-sec-nde,?.   22. canker-lesion:	dna,brown,dk-brown-blk,tan,?.   23. fruiting-bodies:	absent,present,?.   24. external decay:	absent,firm-and-dry,watery,?.   25. mycelium:	absent,present,?.   26. int-discolor:	none,brown,black,?.   27. sclerotia:	absent,present,?.   28. fruit-pods:	norm,diseased,few-present,dna,?.   29. fruit spots:	absent,colored,brown-w/blk-specks,distort,dna,?.   30. seed:		norm,abnorm,?.   31. mold-growth:	absent,present,?.   32. seed-discolor:	absent,present,?.   33. seed-size:	norm,lt-norm,?.   34. shriveling:	absent,present,?.   35. roots:		norm,rotted,galls-cysts,?.","Michalski's famous soybean disease databaseThere are 19 classes, only the first 15 of which have been used in prior work. The folklore seems to be that the last four classes are unjustified by the data since they have so few examples. There are 35 categorical attributes, some nominal and some ordered.  The value ""dna'' means does not apply.  The values for attributes are encoded numerically, with the first value encoded as ""0,'' the second as ""1,'' and so forth.  An unknown values is encoded as ""?''.    -- 19 Classes     diaporthe-stem-canker, charcoal-rot, rhizoctonia-root-rot,     phytophthora-rot, brown-stem-rot, powdery-mildew,     downy-mildew, brown-spot, bacterial-blight,     bacterial-pustule, purple-seed-stain, anthracnose,     phyllosticta-leaf-spot, alternarialeaf-spot,     frog-eye-leaf-spot, diaporthe-pod-&-stem-blight,     cyst-nematode, 2-4-d-injury, herbicide-injury.	    1. date:		april,may,june,july,august,september,october,?.    2. plant-stand:	normal,lt-normal,?.    3. precip:		lt-norm,norm,gt-norm,?.    4. temp:		lt-norm,norm,gt-norm,?.    5. hail:		yes,no,?.    6. crop-hist:	diff-lst-year,same-lst-yr,same-lst-two-yrs,                        same-lst-sev-yrs,?.    7. area-damaged:	scattered,low-areas,upper-areas,whole-field,?.    8. severity:	minor,pot-severe,severe,?.    9. seed-tmt:	none,fungicide,other,?.   10. germination:	90-100%,80-89%,lt-80%,?.   11. plant-growth:	norm,abnorm,?.   12. leaves:		norm,abnorm.   13. leafspots-halo:	absent,yellow-halos,no-yellow-halos,?.   14. leafspots-marg:	w-s-marg,no-w-s-marg,dna,?.   15. leafspot-size:	lt-1/8,gt-1/8,dna,?.   16. leaf-shread:	absent,present,?.   17. leaf-malf:	absent,present,?.   18. leaf-mild:	absent,upper-surf,lower-surf,?.   19. stem:		norm,abnorm,?.   20. lodging:    	yes,no,?.   21. stem-cankers:	absent,below-soil,above-soil,above-sec-nde,?.   22. canker-lesion:	dna,brown,dk-brown-blk,tan,?.   23. fruiting-bodies:	absent,present,?.   24. external decay:	absent,firm-and-dry,watery,?.   25. mycelium:	absent,present,?.   26. int-discolor:	none,brown,black,?.   27. sclerotia:	absent,present,?.   28. fruit-pods:	norm,diseased,few-present,dna,?.   29. fruit spots:	absent,colored,brown-w/blk-specks,distort,dna,?.   30. seed:		norm,abnorm,?.   31. mold-growth:	absent,present,?.   32. seed-discolor:	absent,present,?.   33. seed-size:	norm,lt-norm,?.   34. shriveling:	absent,present,?.   35. roots:		norm,rotted,galls-cysts,?."
Soybean (Small),Soybean (Small),Michalski's famous soybean disease database,Soybean+%28Small%29,https://archive.ics.uci.edu/ml//machine-learning-databases/soybean/,https://archive.ics.uci.edu/ml/datasets/Soybean+%28Small%29,"A small subset of the original soybean database.  See the reference for Fisher and Schlimmer in soybean-large.names for more information.    Steven Souders wrote:    > Figure 15 in the Michalski and Stepp paper (PAMI-82) says that the    > discriminant values for the attribute CONDITION OF FRUIT PODS for the    > classes Rhizoctonia Root Rot and Phytophthora Rot are ""few or none""    > and ""irrelevant"" respectively.  However, in the SOYBEAN-SMALL dataset    > I got from UCI, the value for this attribute is ""dna"" (does not apply)    > for both classes.  I show the actual data below for cases D3    > (Rhizoctonia Root Rot) and D4 (Phytophthora Rot).  According to the    > attribute names given in soybean-large.names, FRUIT-PODS is attribute    > #28.  If you look at column 28 in the data below (marked with arrows)    > you'll notice that all cases of D3 and D4 have the same value.  Thus,    > the SOYBEAN-SMALL dataset from UCI could NOT have produced the results    > in the Michalski and Stepp paper.I do not have that paper, but have found what is probably a later variation of that figure in Stepp's dissertation, which lists the value ""normal"" for the first 2 classes and ""irrelevant"" for the latter 2 classes.  I believe that ""irrelevant"" is used here as a synonym for ""not-applicable"", ""dna"", and ""does-not-apply"".  I believe that there is a mis-print in the figure he read in their PAMI-83 article. I have checked over each attribute value in this database.  It corresponds exactly with the copies listed in both Stepp's and Fisher's dissertations.",Life,"    1. date:		april,may,june,july,august,september,october,?.    2. plant-stand:	normal,lt-normal,?.    3. precip:		lt-norm,norm,gt-norm,?.    4. temp:		lt-norm,norm,gt-norm,?.    5. hail:		yes,no,?.    6. crop-hist:	diff-lst-year,same-lst-yr,same-lst-two-yrs,                        same-lst-sev-yrs,?.    7. area-damaged:	scattered,low-areas,upper-areas,whole-field,?.    8. severity:	minor,pot-severe,severe,?.    9. seed-tmt:	none,fungicide,other,?.   10. germination:	90-100%,80-89%,lt-80%,?.   11. plant-growth:	norm,abnorm,?.   12. leaves:		norm,abnorm.   13. leafspots-halo:	absent,yellow-halos,no-yellow-halos,?.   14. leafspots-marg:	w-s-marg,no-w-s-marg,dna,?.   15. leafspot-size:	lt-1/8,gt-1/8,dna,?.   16. leaf-shread:	absent,present,?.   17. leaf-malf:	absent,present,?.   18. leaf-mild:	absent,upper-surf,lower-surf,?.   19. stem:		norm,abnorm,?.   20. lodging:    	yes,no,?.   21. stem-cankers:	absent,below-soil,above-soil,above-sec-nde,?.   22. canker-lesion:	dna,brown,dk-brown-blk,tan,?.   23. fruiting-bodies:	absent,present,?.   24. external decay:	absent,firm-and-dry,watery,?.   25. mycelium:	absent,present,?.   26. int-discolor:	none,brown,black,?.   27. sclerotia:	absent,present,?.   28. fruit-pods:	norm,diseased,few-present,dna,?.   29. fruit spots:	absent,colored,brown-w/blk-specks,distort,dna,?.   30. seed:		norm,abnorm,?.   31. mold-growth:	absent,present,?.   32. seed-discolor:	absent,present,?.   33. seed-size:	norm,lt-norm,?.   34. shriveling:	absent,present,?.   35. roots:		norm,rotted,galls-cysts,?.","Michalski's famous soybean disease databaseA small subset of the original soybean database.  See the reference for Fisher and Schlimmer in soybean-large.names for more information.    Steven Souders wrote:    > Figure 15 in the Michalski and Stepp paper (PAMI-82) says that the    > discriminant values for the attribute CONDITION OF FRUIT PODS for the    > classes Rhizoctonia Root Rot and Phytophthora Rot are ""few or none""    > and ""irrelevant"" respectively.  However, in the SOYBEAN-SMALL dataset    > I got from UCI, the value for this attribute is ""dna"" (does not apply)    > for both classes.  I show the actual data below for cases D3    > (Rhizoctonia Root Rot) and D4 (Phytophthora Rot).  According to the    > attribute names given in soybean-large.names, FRUIT-PODS is attribute    > #28.  If you look at column 28 in the data below (marked with arrows)    > you'll notice that all cases of D3 and D4 have the same value.  Thus,    > the SOYBEAN-SMALL dataset from UCI could NOT have produced the results    > in the Michalski and Stepp paper.I do not have that paper, but have found what is probably a later variation of that figure in Stepp's dissertation, which lists the value ""normal"" for the first 2 classes and ""irrelevant"" for the latter 2 classes.  I believe that ""irrelevant"" is used here as a synonym for ""not-applicable"", ""dna"", and ""does-not-apply"".  I believe that there is a mis-print in the figure he read in their PAMI-83 article. I have checked over each attribute value in this database.  It corresponds exactly with the copies listed in both Stepp's and Fisher's dissertations.    1. date:		april,may,june,july,august,september,october,?.    2. plant-stand:	normal,lt-normal,?.    3. precip:		lt-norm,norm,gt-norm,?.    4. temp:		lt-norm,norm,gt-norm,?.    5. hail:		yes,no,?.    6. crop-hist:	diff-lst-year,same-lst-yr,same-lst-two-yrs,                        same-lst-sev-yrs,?.    7. area-damaged:	scattered,low-areas,upper-areas,whole-field,?.    8. severity:	minor,pot-severe,severe,?.    9. seed-tmt:	none,fungicide,other,?.   10. germination:	90-100%,80-89%,lt-80%,?.   11. plant-growth:	norm,abnorm,?.   12. leaves:		norm,abnorm.   13. leafspots-halo:	absent,yellow-halos,no-yellow-halos,?.   14. leafspots-marg:	w-s-marg,no-w-s-marg,dna,?.   15. leafspot-size:	lt-1/8,gt-1/8,dna,?.   16. leaf-shread:	absent,present,?.   17. leaf-malf:	absent,present,?.   18. leaf-mild:	absent,upper-surf,lower-surf,?.   19. stem:		norm,abnorm,?.   20. lodging:    	yes,no,?.   21. stem-cankers:	absent,below-soil,above-soil,above-sec-nde,?.   22. canker-lesion:	dna,brown,dk-brown-blk,tan,?.   23. fruiting-bodies:	absent,present,?.   24. external decay:	absent,firm-and-dry,watery,?.   25. mycelium:	absent,present,?.   26. int-discolor:	none,brown,black,?.   27. sclerotia:	absent,present,?.   28. fruit-pods:	norm,diseased,few-present,dna,?.   29. fruit spots:	absent,colored,brown-w/blk-specks,distort,dna,?.   30. seed:		norm,abnorm,?.   31. mold-growth:	absent,present,?.   32. seed-discolor:	absent,present,?.   33. seed-size:	norm,lt-norm,?.   34. shriveling:	absent,present,?.   35. roots:		norm,rotted,galls-cysts,?."
SPECT Heart,SPECT Heart,Data on cardiac Single Proton Emission Computed Tomography (SPECT) images. Each patient classified into two categories: normal and abnormal.,SPECT+Heart,https://archive.ics.uci.edu/ml//machine-learning-databases/spect/,https://archive.ics.uci.edu/ml/datasets/SPECT+Heart,"The dataset describes diagnosing of cardiac Single Proton Emission Computed Tomography (SPECT) images. Each of the patients is classified into two categories: normal and abnormal. The database of 267 SPECT image sets (patients) was processed to extract features that summarize the original SPECT images. As a result, 44 continuous feature pattern was created for each patient. The pattern was further processed to obtain 22 binary feature patterns. The CLIP3 algorithm was used to generate classification rules from these patterns. The CLIP3 algorithm generated rules that were 84.0% accurate (as compared with cardilogists' diagnoses).SPECT is a good data set for testing ML algorithms; it has 267 instances that are descibed by 23 binary attributes",Life,"   1.  OVERALL_DIAGNOSIS: 0,1 (class attribute, binary)   2.  F1:  0,1 (the partial diagnosis 1, binary)   3.  F2:  0,1 (the partial diagnosis 2, binary)   4.  F3:  0,1 (the partial diagnosis 3, binary)   5.  F4:  0,1 (the partial diagnosis 4, binary)   6.  F5:  0,1 (the partial diagnosis 5, binary)   7.  F6:  0,1 (the partial diagnosis 6, binary)   8.  F7:  0,1 (the partial diagnosis 7, binary)   9.  F8:  0,1 (the partial diagnosis 8, binary)   10. F9:  0,1 (the partial diagnosis 9, binary)   11. F10: 0,1 (the partial diagnosis 10, binary)   12. F11: 0,1 (the partial diagnosis 11, binary)   13. F12: 0,1 (the partial diagnosis 12, binary)   14. F13: 0,1 (the partial diagnosis 13, binary)   15. F14: 0,1 (the partial diagnosis 14, binary)   16. F15: 0,1 (the partial diagnosis 15, binary)   17. F16: 0,1 (the partial diagnosis 16, binary)   18. F17: 0,1 (the partial diagnosis 17, binary)   19. F18: 0,1 (the partial diagnosis 18, binary)   20. F19: 0,1 (the partial diagnosis 19, binary)   21. F20: 0,1 (the partial diagnosis 20, binary)   22. F21: 0,1 (the partial diagnosis 21, binary)   23. F22: 0,1 (the partial diagnosis 22, binary)   - dataset is divided into:	-- training data (""SPECT.train"" 80 instances)	-- testing data (""SPECT.test"" 187 instances)","Data on cardiac Single Proton Emission Computed Tomography (SPECT) images. Each patient classified into two categories: normal and abnormal.The dataset describes diagnosing of cardiac Single Proton Emission Computed Tomography (SPECT) images. Each of the patients is classified into two categories: normal and abnormal. The database of 267 SPECT image sets (patients) was processed to extract features that summarize the original SPECT images. As a result, 44 continuous feature pattern was created for each patient. The pattern was further processed to obtain 22 binary feature patterns. The CLIP3 algorithm was used to generate classification rules from these patterns. The CLIP3 algorithm generated rules that were 84.0% accurate (as compared with cardilogists' diagnoses).SPECT is a good data set for testing ML algorithms; it has 267 instances that are descibed by 23 binary attributes   1.  OVERALL_DIAGNOSIS: 0,1 (class attribute, binary)   2.  F1:  0,1 (the partial diagnosis 1, binary)   3.  F2:  0,1 (the partial diagnosis 2, binary)   4.  F3:  0,1 (the partial diagnosis 3, binary)   5.  F4:  0,1 (the partial diagnosis 4, binary)   6.  F5:  0,1 (the partial diagnosis 5, binary)   7.  F6:  0,1 (the partial diagnosis 6, binary)   8.  F7:  0,1 (the partial diagnosis 7, binary)   9.  F8:  0,1 (the partial diagnosis 8, binary)   10. F9:  0,1 (the partial diagnosis 9, binary)   11. F10: 0,1 (the partial diagnosis 10, binary)   12. F11: 0,1 (the partial diagnosis 11, binary)   13. F12: 0,1 (the partial diagnosis 12, binary)   14. F13: 0,1 (the partial diagnosis 13, binary)   15. F14: 0,1 (the partial diagnosis 14, binary)   16. F15: 0,1 (the partial diagnosis 15, binary)   17. F16: 0,1 (the partial diagnosis 16, binary)   18. F17: 0,1 (the partial diagnosis 17, binary)   19. F18: 0,1 (the partial diagnosis 18, binary)   20. F19: 0,1 (the partial diagnosis 19, binary)   21. F20: 0,1 (the partial diagnosis 20, binary)   22. F21: 0,1 (the partial diagnosis 21, binary)   23. F22: 0,1 (the partial diagnosis 22, binary)   - dataset is divided into:	-- training data (""SPECT.train"" 80 instances)	-- testing data (""SPECT.test"" 187 instances)"
SPECTF Heart,SPECTF Heart,Data on cardiac Single Proton Emission Computed Tomography (SPECT) images. Each patient classified into two categories: normal and abnormal.,SPECTF+Heart,https://archive.ics.uci.edu/ml//machine-learning-databases/spect/,https://archive.ics.uci.edu/ml/datasets/SPECTF+Heart,"The dataset describes diagnosing of cardiac Single Proton Emission Computed Tomography (SPECT) images. Each of the patients is classified into two categories: normal and abnormal. The database of 267 SPECT image sets (patients) was processed to extract features that summarize the original SPECT images. As a result, 44 continuous feature pattern was created for each patient. The CLIP3 algorithm was used to generate classification rules from these patterns. The CLIP3 algorithm generated rules that were 77.0% accurate (as compared with cardilogists' diagnoses). SPECTF is a good data set for testing ML algorithms; it has 267 instances that are descibed by 45 attributes.	 Predicted attribute: OVERALL_DIAGNOSIS (binary) NOTE: See the SPECT heart data for binary data for the same classification task.",Life,"   1.   OVERALL_DIAGNOSIS: 0,1 (class attribute, binary)   2.   F1R:   continuous (count in ROI (region of interest) 1 in rest)   3.   F1S:   continuous (count in ROI 1 in stress)   4.   F2R:   continuous (count in ROI 2 in rest)   5.   F2S:   continuous (count in ROI 2 in stress)   6.   F3R:   continuous (count in ROI 3 in rest)   7.   F3S:   continuous (count in ROI 3 in stress)   8.   F4R:   continuous (count in ROI 4 in rest)   9.   F4S:   continuous (count in ROI 4 in stress)   10.  F5R:   continuous (count in ROI 5 in rest)   11.  F5S:   continuous (count in ROI 5 in stress)   12.  F6R:   continuous (count in ROI 6 in rest)   13.  F6S:   continuous (count in ROI 6 in stress)   14.  F7R:   continuous (count in ROI 7 in rest)   15.  F7S:   continuous (count in ROI 7 in stress)   16.  F8R:   continuous (count in ROI 8 in rest)   17.  F8S:   continuous (count in ROI 8 in stress)   18.  F9R:   continuous (count in ROI 9 in rest)   19.  F9S:   continuous (count in ROI 9 in stress)   20.  F10R:  continuous (count in ROI 10 in rest)   21.  F10S:  continuous (count in ROI 10 in stress)   22.  F11R:  continuous (count in ROI 11 in rest)   23.  F11S:  continuous (count in ROI 11 in stress)   24.  F12R:  continuous (count in ROI 12 in rest)   25.  F12S:  continuous (count in ROI 12 in stress)   26.  F13R:  continuous (count in ROI 13 in rest)   27.  F13S:  continuous (count in ROI 13 in stress)   28.  F14R:  continuous (count in ROI 14 in rest)   29.  F14S:  continuous (count in ROI 14 in stress)   30.  F15R:  continuous (count in ROI 15 in rest)   31.  F15S:  continuous (count in ROI 15 in stress)   32.  F16R:  continuous (count in ROI 16 in rest)   33.  F16S:  continuous (count in ROI 16 in stress)   34.  F17R:  continuous (count in ROI 17 in rest)   35.  F17S:  continuous (count in ROI 17 in stress)   36.  F18R:  continuous (count in ROI 18 in rest)   37.  F18S:  continuous (count in ROI 18 in stress)   38.  F19R:  continuous (count in ROI 19 in rest)   39.  F19S:  continuous (count in ROI 19 in stress)   40.  F20R:  continuous (count in ROI 20 in rest)   41.  F20S:  continuous (count in ROI 20 in stress)   42.  F21R:  continuous (count in ROI 21 in rest)   43.  F21S:  continuous (count in ROI 21 in stress)   44.  F22R:  continuous (count in ROI 22 in rest)   45.  F22S:  continuous (count in ROI 22 in stress)   - all continuous attributes have integer values from the 0 to 100   - dataset is divided into:	-- training data (""SPECTF.train"" 80 instances)	-- testing data (""SPECTF.test"" 187 instances)","Data on cardiac Single Proton Emission Computed Tomography (SPECT) images. Each patient classified into two categories: normal and abnormal.The dataset describes diagnosing of cardiac Single Proton Emission Computed Tomography (SPECT) images. Each of the patients is classified into two categories: normal and abnormal. The database of 267 SPECT image sets (patients) was processed to extract features that summarize the original SPECT images. As a result, 44 continuous feature pattern was created for each patient. The CLIP3 algorithm was used to generate classification rules from these patterns. The CLIP3 algorithm generated rules that were 77.0% accurate (as compared with cardilogists' diagnoses). SPECTF is a good data set for testing ML algorithms; it has 267 instances that are descibed by 45 attributes.	 Predicted attribute: OVERALL_DIAGNOSIS (binary) NOTE: See the SPECT heart data for binary data for the same classification task.   1.   OVERALL_DIAGNOSIS: 0,1 (class attribute, binary)   2.   F1R:   continuous (count in ROI (region of interest) 1 in rest)   3.   F1S:   continuous (count in ROI 1 in stress)   4.   F2R:   continuous (count in ROI 2 in rest)   5.   F2S:   continuous (count in ROI 2 in stress)   6.   F3R:   continuous (count in ROI 3 in rest)   7.   F3S:   continuous (count in ROI 3 in stress)   8.   F4R:   continuous (count in ROI 4 in rest)   9.   F4S:   continuous (count in ROI 4 in stress)   10.  F5R:   continuous (count in ROI 5 in rest)   11.  F5S:   continuous (count in ROI 5 in stress)   12.  F6R:   continuous (count in ROI 6 in rest)   13.  F6S:   continuous (count in ROI 6 in stress)   14.  F7R:   continuous (count in ROI 7 in rest)   15.  F7S:   continuous (count in ROI 7 in stress)   16.  F8R:   continuous (count in ROI 8 in rest)   17.  F8S:   continuous (count in ROI 8 in stress)   18.  F9R:   continuous (count in ROI 9 in rest)   19.  F9S:   continuous (count in ROI 9 in stress)   20.  F10R:  continuous (count in ROI 10 in rest)   21.  F10S:  continuous (count in ROI 10 in stress)   22.  F11R:  continuous (count in ROI 11 in rest)   23.  F11S:  continuous (count in ROI 11 in stress)   24.  F12R:  continuous (count in ROI 12 in rest)   25.  F12S:  continuous (count in ROI 12 in stress)   26.  F13R:  continuous (count in ROI 13 in rest)   27.  F13S:  continuous (count in ROI 13 in stress)   28.  F14R:  continuous (count in ROI 14 in rest)   29.  F14S:  continuous (count in ROI 14 in stress)   30.  F15R:  continuous (count in ROI 15 in rest)   31.  F15S:  continuous (count in ROI 15 in stress)   32.  F16R:  continuous (count in ROI 16 in rest)   33.  F16S:  continuous (count in ROI 16 in stress)   34.  F17R:  continuous (count in ROI 17 in rest)   35.  F17S:  continuous (count in ROI 17 in stress)   36.  F18R:  continuous (count in ROI 18 in rest)   37.  F18S:  continuous (count in ROI 18 in stress)   38.  F19R:  continuous (count in ROI 19 in rest)   39.  F19S:  continuous (count in ROI 19 in stress)   40.  F20R:  continuous (count in ROI 20 in rest)   41.  F20S:  continuous (count in ROI 20 in stress)   42.  F21R:  continuous (count in ROI 21 in rest)   43.  F21S:  continuous (count in ROI 21 in stress)   44.  F22R:  continuous (count in ROI 22 in rest)   45.  F22S:  continuous (count in ROI 22 in stress)   - all continuous attributes have integer values from the 0 to 100   - dataset is divided into:	-- training data (""SPECTF.train"" 80 instances)	-- testing data (""SPECTF.test"" 187 instances)"
Sponge,Sponge,Data on sponges; Attributes in spanish,Sponge,https://archive.ics.uci.edu/ml//machine-learning-databases/sponge/,https://archive.ics.uci.edu/ml/datasets/Sponge,These are atlantic-mediterranean marine sponges that belong to O.Hadromerida (Demospongiae.Porifera).,Life,27 attributes are non-numeric and nominal.15 attributes are boolean and take the values (NO SI).3 attributes are numeric and take natural numbers.,Data on sponges; Attributes in spanishThese are atlantic-mediterranean marine sponges that belong to O.Hadromerida (Demospongiae.Porifera).27 attributes are non-numeric and nominal.15 attributes are boolean and take the values (NO SI).3 attributes are numeric and take natural numbers.
Statlog (Heart),Statlog (Heart),This dataset is a heart disease database similar to a database already present in the repository (Heart Disease databases) but in a slightly different form,Statlog+%28Heart%29,https://archive.ics.uci.edu/ml//machine-learning-databases/statlog/heart/,https://archive.ics.uci.edu/ml/datasets/Statlog+%28Heart%29,Cost Matrix_______	 abse  presabsence	 0	1presence  5	0where the rows represent the true values and the columns the predicted.,Life,"Attribute Information:------------------------      -- 1. age             -- 2. sex             -- 3. chest pain type  (4 values)             -- 4. resting blood pressure        -- 5. serum cholesterol in mg/dl            -- 6. fasting blood sugar > 120 mg/dl             -- 7. resting electrocardiographic results  (values 0,1,2)       -- 8. maximum heart rate achieved        -- 9. exercise induced angina          -- 10. oldpeak = ST depression induced by exercise relative to rest         -- 11. the slope of the peak exercise ST segment           -- 12. number of major vessels (0-3) colored by flourosopy              -- 13.  thal: 3 = normal; 6 = fixed defect; 7 = reversable defect     Attributes types-----------------Real: 1,4,5,8,10,12Ordered:11,Binary: 2,6,9Nominal:7,3,13Variable to be predicted------------------------Absence (1) or presence (2) of heart disease","This dataset is a heart disease database similar to a database already present in the repository (Heart Disease databases) but in a slightly different formCost Matrix_______	 abse  presabsence	 0	1presence  5	0where the rows represent the true values and the columns the predicted.Attribute Information:------------------------      -- 1. age             -- 2. sex             -- 3. chest pain type  (4 values)             -- 4. resting blood pressure        -- 5. serum cholesterol in mg/dl            -- 6. fasting blood sugar > 120 mg/dl             -- 7. resting electrocardiographic results  (values 0,1,2)       -- 8. maximum heart rate achieved        -- 9. exercise induced angina          -- 10. oldpeak = ST depression induced by exercise relative to rest         -- 11. the slope of the peak exercise ST segment           -- 12. number of major vessels (0-3) colored by flourosopy              -- 13.  thal: 3 = normal; 6 = fixed defect; 7 = reversable defect     Attributes types-----------------Real: 1,4,5,8,10,12Ordered:11,Binary: 2,6,9Nominal:7,3,13Variable to be predicted------------------------Absence (1) or presence (2) of heart disease"
Thoracic Surgery Data,Thoracic Surgery Data,"The data is dedicated to classification problem related to the post-operative life expectancy in the lung cancer patients: class 1 - death within one year after surgery, class 2 - survival.",Thoracic+Surgery+Data,https://archive.ics.uci.edu/ml//machine-learning-databases/00277/,https://archive.ics.uci.edu/ml/datasets/Thoracic+Surgery+Data,"The data was collected retrospectively at Wroclaw Thoracic Surgery Centre for patients who underwent major lung resections for primary lung cancer in the years 2007Ã¢â‚¬â€œ2011. The Centre is associated with the Department of Thoracic Surgery of the Medical University of Wroclaw and Lower-Silesian Centre for Pulmonary Diseases, Poland, while the research database constitutes a part of the National Lung Cancer Registry, administered by the Institute of Tuberculosis and Pulmonary Diseases in Warsaw, Poland.",Life,"1. DGN: Diagnosis - specific combination of ICD-10 codes for primary and secondary as well multiple tumours if any (DGN3,DGN2,DGN4,DGN6,DGN5,DGN8,DGN1)2. PRE4: Forced vital capacity - FVC (numeric)3. PRE5: Volume that has been exhaled at the end of the first second of forced expiration - FEV1 (numeric)4. PRE6: Performance status - Zubrod scale (PRZ2,PRZ1,PRZ0)5. PRE7: Pain before surgery (T,F)6. PRE8: Haemoptysis before surgery (T,F)7. PRE9: Dyspnoea before surgery (T,F)8. PRE10: Cough before surgery (T,F)9. PRE11: Weakness before surgery (T,F)10. PRE14: T in clinical TNM - size of the original tumour, from OC11 (smallest) to OC14 (largest) (OC11,OC14,OC12,OC13)11. PRE17: Type 2 DM - diabetes mellitus (T,F)12. PRE19: MI up to 6 months (T,F)13. PRE25: PAD - peripheral arterial diseases (T,F)14. PRE30: Smoking (T,F)15. PRE32: Asthma (T,F)16. AGE: Age at surgery (numeric)17. Risk1Y: 1 year survival period - (T)rue value if died (T,F)Class Distribution: the class value (Risk1Y) is binary valued.   Risk1Y Value:   Number of Instances:	T                  70	N                  400Summary Statistics:	Binary Attributes Distribution:	   PRE7 Value:   Number of Instances:		T              	31		N             	439	   PRE8 Value:   Number of Instances:		T              	68		N             	402	   PRE9 Value:   Number of Instances:		T              	31		N             	439	   PRE10 Value:   Number of Instances:		T              	323		N             	147	   PRE11 Value:   Number of Instances:		T              	78		N             	392			   PRE17 Value:   Number of Instances:		T              	35		N             	435		   PRE19 Value:   Number of Instances:		T              	2		N             	468		   PRE25 Value:   Number of Instances:		T              	8		N             	462	   PRE30 Value:   Number of Instances:		T              	386		N             	84				   PRE32 Value:   Number of Instances:		T              	368		N             	2					Nominal Attributes Distribution:	   DGN Value:   Number of Instances:		DGN3           349		DGN2           52		DGN4           47		DGN6           4		DGN5           15		DGN8           2				DGN1           1		   PRE6 Value:   Number of Instances:		PRZ2           27		PRZ1           313		PRZ0           130	   PRE14 Value:   Number of Instances:		OC11           177		OC14           17		OC12           257		OC13           19			Numeric Attributes Statistics:		     Min   Max   Mean    SD          PRE4:    1.4   6.3   3.3     0.9       PRE5:    0.96  86.3  4.6     11.8       AGE:     21    87    52.5    8.7","The data is dedicated to classification problem related to the post-operative life expectancy in the lung cancer patients: class 1 - death within one year after surgery, class 2 - survival.The data was collected retrospectively at Wroclaw Thoracic Surgery Centre for patients who underwent major lung resections for primary lung cancer in the years 2007Ã¢â‚¬â€œ2011. The Centre is associated with the Department of Thoracic Surgery of the Medical University of Wroclaw and Lower-Silesian Centre for Pulmonary Diseases, Poland, while the research database constitutes a part of the National Lung Cancer Registry, administered by the Institute of Tuberculosis and Pulmonary Diseases in Warsaw, Poland.1. DGN: Diagnosis - specific combination of ICD-10 codes for primary and secondary as well multiple tumours if any (DGN3,DGN2,DGN4,DGN6,DGN5,DGN8,DGN1)2. PRE4: Forced vital capacity - FVC (numeric)3. PRE5: Volume that has been exhaled at the end of the first second of forced expiration - FEV1 (numeric)4. PRE6: Performance status - Zubrod scale (PRZ2,PRZ1,PRZ0)5. PRE7: Pain before surgery (T,F)6. PRE8: Haemoptysis before surgery (T,F)7. PRE9: Dyspnoea before surgery (T,F)8. PRE10: Cough before surgery (T,F)9. PRE11: Weakness before surgery (T,F)10. PRE14: T in clinical TNM - size of the original tumour, from OC11 (smallest) to OC14 (largest) (OC11,OC14,OC12,OC13)11. PRE17: Type 2 DM - diabetes mellitus (T,F)12. PRE19: MI up to 6 months (T,F)13. PRE25: PAD - peripheral arterial diseases (T,F)14. PRE30: Smoking (T,F)15. PRE32: Asthma (T,F)16. AGE: Age at surgery (numeric)17. Risk1Y: 1 year survival period - (T)rue value if died (T,F)Class Distribution: the class value (Risk1Y) is binary valued.   Risk1Y Value:   Number of Instances:	T                  70	N                  400Summary Statistics:	Binary Attributes Distribution:	   PRE7 Value:   Number of Instances:		T              	31		N             	439	   PRE8 Value:   Number of Instances:		T              	68		N             	402	   PRE9 Value:   Number of Instances:		T              	31		N             	439	   PRE10 Value:   Number of Instances:		T              	323		N             	147	   PRE11 Value:   Number of Instances:		T              	78		N             	392			   PRE17 Value:   Number of Instances:		T              	35		N             	435		   PRE19 Value:   Number of Instances:		T              	2		N             	468		   PRE25 Value:   Number of Instances:		T              	8		N             	462	   PRE30 Value:   Number of Instances:		T              	386		N             	84				   PRE32 Value:   Number of Instances:		T              	368		N             	2					Nominal Attributes Distribution:	   DGN Value:   Number of Instances:		DGN3           349		DGN2           52		DGN4           47		DGN6           4		DGN5           15		DGN8           2				DGN1           1		   PRE6 Value:   Number of Instances:		PRZ2           27		PRZ1           313		PRZ0           130	   PRE14 Value:   Number of Instances:		OC11           177		OC14           17		OC12           257		OC13           19			Numeric Attributes Statistics:		     Min   Max   Mean    SD          PRE4:    1.4   6.3   3.3     0.9       PRE5:    0.96  86.3  4.6     11.8       AGE:     21    87    52.5    8.7"
Tamilnadu Electricity Board Hourly Readings,Tamilnadu Electricity Board Hourly Readings,This data can be effectively produced the result to fewer parameter of the Load profile can be reduced in the Database  ,Tamilnadu+Electricity+Board+Hourly+Readings,https://archive.ics.uci.edu/ml//machine-learning-databases/00290/,https://archive.ics.uci.edu/ml/datasets/Tamilnadu+Electricity+Board+Hourly+Readings,"Collect the real time readings for residential,commercial,industrial,agriculure,to find the accuracy consumption in Tamil Nadu Around Thanajvur",Life,"forkva,forkw,type,sector,service","This data can be effectively produced the result to fewer parameter of the Load profile can be reduced in the Database  Collect the real time readings for residential,commercial,industrial,agriculure,to find the accuracy consumption in Tamil Nadu Around Thanajvurforkva,forkw,type,sector,service"
Thyroid Disease,Thyroid Disease,10 separate databases from Garavan Institute,Thyroid+Disease,https://archive.ics.uci.edu/ml//machine-learning-databases/thyroid-disease/,https://archive.ics.uci.edu/ml/datasets/Thyroid+Disease,"# From Garavan Institute# Documentation: as given by Ross Quinlan# 6 databases from the Garavan Institute in Sydney, Australia# Approximately the following for each database:    ** 2800 training (data) instances and 972 test instances    ** Plenty of missing data    ** 29 or so attributes, either Boolean or continuously-valued # 2 additional databases, also from Ross Quinlan, are also here    ** Hypothyroid.data and sick-euthyroid.data    ** Quinlan believes that these databases have been corrupted    ** Their format is highly similar to the other databases # 1 more database of 9172 instances that cover 20 classes, and a related domain theory# Another thyroid database from Stefan Aeberhard    ** 3 classes, 215 instances, 5 attributes    ** No missing values # A Thyroid database suited for training ANNs    ** 3 classes    ** 3772 training instances, 3428 testing instances    ** Includes cost data (donated by Peter Turney) ",Life,,"10 separate databases from Garavan Institute# From Garavan Institute# Documentation: as given by Ross Quinlan# 6 databases from the Garavan Institute in Sydney, Australia# Approximately the following for each database:    ** 2800 training (data) instances and 972 test instances    ** Plenty of missing data    ** 29 or so attributes, either Boolean or continuously-valued # 2 additional databases, also from Ross Quinlan, are also here    ** Hypothyroid.data and sick-euthyroid.data    ** Quinlan believes that these databases have been corrupted    ** Their format is highly similar to the other databases # 1 more database of 9172 instances that cover 20 classes, and a related domain theory# Another thyroid database from Stefan Aeberhard    ** 3 classes, 215 instances, 5 attributes    ** No missing values # A Thyroid database suited for training ANNs    ** 3 classes    ** 3772 training instances, 3428 testing instances    ** Includes cost data (donated by Peter Turney) nan"
Quadruped Mammals,Quadruped Mammals, The file animals.c is a data generator of structured instances representing quadruped animals,Quadruped+Mammals,https://archive.ics.uci.edu/ml//machine-learning-databases/quadrapeds/,https://archive.ics.uci.edu/ml/datasets/Quadruped+Mammals,"The file animals.c is a data generator of structured instances representing quadruped animals as used by Gennari, Langley, and Fisher (1989) to evaluate the CLASSIT unsupervised learning algorithm. Instances have 8 components: neck, four legs, torso, head, and tail.  Each component is represented as a simplified/generalized cylinder (i.e., inspired by David Marr's work in ""Vision: A Computational Investigation Into the Human Representation  and Processing of Visual Information"", published by Freeman in 1982). Each cylinder is itself described by 9 attributes: location x 3, axis x 3, height, radius, and texture.  This code generates instances in one of four classes: dogs, cats, horses, and giraffes.  The program generates instances by selecting a class according to a distribution determined by function rand4().  Each class has a prototype; the prototype of the selected class is perturbed according to a distribution described in the code for the four classes (i.e., parameterized means with Guassian distributions are used to represent prototypes and perturbation distributions, where the means are used to distinguish the four classes).From John Gennari: (1990)The only notes I have about it is that I don't use the data format it creates any more. To change this, modify ""printpart()"". Also, it uses a very rough approximation for a bell-shaped distribution. Currently, I use a much more sophisticated random number generator. To fix this, just replace ""bellrand()"" with a real bell shaped distribution.",Life,     A. Eight components per instances/animal:        1. Head        2. Tail        3. 4 legs        4. torso        5. neck        B. Nine attributes per component:        1. Location 1        2. Location 2	3. Location 3	4. Axis 1	5. Axis 2	6. Axis 3	7. Height	8. Radius	9. Texture," The file animals.c is a data generator of structured instances representing quadruped animalsThe file animals.c is a data generator of structured instances representing quadruped animals as used by Gennari, Langley, and Fisher (1989) to evaluate the CLASSIT unsupervised learning algorithm. Instances have 8 components: neck, four legs, torso, head, and tail.  Each component is represented as a simplified/generalized cylinder (i.e., inspired by David Marr's work in ""Vision: A Computational Investigation Into the Human Representation  and Processing of Visual Information"", published by Freeman in 1982). Each cylinder is itself described by 9 attributes: location x 3, axis x 3, height, radius, and texture.  This code generates instances in one of four classes: dogs, cats, horses, and giraffes.  The program generates instances by selecting a class according to a distribution determined by function rand4().  Each class has a prototype; the prototype of the selected class is perturbed according to a distribution described in the code for the four classes (i.e., parameterized means with Guassian distributions are used to represent prototypes and perturbation distributions, where the means are used to distinguish the four classes).From John Gennari: (1990)The only notes I have about it is that I don't use the data format it creates any more. To change this, modify ""printpart()"". Also, it uses a very rough approximation for a bell-shaped distribution. Currently, I use a much more sophisticated random number generator. To fix this, just replace ""bellrand()"" with a real bell shaped distribution.     A. Eight components per instances/animal:        1. Head        2. Tail        3. 4 legs        4. torso        5. neck        B. Nine attributes per component:        1. Location 1        2. Location 2	3. Location 3	4. Axis 1	5. Axis 2	6. Axis 3	7. Height	8. Radius	9. Texture"
sEMG for Basic Hand movements,sEMG for Basic Hand movements,The sEMG for Basic Hand movements includes 2 databases of surface electromyographic signals of 6 hand movements using Delsys' EMG System. Healthy subjects conducted six daily life grasps.,sEMG+for+Basic+Hand+movements,https://archive.ics.uci.edu/ml//machine-learning-databases/00313/,https://archive.ics.uci.edu/ml/datasets/sEMG+for+Basic+Hand+movements,"Instrumentation:The data were collected at a sampling rate of 500 Hz, using as a programming kernel the National Instruments (NI) Labview. The signals were band-pass filtered using a Butterworth Band Pass filter with low and high cutoff at 15Hz and 500Hz respectively and a notch filter at 50Hz to eliminate line interference artifacts.The hardware that was used was an NI analog/digital conversion card NI USB- 009, mounted on a PC. The signal was taken from two Differential EMG Sensors and the signals were transmitted to a 2-channel EMG system by Delsys BagnoliÃ¢ Handheld EMG Systems.Protocol: The experiments consisted of freely and repeatedly grasping of different items, which were essential to conduct the hand movements. The speed and force were intentionally left to the subjects will. There were two forearm surface EMG electrodes Flexor Capri Ulnaris and Extensor Capri Radialis, Longus and Brevis) held in place by elastic bands and the reference electrode in the middle, in order to gather information about the muscle activation.The subjects were asked to perform repeatedly the following six movements, which can be considered as daily hand grasps:a) Spherical: for holding spherical toolsb) Tip: for holding small tools c) Palmar: for grasping with palm facing the objectd) Lateral: for holding thin, flat objectse) Cylindrical: for holding cylindrical toolsf) Hook: for supporting a heavy loadAn illustrative photo is included in the data folder.Two different databases are included:1) 5 healthy subjects (two males and three females) of the same age approximately (20 to 22-year-old) conducted the six grasps for 30 times each. The measured time is 6 sec. There is a mat file available for every subject. 2) 1 healthy subject (male, 22-year-old) conducted the six grasps for 100 times each for 3 consecutive days. The measured time is 5 sec. There is a mat file available for every day.",Life,"Data Format:The format of each mat file is the following: The data per grasp and per channel are in separate table with an obvious naming. {Spherical --> (spher_ch1, spher_ch2), Tip --> (tip_ch1, tip_ch2), Palmar --> (palm_ch1, palm_ch2), Lateral --> (lat_ch1, lat_ch2), Cylindrical --> (cyl_ch1, cyl_ch2), Hook --> (hook_ch1, hook_ch2)}Each row of these tables has the whole signal per trial. The signal value is measured in Voltage.In summary, in each subject, there will be a mat file with 12 matrixes, in which matrix there will be 30 (trials) rows and 3000 (points of the signal) columns for database 1 (or 100 rows and 2500 columns for database 2).","The sEMG for Basic Hand movements includes 2 databases of surface electromyographic signals of 6 hand movements using Delsys' EMG System. Healthy subjects conducted six daily life grasps.Instrumentation:The data were collected at a sampling rate of 500 Hz, using as a programming kernel the National Instruments (NI) Labview. The signals were band-pass filtered using a Butterworth Band Pass filter with low and high cutoff at 15Hz and 500Hz respectively and a notch filter at 50Hz to eliminate line interference artifacts.The hardware that was used was an NI analog/digital conversion card NI USB- 009, mounted on a PC. The signal was taken from two Differential EMG Sensors and the signals were transmitted to a 2-channel EMG system by Delsys BagnoliÃ¢ Handheld EMG Systems.Protocol: The experiments consisted of freely and repeatedly grasping of different items, which were essential to conduct the hand movements. The speed and force were intentionally left to the subjects will. There were two forearm surface EMG electrodes Flexor Capri Ulnaris and Extensor Capri Radialis, Longus and Brevis) held in place by elastic bands and the reference electrode in the middle, in order to gather information about the muscle activation.The subjects were asked to perform repeatedly the following six movements, which can be considered as daily hand grasps:a) Spherical: for holding spherical toolsb) Tip: for holding small tools c) Palmar: for grasping with palm facing the objectd) Lateral: for holding thin, flat objectse) Cylindrical: for holding cylindrical toolsf) Hook: for supporting a heavy loadAn illustrative photo is included in the data folder.Two different databases are included:1) 5 healthy subjects (two males and three females) of the same age approximately (20 to 22-year-old) conducted the six grasps for 30 times each. The measured time is 6 sec. There is a mat file available for every subject. 2) 1 healthy subject (male, 22-year-old) conducted the six grasps for 100 times each for 3 consecutive days. The measured time is 5 sec. There is a mat file available for every day.Data Format:The format of each mat file is the following: The data per grasp and per channel are in separate table with an obvious naming. {Spherical --> (spher_ch1, spher_ch2), Tip --> (tip_ch1, tip_ch2), Palmar --> (palm_ch1, palm_ch2), Lateral --> (lat_ch1, lat_ch2), Cylindrical --> (cyl_ch1, cyl_ch2), Hook --> (hook_ch1, hook_ch2)}Each row of these tables has the whole signal per trial. The signal value is measured in Voltage.In summary, in each subject, there will be a mat file with 12 matrixes, in which matrix there will be 30 (trials) rows and 3000 (points of the signal) columns for database 1 (or 100 rows and 2500 columns for database 2)."
Contraceptive Method Choice,Contraceptive Method Choice,Dataset is a subset of the 1987 National Indonesia Contraceptive Prevalence Survey.,Contraceptive+Method+Choice,https://archive.ics.uci.edu/ml//machine-learning-databases/cmc/,https://archive.ics.uci.edu/ml/datasets/Contraceptive+Method+Choice,"This dataset is a subset of the 1987 National Indonesia Contraceptive Prevalence Survey. The samples are married women who were either not pregnant or do not know if they were at the time of interview. The problem is to predict the current contraceptive method choice (no use, long-term methods, or short-term methods) of a woman based on her demographic and socio-economic characteristics.",Life,"   1. Wife's age                     (numerical)   2. Wife's education               (categorical)      1=low, 2, 3, 4=high   3. Husband's education            (categorical)      1=low, 2, 3, 4=high   4. Number of children ever born   (numerical)   5. Wife's religion                (binary)           0=Non-Islam, 1=Islam   6. Wife's now working?            (binary)           0=Yes, 1=No   7. Husband's occupation           (categorical)      1, 2, 3, 4   8. Standard-of-living index       (categorical)      1=low, 2, 3, 4=high   9. Media exposure                 (binary)           0=Good, 1=Not good   10. Contraceptive method used     (class attribute)  1=No-use, 2=Long-term, 3=Short-term","Dataset is a subset of the 1987 National Indonesia Contraceptive Prevalence Survey.This dataset is a subset of the 1987 National Indonesia Contraceptive Prevalence Survey. The samples are married women who were either not pregnant or do not know if they were at the time of interview. The problem is to predict the current contraceptive method choice (no use, long-term methods, or short-term methods) of a woman based on her demographic and socio-economic characteristics.   1. Wife's age                     (numerical)   2. Wife's education               (categorical)      1=low, 2, 3, 4=high   3. Husband's education            (categorical)      1=low, 2, 3, 4=high   4. Number of children ever born   (numerical)   5. Wife's religion                (binary)           0=Non-Islam, 1=Islam   6. Wife's now working?            (binary)           0=Yes, 1=No   7. Husband's occupation           (categorical)      1, 2, 3, 4   8. Standard-of-living index       (categorical)      1=low, 2, 3, 4=high   9. Media exposure                 (binary)           0=Good, 1=Not good   10. Contraceptive method used     (class attribute)  1=No-use, 2=Long-term, 3=Short-term"
Quality Assessment of Digital Colposcopies,Quality Assessment of Digital Colposcopies,This dataset explores the subjective quality assessment of digital colposcopies.,Quality+Assessment+of+Digital+Colposcopies,https://archive.ics.uci.edu/ml//machine-learning-databases/00384/,https://archive.ics.uci.edu/ml/datasets/Quality+Assessment+of+Digital+Colposcopies,"* The dataset was acquired and annotated by professional physicians at 'Hospital Universitario de Caracas'.* The subjective judgments (target variables) were originally done in an ordinal manner (poor, fair, good, excellent) and was discretized in two classes (bad, good).* Images were randomly sampled from the original colposcopic sequences (videos).* The original images and the manual segmentations are included in the 'images' directory.* The dataset has three modalities (i.e. Hinselmann, Green, Schiller).* The target variables are expert::X (X in 0,...,5) and consensus.",Life,"Three modalities: hinselmann, green, schiller.Number of Attributes: 69 (62 predictive attributes, 7 target variables)cervix_area: image area with cervix.os_area: image area with external os.walls_area: image area with vaginal walls.speculum_area: image area with the speculum.artifacts_area: image area with artifacts.cervix_artifacts_area: cervix area with the artifacts.os_artifacts_area: external os area with the artifacts.walls_artifacts_area: vaginal walls with the artifacts.speculum_artifacts_area: speculum area with the artifacts.cervix_specularities_area: cervix area with the specular reflections.os_specularities_area: external os area with the specular reflections.walls_specularities_area: vaginal walls area with the specular reflections.speculum_specularities_area: speculum area with the specular reflections.specularities_area: total area with specular reflections.area_h_max_diff: maximum area differences between the four cervix quadrants.rgb_cervix_r_mean: average color information in the cervix (R channel).rgb_cervix_r_std: stddev color information in the cervix (R channel).rgb_cervix_r_mean_minus_std: (avg - stddev) color information in the cervix (R channel).rgb_cervix_r_mean_plus_std: (avg + stddev) information in the cervix (R channel).rgb_cervix_g_mean: average color information in the cervix (G channel).rgb_cervix_g_std: stddev color information in the cervix (G channel).rgb_cervix_g_mean_minus_std: (avg - stddev)  color information in the cervix (G channel).rgb_cervix_g_mean_plus_std: (avg + stddev) color information in the cervix (G channel).rgb_cervix_b_mean: average color information in the cervix (B channel).rgb_cervix_b_std: stddev color information in the cervix (B channel).rgb_cervix_b_mean_minus_std: (avg - stddev) color information in the cervix (B channel).rgb_cervix_b_mean_plus_std: (avg + stddev) color information in the cervix (B channel).rgb_total_r_mean: average color information in the image (B channel).rgb_total_r_std: stddev color information in the image (R channel).rgb_total_r_mean_minus_std: (avg - stddev) color information in the image (R channel).rgb_total_r_mean_plus_std: (avg + stddev) color information in the image (R channel).rgb_total_g_mean: average color information in the image (G channel).rgb_total_g_std: stddev color information in the image (G channel).rgb_total_g_mean_minus_std: (avg - stddev) color information in the image (G channel).rgb_total_g_mean_plus_std: (avg + stddev) color information in the image (G channel).rgb_total_b_mean: average color information in the image (B channel).rgb_total_b_std: stddev color information in the image (B channel).rgb_total_b_mean_minus_std: (avg - stddev) color information in the image (B channel).rgb_total_b_mean_plus_std: (avg + stddev) color information in the image (B channel).hsv_cervix_h_mean: average color information in the cervix (H channel).hsv_cervix_h_std: stddev color information in the cervix (H channel).hsv_cervix_s_mean: average color information in the cervix (S channel).hsv_cervix_s_std: stddev color information in the cervix (S channel).hsv_cervix_v_mean: average color information in the cervix (V channel).hsv_cervix_v_std: stddev color information in the cervix (V channel).hsv_total_h_mean: average color information in the image (H channel).hsv_total_h_std: stddev color information in the image (H channel).hsv_total_s_mean: average color information in the image (S channel).hsv_total_s_std: stddev color information in the image (S channel).hsv_total_v_mean: average color information in the image (V channel).hsv_total_v_std: stddev color information in the image (V channel).fit_cervix_hull_rate: Coverage of the cervix convex hull by the cervix.fit_cervix_hull_total: Image coverage of the cervix convex hull.fit_cervix_bbox_rate: Coverage of the cervix bounding box by the cervix.fit_cervix_bbox_total: Image coverage of the cervix bounding box.fit_circle_rate: Coverage of the cervix circle by the cervix.fit_circle_total: Image coverage of the cervix circle.fit_ellipse_rate: Coverage of the cervix ellipse by the cervix.fit_ellipse_total: Image coverage of the cervix ellipse.fit_ellipse_goodness: Goodness of the ellipse fitting.dist_to_center_cervix: Distance between the cervix center and the image center.dist_to_center_os: Distance between the cervical os center and the image center.experts::0: subjective assessment of the Expert 0 (target variable).experts::1: subjective assessment of the Expert 1 (target variable).experts::2: subjective assessment of the Expert 2 (target variable).experts::3: subjective assessment of the Expert 3 (target variable).experts::4: subjective assessment of the Expert 4 (target variable).experts::5: subjective assessment of the Expert 5 (target variable).consensus: subjective assessment of the consensus (target variable).","This dataset explores the subjective quality assessment of digital colposcopies.* The dataset was acquired and annotated by professional physicians at 'Hospital Universitario de Caracas'.* The subjective judgments (target variables) were originally done in an ordinal manner (poor, fair, good, excellent) and was discretized in two classes (bad, good).* Images were randomly sampled from the original colposcopic sequences (videos).* The original images and the manual segmentations are included in the 'images' directory.* The dataset has three modalities (i.e. Hinselmann, Green, Schiller).* The target variables are expert::X (X in 0,...,5) and consensus.Three modalities: hinselmann, green, schiller.Number of Attributes: 69 (62 predictive attributes, 7 target variables)cervix_area: image area with cervix.os_area: image area with external os.walls_area: image area with vaginal walls.speculum_area: image area with the speculum.artifacts_area: image area with artifacts.cervix_artifacts_area: cervix area with the artifacts.os_artifacts_area: external os area with the artifacts.walls_artifacts_area: vaginal walls with the artifacts.speculum_artifacts_area: speculum area with the artifacts.cervix_specularities_area: cervix area with the specular reflections.os_specularities_area: external os area with the specular reflections.walls_specularities_area: vaginal walls area with the specular reflections.speculum_specularities_area: speculum area with the specular reflections.specularities_area: total area with specular reflections.area_h_max_diff: maximum area differences between the four cervix quadrants.rgb_cervix_r_mean: average color information in the cervix (R channel).rgb_cervix_r_std: stddev color information in the cervix (R channel).rgb_cervix_r_mean_minus_std: (avg - stddev) color information in the cervix (R channel).rgb_cervix_r_mean_plus_std: (avg + stddev) information in the cervix (R channel).rgb_cervix_g_mean: average color information in the cervix (G channel).rgb_cervix_g_std: stddev color information in the cervix (G channel).rgb_cervix_g_mean_minus_std: (avg - stddev)  color information in the cervix (G channel).rgb_cervix_g_mean_plus_std: (avg + stddev) color information in the cervix (G channel).rgb_cervix_b_mean: average color information in the cervix (B channel).rgb_cervix_b_std: stddev color information in the cervix (B channel).rgb_cervix_b_mean_minus_std: (avg - stddev) color information in the cervix (B channel).rgb_cervix_b_mean_plus_std: (avg + stddev) color information in the cervix (B channel).rgb_total_r_mean: average color information in the image (B channel).rgb_total_r_std: stddev color information in the image (R channel).rgb_total_r_mean_minus_std: (avg - stddev) color information in the image (R channel).rgb_total_r_mean_plus_std: (avg + stddev) color information in the image (R channel).rgb_total_g_mean: average color information in the image (G channel).rgb_total_g_std: stddev color information in the image (G channel).rgb_total_g_mean_minus_std: (avg - stddev) color information in the image (G channel).rgb_total_g_mean_plus_std: (avg + stddev) color information in the image (G channel).rgb_total_b_mean: average color information in the image (B channel).rgb_total_b_std: stddev color information in the image (B channel).rgb_total_b_mean_minus_std: (avg - stddev) color information in the image (B channel).rgb_total_b_mean_plus_std: (avg + stddev) color information in the image (B channel).hsv_cervix_h_mean: average color information in the cervix (H channel).hsv_cervix_h_std: stddev color information in the cervix (H channel).hsv_cervix_s_mean: average color information in the cervix (S channel).hsv_cervix_s_std: stddev color information in the cervix (S channel).hsv_cervix_v_mean: average color information in the cervix (V channel).hsv_cervix_v_std: stddev color information in the cervix (V channel).hsv_total_h_mean: average color information in the image (H channel).hsv_total_h_std: stddev color information in the image (H channel).hsv_total_s_mean: average color information in the image (S channel).hsv_total_s_std: stddev color information in the image (S channel).hsv_total_v_mean: average color information in the image (V channel).hsv_total_v_std: stddev color information in the image (V channel).fit_cervix_hull_rate: Coverage of the cervix convex hull by the cervix.fit_cervix_hull_total: Image coverage of the cervix convex hull.fit_cervix_bbox_rate: Coverage of the cervix bounding box by the cervix.fit_cervix_bbox_total: Image coverage of the cervix bounding box.fit_circle_rate: Coverage of the cervix circle by the cervix.fit_circle_total: Image coverage of the cervix circle.fit_ellipse_rate: Coverage of the cervix ellipse by the cervix.fit_ellipse_total: Image coverage of the cervix ellipse.fit_ellipse_goodness: Goodness of the ellipse fitting.dist_to_center_cervix: Distance between the cervix center and the image center.dist_to_center_os: Distance between the cervical os center and the image center.experts::0: subjective assessment of the Expert 0 (target variable).experts::1: subjective assessment of the Expert 1 (target variable).experts::2: subjective assessment of the Expert 2 (target variable).experts::3: subjective assessment of the Expert 3 (target variable).experts::4: subjective assessment of the Expert 4 (target variable).experts::5: subjective assessment of the Expert 5 (target variable).consensus: subjective assessment of the consensus (target variable)."
Raisin Dataset,Raisin Dataset,"Images of the Kecimen and Besni raisin varieties were obtained with CVS. A total of 900 raisins were used, including 450 from both varieties, and 7 morphological features were extracted.",Raisin+Dataset,https://archive.ics.uci.edu/ml//machine-learning-databases/00617/,https://archive.ics.uci.edu/ml/datasets/Raisin+Dataset,"Images of Kecimen and Besni raisin varieties grown in Turkey were obtained with CVS. A total of 900 raisin grains were used, including 450 pieces from both varieties. These images were subjected to various stages of pre-processing and 7 morphological features were extracted. These features have been classified using three different artificial intelligence techniques.",Life,"1.) Area: Gives the number of pixels within the boundaries of the raisin. 2.) Perimeter: It measures the environment by calculating the distance between the boundaries of the raisin and the pixels around it.3.) MajorAxisLength: Gives the length of the main axis, which is the longest line that can be drawn on the raisin.4.) MinorAxisLength: Gives the length of the small axis, which is the shortest line that can be drawn on the raisin.5.) Eccentricity: It gives a measure of the eccentricity of the ellipse, which has the same moments as raisins. 6.) ConvexArea: Gives the number of pixels of the smallest convex shell of the region formed by the raisin.7.) Extent: Gives the ratio of the region formed by the raisin to the total pixels in the bounding box.8.) Class: Kecimen and Besni raisin.","Images of the Kecimen and Besni raisin varieties were obtained with CVS. A total of 900 raisins were used, including 450 from both varieties, and 7 morphological features were extracted.Images of Kecimen and Besni raisin varieties grown in Turkey were obtained with CVS. A total of 900 raisin grains were used, including 450 pieces from both varieties. These images were subjected to various stages of pre-processing and 7 morphological features were extracted. These features have been classified using three different artificial intelligence techniques.1.) Area: Gives the number of pixels within the boundaries of the raisin. 2.) Perimeter: It measures the environment by calculating the distance between the boundaries of the raisin and the pixels around it.3.) MajorAxisLength: Gives the length of the main axis, which is the longest line that can be drawn on the raisin.4.) MinorAxisLength: Gives the length of the small axis, which is the shortest line that can be drawn on the raisin.5.) Eccentricity: It gives a measure of the eccentricity of the ellipse, which has the same moments as raisins. 6.) ConvexArea: Gives the number of pixels of the smallest convex shell of the region formed by the raisin.7.) Extent: Gives the ratio of the region formed by the raisin to the total pixels in the bounding box.8.) Class: Kecimen and Besni raisin."
Autistic Spectrum Disorder Screening Data for Children  ,Autistic Spectrum Disorder Screening Data for Children  ,Children screening data for autism suitable for classification and predictive tasks ,Autistic+Spectrum+Disorder+Screening+Data+for+Children++,https://archive.ics.uci.edu/ml//machine-learning-databases/00419/,https://archive.ics.uci.edu/ml/datasets/Autistic+Spectrum+Disorder+Screening+Data+for+Children++,see attached file for variables' description ,Life,see attached file for variables' description ,Children screening data for autism suitable for classification and predictive tasks see attached file for variables' description see attached file for variables' description 
Caesarian Section Classification Dataset,Caesarian Section Classification Dataset,This dataset contains information about caesarian section results of  80 pregnant women with the most important characteristics of delivery problems in the medical field.,Caesarian+Section+Classification+Dataset,https://archive.ics.uci.edu/ml//machine-learning-databases/00472/,https://archive.ics.uci.edu/ml/datasets/Caesarian+Section+Classification+Dataset,Provide all relevant information about your data set.,Life,"We choose age, delivery number, delivery time, blood pressure and heart status.We classify delivery time to Premature, Timely and Latecomer. As like the delivery time we consider blood pressure in three statuses of Low, Normal and High moods. Heart Problem is classified as apt and inept.@attribute 'Age' { 22,26,28,27,32,36,33,23,20,29,25,37,24,18,30,40,31,19,21,35,17,38 } @attribute 'Delivery number' { 1,2,3,4 }@attribute 'Delivery time' { 0,1,2 } -> {0 = timely , 1 = premature , 2 = latecomer}@attribute 'Blood of Pressure' { 2,1,0 } -> {0 = low , 1 = normal , 2 = high }@attribute 'Heart Problem' { 1,0 } -> {0 = apt, 1 = inept }@attribute Caesarian { 0,1 } -> {0 = No, 1 = Yes } ","This dataset contains information about caesarian section results of  80 pregnant women with the most important characteristics of delivery problems in the medical field.Provide all relevant information about your data set.We choose age, delivery number, delivery time, blood pressure and heart status.We classify delivery time to Premature, Timely and Latecomer. As like the delivery time we consider blood pressure in three statuses of Low, Normal and High moods. Heart Problem is classified as apt and inept.@attribute 'Age' { 22,26,28,27,32,36,33,23,20,29,25,37,24,18,30,40,31,19,21,35,17,38 } @attribute 'Delivery number' { 1,2,3,4 }@attribute 'Delivery time' { 0,1,2 } -> {0 = timely , 1 = premature , 2 = latecomer}@attribute 'Blood of Pressure' { 2,1,0 } -> {0 = low , 1 = normal , 2 = high }@attribute 'Heart Problem' { 1,0 } -> {0 = apt, 1 = inept }@attribute Caesarian { 0,1 } -> {0 = No, 1 = Yes } "
Breath Metabolomics,Breath Metabolomics,"Breath analysis is a pivotal method for biological phenotyping. In a pilot study, 100 experiments with four subjects have been performed to study the reproducibility of this technique.",Breath+Metabolomics,https://archive.ics.uci.edu/ml//machine-learning-databases/00548/,https://archive.ics.uci.edu/ml/datasets/Breath+Metabolomics,104 breath metabolomic experiments with 4 subjects have been performed. Average exhalation parameters together with metabolote signal intensities in breath of 1652 chemical compounds were recorded.,Life,CO2: CO2 concentration in %V: Exhaled Volume in LQ: Exhalation Flowrate in L/minp: Exhalation Pressure in mbarX: Chemical Compound Intensity in a.u.,"Breath analysis is a pivotal method for biological phenotyping. In a pilot study, 100 experiments with four subjects have been performed to study the reproducibility of this technique.104 breath metabolomic experiments with 4 subjects have been performed. Average exhalation parameters together with metabolote signal intensities in breath of 1652 chemical compounds were recorded.CO2: CO2 concentration in %V: Exhaled Volume in LQ: Exhalation Flowrate in L/minp: Exhalation Pressure in mbarX: Chemical Compound Intensity in a.u."
"Reuters RCV1 RCV2 Multilingual, Multiview Text Categorization Test collection","Reuters RCV1 RCV2 Multilingual, Multiview Text Categorization Test collection","This test collection contains feature characteristics of documents originally written in five different languages and their translations, over a common set of 6 categories. ",Reuters+RCV1+RCV2+Multilingual%2C+Multiview+Text+Categorization+Test+collection,https://archive.ics.uci.edu/ml//machine-learning-databases/00259/,https://archive.ics.uci.edu/ml/datasets/Reuters+RCV1+RCV2+Multilingual%2C+Multiview+Text+Categorization+Test+collection,"Uncompressing rcv1rcv2aminigoutte.tar.bz2 will create a directory  that contains 5 subdirectories EN, FR, GR, IT and SP, corresponding to the 5 languages. Each subdirectory in {EN, FR, GR, IT, SP} contains 5 files, each containing indexes of the documents written or translated in that language.  For example, EN contains files: - Index_EN-EN : Original English documents - Index_FR-EN : French documents translated to English - Index_GR-EN : German documents translated to English - Index_IT-EN : Italian documents translated to English - Index_SP-EN : Spanish documents translated to EnglishAnd similarly for the 4 other languages.Each file contains one indexed document per line, in a format similar to SVM_light.  Each line is of the form:  : : ... where  is the category label, ie one of C15, CCAT, E21, ECAT, GCAT or M11. : is the feature, value pair, in ascending order of feature index.The order of documents is maintained in corresponding files, for example, FR/Index_EN-FR and EN/Index_EN-EN have the same number of documents (and therefore the same number of lines), in the same order. ",Life,"We focused on six relatively populous categories: C15, CCAT, E21, ECAT, GCAT, M11. For each language and each class, we sampled up to 5000 documents from the RCV1 (for English) or RCV2 (for other languages). Documents belonging to more than one of our 6 classes were assigned the label of their smallest class.  This resulted in 12-30K documents per language, and 11-34K documents per class. The distribution of documents over languages and classes are:              Number of                   VocabularyLanguage      documents     percentage       size************  **********   ************  ************ English        18,758         16.78        21,531French         26,648         23.45        24,893German         29,953         26.80        34,279Italian        24,039         21.51        15,506Spanish        12,342         11.46        11,547-------Total         111,740The distribution of classes in the whole collection is           Number of                 Class      documents     percentage  *********  **********   ************ C15          18,816         16.84     CCAT         21,426         19.17     E21          13,701         12.26        ECAT         19,198         17.18        GCAT         19,178         17.16        M11          19,421         17.39In experiments that we conducted in cite{AUG09}, we considered each document available in a given language as the observed view for an example and all translated documents were used as the other views for that example, generated using Machine Translation. Results shown in this study were averaged over 10 random samples of 10 labeled examples per view for training, and 20% of the collection for testing. ","This test collection contains feature characteristics of documents originally written in five different languages and their translations, over a common set of 6 categories. Uncompressing rcv1rcv2aminigoutte.tar.bz2 will create a directory  that contains 5 subdirectories EN, FR, GR, IT and SP, corresponding to the 5 languages. Each subdirectory in {EN, FR, GR, IT, SP} contains 5 files, each containing indexes of the documents written or translated in that language.  For example, EN contains files: - Index_EN-EN : Original English documents - Index_FR-EN : French documents translated to English - Index_GR-EN : German documents translated to English - Index_IT-EN : Italian documents translated to English - Index_SP-EN : Spanish documents translated to EnglishAnd similarly for the 4 other languages.Each file contains one indexed document per line, in a format similar to SVM_light.  Each line is of the form:  : : ... where  is the category label, ie one of C15, CCAT, E21, ECAT, GCAT or M11. : is the feature, value pair, in ascending order of feature index.The order of documents is maintained in corresponding files, for example, FR/Index_EN-FR and EN/Index_EN-EN have the same number of documents (and therefore the same number of lines), in the same order. We focused on six relatively populous categories: C15, CCAT, E21, ECAT, GCAT, M11. For each language and each class, we sampled up to 5000 documents from the RCV1 (for English) or RCV2 (for other languages). Documents belonging to more than one of our 6 classes were assigned the label of their smallest class.  This resulted in 12-30K documents per language, and 11-34K documents per class. The distribution of documents over languages and classes are:              Number of                   VocabularyLanguage      documents     percentage       size************  **********   ************  ************ English        18,758         16.78        21,531French         26,648         23.45        24,893German         29,953         26.80        34,279Italian        24,039         21.51        15,506Spanish        12,342         11.46        11,547-------Total         111,740The distribution of classes in the whole collection is           Number of                 Class      documents     percentage  *********  **********   ************ C15          18,816         16.84     CCAT         21,426         19.17     E21          13,701         12.26        ECAT         19,198         17.18        GCAT         19,178         17.16        M11          19,421         17.39In experiments that we conducted in cite{AUG09}, we considered each document available in a given language as the observed view for an example and all translated documents were used as the other views for that example, generated using Machine Translation. Results shown in this study were averaged over 10 random samples of 10 labeled examples per view for training, and 20% of the collection for testing. "
Breast Tissue,Breast Tissue,Dataset with electrical impedance measurements of freshly excised tissue samples from the breast.,Breast+Tissue,https://archive.ics.uci.edu/ml//machine-learning-databases/00192/,https://archive.ics.uci.edu/ml/datasets/Breast+Tissue,"Impedance measurements were made at the frequencies: 15.625, 31.25, 62.5, 125, 250, 500, 1000 KHzImpedance measurements of freshly excised breast tissue were made at the follwoing frequencies: 15.625, 31.25, 62.5, 125, 250, 500, 1000 KHz. These measurements plotted in the (real, -imaginary) plane constitute the impedance spectrum from where the breast tissue features are computed.The dataset can be used for predicting the classification of either the original 6 classes or of 4 classes by merging together the fibro-adenoma, mastopathy and glandular classes whose discrimination is not important (they cannot be accurately discriminated anyway).",Life,"I0	Impedivity (ohm) at zero frequencyPA500	phase angle at 500 KHzHFS	high-frequency slope of phase angleDA	impedance distance between spectral endsAREA	area under spectrumA/DA	area normalized by DAMAX IP	maximum of the spectrumDR	distance between I0 and real part of the maximum frequency pointP	length of the spectral curveClass   car(carcinoma), fad (fibro-adenoma), mas (mastopathy), gla (glandular), con (connective), adi (adipose). The ","Dataset with electrical impedance measurements of freshly excised tissue samples from the breast.Impedance measurements were made at the frequencies: 15.625, 31.25, 62.5, 125, 250, 500, 1000 KHzImpedance measurements of freshly excised breast tissue were made at the follwoing frequencies: 15.625, 31.25, 62.5, 125, 250, 500, 1000 KHz. These measurements plotted in the (real, -imaginary) plane constitute the impedance spectrum from where the breast tissue features are computed.The dataset can be used for predicting the classification of either the original 6 classes or of 4 classes by merging together the fibro-adenoma, mastopathy and glandular classes whose discrimination is not important (they cannot be accurately discriminated anyway).I0	Impedivity (ohm) at zero frequencyPA500	phase angle at 500 KHzHFS	high-frequency slope of phase angleDA	impedance distance between spectral endsAREA	area under spectrumA/DA	area normalized by DAMAX IP	maximum of the spectrumDR	distance between I0 and real part of the maximum frequency pointP	length of the spectral curveClass   car(carcinoma), fad (fibro-adenoma), mas (mastopathy), gla (glandular), con (connective), adi (adipose). The "
Breast Cancer Wisconsin (Prognostic),Breast Cancer Wisconsin (Prognostic),Prognostic Wisconsin Breast Cancer Database,Breast+Cancer+Wisconsin+%28Prognostic%29,https://archive.ics.uci.edu/ml//machine-learning-databases/breast-cancer-wisconsin/,https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Prognostic%29,"Each record represents follow-up data for one breast cancer case.  These are consecutive patients seen by Dr. Wolberg since 1984, and include only those cases exhibiting invasive breast cancer and no evidence of distant metastases at the time of diagnosis. The first 30 features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass.  They describe characteristics of the cell nuclei present in the image. A few of the images can be found at [Web Link]The separation described above was obtained using Multisurface Method-Tree (MSM-T) [K. P. Bennett, ""Decision Tree Construction Via Linear Programming."" Proceedings of the 4th Midwest Artificial Intelligence and Cognitive Science Society, pp. 97-101, 1992], a classification method which uses linear programming to construct a decision tree.  Relevant features were selected using an exhaustive search in the space of 1-4 features and 1-3 separating planes.The actual linear program used to obtain the separating plane in the 3-dimensional space is that described in: [K. P. Bennett and O. L. Mangasarian: ""Robust Linear Programming Discrimination of Two Linearly Inseparable Sets"", Optimization Methods and Software 1, 1992, 23-34].The Recurrence Surface Approximation (RSA) method is a linear programming model which predicts Time To Recur using both recurrent and nonrecurrent cases.  See references (i) and (ii) above for details of the RSA method. This database is also available through the UW CS ftp server:ftp ftp.cs.wisc.educd math-prog/cpo-dataset/machine-learn/WPBC/",Life,"1) ID number2) Outcome (R = recur, N = nonrecur)3) Time (recurrence time if field 2 = R, disease-free time if field 2 = N)4-33) Ten real-valued features are computed for each cell nucleus:	a) radius (mean of distances from center to points on the perimeter)	b) texture (standard deviation of gray-scale values)	c) perimeter	d) area	e) smoothness (local variation in radius lengths)	f) compactness (perimeter^2 / area - 1.0)	g) concavity (severity of concave portions of the contour)	h) concave points (number of concave portions of the contour)	i) symmetry 	j) fractal dimension (""coastline approximation"" - 1)","Prognostic Wisconsin Breast Cancer DatabaseEach record represents follow-up data for one breast cancer case.  These are consecutive patients seen by Dr. Wolberg since 1984, and include only those cases exhibiting invasive breast cancer and no evidence of distant metastases at the time of diagnosis. The first 30 features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass.  They describe characteristics of the cell nuclei present in the image. A few of the images can be found at [Web Link]The separation described above was obtained using Multisurface Method-Tree (MSM-T) [K. P. Bennett, ""Decision Tree Construction Via Linear Programming."" Proceedings of the 4th Midwest Artificial Intelligence and Cognitive Science Society, pp. 97-101, 1992], a classification method which uses linear programming to construct a decision tree.  Relevant features were selected using an exhaustive search in the space of 1-4 features and 1-3 separating planes.The actual linear program used to obtain the separating plane in the 3-dimensional space is that described in: [K. P. Bennett and O. L. Mangasarian: ""Robust Linear Programming Discrimination of Two Linearly Inseparable Sets"", Optimization Methods and Software 1, 1992, 23-34].The Recurrence Surface Approximation (RSA) method is a linear programming model which predicts Time To Recur using both recurrent and nonrecurrent cases.  See references (i) and (ii) above for details of the RSA method. This database is also available through the UW CS ftp server:ftp ftp.cs.wisc.educd math-prog/cpo-dataset/machine-learn/WPBC/1) ID number2) Outcome (R = recur, N = nonrecur)3) Time (recurrence time if field 2 = R, disease-free time if field 2 = N)4-33) Ten real-valued features are computed for each cell nucleus:	a) radius (mean of distances from center to points on the perimeter)	b) texture (standard deviation of gray-scale values)	c) perimeter	d) area	e) smoothness (local variation in radius lengths)	f) compactness (perimeter^2 / area - 1.0)	g) concavity (severity of concave portions of the contour)	h) concave points (number of concave portions of the contour)	i) symmetry 	j) fractal dimension (""coastline approximation"" - 1)"
Breast Cancer Wisconsin (Original),Breast Cancer Wisconsin (Original),Original Wisconsin Breast Cancer Database,Breast+Cancer+Wisconsin+%28Original%29,https://archive.ics.uci.edu/ml//machine-learning-databases/breast-cancer-wisconsin/,https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Original%29,"Samples arrive periodically as Dr. Wolberg reports his clinical cases. The database therefore reflects this chronological grouping of the data. This grouping information appears immediately below, having been removed from the data itself:Group 1: 367 instances (January 1989)Group 2:  70 instances (October 1989)Group 3:  31 instances (February 1990)Group 4:  17 instances (April 1990)Group 5:  48 instances (August 1990)Group 6:  49 instances (Updated January 1991)Group 7:  31 instances (June 1991)Group 8:  86 instances (November 1991)-----------------------------------------Total:   699 points (as of the donated datbase on 15 July 1992)Note that the results summarized above in Past Usage refer to a dataset of size 369, while Group 1 has only 367 instances.  This is because it originally contained 369 instances; 2 were removed.  The following statements summarizes changes to the original Group 1's set of data:#####  Group 1 : 367 points: 200B 167M (January 1989)#####  Revised Jan 10, 1991: Replaced zero bare nuclei in 1080185 & 1187805#####  Revised Nov 22,1991: Removed 765878,4,5,9,7,10,10,10,3,8,1 no record#####                  : Removed 484201,2,7,8,8,4,3,10,3,4,1 zero epithelial#####                  : Changed 0 to 1 in field 6 of sample 1219406#####                  : Changed 0 to 1 in field 8 of following sample:#####                  : 1182404,2,3,1,1,1,2,0,1,1,1",Life,"1. Sample code number:            id number2. Clump Thickness:               1 - 103. Uniformity of Cell Size:       1 - 104. Uniformity of Cell Shape:      1 - 105. Marginal Adhesion:             1 - 106. Single Epithelial Cell Size:   1 - 107. Bare Nuclei:                   1 - 108. Bland Chromatin:               1 - 109. Normal Nucleoli:               1 - 1010. Mitoses:                       1 - 1011. Class:                        (2 for benign, 4 for malignant)","Original Wisconsin Breast Cancer DatabaseSamples arrive periodically as Dr. Wolberg reports his clinical cases. The database therefore reflects this chronological grouping of the data. This grouping information appears immediately below, having been removed from the data itself:Group 1: 367 instances (January 1989)Group 2:  70 instances (October 1989)Group 3:  31 instances (February 1990)Group 4:  17 instances (April 1990)Group 5:  48 instances (August 1990)Group 6:  49 instances (Updated January 1991)Group 7:  31 instances (June 1991)Group 8:  86 instances (November 1991)-----------------------------------------Total:   699 points (as of the donated datbase on 15 July 1992)Note that the results summarized above in Past Usage refer to a dataset of size 369, while Group 1 has only 367 instances.  This is because it originally contained 369 instances; 2 were removed.  The following statements summarizes changes to the original Group 1's set of data:#####  Group 1 : 367 points: 200B 167M (January 1989)#####  Revised Jan 10, 1991: Replaced zero bare nuclei in 1080185 & 1187805#####  Revised Nov 22,1991: Removed 765878,4,5,9,7,10,10,10,3,8,1 no record#####                  : Removed 484201,2,7,8,8,4,3,10,3,4,1 zero epithelial#####                  : Changed 0 to 1 in field 6 of sample 1219406#####                  : Changed 0 to 1 in field 8 of following sample:#####                  : 1182404,2,3,1,1,1,2,0,1,1,11. Sample code number:            id number2. Clump Thickness:               1 - 103. Uniformity of Cell Size:       1 - 104. Uniformity of Cell Shape:      1 - 105. Marginal Adhesion:             1 - 106. Single Epithelial Cell Size:   1 - 107. Bare Nuclei:                   1 - 108. Bland Chromatin:               1 - 109. Normal Nucleoli:               1 - 1010. Mitoses:                       1 - 1011. Class:                        (2 for benign, 4 for malignant)"
Anuran Calls (MFCCs),Anuran Calls (MFCCs),"Acoustic features extracted from syllables of anuran (frogs) calls, including the family, the genus, and the species labels (multilabel). ",Anuran+Calls+%28MFCCs%29,https://archive.ics.uci.edu/ml//machine-learning-databases/00406/,https://archive.ics.uci.edu/ml/datasets/Anuran+Calls+%28MFCCs%29,"This dataset was used in several classifications tasks related to the challenge of anuran species recognition through their calls. It is a multilabel dataset with three columns of labels. This dataset was created segmenting 60 audio records belonging to 4 different families, 8 genus, and 10 species. Each audio corresponds to one specimen (an individual frog), the record ID is also included as an extra column. We used the spectral entropy and a binary cluster method to detect audio frames belonging to each syllable. The segmentation and feature extraction were carried out in Matlab. After the segmentation we got 7195 syllables, which became instances for train and test the classifier. These records were collected in situ under real noise conditions (the background sound). Some species are from the campus of Federal University of Amazonas, Manaus, others from Mata AtlÃƒÂ¢ntica, Brazil, and one of them from CÃƒÂ³rdoba, Argentina. The recordings were stored in wav format with 44.1kHz of sampling frequency and 32bit of resolution, which allows us to analyze signals up to 22kHz. From every extracted syllable 22 MFCCs were calculated by using 44 triangular filters. These coefficients were normalized between -1 Ã¢â€°Â¤ mfcc Ã¢â€°Â¤ 1. The amount of instances per class are:Families:	 Bufonidae              68      Dendrobatidae         542      Hylidae              2165      Leptodactylidae      4420 Genus:     Adenomera          4150      Ameerega            542      Dendropsophus       310      Hypsiboas          1593      Leptodactylus       270      Osteocephalus       114      Rhinella             68      Scinax              148 Species:     AdenomeraAndre             672      AdenomeraHylaedactÃ¢â‚¬Â¦       3478      Ameeregatrivittata         542      HylaMinuta                 310      HypsiboasCinerascens       472      HypsiboasCordobae         1121      LeptodactylusFuscus        270      OsteocephalusOophaÃ¢â‚¬Â¦        114      Rhinellagranulosa           68      ScinaxRuber                148 ",Life,"Mel-frequency cepstral coefficients (MFCCs) are coefficients that collectively make up an mel-frequency cepstrum (MFC). Due to each syllable has different length, every row (i) was normalized acording to MFCCs_i/(max(abs(MFCCs_i))).","Acoustic features extracted from syllables of anuran (frogs) calls, including the family, the genus, and the species labels (multilabel). This dataset was used in several classifications tasks related to the challenge of anuran species recognition through their calls. It is a multilabel dataset with three columns of labels. This dataset was created segmenting 60 audio records belonging to 4 different families, 8 genus, and 10 species. Each audio corresponds to one specimen (an individual frog), the record ID is also included as an extra column. We used the spectral entropy and a binary cluster method to detect audio frames belonging to each syllable. The segmentation and feature extraction were carried out in Matlab. After the segmentation we got 7195 syllables, which became instances for train and test the classifier. These records were collected in situ under real noise conditions (the background sound). Some species are from the campus of Federal University of Amazonas, Manaus, others from Mata AtlÃƒÂ¢ntica, Brazil, and one of them from CÃƒÂ³rdoba, Argentina. The recordings were stored in wav format with 44.1kHz of sampling frequency and 32bit of resolution, which allows us to analyze signals up to 22kHz. From every extracted syllable 22 MFCCs were calculated by using 44 triangular filters. These coefficients were normalized between -1 Ã¢â€°Â¤ mfcc Ã¢â€°Â¤ 1. The amount of instances per class are:Families:	 Bufonidae              68      Dendrobatidae         542      Hylidae              2165      Leptodactylidae      4420 Genus:     Adenomera          4150      Ameerega            542      Dendropsophus       310      Hypsiboas          1593      Leptodactylus       270      Osteocephalus       114      Rhinella             68      Scinax              148 Species:     AdenomeraAndre             672      AdenomeraHylaedactÃ¢â‚¬Â¦       3478      Ameeregatrivittata         542      HylaMinuta                 310      HypsiboasCinerascens       472      HypsiboasCordobae         1121      LeptodactylusFuscus        270      OsteocephalusOophaÃ¢â‚¬Â¦        114      Rhinellagranulosa           68      ScinaxRuber                148 Mel-frequency cepstral coefficients (MFCCs) are coefficients that collectively make up an mel-frequency cepstrum (MFC). Due to each syllable has different length, every row (i) was normalized acording to MFCCs_i/(max(abs(MFCCs_i)))."
Breast Cancer Wisconsin (Diagnostic),Breast Cancer Wisconsin (Diagnostic),Diagnostic Wisconsin Breast Cancer Database,Breast+Cancer+Wisconsin+%28Diagnostic%29,https://archive.ics.uci.edu/ml//machine-learning-databases/breast-cancer-wisconsin/,https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29,"Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass.  They describe characteristics of the cell nuclei present in the image. A few of the images can be found at [Web Link]Separating plane described above was obtained using Multisurface Method-Tree (MSM-T) [K. P. Bennett, ""Decision Tree Construction Via Linear Programming."" Proceedings of the 4th Midwest Artificial Intelligence and Cognitive Science Society, pp. 97-101, 1992], a classification method which uses linear programming to construct a decision tree.  Relevant features were selected using an exhaustive search in the space of 1-4 features and 1-3 separating planes.The actual linear program used to obtain the separating plane in the 3-dimensional space is that described in: [K. P. Bennett and O. L. Mangasarian: ""Robust Linear Programming Discrimination of Two Linearly Inseparable Sets"", Optimization Methods and Software 1, 1992, 23-34].This database is also available through the UW CS ftp server:ftp ftp.cs.wisc.educd math-prog/cpo-dataset/machine-learn/WDBC/",Life,"1) ID number2) Diagnosis (M = malignant, B = benign)3-32)Ten real-valued features are computed for each cell nucleus:	a) radius (mean of distances from center to points on the perimeter)	b) texture (standard deviation of gray-scale values)	c) perimeter	d) area	e) smoothness (local variation in radius lengths)	f) compactness (perimeter^2 / area - 1.0)	g) concavity (severity of concave portions of the contour)	h) concave points (number of concave portions of the contour)	i) symmetry 	j) fractal dimension (""coastline approximation"" - 1)","Diagnostic Wisconsin Breast Cancer DatabaseFeatures are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass.  They describe characteristics of the cell nuclei present in the image. A few of the images can be found at [Web Link]Separating plane described above was obtained using Multisurface Method-Tree (MSM-T) [K. P. Bennett, ""Decision Tree Construction Via Linear Programming."" Proceedings of the 4th Midwest Artificial Intelligence and Cognitive Science Society, pp. 97-101, 1992], a classification method which uses linear programming to construct a decision tree.  Relevant features were selected using an exhaustive search in the space of 1-4 features and 1-3 separating planes.The actual linear program used to obtain the separating plane in the 3-dimensional space is that described in: [K. P. Bennett and O. L. Mangasarian: ""Robust Linear Programming Discrimination of Two Linearly Inseparable Sets"", Optimization Methods and Software 1, 1992, 23-34].This database is also available through the UW CS ftp server:ftp ftp.cs.wisc.educd math-prog/cpo-dataset/machine-learn/WDBC/1) ID number2) Diagnosis (M = malignant, B = benign)3-32)Ten real-valued features are computed for each cell nucleus:	a) radius (mean of distances from center to points on the perimeter)	b) texture (standard deviation of gray-scale values)	c) perimeter	d) area	e) smoothness (local variation in radius lengths)	f) compactness (perimeter^2 / area - 1.0)	g) concavity (severity of concave portions of the contour)	h) concave points (number of concave portions of the contour)	i) symmetry 	j) fractal dimension (""coastline approximation"" - 1)"
Risk Factor prediction of Chronic Kidney Disease,Risk Factor prediction of Chronic Kidney Disease,Chronic kidney disease (CKD) is an increasing medical issue that declines the productivity of renal capacities and subsequently damages the kidneys.,Risk+Factor+prediction+of+Chronic+Kidney+Disease,https://archive.ics.uci.edu/ml//machine-learning-databases/00624/,https://archive.ics.uci.edu/ml/datasets/Risk+Factor+prediction+of+Chronic+Kidney+Disease,"This dataset is not pre-processing, if you want to apply a Machine learning Algorithm at first you have to need to pre-process the data. We are using the following criteria to collect the data.1. bp(Diastolic)2. bp limit3. sg4. al5. class6. rbc7. su8. pc9. pcc10. ba11.bgr12. bu13. sod14. sc15. pot16. hemo17. pcv18. rbcc19. wbcc20. htn21. dm22. cad23. appet24. pe25. ane26. grf27. stage28. affected29. age",Life,1. bp(Diastolic)2. bp limit3. sg4. al5. class6. rbc7. su8. pc9. pcc10. ba11.bgr12. bu13. sod14. sc15. pot16. hemo17. pcv18. rbcc19. wbcc20. htn21. dm22. cad23. appet24. pe25. ane26. grf27. stage28. affected29. age,"Chronic kidney disease (CKD) is an increasing medical issue that declines the productivity of renal capacities and subsequently damages the kidneys.This dataset is not pre-processing, if you want to apply a Machine learning Algorithm at first you have to need to pre-process the data. We are using the following criteria to collect the data.1. bp(Diastolic)2. bp limit3. sg4. al5. class6. rbc7. su8. pc9. pcc10. ba11.bgr12. bu13. sod14. sc15. pot16. hemo17. pcv18. rbcc19. wbcc20. htn21. dm22. cad23. appet24. pe25. ane26. grf27. stage28. affected29. age1. bp(Diastolic)2. bp limit3. sg4. al5. class6. rbc7. su8. pc9. pcc10. ba11.bgr12. bu13. sod14. sc15. pot16. hemo17. pcv18. rbcc19. wbcc20. htn21. dm22. cad23. appet24. pe25. ane26. grf27. stage28. affected29. age"
Algerian Forest Fires Dataset  ,Algerian Forest Fires Dataset  ,The dataset includes 244 instances that regroup a data of two regions of Algeria.,Algerian+Forest+Fires+Dataset++,https://archive.ics.uci.edu/ml//machine-learning-databases/00547/,https://archive.ics.uci.edu/ml/datasets/Algerian+Forest+Fires+Dataset++,"The dataset includes 244 instances that regroup a data of two regions of Algeria,namely the Bejaia region located in the northeast of Algeria and the Sidi Bel-abbes region located in the northwest of Algeria.122 instances for each region. The period from June 2012 to September 2012. The dataset includes 11 attribues and 1 output attribue (class)The 244 instances have been classified into Ã¢â‚¬ËœfireÃ¢â‚¬â„¢ (138 classes) and Ã¢â‚¬Ëœnot fireÃ¢â‚¬â„¢ (106 classes) classes.",Life,"1. Date : (DD/MM/YYYY) Day, month ('june' to 'september'), year (2012)Weather data observations 2. Temp : temperature noon (temperature max)  in Celsius degrees: 22 to 423. RH : Relative Humidity in %: 21 to 90 4. Ws :Wind speed in km/h: 6 to 29 5. Rain: total day in mm: 0 to 16.8FWI Components  6. Fine Fuel Moisture Code (FFMC) index from the FWI system: 28.6 to 92.5 7. Duff Moisture Code (DMC) index from the FWI system: 1.1 to 65.9 8. Drought Code (DC) index from the FWI system:  7 to 220.49. Initial Spread Index (ISI) index from the FWI system: 0 to 18.5 10. Buildup Index (BUI) index from the FWI system: 1.1 to 6811. Fire Weather Index (FWI) Index: 0 to 31.112. Classes: two classes, namely   Ã¢â‚¬Å“FireÃ¢â‚¬Â� and Ã¢â‚¬Å“not FireÃ¢â‚¬Â�","The dataset includes 244 instances that regroup a data of two regions of Algeria.The dataset includes 244 instances that regroup a data of two regions of Algeria,namely the Bejaia region located in the northeast of Algeria and the Sidi Bel-abbes region located in the northwest of Algeria.122 instances for each region. The period from June 2012 to September 2012. The dataset includes 11 attribues and 1 output attribue (class)The 244 instances have been classified into Ã¢â‚¬ËœfireÃ¢â‚¬â„¢ (138 classes) and Ã¢â‚¬Ëœnot fireÃ¢â‚¬â„¢ (106 classes) classes.1. Date : (DD/MM/YYYY) Day, month ('june' to 'september'), year (2012)Weather data observations 2. Temp : temperature noon (temperature max)  in Celsius degrees: 22 to 423. RH : Relative Humidity in %: 21 to 90 4. Ws :Wind speed in km/h: 6 to 29 5. Rain: total day in mm: 0 to 16.8FWI Components  6. Fine Fuel Moisture Code (FFMC) index from the FWI system: 28.6 to 92.5 7. Duff Moisture Code (DMC) index from the FWI system: 1.1 to 65.9 8. Drought Code (DC) index from the FWI system:  7 to 220.49. Initial Spread Index (ISI) index from the FWI system: 0 to 18.5 10. Buildup Index (BUI) index from the FWI system: 1.1 to 6811. Fire Weather Index (FWI) Index: 0 to 31.112. Classes: two classes, namely   Ã¢â‚¬Å“FireÃ¢â‚¬Â� and Ã¢â‚¬Å“not FireÃ¢â‚¬Â�"
Breast Cancer,Breast Cancer,Breast Cancer Data (Restricted Access),Breast+Cancer,https://archive.ics.uci.edu/ml//machine-learning-databases/breast-cancer/,https://archive.ics.uci.edu/ml/datasets/Breast+Cancer,"This is one of three domains provided by the Oncology Institute that has repeatedly appeared in the machine learning literature. (See also lymphography and primary-tumor.)This data set includes 201 instances of one class and 85 instances of another class.  The instances are described by 9 attributes, some of which are linear and some are nominal.",Life,"   1. Class: no-recurrence-events, recurrence-events   2. age: 10-19, 20-29, 30-39, 40-49, 50-59, 60-69, 70-79, 80-89, 90-99.   3. menopause: lt40, ge40, premeno.   4. tumor-size: 0-4, 5-9, 10-14, 15-19, 20-24, 25-29, 30-34, 35-39, 40-44, 45-49, 50-54, 55-59.   5. inv-nodes: 0-2, 3-5, 6-8, 9-11, 12-14, 15-17, 18-20, 21-23, 24-26, 27-29, 30-32, 33-35, 36-39.   6. node-caps: yes, no.   7. deg-malig: 1, 2, 3.   8. breast: left, right.   9. breast-quad: left-up, left-low, right-up,	right-low, central.  10. irradiat:	yes, no.","Breast Cancer Data (Restricted Access)This is one of three domains provided by the Oncology Institute that has repeatedly appeared in the machine learning literature. (See also lymphography and primary-tumor.)This data set includes 201 instances of one class and 85 instances of another class.  The instances are described by 9 attributes, some of which are linear and some are nominal.   1. Class: no-recurrence-events, recurrence-events   2. age: 10-19, 20-29, 30-39, 40-49, 50-59, 60-69, 70-79, 80-89, 90-99.   3. menopause: lt40, ge40, premeno.   4. tumor-size: 0-4, 5-9, 10-14, 15-19, 20-24, 25-29, 30-34, 35-39, 40-44, 45-49, 50-54, 55-59.   5. inv-nodes: 0-2, 3-5, 6-8, 9-11, 12-14, 15-17, 18-20, 21-23, 24-26, 27-29, 30-32, 33-35, 36-39.   6. node-caps: yes, no.   7. deg-malig: 1, 2, 3.   8. breast: left, right.   9. breast-quad: left-up, left-low, right-up,	right-low, central.  10. irradiat:	yes, no."
Amphibians,Amphibians,The dataset is a multilabel classification problem. The goal is to predict the presence of amphibians species near the water reservoirs based on features obtained from GIS systems and satellite images,Amphibians,https://archive.ics.uci.edu/ml//machine-learning-databases/00528/,https://archive.ics.uci.edu/ml/datasets/Amphibians,"The data used was derived from GIS and satellite information, as well as from information gathered from the natural inventories that were prepared for the environmental impact assessment (EIA) reports for two planned road projects (Road A and Road B) in Poland. These reports were mostly used to gather information on the size of the amphibian population in each of the 189 occurrence sites.Road A project concerned part of the planned A1 motorway section in Pyrzowice; the section is located along the northern border of the Silesian Voivodship and is about 75 km long. The field research involved a strip of land with a width of 500 m on both sides of the proposed project area. The field inventory was carried out in 2010 [1] and 2011 [2,3]. The results of these inventories were complemented by Marek SoÃ…â€štysiak observations, which were conducted between 2014 and 2016 [4]. Finally, the first project included 80 amphibian breeding sites.Road B inventory was prepared in the vicinity of two variants of the planned Beskidy Integration Way on the Bielsko BiaÃ…â€ša-Wadowice-GÃ…â€šogoczÃƒÂ³w section of the S52 motorway. The length of this section of road is approximately 60 km. During the inventory, which was taken in 2010, 125 real and potential amphibian occurrence sites were described in [5]. The methodology of the herpetological inventory included map analysis, literature and archive data analysis, and, then, field observations. As in the first case, the inventory was made in the spring time and consisted of the observation of the occurrence of amphibians in water reservoirs. The research area included a 500 m wide belt for each of the considered variants of the planned road. In order to conduct the final experiments, 109 amphibian occurrence sites were taken into account.[1] StruzyÃ…â€žski, W. Ã‹â„¢ Inventory of Occurrence of Amphibians and Reptiles, Including Their Migratory Routes in the Vicinity of the Planned Highway A-1, Section: The Northern Boundary of the Silesian VoivodeshipÃ¢â‚¬â€�Pyrzowice; Warsaw Univ. of Life Sci.: Warsaw, Poland, 2010.[2] KiczyÃ…â€žska, A.; Falkowski, M.; JaskuÃ…â€ša, R.; Kaczkowski, Z.; Hejduk, J.; Horbacz, A. Natural Inventory for the A1 Motorway TuszynÃ¢â‚¬â€œPyrzowice Section ZawodzieÃ¢â‚¬â€œPyrzowice; National Foundation for Environmental Protection, Warszawa: Katowice, Poland, 2011.[3] Ã…Â�ukaszek, M.; CabaÃ…â€ša, S.; Zygmunt, J.; Wojtas, P. Report from the Field Research and Natural Inventory for Documentation: Ã¢â‚¬Å“Construction of the A1 Motorway TuszynÃ¢â‚¬â€�Pyrzowice Part II, Section 2 the Northern Boundary of the Silesian VoivodeshipÃ¢â‚¬â€œZawodzie; Environmental Protection Company EKOSOUND: Sosnowiec, Poland, 2011.[4] SoÃ…â€štysiak, M.; DÃ„â€¦browska, D. Inventory of Occurrence of Amphibians in the Vicinity of the Planned Highway A-1, Section: The Northern Boundary of the Silesian VoivodeshipÃ¢â‚¬â€œPyrzowice; The Upper Silesian Nature Society: Katowice, Poland, 2016.[5] Guzik, M.; BaÃ…â€º, G.; Kurek, K.; PoÃ…â€šczyÃ…â€žskaÃ¢â‚¬â€œKonior, G.; Potoczek, M.; SmÃƒÂ³Ã…â€ška, M.; SnieÃ…Â¼ko, S.; ZyÃ…â€ºk, B.;  Najberek, K.; GaÃ…â€š, A,. Inventory of Reptiles, Amphibians and Their Habitats in the Vicinity of the Beskidy Integration Way, Section Bielsko BialaÃ¢â‚¬â€�GÃ…â€šogoczÃƒÂ³w with Protection Proposals; Institute of Nature Conservation: KrakÃƒÂ³w, Poland, 2011",Life,"Provide information about each attribute in your data set.List of attributes and types:ID -> IntegerMV -> CategoricalSR -> NumericalNR -> NumericalTR -> CategoricalVR -> CategoricalSUR1 -> CategoricalSUR2 -> CategoricalSUR3 -> CategoricalUR -> CategoricalFR -> CategoricalOR -> NumericalRR -> Ordinal; BR -> Ordinal; MR -> CategoricalCR -> CategoricalGreen frogs -> Categorical; Label 1Brown frogs -> Categorical; Label 2Common toad -> Categorical; Label 3Fire-bellied toad -> Categorical; Label 4Tree frog -> Categorical; Label 5Common newt -> Categorical; Label 6Great crested newt -> Categorical; Label 7Name and symbol type description:1)	ID Ã¢â‚¬â€œ vector ID (not used in the calculations)2)	MV Ã¢â‚¬â€œ motorway (not used in the calculations)3)	SR -> Surface of water reservoir numeric [m2]4)	NR -> Number of water reservoirs in habitat - Comment: The larger the number of reservoirs, the more likely it is that some of them will be suitable for amphibian breeding.5)	TR -> Type of water reservoirs:a.	reservoirs with natural features that are natural or anthropogenic water reservoirs (e.g., subsidence post-exploited water reservoirs), not subjected to naturalizationb.	recently formed reservoirs, not subjected to naturalization c.	settling pondsd.	water reservoirs located near housese.	technological water reservoirsf.	water reservoirs in allotment gardens g.	trenchesh.	wet meadows, flood plains, marshesi.	river valleysj.	streams and very small watercourses6)	VR - Presence of vegetation within the reservoirs:a.	no vegetationb.	narrow patches at the edgesc.	areas heavily overgrownd.	lush vegetation within the reservoir with some part devoid of vegetatione.	reservoirs completely overgrown with a disappearing water tableComment: The vegetation in the reservoir favors amphibians, facilitates breeding, and allows the larvae to feed and give shelter. However, excess vegetation can lead to the overgrowth of the pond and water shortages.7)	SUR1 - Surroundings 1Ã¢â‚¬â€�the dominant types of land cover surrounding the water reservoir8)	SUR2 - Surroundings 2Ã¢â‚¬â€�the second most dominant types of land cover surrounding the water reservoir9)	SUR3 - Surroundings 3Ã¢â‚¬â€�the third most dominant types of land cover surrounding the water reservoirComment: The Ã¢â‚¬Å“surroundingsÃ¢â‚¬Â� feature was designated in three stages. First, the dominant surroundings were selected. Then, two secondary types were chosen.a.	forest areas (with meadows) and densely wooded areasb.	areas of wasteland and meadowsc.	allotment gardensd.	parks and green arease.	dense building development, industrial areasf.	dispersed habitation, orchards, gardensg.	river valleysh.	roads, streetsi.	agricultural landThe most valuable surroundings of water reservoirs for amphibians are areas with the least anthropopressure and proper moisture.10)	UR - Use of water reservoirs:a.	unused by man (very attractive for amphibians)b.	recreational and scenic (care work is performed)c.	used economically (often fish farming)d.	technological11)	FR - The presence of fishing:a.	lack of or occasional fishingb.	intense fishingc.	breeding reservoirsComment: The presence of a large amount of fishing, in particular predatory and intense fishing, is not conducive to the presence of amphibians.12)	OR - Percentage access from the edges of the reservoir to undeveloped areas (the proposed percentage ranges are a numerical reflection of the phrases: lack of access, low access, medium access, large access to free space):a.	0Ã¢â‚¬â€œ25%Ã¢â‚¬â€�lack of access or poor accessb.	25Ã¢â‚¬â€œ50%Ã¢â‚¬â€�low accessc.	50Ã¢â‚¬â€œ75%Ã¢â‚¬â€�medium access,d.	75Ã¢â‚¬â€œ100%Ã¢â‚¬â€�large access to terrestrial habitats of the shoreline is in contact with the terrestrial habitat of amphibians.13)	RR Minimum distance from the water reservoir to roads:a.	<50 mb.	50Ã¢â‚¬â€œ100 mc.	100Ã¢â‚¬â€œ200 md.	200Ã¢â‚¬â€œ500 me.	500Ã¢â‚¬â€œ1000 mf.	>1000 mComment: The greater the distance between the reservoir and the road, the more safety for amphibians.14)	BR - Building development - Minimum distance to buildings:a.	 <50 mb.	50Ã¢â‚¬â€œ100 mc.	100Ã¢â‚¬â€œ200 md.	200Ã¢â‚¬â€œ500 me.	500Ã¢â‚¬â€œ1000 mf.	>1000 mComment: The more distant the buildings, the more favorable the conditions for the occurrence of amphibians. 15)	MR - Maintenance status of the reservoir:a.	Cleanb.	slightly litteredc.	reservoirs heavily or very heavily litteredComment: Trash causes devastation of the reservoir ecosystem. Backfilling and leveling of water reservoirs with ground and debris should also be considered.16)	CR - Type of shore a.	Natural b.	ConcreteComment: A concrete shore of a reservoir is not attractive for amphibians. A vertical concrete shore is usually a barrier for amphibians when they try to leave the water.17)	Label 1 Ã¢â‚¬â€œ the presence of Green frogs 18)	Label 2 Ã¢â‚¬â€œ the presence of Brown frogs19)	Label 3 Ã¢â‚¬â€œ the presence of Common toad20)	Label 4 Ã¢â‚¬â€œ the presence of Fire-bellied toad21)	Label 5 Ã¢â‚¬â€œ the presence of Tree frog22)	Label 6 Ã¢â‚¬â€œ the presence of Common newt23)	Label 7 Ã¢â‚¬â€œ the presence of Great crested newt The dataset is described in details in:Marcin Blachnik, Marek SoÃ…â€štysiak, Dominika DÃ„â€¦browska Predicting presence of amphibian species using features obtained from GIS and satellite images.. ISPRS International Journal of Geo-Information 8 (3) pp. 123. MDPI. 2019","The dataset is a multilabel classification problem. The goal is to predict the presence of amphibians species near the water reservoirs based on features obtained from GIS systems and satellite imagesThe data used was derived from GIS and satellite information, as well as from information gathered from the natural inventories that were prepared for the environmental impact assessment (EIA) reports for two planned road projects (Road A and Road B) in Poland. These reports were mostly used to gather information on the size of the amphibian population in each of the 189 occurrence sites.Road A project concerned part of the planned A1 motorway section in Pyrzowice; the section is located along the northern border of the Silesian Voivodship and is about 75 km long. The field research involved a strip of land with a width of 500 m on both sides of the proposed project area. The field inventory was carried out in 2010 [1] and 2011 [2,3]. The results of these inventories were complemented by Marek SoÃ…â€štysiak observations, which were conducted between 2014 and 2016 [4]. Finally, the first project included 80 amphibian breeding sites.Road B inventory was prepared in the vicinity of two variants of the planned Beskidy Integration Way on the Bielsko BiaÃ…â€ša-Wadowice-GÃ…â€šogoczÃƒÂ³w section of the S52 motorway. The length of this section of road is approximately 60 km. During the inventory, which was taken in 2010, 125 real and potential amphibian occurrence sites were described in [5]. The methodology of the herpetological inventory included map analysis, literature and archive data analysis, and, then, field observations. As in the first case, the inventory was made in the spring time and consisted of the observation of the occurrence of amphibians in water reservoirs. The research area included a 500 m wide belt for each of the considered variants of the planned road. In order to conduct the final experiments, 109 amphibian occurrence sites were taken into account.[1] StruzyÃ…â€žski, W. Ã‹â„¢ Inventory of Occurrence of Amphibians and Reptiles, Including Their Migratory Routes in the Vicinity of the Planned Highway A-1, Section: The Northern Boundary of the Silesian VoivodeshipÃ¢â‚¬â€�Pyrzowice; Warsaw Univ. of Life Sci.: Warsaw, Poland, 2010.[2] KiczyÃ…â€žska, A.; Falkowski, M.; JaskuÃ…â€ša, R.; Kaczkowski, Z.; Hejduk, J.; Horbacz, A. Natural Inventory for the A1 Motorway TuszynÃ¢â‚¬â€œPyrzowice Section ZawodzieÃ¢â‚¬â€œPyrzowice; National Foundation for Environmental Protection, Warszawa: Katowice, Poland, 2011.[3] Ã…Â�ukaszek, M.; CabaÃ…â€ša, S.; Zygmunt, J.; Wojtas, P. Report from the Field Research and Natural Inventory for Documentation: Ã¢â‚¬Å“Construction of the A1 Motorway TuszynÃ¢â‚¬â€�Pyrzowice Part II, Section 2 the Northern Boundary of the Silesian VoivodeshipÃ¢â‚¬â€œZawodzie; Environmental Protection Company EKOSOUND: Sosnowiec, Poland, 2011.[4] SoÃ…â€štysiak, M.; DÃ„â€¦browska, D. Inventory of Occurrence of Amphibians in the Vicinity of the Planned Highway A-1, Section: The Northern Boundary of the Silesian VoivodeshipÃ¢â‚¬â€œPyrzowice; The Upper Silesian Nature Society: Katowice, Poland, 2016.[5] Guzik, M.; BaÃ…â€º, G.; Kurek, K.; PoÃ…â€šczyÃ…â€žskaÃ¢â‚¬â€œKonior, G.; Potoczek, M.; SmÃƒÂ³Ã…â€ška, M.; SnieÃ…Â¼ko, S.; ZyÃ…â€ºk, B.;  Najberek, K.; GaÃ…â€š, A,. Inventory of Reptiles, Amphibians and Their Habitats in the Vicinity of the Beskidy Integration Way, Section Bielsko BialaÃ¢â‚¬â€�GÃ…â€šogoczÃƒÂ³w with Protection Proposals; Institute of Nature Conservation: KrakÃƒÂ³w, Poland, 2011Provide information about each attribute in your data set.List of attributes and types:ID -> IntegerMV -> CategoricalSR -> NumericalNR -> NumericalTR -> CategoricalVR -> CategoricalSUR1 -> CategoricalSUR2 -> CategoricalSUR3 -> CategoricalUR -> CategoricalFR -> CategoricalOR -> NumericalRR -> Ordinal; BR -> Ordinal; MR -> CategoricalCR -> CategoricalGreen frogs -> Categorical; Label 1Brown frogs -> Categorical; Label 2Common toad -> Categorical; Label 3Fire-bellied toad -> Categorical; Label 4Tree frog -> Categorical; Label 5Common newt -> Categorical; Label 6Great crested newt -> Categorical; Label 7Name and symbol type description:1)	ID Ã¢â‚¬â€œ vector ID (not used in the calculations)2)	MV Ã¢â‚¬â€œ motorway (not used in the calculations)3)	SR -> Surface of water reservoir numeric [m2]4)	NR -> Number of water reservoirs in habitat - Comment: The larger the number of reservoirs, the more likely it is that some of them will be suitable for amphibian breeding.5)	TR -> Type of water reservoirs:a.	reservoirs with natural features that are natural or anthropogenic water reservoirs (e.g., subsidence post-exploited water reservoirs), not subjected to naturalizationb.	recently formed reservoirs, not subjected to naturalization c.	settling pondsd.	water reservoirs located near housese.	technological water reservoirsf.	water reservoirs in allotment gardens g.	trenchesh.	wet meadows, flood plains, marshesi.	river valleysj.	streams and very small watercourses6)	VR - Presence of vegetation within the reservoirs:a.	no vegetationb.	narrow patches at the edgesc.	areas heavily overgrownd.	lush vegetation within the reservoir with some part devoid of vegetatione.	reservoirs completely overgrown with a disappearing water tableComment: The vegetation in the reservoir favors amphibians, facilitates breeding, and allows the larvae to feed and give shelter. However, excess vegetation can lead to the overgrowth of the pond and water shortages.7)	SUR1 - Surroundings 1Ã¢â‚¬â€�the dominant types of land cover surrounding the water reservoir8)	SUR2 - Surroundings 2Ã¢â‚¬â€�the second most dominant types of land cover surrounding the water reservoir9)	SUR3 - Surroundings 3Ã¢â‚¬â€�the third most dominant types of land cover surrounding the water reservoirComment: The Ã¢â‚¬Å“surroundingsÃ¢â‚¬Â� feature was designated in three stages. First, the dominant surroundings were selected. Then, two secondary types were chosen.a.	forest areas (with meadows) and densely wooded areasb.	areas of wasteland and meadowsc.	allotment gardensd.	parks and green arease.	dense building development, industrial areasf.	dispersed habitation, orchards, gardensg.	river valleysh.	roads, streetsi.	agricultural landThe most valuable surroundings of water reservoirs for amphibians are areas with the least anthropopressure and proper moisture.10)	UR - Use of water reservoirs:a.	unused by man (very attractive for amphibians)b.	recreational and scenic (care work is performed)c.	used economically (often fish farming)d.	technological11)	FR - The presence of fishing:a.	lack of or occasional fishingb.	intense fishingc.	breeding reservoirsComment: The presence of a large amount of fishing, in particular predatory and intense fishing, is not conducive to the presence of amphibians.12)	OR - Percentage access from the edges of the reservoir to undeveloped areas (the proposed percentage ranges are a numerical reflection of the phrases: lack of access, low access, medium access, large access to free space):a.	0Ã¢â‚¬â€œ25%Ã¢â‚¬â€�lack of access or poor accessb.	25Ã¢â‚¬â€œ50%Ã¢â‚¬â€�low accessc.	50Ã¢â‚¬â€œ75%Ã¢â‚¬â€�medium access,d.	75Ã¢â‚¬â€œ100%Ã¢â‚¬â€�large access to terrestrial habitats of the shoreline is in contact with the terrestrial habitat of amphibians.13)	RR Minimum distance from the water reservoir to roads:a.	<50 mb.	50Ã¢â‚¬â€œ100 mc.	100Ã¢â‚¬â€œ200 md.	200Ã¢â‚¬â€œ500 me.	500Ã¢â‚¬â€œ1000 mf.	>1000 mComment: The greater the distance between the reservoir and the road, the more safety for amphibians.14)	BR - Building development - Minimum distance to buildings:a.	 <50 mb.	50Ã¢â‚¬â€œ100 mc.	100Ã¢â‚¬â€œ200 md.	200Ã¢â‚¬â€œ500 me.	500Ã¢â‚¬â€œ1000 mf.	>1000 mComment: The more distant the buildings, the more favorable the conditions for the occurrence of amphibians. 15)	MR - Maintenance status of the reservoir:a.	Cleanb.	slightly litteredc.	reservoirs heavily or very heavily litteredComment: Trash causes devastation of the reservoir ecosystem. Backfilling and leveling of water reservoirs with ground and debris should also be considered.16)	CR - Type of shore a.	Natural b.	ConcreteComment: A concrete shore of a reservoir is not attractive for amphibians. A vertical concrete shore is usually a barrier for amphibians when they try to leave the water.17)	Label 1 Ã¢â‚¬â€œ the presence of Green frogs 18)	Label 2 Ã¢â‚¬â€œ the presence of Brown frogs19)	Label 3 Ã¢â‚¬â€œ the presence of Common toad20)	Label 4 Ã¢â‚¬â€œ the presence of Fire-bellied toad21)	Label 5 Ã¢â‚¬â€œ the presence of Tree frog22)	Label 6 Ã¢â‚¬â€œ the presence of Common newt23)	Label 7 Ã¢â‚¬â€œ the presence of Great crested newt The dataset is described in details in:Marcin Blachnik, Marek SoÃ…â€štysiak, Dominika DÃ„â€¦browska Predicting presence of amphibian species using features obtained from GIS and satellite images.. ISPRS International Journal of Geo-Information 8 (3) pp. 123. MDPI. 2019"
Bone marrow transplant: children,Bone marrow transplant: children,"The data set describes pediatric patients with several hematologic diseases, who were subject to the unmanipulated allogeneic unrelated donor hematopoietic stem cell transplantation.",Bone+marrow+transplant%3A+children,https://archive.ics.uci.edu/ml//machine-learning-databases/00565/,https://archive.ics.uci.edu/ml/datasets/Bone+marrow+transplant%3A+children,"The data set describes pediatric patients with several hematologic diseases: malignant disorders (i.a. acute lymphoblastic leukemia, acute myelogenous leukemia, chronic myelogenous leukemia, myelodysplastic syndrome) and nonmalignant cases (i.a. severe aplastic anemia, Fanconi anemia, with X-linked adrenoleukodystrophy). All patients were subject to the unmanipulated allogeneic unrelated donor hematopoietic stem cell transplantation.  The motivation of the study was to identify the most important factors influencing the success or failure of the transplantation procedure. In particular, the aim was to verify the hypothesis that increased dosage of CD34+ cells / kg extends overall survival time without simultaneous occurrence of undesirable events affecting patients' quality of life (KawÃ…â€šak et al., 2010).The data set has been used in our work concerning survival rules (WrÃƒÂ³bel et al., 2017) and user-guided rule induction (Sikora et al., 2019). The authors of the research on stem cell transplantation (KawÃ…â€šak et al., 2010) who inspired our study also contributed to the set.",Life,"donor_age - Age of the donor at the time of hematopoietic stem cells apheresisdonor_age_below_35 - Is donor age less than 35 (yes, no)donor_ABO - ABO blood group of the donor of hematopoietic stem cells (0, A, B, AB)donor_CMV - Presence of cytomegalovirus infection in the donor of hematopoietic stem cells prior to transplantation (present, absent)recipient_age - Age of the recipient of hematopoietic stem cells at the time of transplantationrecipient_age_below_10 - Is recipient age below 10 (yes, no)recipient_age_int - Age of the recipient discretized to intervals (0,5], (5, 10], (10, 20]recipient_gender - Gender of the recipient (female, male)recipient_body_mass - Body mass of the recipient of hematopoietic stem cells at the time of the transplantationrecipient_ABO - ABO blood group of the recipient of hematopoietic stem cells (0, A, B, AB)recipient_rh - Presence of the Rh factor on recipientÃ¢â‚¬â„¢s red blood cells (plus, minus)recipient_CMV - Presence of cytomegalovirus infection in the donor of hematopoietic stem cells prior to transplantation (present, absent)disease - Type of disease (ALL, AML, chronic, nonmalignant, lymphoma)disease_group - Type of disease (malignant, nonmalignant)gender_match - Compatibility of the donor and recipient according to their gender (female to male, other)ABO_match - Compatibility of the donor and the recipient of hematopoietic stem cells according to ABO blood group (matched, mismatched)CMV_status - Serological compatibility of the donor and the recipient of hematopoietic stem cells according to cytomegalovirus infection prior to transplantation (the higher the value, the lower the compatibility)HLA_match - Compatibility of antigens of the main histocompatibility complex of the donor and the recipient of hematopoietic stem cells (10/10, 9/10, 8/10, 7/10)HLA_mismatch - HLA matched or mismatchedantigen - In how many antigens there is a difference between the donor and the recipient (0-3)allel - In how many allele there is a difference between the donor and the recipient (0-4)HLA_group_1 - The difference type between the donor and the recipient (HLA matched, one antigen, one allel, DRB1 cell, two allele or allel+antigen, two antigenes+allel, mismatched)risk_group - Risk group (high, low)stem_cell_source - Source of hematopoietic stem cells (peripheral blood, bone marrow)tx_post_relapse - The second bone marrow transplantation after relapse (yes ,no)CD34_x1e6_per_kg - CD34kgx10d6 - CD34+ cell dose per kg of recipient body weight (10^6/kg)CD3_x1e8_per_kg - CD3+ cell dose per kg of recipient body weight (10^8/kg)CD3_to_CD34_ratio - CD3+ cell to CD34+ cell ratioANC_recovery - Neutrophils recovery defined as neutrophils count >0.5 x 10^9/L (yes, no)time_to_ANC_recovery - Time in days to neutrophils recoveryPLT_recovery - Platelet recovery defined as platelet count >50000/mm3 (yes, no)time_to_PLT_recovery - Time in days to platelet recoveryacute_GvHD_II_III_IV - Development of acute graft versus host disease stage II or III or IV (yes, no)acute_GvHD_III_IV - Development of acute graft versus host disease stage III or IV (yes, no)time_to_acute_GvHD_III_IV - Time in days to development of acute graft versus host disease stage III or IVextensive_chronic_GvHD - Development of extensive chronic graft versus host disease (yes, no)relapse - Relapse of the disease (yes, no)survival_time - Time of observation (if alive) or time to event (if dead) in dayssurvival_status - Survival status (0 - alive, 1 - dead)","The data set describes pediatric patients with several hematologic diseases, who were subject to the unmanipulated allogeneic unrelated donor hematopoietic stem cell transplantation.The data set describes pediatric patients with several hematologic diseases: malignant disorders (i.a. acute lymphoblastic leukemia, acute myelogenous leukemia, chronic myelogenous leukemia, myelodysplastic syndrome) and nonmalignant cases (i.a. severe aplastic anemia, Fanconi anemia, with X-linked adrenoleukodystrophy). All patients were subject to the unmanipulated allogeneic unrelated donor hematopoietic stem cell transplantation.  The motivation of the study was to identify the most important factors influencing the success or failure of the transplantation procedure. In particular, the aim was to verify the hypothesis that increased dosage of CD34+ cells / kg extends overall survival time without simultaneous occurrence of undesirable events affecting patients' quality of life (KawÃ…â€šak et al., 2010).The data set has been used in our work concerning survival rules (WrÃƒÂ³bel et al., 2017) and user-guided rule induction (Sikora et al., 2019). The authors of the research on stem cell transplantation (KawÃ…â€šak et al., 2010) who inspired our study also contributed to the set.donor_age - Age of the donor at the time of hematopoietic stem cells apheresisdonor_age_below_35 - Is donor age less than 35 (yes, no)donor_ABO - ABO blood group of the donor of hematopoietic stem cells (0, A, B, AB)donor_CMV - Presence of cytomegalovirus infection in the donor of hematopoietic stem cells prior to transplantation (present, absent)recipient_age - Age of the recipient of hematopoietic stem cells at the time of transplantationrecipient_age_below_10 - Is recipient age below 10 (yes, no)recipient_age_int - Age of the recipient discretized to intervals (0,5], (5, 10], (10, 20]recipient_gender - Gender of the recipient (female, male)recipient_body_mass - Body mass of the recipient of hematopoietic stem cells at the time of the transplantationrecipient_ABO - ABO blood group of the recipient of hematopoietic stem cells (0, A, B, AB)recipient_rh - Presence of the Rh factor on recipientÃ¢â‚¬â„¢s red blood cells (plus, minus)recipient_CMV - Presence of cytomegalovirus infection in the donor of hematopoietic stem cells prior to transplantation (present, absent)disease - Type of disease (ALL, AML, chronic, nonmalignant, lymphoma)disease_group - Type of disease (malignant, nonmalignant)gender_match - Compatibility of the donor and recipient according to their gender (female to male, other)ABO_match - Compatibility of the donor and the recipient of hematopoietic stem cells according to ABO blood group (matched, mismatched)CMV_status - Serological compatibility of the donor and the recipient of hematopoietic stem cells according to cytomegalovirus infection prior to transplantation (the higher the value, the lower the compatibility)HLA_match - Compatibility of antigens of the main histocompatibility complex of the donor and the recipient of hematopoietic stem cells (10/10, 9/10, 8/10, 7/10)HLA_mismatch - HLA matched or mismatchedantigen - In how many antigens there is a difference between the donor and the recipient (0-3)allel - In how many allele there is a difference between the donor and the recipient (0-4)HLA_group_1 - The difference type between the donor and the recipient (HLA matched, one antigen, one allel, DRB1 cell, two allele or allel+antigen, two antigenes+allel, mismatched)risk_group - Risk group (high, low)stem_cell_source - Source of hematopoietic stem cells (peripheral blood, bone marrow)tx_post_relapse - The second bone marrow transplantation after relapse (yes ,no)CD34_x1e6_per_kg - CD34kgx10d6 - CD34+ cell dose per kg of recipient body weight (10^6/kg)CD3_x1e8_per_kg - CD3+ cell dose per kg of recipient body weight (10^8/kg)CD3_to_CD34_ratio - CD3+ cell to CD34+ cell ratioANC_recovery - Neutrophils recovery defined as neutrophils count >0.5 x 10^9/L (yes, no)time_to_ANC_recovery - Time in days to neutrophils recoveryPLT_recovery - Platelet recovery defined as platelet count >50000/mm3 (yes, no)time_to_PLT_recovery - Time in days to platelet recoveryacute_GvHD_II_III_IV - Development of acute graft versus host disease stage II or III or IV (yes, no)acute_GvHD_III_IV - Development of acute graft versus host disease stage III or IV (yes, no)time_to_acute_GvHD_III_IV - Time in days to development of acute graft versus host disease stage III or IVextensive_chronic_GvHD - Development of extensive chronic graft versus host disease (yes, no)relapse - Relapse of the disease (yes, no)survival_time - Time of observation (if alive) or time to event (if dead) in dayssurvival_status - Survival status (0 - alive, 1 - dead)"
SCADI,SCADI,First self-care activities dataset based on ICF-CY.,SCADI,https://archive.ics.uci.edu/ml//machine-learning-databases/00446/,https://archive.ics.uci.edu/ml/datasets/SCADI,"This dataset contains 206 attributes of 70 children with physical and motor disability based on ICF-CY. In particular, the SCADI dataset is the only one that has been used by ML researchers for self-care problems classification based on ICF-CY to this date. The 'Class' field refers to the presence of the self-care problems of the children with physical and motor disabilities.The classes are determined by occupational therapists.The names and social security numbers of the children were recently removed from the dataset. Two files have been 'processed', SCADI.arff for using in WEKA and SCADI.CSV for using in MATLAB and similar tools. ",Life,"1:     gender: gender (1 = male; 0 = female)2:     age: age in years 3-205: self-care activities based on ICF-CY (1 = The case has this feature; 0 = otherwise) 206:   Classes ( class1 = Caring for body parts problem; class2 = Toileting problem; class3 = Dressing problem; class4 = Washing oneself and Caring for body parts and Dressing problem; class5 = Washing oneself, Caring for body parts, Toileting, and Dressing problem; class6 = Eating, Drinking, Washing oneself, Caring for body parts, toileting,Dressing, Looking after oneÃ¢â‚¬â„¢s health and Looking  after oneÃ¢â‚¬â„¢s safety problem; class7 = No Problem; ) ","First self-care activities dataset based on ICF-CY.This dataset contains 206 attributes of 70 children with physical and motor disability based on ICF-CY. In particular, the SCADI dataset is the only one that has been used by ML researchers for self-care problems classification based on ICF-CY to this date. The 'Class' field refers to the presence of the self-care problems of the children with physical and motor disabilities.The classes are determined by occupational therapists.The names and social security numbers of the children were recently removed from the dataset. Two files have been 'processed', SCADI.arff for using in WEKA and SCADI.CSV for using in MATLAB and similar tools. 1:     gender: gender (1 = male; 0 = female)2:     age: age in years 3-205: self-care activities based on ICF-CY (1 = The case has this feature; 0 = otherwise) 206:   Classes ( class1 = Caring for body parts problem; class2 = Toileting problem; class3 = Dressing problem; class4 = Washing oneself and Caring for body parts and Dressing problem; class5 = Washing oneself, Caring for body parts, Toileting, and Dressing problem; class6 = Eating, Drinking, Washing oneself, Caring for body parts, toileting,Dressing, Looking after oneÃ¢â‚¬â„¢s health and Looking  after oneÃ¢â‚¬â„¢s safety problem; class7 = No Problem; ) "
Anticancer peptides,Anticancer peptides,Peptides with experimental annotations on their anticancer action on breast and lung cancer cells. ,Anticancer+peptides,https://archive.ics.uci.edu/ml//machine-learning-databases/00589/,https://archive.ics.uci.edu/ml/datasets/Anticancer+peptides,"Membranolytic anticancer peptides (ACPs) are drawing increasing attention as potential future therapeutics against cancer, due to their ability to hinder the development of cellular resistance and their potential to overcome common hurdles of chemotherapy, e.g., side effects and cytotoxicity. This dataset contains information on peptides (annotated for their one-letter amino acid code) and their anticancer activity on breast and lung cancer cell lines.Two peptide datasets targeting breast and lung cancer cells were assembled and curated manually from CancerPPD. EC50, IC50, LD50 and LC50 annotations on breast and lung cancer cells were retained (breast cell lines: MCF7Ã¢â‚¬â€°=Ã¢â‚¬â€°57%, MDA-MB-361Ã¢â‚¬â€°=Ã¢â‚¬â€°11%, MT-1Ã¢â‚¬â€°=Ã¢â‚¬â€°9%; lung cell lines: H-1299Ã¢â‚¬â€°=Ã¢â‚¬â€°45%, A-549Ã¢â‚¬â€°=Ã¢â‚¬â€°17.7%); mg mlÃ¢Ë†â€™1 values were converted to ÃŽÂ¼M units. Linear and l-chiral peptides were retained, while cyclic, mixed or d-chiral peptides were discarded. In the presence of both amidated and non-amidated data for the same sequence, only the value referred to the amidated peptide was retained. Peptides were split into three classes for model training: (1) very active (EC/IC/LD/LC50Ã¢â‚¬â€°Ã¢â€°Â¤Ã¢â‚¬â€°5 ÃŽÂ¼M), (2) moderately active (EC/IC/LD/LC50 values up to 50 ÃŽÂ¼M) and (3) inactive (EC/IC/LD/LC50Ã¢â‚¬â€°>Ã¢â‚¬â€°50 ÃŽÂ¼M) peptides. Duplicates with conflicting class annotations were compared manually to the original sources, and, if necessary, corrected. If multiple class annotations were present for the same sequence, the most frequently represented class was chosen; in case of ties, the less active class was chosen. Since the CancerPPD is biased towards the annotation of active peptides, we built a set of presumably inactive peptides by randomly extracting 750 alpha-helical sequences from crystal structures deposited in the Protein Data Bank (7Ã¢â‚¬â€œ30 amino acids). The final training sets contained 949 peptides for Breast cancer and 901 peptides for Lung cancer. The datasets were used to develop neural networks model for anticancer peptide design and are provided as .csv file in a .zip folder.Additional details can be found in: Grisoni, F., Neuhaus, C.S., Hishinuma, M., Gabernet, G., Hiss, J.A., Kotera, M. and Schneider, G., 2019. De novo design of anticancer peptides by ensemble artificial neural networks. Journal of Molecular Modeling, 25(5), 112.",Life,"The dataset contains three attributes:1. Peptide ID 2. One-letter amino-acid sequence3. Class (active, moderately active, experimental inactive, virtual inactive)","Peptides with experimental annotations on their anticancer action on breast and lung cancer cells. Membranolytic anticancer peptides (ACPs) are drawing increasing attention as potential future therapeutics against cancer, due to their ability to hinder the development of cellular resistance and their potential to overcome common hurdles of chemotherapy, e.g., side effects and cytotoxicity. This dataset contains information on peptides (annotated for their one-letter amino acid code) and their anticancer activity on breast and lung cancer cell lines.Two peptide datasets targeting breast and lung cancer cells were assembled and curated manually from CancerPPD. EC50, IC50, LD50 and LC50 annotations on breast and lung cancer cells were retained (breast cell lines: MCF7Ã¢â‚¬â€°=Ã¢â‚¬â€°57%, MDA-MB-361Ã¢â‚¬â€°=Ã¢â‚¬â€°11%, MT-1Ã¢â‚¬â€°=Ã¢â‚¬â€°9%; lung cell lines: H-1299Ã¢â‚¬â€°=Ã¢â‚¬â€°45%, A-549Ã¢â‚¬â€°=Ã¢â‚¬â€°17.7%); mg mlÃ¢Ë†â€™1 values were converted to ÃŽÂ¼M units. Linear and l-chiral peptides were retained, while cyclic, mixed or d-chiral peptides were discarded. In the presence of both amidated and non-amidated data for the same sequence, only the value referred to the amidated peptide was retained. Peptides were split into three classes for model training: (1) very active (EC/IC/LD/LC50Ã¢â‚¬â€°Ã¢â€°Â¤Ã¢â‚¬â€°5 ÃŽÂ¼M), (2) moderately active (EC/IC/LD/LC50 values up to 50 ÃŽÂ¼M) and (3) inactive (EC/IC/LD/LC50Ã¢â‚¬â€°>Ã¢â‚¬â€°50 ÃŽÂ¼M) peptides. Duplicates with conflicting class annotations were compared manually to the original sources, and, if necessary, corrected. If multiple class annotations were present for the same sequence, the most frequently represented class was chosen; in case of ties, the less active class was chosen. Since the CancerPPD is biased towards the annotation of active peptides, we built a set of presumably inactive peptides by randomly extracting 750 alpha-helical sequences from crystal structures deposited in the Protein Data Bank (7Ã¢â‚¬â€œ30 amino acids). The final training sets contained 949 peptides for Breast cancer and 901 peptides for Lung cancer. The datasets were used to develop neural networks model for anticancer peptide design and are provided as .csv file in a .zip folder.Additional details can be found in: Grisoni, F., Neuhaus, C.S., Hishinuma, M., Gabernet, G., Hiss, J.A., Kotera, M. and Schneider, G., 2019. De novo design of anticancer peptides by ensemble artificial neural networks. Journal of Molecular Modeling, 25(5), 112.The dataset contains three attributes:1. Peptide ID 2. One-letter amino-acid sequence3. Class (active, moderately active, experimental inactive, virtual inactive)"
Secondary Mushroom Dataset,Secondary Mushroom Dataset,Dataset of simulated mushrooms for binary classification into edible and poisonous.,Secondary+Mushroom+Dataset,https://archive.ics.uci.edu/ml//machine-learning-databases/00615/,https://archive.ics.uci.edu/ml/datasets/Secondary+Mushroom+Dataset,"The given information is about the Secondary Mushroom Dataset, the Primary Mushroom Dataset used for the simulation and the respective metadata can be found in the zip.This dataset includes 61069 hypothetical mushrooms with caps based on 173 species (353 mushroomsper species). Each mushroom is identified as definitely edible, definitely poisonous, or of unknown edibility and not recommended (the latter class was combined with the poisonous class).The related Python project contains a Python module secondary_data_generation.pyused to generate this data based on primary_data_edited.csv also found in the repository.Both nominal and metrical variables are a result of randomization.The simulated and ordered by species version is found in secondary_data_generated.csv.The randomly shuffled version is found in secondary_data_shuffled.csv.",Life,"One binary class divided in edible=e and poisonous=p (with the latter one also containing mushrooms of unknown edibility).Twenty remaining variables (n: nominal, m: metrical)   1. cap-diameter (m):		float number in cm   2. cap-shape (n):            bell=b, conical=c, convex=x, flat=f,                                sunken=s, spherical=p, others=o   3. cap-surface (n):          fibrous=i, grooves=g, scaly=y, smooth=s,				shiny=h, leathery=l, silky=k, sticky=t,				wrinkled=w, fleshy=e   4. cap-color (n):            brown=n, buff=b, gray=g, green=r, pink=p,				purple=u, red=e, white=w, yellow=y, blue=l, 				orange=o,  black=k   5. does-bruise-bleed (n):	bruises-or-bleeding=t,no=f   6. gill-attachment (n):      adnate=a, adnexed=x, decurrent=d, free=e, 				sinuate=s, pores=p, none=f, unknown=?   7. gill-spacing (n):         close=c, distant=d, none=f   8. gill-color (n):           see cap-color + none=f   9. stem-height (m):		float number in cm   10. stem-width (m):		float number in mm      11. stem-root (n):           bulbous=b, swollen=s, club=c, cup=u, equal=e,                                rhizomorphs=z, rooted=r   12. stem-surface (n): 	see cap-surface + none=f   13. stem-color (n):		see cap-color + none=f   14. veil-type (n):           partial=p, universal=u   15. veil-color (n):          see cap-color + none=f   16. has-ring (n):            ring=t, none=f   17. ring-type (n):           cobwebby=c, evanescent=e, flaring=r, grooved=g, 				large=l, pendant=p, sheathing=s, zone=z, scaly=y, movable=m, none=f, unknown=?   18. spore-print-color (n):   see cap color   19. habitat (n):             grasses=g, leaves=l, meadows=m, paths=p, heaths=h,                                urban=u, waste=w, woods=d   20. season (n):		spring=s, summer=u, autumn=a, winter=w","Dataset of simulated mushrooms for binary classification into edible and poisonous.The given information is about the Secondary Mushroom Dataset, the Primary Mushroom Dataset used for the simulation and the respective metadata can be found in the zip.This dataset includes 61069 hypothetical mushrooms with caps based on 173 species (353 mushroomsper species). Each mushroom is identified as definitely edible, definitely poisonous, or of unknown edibility and not recommended (the latter class was combined with the poisonous class).The related Python project contains a Python module secondary_data_generation.pyused to generate this data based on primary_data_edited.csv also found in the repository.Both nominal and metrical variables are a result of randomization.The simulated and ordered by species version is found in secondary_data_generated.csv.The randomly shuffled version is found in secondary_data_shuffled.csv.One binary class divided in edible=e and poisonous=p (with the latter one also containing mushrooms of unknown edibility).Twenty remaining variables (n: nominal, m: metrical)   1. cap-diameter (m):		float number in cm   2. cap-shape (n):            bell=b, conical=c, convex=x, flat=f,                                sunken=s, spherical=p, others=o   3. cap-surface (n):          fibrous=i, grooves=g, scaly=y, smooth=s,				shiny=h, leathery=l, silky=k, sticky=t,				wrinkled=w, fleshy=e   4. cap-color (n):            brown=n, buff=b, gray=g, green=r, pink=p,				purple=u, red=e, white=w, yellow=y, blue=l, 				orange=o,  black=k   5. does-bruise-bleed (n):	bruises-or-bleeding=t,no=f   6. gill-attachment (n):      adnate=a, adnexed=x, decurrent=d, free=e, 				sinuate=s, pores=p, none=f, unknown=?   7. gill-spacing (n):         close=c, distant=d, none=f   8. gill-color (n):           see cap-color + none=f   9. stem-height (m):		float number in cm   10. stem-width (m):		float number in mm      11. stem-root (n):           bulbous=b, swollen=s, club=c, cup=u, equal=e,                                rhizomorphs=z, rooted=r   12. stem-surface (n): 	see cap-surface + none=f   13. stem-color (n):		see cap-color + none=f   14. veil-type (n):           partial=p, universal=u   15. veil-color (n):          see cap-color + none=f   16. has-ring (n):            ring=t, none=f   17. ring-type (n):           cobwebby=c, evanescent=e, flaring=r, grooved=g, 				large=l, pendant=p, sheathing=s, zone=z, scaly=y, movable=m, none=f, unknown=?   18. spore-print-color (n):   see cap color   19. habitat (n):             grasses=g, leaves=l, meadows=m, paths=p, heaths=h,                                urban=u, waste=w, woods=d   20. season (n):		spring=s, summer=u, autumn=a, winter=w"
seeds,seeds,"Measurements of geometrical properties of kernels belonging to three different varieties of wheat. A soft X-ray technique and GRAINS package were used to construct all seven, real-valued attributes.",seeds,https://archive.ics.uci.edu/ml//machine-learning-databases/00236/,https://archive.ics.uci.edu/ml/datasets/seeds,"The examined group comprised kernels belonging to three different varieties of wheat: Kama, Rosa and Canadian, 70 elements each, randomly selected forthe experiment. High quality visualization of the internal kernel structure was detected using a soft X-ray technique. It is non-destructive and considerably cheaper than other more sophisticated imaging techniques like scanning microscopy or laser technology. The images were recorded on 13x18 cm X-ray KODAK plates. Studies were conducted using combine harvested wheat grain originating from experimental fields, explored at the Institute of Agrophysics of the Polish Academy of Sciences in Lublin.The data set can be used for the tasks of classification and cluster analysis.",Life,"To construct the data, seven geometric parameters of wheat kernels were measured: 1. area A, 2. perimeter P, 3. compactness C = 4*pi*A/P^2, 4. length of kernel,5. width of kernel,6. asymmetry coefficient7. length of kernel groove.All of these parameters were real-valued continuous.","Measurements of geometrical properties of kernels belonging to three different varieties of wheat. A soft X-ray technique and GRAINS package were used to construct all seven, real-valued attributes.The examined group comprised kernels belonging to three different varieties of wheat: Kama, Rosa and Canadian, 70 elements each, randomly selected forthe experiment. High quality visualization of the internal kernel structure was detected using a soft X-ray technique. It is non-destructive and considerably cheaper than other more sophisticated imaging techniques like scanning microscopy or laser technology. The images were recorded on 13x18 cm X-ray KODAK plates. Studies were conducted using combine harvested wheat grain originating from experimental fields, explored at the Institute of Agrophysics of the Polish Academy of Sciences in Lublin.The data set can be used for the tasks of classification and cluster analysis.To construct the data, seven geometric parameters of wheat kernels were measured: 1. area A, 2. perimeter P, 3. compactness C = 4*pi*A/P^2, 4. length of kernel,5. width of kernel,6. asymmetry coefficient7. length of kernel groove.All of these parameters were real-valued continuous."
Breast Cancer Coimbra,Breast Cancer Coimbra,Clinical features were observed or measured for 64 patients with breast cancer and 52 healthy controls. ,Breast+Cancer+Coimbra,https://archive.ics.uci.edu/ml//machine-learning-databases/00451/,https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Coimbra,"There are 10 predictors, all quantitative, and a binary dependent variable, indicating the presence or absence of breast cancer. The predictors are anthropometric data and parameters which can be gathered in routine blood analysis. Prediction models based on these predictors, if accurate, can potentially be used as a biomarker of breast cancer.",Life,Quantitative Attributes: Age (years)BMI (kg/m2)Glucose (mg/dL)Insulin (ÂµU/mL)HOMALeptin (ng/mL)Adiponectin (Âµg/mL)Resistin (ng/mL)MCP-1(pg/dL)Labels:1=Healthy controls2=Patients,"Clinical features were observed or measured for 64 patients with breast cancer and 52 healthy controls. There are 10 predictors, all quantitative, and a binary dependent variable, indicating the presence or absence of breast cancer. The predictors are anthropometric data and parameters which can be gathered in routine blood analysis. Prediction models based on these predictors, if accurate, can potentially be used as a biomarker of breast cancer.Quantitative Attributes: Age (years)BMI (kg/m2)Glucose (mg/dL)Insulin (ÂµU/mL)HOMALeptin (ng/mL)Adiponectin (Âµg/mL)Resistin (ng/mL)MCP-1(pg/dL)Labels:1=Healthy controls2=Patients"
Refractive errors,Refractive errors,Effect of life style and genetic on eye refractive errors.,Refractive+errors,https://archive.ics.uci.edu/ml//machine-learning-databases/00568/,https://archive.ics.uci.edu/ml/datasets/Refractive+errors,"The aim of this dataset is to study the impact of personal lifestyle and genetic on eye refractive errors. This dataset is gathered from forms filled by 467 individual. First sheet contains information of 210 people suffering from eye refractive errors and the second sheet contains the information of the remaining 257 participants, who had a healthy eye condition. For being more precise, we asked participants, who had refractive errors, to fill information about their lifestyle before being affected by eye refractive errors.",Life,"Attributes ending by _B indicate the past lifestyle for individuals with refractive error.classes:	R.type	Refractive error type: {myopia}, {astigmatism}, {hyperopia}, {astigmatism,hyperopia}, {astigmatism,myopia} R.type.myopia	T,FR.type.hyperopia	T,FR.type.astigmatism	T,Fother variables:R.editVisionOperation	T, F, lasekR.glasses	IntR.Fglasses	IntN.dairy	        cat: 0, 1, 2N.vegetable	cat: 0, 1, 2N.seafood	cat: 0, 1, 2N.nuts	        cat: 0, 1, 2A.Dreading_N	cat: 0, 2, 4, 6, 8A.Dreading_B	cat: 0, 2, 4, 6, 8A.computer_N	cat: 0, 2, 4, 6, 8A.computer_B	cat: 0, 2, 4, 6, 8A.TV_N	        cat: 0, 2, 4, 6, 8A.TV	        cat: 0, 2, 4, 6, 8A.focus	        cat: Yes, No, the activityA.focus.yes	T,FA.dark	        T,FA.dark_N	T,FD.Edamage	no, yes, the eye damage nameD.Edisease_N	no, yes, the eye disease nameD.Edisease_B	no, yes, the eye disease nameD.Sdisease_N	no, yes, the other disease nameD.Sdisease_B	no, yes, the other disease nameD.allergy_N	T,FD.allergy_B	T,FD.allergy.seasonalAllergy	T,FD.allergy.skinAllergy	        T,FD.allergy.hives	                T,FD.drug_N	                no, yes, drugs nameD.drug_N.familyDrug	        no, yes, drugs nameD.drug_B	                no, yes, drugs nameD.drug.familyDrug	        no, yes, drugs nameD.drug.familyDrug.vitamins	        T,FD.drug.familyDrug.birth control pills	T,FD.drug.familyDrug.cardiovascular	T,FD.drug.familyDrug.antiepileptics	T,FD.drug.familyDrug.antidepressants	T,FD.drug.familyDrug.thyroid	        T,FD.drug.familyDrug.gastrointestina	T,FO.inherit.mother	                T,FO.inherit.father	                T,FO.inherit.sisterOrBrother	        T,FO.inherit.auntOrUncle	                T,FO.inherit.grandFatherOrMother	        T,FO.inherit.cousin	                T,FO.inherit	cat: the relationship of the relative with eye disease problemO.weather	hot, cold, mild & humidO.pollution	T,FL.smoking_B	T,FL.smoking_N	T,FL.alcohol_B	T,FL.alcohol_N	T,FL.Isunglasses_B	T,FL.Isunglasses_N	T,F (using any sun-glass)L.Ssunglasses_B	T,FL.Ssunglasses_N	T,F (using only standard sun-glasses)L.makeup_B	T,FL.makeup_N	T,FL.lences_B	T,FL.lences_N	T,FP.gender	0 (F),1 (M)P.age_B	        Int P.age_N	        Int P.height	Int P.weight	Int P.city_N	city nameP.city_B	city nameP.state	        state nameP.degree	cat: 0, 1, 2, 3P.job	        job nameP.job.collegian	T,FP.job.employee	T,FP.job.no work	T,FP.job.student	T,FP.job.university professor	T,Ffrom	how the form is filled: internet, alborz, iust, hakim","Effect of life style and genetic on eye refractive errors.The aim of this dataset is to study the impact of personal lifestyle and genetic on eye refractive errors. This dataset is gathered from forms filled by 467 individual. First sheet contains information of 210 people suffering from eye refractive errors and the second sheet contains the information of the remaining 257 participants, who had a healthy eye condition. For being more precise, we asked participants, who had refractive errors, to fill information about their lifestyle before being affected by eye refractive errors.Attributes ending by _B indicate the past lifestyle for individuals with refractive error.classes:	R.type	Refractive error type: {myopia}, {astigmatism}, {hyperopia}, {astigmatism,hyperopia}, {astigmatism,myopia} R.type.myopia	T,FR.type.hyperopia	T,FR.type.astigmatism	T,Fother variables:R.editVisionOperation	T, F, lasekR.glasses	IntR.Fglasses	IntN.dairy	        cat: 0, 1, 2N.vegetable	cat: 0, 1, 2N.seafood	cat: 0, 1, 2N.nuts	        cat: 0, 1, 2A.Dreading_N	cat: 0, 2, 4, 6, 8A.Dreading_B	cat: 0, 2, 4, 6, 8A.computer_N	cat: 0, 2, 4, 6, 8A.computer_B	cat: 0, 2, 4, 6, 8A.TV_N	        cat: 0, 2, 4, 6, 8A.TV	        cat: 0, 2, 4, 6, 8A.focus	        cat: Yes, No, the activityA.focus.yes	T,FA.dark	        T,FA.dark_N	T,FD.Edamage	no, yes, the eye damage nameD.Edisease_N	no, yes, the eye disease nameD.Edisease_B	no, yes, the eye disease nameD.Sdisease_N	no, yes, the other disease nameD.Sdisease_B	no, yes, the other disease nameD.allergy_N	T,FD.allergy_B	T,FD.allergy.seasonalAllergy	T,FD.allergy.skinAllergy	        T,FD.allergy.hives	                T,FD.drug_N	                no, yes, drugs nameD.drug_N.familyDrug	        no, yes, drugs nameD.drug_B	                no, yes, drugs nameD.drug.familyDrug	        no, yes, drugs nameD.drug.familyDrug.vitamins	        T,FD.drug.familyDrug.birth control pills	T,FD.drug.familyDrug.cardiovascular	T,FD.drug.familyDrug.antiepileptics	T,FD.drug.familyDrug.antidepressants	T,FD.drug.familyDrug.thyroid	        T,FD.drug.familyDrug.gastrointestina	T,FO.inherit.mother	                T,FO.inherit.father	                T,FO.inherit.sisterOrBrother	        T,FO.inherit.auntOrUncle	                T,FO.inherit.grandFatherOrMother	        T,FO.inherit.cousin	                T,FO.inherit	cat: the relationship of the relative with eye disease problemO.weather	hot, cold, mild & humidO.pollution	T,FL.smoking_B	T,FL.smoking_N	T,FL.alcohol_B	T,FL.alcohol_N	T,FL.Isunglasses_B	T,FL.Isunglasses_N	T,F (using any sun-glass)L.Ssunglasses_B	T,FL.Ssunglasses_N	T,F (using only standard sun-glasses)L.makeup_B	T,FL.makeup_N	T,FL.lences_B	T,FL.lences_N	T,FP.gender	0 (F),1 (M)P.age_B	        Int P.age_N	        Int P.height	Int P.weight	Int P.city_N	city nameP.city_B	city nameP.state	        state nameP.degree	cat: 0, 1, 2, 3P.job	        job nameP.job.collegian	T,FP.job.employee	T,FP.job.no work	T,FP.job.student	T,FP.job.university professor	T,Ffrom	how the form is filled: internet, alborz, iust, hakim"
Zoo,Zoo,"Artificial, 7 classes of animals",Zoo,https://archive.ics.uci.edu/ml//machine-learning-databases/zoo/,https://archive.ics.uci.edu/ml/datasets/Zoo,"A simple database containing 17 Boolean-valued attributes.  The ""type"" attribute appears to be the class attribute.  Here is a breakdown of which animals are in which type: (I find it unusual that there are 2 instances of ""frog"" and one of ""girl""!)Class# -- Set of animals:====== ====================================================1 -- (41) aardvark, antelope, bear, boar, buffalo, calf, cavy, cheetah, deer, dolphin, elephant, fruitbat, giraffe, girl, goat, gorilla, hamster, hare, leopard, lion, lynx, mink, mole, mongoose, opossum, oryx, platypus, polecat, pony, porpoise, puma, pussycat, raccoon, reindeer, seal, sealion, squirrel, vampire, vole, wallaby,wolf2 -- (20) chicken, crow, dove, duck, flamingo, gull, hawk, kiwi, lark, ostrich, parakeet, penguin, pheasant, rhea, skimmer, skua, sparrow, swan, vulture, wren3 -- (5)  pitviper, seasnake, slowworm, tortoise, tuatara 4 -- (13) bass, carp, catfish, chub, dogfish, haddock, herring, pike, piranha, seahorse, sole, stingray, tuna5 -- (4)  frog, frog, newt, toad 6 -- (8)  flea, gnat, honeybee, housefly, ladybird, moth, termite, wasp7 -- (10) clam, crab, crayfish, lobster, octopus, scorpion, seawasp, slug, starfish, worm",Life,"   1. animal name:      Unique for each instance   2. hair:		Boolean   3. feathers:		Boolean   4. eggs:		Boolean   5. milk:		Boolean   6. airborne:		Boolean   7. aquatic:		Boolean   8. predator:		Boolean   9. toothed:		Boolean  10. backbone:		Boolean  11. breathes:		Boolean  12. venomous:		Boolean  13. fins:		Boolean  14. legs:		Numeric (set of values: {0,2,4,5,6,8})  15. tail:		Boolean  16. domestic:		Boolean  17. catsize:		Boolean  18. type:		Numeric (integer values in range [1,7])","Artificial, 7 classes of animalsA simple database containing 17 Boolean-valued attributes.  The ""type"" attribute appears to be the class attribute.  Here is a breakdown of which animals are in which type: (I find it unusual that there are 2 instances of ""frog"" and one of ""girl""!)Class# -- Set of animals:====== ====================================================1 -- (41) aardvark, antelope, bear, boar, buffalo, calf, cavy, cheetah, deer, dolphin, elephant, fruitbat, giraffe, girl, goat, gorilla, hamster, hare, leopard, lion, lynx, mink, mole, mongoose, opossum, oryx, platypus, polecat, pony, porpoise, puma, pussycat, raccoon, reindeer, seal, sealion, squirrel, vampire, vole, wallaby,wolf2 -- (20) chicken, crow, dove, duck, flamingo, gull, hawk, kiwi, lark, ostrich, parakeet, penguin, pheasant, rhea, skimmer, skua, sparrow, swan, vulture, wren3 -- (5)  pitviper, seasnake, slowworm, tortoise, tuatara 4 -- (13) bass, carp, catfish, chub, dogfish, haddock, herring, pike, piranha, seahorse, sole, stingray, tuna5 -- (4)  frog, frog, newt, toad 6 -- (8)  flea, gnat, honeybee, housefly, ladybird, moth, termite, wasp7 -- (10) clam, crab, crayfish, lobster, octopus, scorpion, seawasp, slug, starfish, worm   1. animal name:      Unique for each instance   2. hair:		Boolean   3. feathers:		Boolean   4. eggs:		Boolean   5. milk:		Boolean   6. airborne:		Boolean   7. aquatic:		Boolean   8. predator:		Boolean   9. toothed:		Boolean  10. backbone:		Boolean  11. breathes:		Boolean  12. venomous:		Boolean  13. fins:		Boolean  14. legs:		Numeric (set of values: {0,2,4,5,6,8})  15. tail:		Boolean  16. domestic:		Boolean  17. catsize:		Boolean  18. type:		Numeric (integer values in range [1,7])"
HCC Survival,HCC Survival,Hepatocellular Carcinoma dataset (HCC dataset) was collected at a University Hospital in Portugal. It contains real clinical data of 165 patients diagnosed with HCC.,HCC+Survival,https://archive.ics.uci.edu/ml//machine-learning-databases/00423/,https://archive.ics.uci.edu/ml/datasets/HCC+Survival,"HCC dataset was obtained at a University Hospital in Portugal and contais several demographic, risk factors, laboratory and overall survival features of 165 real patients diagnosed with HCC. The dataset contains 49 features selected according to the EASL-EORTC (European Association for the Study of the Liver - European Organisation for Research and Treatment of Cancer) Clinical Practice Guidelines, which are the current state-of-the-art on the management of HCC.This is an heterogeneous dataset, with 23 quantitative variables, and 26 qualitative variables. Overall, missing data represents 10.22% of the whole dataset and only eight patients have complete information in all fields (4.85%). The target variables is the survival at 1 year, and was encoded as a binary variable: 0 (dies) and 1 (lives). A certain degree of class-imbalance is also present (63 cases labeled as Ã¢â‚¬Å“diesÃ¢â‚¬Â� and 102 as Ã¢â‚¬Å“livesÃ¢â‚¬Â�).A detailed description of the HCC dataset (feature's type/scale, range, mean/mode and missing data percentages) is provided in Santos et al. A new cluster-based oversampling method for improving survival prediction of hepatocellular carcinoma patients, Journal of biomedical informatics, 58, 49-59, 2015.",Life,"Gender: nominalSymptoms: nominalAlcohol: nominalHepatitis B Surface Antigen: nominalHepatitis B e Antigen: nominalHepatitis B Core Antibody: nominalHepatitis C Virus Antibody: nominalCirrhosis	: nominal	Endemic Countries: nominalSmoking: nominalDiabetes: nominalObesity: nominalHemochromatosis: nominalArterial Hypertension: nominalChronic Renal Insufficiency: nominalHuman Immunodeficiency Virus: nominalNonalcoholic Steatohepatitis: nominalEsophageal Varices: nominalSplenomegaly: nominalPortal Hypertension: nominalPortal Vein Thrombosis: nominalLiver Metastasis: nominalRadiological Hallmark: nominalAge at diagnosis: integerGrams of Alcohol per day: continuousPacks of cigarets per year: continuousPerformance Status: ordinalEncefalopathy	degree: ordinalAscites degree: ordinalInternational Normalised Ratio: continuousAlpha-Fetoprotein (ng/mL): continuousHaemoglobin (g/dL): continuousMean Corpuscular Volume	 (fl): continuousLeukocytes(G/L): continuousPlatelets	(G/L): continuousAlbumin (mg/dL): continuousTotal Bilirubin(mg/dL): continuousAlanine transaminase (U/L): continuousAspartate transaminase (U/L): continuousGamma glutamyl transferase (U/L): continuousAlkaline phosphatase (U/L): continuousTotal Proteins (g/dL): continuousCreatinine (mg/dL): continuousNumber of Nodules: integerMajor dimension of nodule (cm): continuousDirect Bilirubin (mg/dL): continuousIron	(mcg/dL): continuousOxygen Saturation (%): continuousFerritin (ng/mL): continuousClass: nominal (1 if patient survives, 0 if patient died)","Hepatocellular Carcinoma dataset (HCC dataset) was collected at a University Hospital in Portugal. It contains real clinical data of 165 patients diagnosed with HCC.HCC dataset was obtained at a University Hospital in Portugal and contais several demographic, risk factors, laboratory and overall survival features of 165 real patients diagnosed with HCC. The dataset contains 49 features selected according to the EASL-EORTC (European Association for the Study of the Liver - European Organisation for Research and Treatment of Cancer) Clinical Practice Guidelines, which are the current state-of-the-art on the management of HCC.This is an heterogeneous dataset, with 23 quantitative variables, and 26 qualitative variables. Overall, missing data represents 10.22% of the whole dataset and only eight patients have complete information in all fields (4.85%). The target variables is the survival at 1 year, and was encoded as a binary variable: 0 (dies) and 1 (lives). A certain degree of class-imbalance is also present (63 cases labeled as Ã¢â‚¬Å“diesÃ¢â‚¬Â� and 102 as Ã¢â‚¬Å“livesÃ¢â‚¬Â�).A detailed description of the HCC dataset (feature's type/scale, range, mean/mode and missing data percentages) is provided in Santos et al. A new cluster-based oversampling method for improving survival prediction of hepatocellular carcinoma patients, Journal of biomedical informatics, 58, 49-59, 2015.Gender: nominalSymptoms: nominalAlcohol: nominalHepatitis B Surface Antigen: nominalHepatitis B e Antigen: nominalHepatitis B Core Antibody: nominalHepatitis C Virus Antibody: nominalCirrhosis	: nominal	Endemic Countries: nominalSmoking: nominalDiabetes: nominalObesity: nominalHemochromatosis: nominalArterial Hypertension: nominalChronic Renal Insufficiency: nominalHuman Immunodeficiency Virus: nominalNonalcoholic Steatohepatitis: nominalEsophageal Varices: nominalSplenomegaly: nominalPortal Hypertension: nominalPortal Vein Thrombosis: nominalLiver Metastasis: nominalRadiological Hallmark: nominalAge at diagnosis: integerGrams of Alcohol per day: continuousPacks of cigarets per year: continuousPerformance Status: ordinalEncefalopathy	degree: ordinalAscites degree: ordinalInternational Normalised Ratio: continuousAlpha-Fetoprotein (ng/mL): continuousHaemoglobin (g/dL): continuousMean Corpuscular Volume	 (fl): continuousLeukocytes(G/L): continuousPlatelets	(G/L): continuousAlbumin (mg/dL): continuousTotal Bilirubin(mg/dL): continuousAlanine transaminase (U/L): continuousAspartate transaminase (U/L): continuousGamma glutamyl transferase (U/L): continuousAlkaline phosphatase (U/L): continuousTotal Proteins (g/dL): continuousCreatinine (mg/dL): continuousNumber of Nodules: integerMajor dimension of nodule (cm): continuousDirect Bilirubin (mg/dL): continuousIron	(mcg/dL): continuousOxygen Saturation (%): continuousFerritin (ng/mL): continuousClass: nominal (1 if patient survives, 0 if patient died)"
M. Tuberculosis Genes,M. Tuberculosis Genes," Data giving characteristics of each ORF (potential gene) in the M. tuberculosis bacterium. Sequence, homology (similarity to other genes) and structural information, and function (if known) are provided",M.+Tuberculosis+Genes,https://archive.ics.uci.edu/ml//machine-learning-databases/tb-mld/,https://archive.ics.uci.edu/ml/datasets/M.+Tuberculosis+Genes,"The data was collected from several sources, including the Sanger Centre ([Web Link]) and SWISSPROT ([Web Link]). Structure prediction was made by PROF ([Web Link]). Homology search was made by PSI-BLAST ([Web Link]).The data is in Datalog format. Missing values are not explicit, but some genes have more relationships than others.Dependencies:M. tuberculosis genes (ORFs) are related to each other by the predicate tb_to_tb_evalue(TBNumber,E-value). They are related to other (SWISSPROT) proteins by the predicate e_val(AccNo,E-value). All the data for a single gene (ORF) is enclosed between delimiters of the form:   begin(model(TBNumber)).   end(model(TBNumber)).Other Relevant Information:The gene functional classes are in a hierarchy. See [Web Link].There are two datalog files: tb_data.pl and ecoli_functions.pl1. tb_functions.plLists classes and ORF functions. Lines are of the following form:   class([1,0,0,0],""Small-molecule metabolism "").   class([1,1,0,0],""Degradation "").   class([1,1,1,0],""Carbon compounds "").  Arguments are a list of 4 numbers (describing class at the 4 different levels), followed by a string class description. For example,   function(tb186,[1,1,1,0],'bglS',""beta-glucosidase""). Arguments are ORF number, list of 4 class numbers, gene name (or null if no gene name) in single quotes, ORF description in double quotes.2. tb_data.plData for each ORF (gene) is delimited by   begin(model(X)).   end(model(X)).where X is the ORF number. Other predicates are as follows (examples):   tb_protein(X).    % X is gene number   function(2,1,5,0,'gyrA','DNA gyrase subunit A').  % 4 levels of functional hierarchy, gene name, description   coding_region(7302,9815). % start,end. integers   tb_mol_wt(19934).  % integer   access(1,e,20). % int (position), {e,i,b}, int (length)    access_exposed(1,20). % int (position), int (length)    access_intermediate(26,1). % int (position), int (length)    access_burried(1,2). % int (position), int (length)    access_dist(b,42.8). % {e,i,b}, float (percentage)   sec_struc(1,c,23). % int (position), {a,b,c}, int (length)   sec_struc_coil(1,23). % int (position), int (length)   sec_struc_alpha(1,15). % int (position), int (length)   sec_struc_beta(1,6). % int (position), int (length)   struc_dist(a,32.1). % {a,b,c}, float (percentage)   sec_struc_conf(78.8). % float (confidence)   sec_struc_conf_alpha(88.9). % float (confidence)   sec_struc_conf_beta(58.0). % float (confidence)   sec_struc_conf_coil(77.7). % float (confidence)   psi_sequences_found(1,7). % how many found, which iteration   psi_sequences_found_again(2,7).  % how many found, which iteration   psi_sequences_found_new(2,0). % how many found, which iteration   amino_acid_ratio(a,11.2). % amino acid letter, float   amino_acid_pair_ratio(a,c,0.0). % amino acid letter, amino acid letter, float (out of 1000, ie 2.8 = 0.28%)   sequence_length(187).  % integer   tb_to_tb_evalue(tb3671,1.100000e-01). % ORF number, e-value (double)     e_val(p35925,7.0e-59). % SWISSPROT accession no, e-value (double)   species(p35925,'streptomyces_coelicolor'). % SWISSPROT acc no, string   classification(p35925,bacteria). % SWISSPROT acc no, name   mol_wt(p35925,19772). % SWISSPROT acc no, integer   keyword(p35925,'hypothetical_protein'). % SWISSPROT acc no, string   db_ref(p35925,embl,l27063,g436026,null). % SWISSPROT acc no, db id, primary id, secondary id, status id   signalip(c,35,no). % {c,y,s}, int (signal peptide c/y/s score), yes/no   signalip(ss,1,34,no). % ss, int, int, yes/no   signalip(cleavage,59,60). % cleavage, int/null, int/null   hydro_cons(-0.498,-0.474,0.624,3.248,0.278). % double, double, double, double, double   gene_name(p41514,'gyrb'). % SWISSPROT acc no, string",Life,," Data giving characteristics of each ORF (potential gene) in the M. tuberculosis bacterium. Sequence, homology (similarity to other genes) and structural information, and function (if known) are providedThe data was collected from several sources, including the Sanger Centre ([Web Link]) and SWISSPROT ([Web Link]). Structure prediction was made by PROF ([Web Link]). Homology search was made by PSI-BLAST ([Web Link]).The data is in Datalog format. Missing values are not explicit, but some genes have more relationships than others.Dependencies:M. tuberculosis genes (ORFs) are related to each other by the predicate tb_to_tb_evalue(TBNumber,E-value). They are related to other (SWISSPROT) proteins by the predicate e_val(AccNo,E-value). All the data for a single gene (ORF) is enclosed between delimiters of the form:   begin(model(TBNumber)).   end(model(TBNumber)).Other Relevant Information:The gene functional classes are in a hierarchy. See [Web Link].There are two datalog files: tb_data.pl and ecoli_functions.pl1. tb_functions.plLists classes and ORF functions. Lines are of the following form:   class([1,0,0,0],""Small-molecule metabolism "").   class([1,1,0,0],""Degradation "").   class([1,1,1,0],""Carbon compounds "").  Arguments are a list of 4 numbers (describing class at the 4 different levels), followed by a string class description. For example,   function(tb186,[1,1,1,0],'bglS',""beta-glucosidase""). Arguments are ORF number, list of 4 class numbers, gene name (or null if no gene name) in single quotes, ORF description in double quotes.2. tb_data.plData for each ORF (gene) is delimited by   begin(model(X)).   end(model(X)).where X is the ORF number. Other predicates are as follows (examples):   tb_protein(X).    % X is gene number   function(2,1,5,0,'gyrA','DNA gyrase subunit A').  % 4 levels of functional hierarchy, gene name, description   coding_region(7302,9815). % start,end. integers   tb_mol_wt(19934).  % integer   access(1,e,20). % int (position), {e,i,b}, int (length)    access_exposed(1,20). % int (position), int (length)    access_intermediate(26,1). % int (position), int (length)    access_burried(1,2). % int (position), int (length)    access_dist(b,42.8). % {e,i,b}, float (percentage)   sec_struc(1,c,23). % int (position), {a,b,c}, int (length)   sec_struc_coil(1,23). % int (position), int (length)   sec_struc_alpha(1,15). % int (position), int (length)   sec_struc_beta(1,6). % int (position), int (length)   struc_dist(a,32.1). % {a,b,c}, float (percentage)   sec_struc_conf(78.8). % float (confidence)   sec_struc_conf_alpha(88.9). % float (confidence)   sec_struc_conf_beta(58.0). % float (confidence)   sec_struc_conf_coil(77.7). % float (confidence)   psi_sequences_found(1,7). % how many found, which iteration   psi_sequences_found_again(2,7).  % how many found, which iteration   psi_sequences_found_new(2,0). % how many found, which iteration   amino_acid_ratio(a,11.2). % amino acid letter, float   amino_acid_pair_ratio(a,c,0.0). % amino acid letter, amino acid letter, float (out of 1000, ie 2.8 = 0.28%)   sequence_length(187).  % integer   tb_to_tb_evalue(tb3671,1.100000e-01). % ORF number, e-value (double)     e_val(p35925,7.0e-59). % SWISSPROT accession no, e-value (double)   species(p35925,'streptomyces_coelicolor'). % SWISSPROT acc no, string   classification(p35925,bacteria). % SWISSPROT acc no, name   mol_wt(p35925,19772). % SWISSPROT acc no, integer   keyword(p35925,'hypothetical_protein'). % SWISSPROT acc no, string   db_ref(p35925,embl,l27063,g436026,null). % SWISSPROT acc no, db id, primary id, secondary id, status id   signalip(c,35,no). % {c,y,s}, int (signal peptide c/y/s score), yes/no   signalip(ss,1,34,no). % ss, int, int, yes/no   signalip(cleavage,59,60). % cleavage, int/null, int/null   hydro_cons(-0.498,-0.474,0.624,3.248,0.278). % double, double, double, double, double   gene_name(p41514,'gyrb'). % SWISSPROT acc no, stringnan"
Influenza outbreak event prediction via Twitter data,Influenza outbreak event prediction via Twitter data,"By identifying influenza-related tweets, the goal is to forecast the spatiotemporal patterns of influenza outbreaks for different locations and dates.",Influenza+outbreak+event+prediction+via+Twitter+data,https://archive.ics.uci.edu/ml//machine-learning-databases/00637/,https://archive.ics.uci.edu/ml/datasets/Influenza+outbreak+event+prediction+via+Twitter+data,"The data is from the United States. The data comes from different states under different weeks. For each week, the task is to predict whether or not there is an influenza outbreak on the next date. More specifically, for influenza activity, there are four levels of flu activities from minimal to high according to CDC Flu Activity Map. An influenza outbreak occurrence is indicated if the activity level is high. The input of the prediction task is the set of the keyword counts for all the tweets in a state in a week. The output is the occurrence of influenza outbreak for the specific state in the next week, which is zero if no event in the next week; or one, otherwise. Here are the briefs of all the variables:'flu_locations': a list of states.'flu_keywords': keyword list.'flu_X_*': input data for all the locations and all the weeks.'flu_Y_*': output data for all the locations and all the weeks.",Life,525 keywords specified in the variable 'flu_keywords' in the data,"By identifying influenza-related tweets, the goal is to forecast the spatiotemporal patterns of influenza outbreaks for different locations and dates.The data is from the United States. The data comes from different states under different weeks. For each week, the task is to predict whether or not there is an influenza outbreak on the next date. More specifically, for influenza activity, there are four levels of flu activities from minimal to high according to CDC Flu Activity Map. An influenza outbreak occurrence is indicated if the activity level is high. The input of the prediction task is the set of the keyword counts for all the tweets in a state in a week. The output is the occurrence of influenza outbreak for the specific state in the next week, which is zero if no event in the next week; or one, otherwise. Here are the briefs of all the variables:'flu_locations': a list of states.'flu_keywords': keyword list.'flu_X_*': input data for all the locations and all the weeks.'flu_Y_*': output data for all the locations and all the weeks.525 keywords specified in the variable 'flu_keywords' in the data"
Exasens,Exasens,"This repository introduces a novel dataset for the classification of 4 groups of respiratory diseases: Chronic Obstructive Pulmonary Disease (COPD), asthma, infected, and Healthy Controls (HC).",Exasens,https://archive.ics.uci.edu/ml//machine-learning-databases/00523/,https://archive.ics.uci.edu/ml/datasets/Exasens,"The Exasens dataset includes demographic information on 4 groups of saliva samples (COPD-Asthma-Infected-HC) collected in the frame of a joint research project, Exasens ([Web Link]), at the Research Center Borstel, BioMaterialBank Nord (Borstel, Germany). The sampling procedure of the patient materials was approved by the local ethics committee of the University of Luebeck under the approval number AZ-16-167 and a written informed consent was obtained from all subjects. A permittivity biosensor, developed at IHP Microelectronics (Frankfurt Oder, Germany), was used for the dielectric characterization of the saliva samples for classification purposes ([Web Link]). Definition of 4 sample groups included within the Exasens dataset:(I) Outpatients and hospitalized patients with COPD without acute respiratory infection (COPD).(II) Outpatients and hospitalized patients with asthma without acute respiratory infections (Asthma).(III) Patients with respiratory infections, but without COPD or asthma (Infected).(IV) Healthy controls without COPD, asthma, or any respiratory infection (HC).",Life,"1- Diagnosis (COPD-HC-Asthma-Infected)2- ID3- Age4- Gender (1=male, 0=female)5- Smoking Status (1=Non-smoker, 2=Ex-smoker, 3=Active-smoker)6- Saliva Permittivity:a) Imaginary part (Min(ÃŽâ€�)=Absolute minimum value, Avg.(ÃŽâ€�)=Average)  b) Real part (Min(ÃŽâ€�)=Absolute minimum value, Avg.(ÃŽâ€�)=Average) ","This repository introduces a novel dataset for the classification of 4 groups of respiratory diseases: Chronic Obstructive Pulmonary Disease (COPD), asthma, infected, and Healthy Controls (HC).The Exasens dataset includes demographic information on 4 groups of saliva samples (COPD-Asthma-Infected-HC) collected in the frame of a joint research project, Exasens ([Web Link]), at the Research Center Borstel, BioMaterialBank Nord (Borstel, Germany). The sampling procedure of the patient materials was approved by the local ethics committee of the University of Luebeck under the approval number AZ-16-167 and a written informed consent was obtained from all subjects. A permittivity biosensor, developed at IHP Microelectronics (Frankfurt Oder, Germany), was used for the dielectric characterization of the saliva samples for classification purposes ([Web Link]). Definition of 4 sample groups included within the Exasens dataset:(I) Outpatients and hospitalized patients with COPD without acute respiratory infection (COPD).(II) Outpatients and hospitalized patients with asthma without acute respiratory infections (Asthma).(III) Patients with respiratory infections, but without COPD or asthma (Infected).(IV) Healthy controls without COPD, asthma, or any respiratory infection (HC).1- Diagnosis (COPD-HC-Asthma-Infected)2- ID3- Age4- Gender (1=male, 0=female)5- Smoking Status (1=Non-smoker, 2=Ex-smoker, 3=Active-smoker)6- Saliva Permittivity:a) Imaginary part (Min(ÃŽâ€�)=Absolute minimum value, Avg.(ÃŽâ€�)=Average)  b) Real part (Min(ÃŽâ€�)=Absolute minimum value, Avg.(ÃŽâ€�)=Average) "
Mammographic Mass,Mammographic Mass,Discrimination of benign and malignant mammographic masses based on BI-RADS attributes and the patient's age.,Mammographic+Mass,https://archive.ics.uci.edu/ml//machine-learning-databases/mammographic-masses/,https://archive.ics.uci.edu/ml/datasets/Mammographic+Mass,"Mammography is the most effective method for breast cancer screeningavailable today. However, the low positive predictive value of breastbiopsy resulting from mammogram interpretation leads to approximately70% unnecessary biopsies with benign outcomes. To reduce the highnumber of unnecessary breast biopsies, several computer-aided diagnosis(CAD) systems have been proposed in the last years.These systemshelp physicians in their decision to perform a breast biopsy on a suspiciouslesion seen in a mammogram or to perform a short term follow-upexamination instead.This data set can be used to predict the severity (benign or malignant)of a mammographic mass lesion from BI-RADS attributes and the patient's age.It contains a BI-RADS assessment, the patient's age and three BI-RADS attributestogether with the ground truth (the severity field) for 516 benign and445 malignant masses that have been identified on full field digital mammogramscollected at the Institute of Radiology of theUniversity Erlangen-Nuremberg between 2003 and 2006.Each instance has an associated BI-RADS assessment ranging from 1 (definitely benign)to 5 (highly suggestive of malignancy) assigned in a double-review process byphysicians. Assuming that all cases with BI-RADS assessments greater or equala given value (varying from 1 to 5), are malignant and the other cases benign,sensitivities and associated specificities can be calculated. These can be anindication of how well a CAD system performs compared to the radiologists.Class Distribution: benign: 516; malignant: 445",Life,"6 Attributes in total (1 goal field, 1 non-predictive, 4 predictive attributes)1. BI-RADS assessment: 1 to 5 (ordinal, non-predictive!)  2. Age: patient's age in years (integer)3. Shape: mass shape: round=1 oval=2 lobular=3 irregular=4 (nominal)4. Margin: mass margin: circumscribed=1 microlobulated=2 obscured=3 ill-defined=4 spiculated=5 (nominal)5. Density: mass density high=1 iso=2 low=3 fat-containing=4 (ordinal)6. Severity: benign=0 or malignant=1 (binominal, goal field!)Missing Attribute Values:    - BI-RADS assessment:    2    - Age:                   5    - Shape:                31    - Margin:               48    - Density:              76    - Severity:              0","Discrimination of benign and malignant mammographic masses based on BI-RADS attributes and the patient's age.Mammography is the most effective method for breast cancer screeningavailable today. However, the low positive predictive value of breastbiopsy resulting from mammogram interpretation leads to approximately70% unnecessary biopsies with benign outcomes. To reduce the highnumber of unnecessary breast biopsies, several computer-aided diagnosis(CAD) systems have been proposed in the last years.These systemshelp physicians in their decision to perform a breast biopsy on a suspiciouslesion seen in a mammogram or to perform a short term follow-upexamination instead.This data set can be used to predict the severity (benign or malignant)of a mammographic mass lesion from BI-RADS attributes and the patient's age.It contains a BI-RADS assessment, the patient's age and three BI-RADS attributestogether with the ground truth (the severity field) for 516 benign and445 malignant masses that have been identified on full field digital mammogramscollected at the Institute of Radiology of theUniversity Erlangen-Nuremberg between 2003 and 2006.Each instance has an associated BI-RADS assessment ranging from 1 (definitely benign)to 5 (highly suggestive of malignancy) assigned in a double-review process byphysicians. Assuming that all cases with BI-RADS assessments greater or equala given value (varying from 1 to 5), are malignant and the other cases benign,sensitivities and associated specificities can be calculated. These can be anindication of how well a CAD system performs compared to the radiologists.Class Distribution: benign: 516; malignant: 4456 Attributes in total (1 goal field, 1 non-predictive, 4 predictive attributes)1. BI-RADS assessment: 1 to 5 (ordinal, non-predictive!)  2. Age: patient's age in years (integer)3. Shape: mass shape: round=1 oval=2 lobular=3 irregular=4 (nominal)4. Margin: mass margin: circumscribed=1 microlobulated=2 obscured=3 ill-defined=4 spiculated=5 (nominal)5. Density: mass density high=1 iso=2 low=3 fat-containing=4 (ordinal)6. Severity: benign=0 or malignant=1 (binominal, goal field!)Missing Attribute Values:    - BI-RADS assessment:    2    - Age:                   5    - Shape:                31    - Margin:               48    - Density:              76    - Severity:              0"
Maternal Health Risk Data Set,Maternal Health Risk Data Set,"Data has been collected from different hospitals, community clinics, maternal health cares from the rural areas of Bangladesh through the IoT based risk monitoring system. ",Maternal+Health+Risk+Data+Set,https://archive.ics.uci.edu/ml//machine-learning-databases/00639/,https://archive.ics.uci.edu/ml/datasets/Maternal+Health+Risk+Data+Set,"Age, Systolic Blood Pressure as SystolicBP, Diastolic BP as DiastolicBP, Blood Sugar as	BS, Body Temperature as BodyTemp, HeartRate and	RiskLevel. All these are the responsible and significant risk factors for maternal mortality, that is one of the main concern of SDG of UN.",Life,"Age: Any ages in years when a women during pregnant.SystolicBP: Upper value of Blood Pressure in mmHg, another significant attribute during pregnancy.DiastolicBP: Lower value of Blood Pressure in mmHg, another significant attribute during pregnancy.BS: Blood glucose levels is in terms of a molar concentration, mmol/L.HeartRate: A normal resting heart rate in beats per minute.Risk Level: Predicted Risk Intensity Level during pregnancy considering the previous attribute.","Data has been collected from different hospitals, community clinics, maternal health cares from the rural areas of Bangladesh through the IoT based risk monitoring system. Age, Systolic Blood Pressure as SystolicBP, Diastolic BP as DiastolicBP, Blood Sugar as	BS, Body Temperature as BodyTemp, HeartRate and	RiskLevel. All these are the responsible and significant risk factors for maternal mortality, that is one of the main concern of SDG of UN.Age: Any ages in years when a women during pregnant.SystolicBP: Upper value of Blood Pressure in mmHg, another significant attribute during pregnancy.DiastolicBP: Lower value of Blood Pressure in mmHg, another significant attribute during pregnancy.BS: Blood glucose levels is in terms of a molar concentration, mmol/L.HeartRate: A normal resting heart rate in beats per minute.Risk Level: Predicted Risk Intensity Level during pregnancy considering the previous attribute."
Covertype,Covertype,Forest CoverType dataset,Covertype,https://archive.ics.uci.edu/ml//machine-learning-databases/covtype/,https://archive.ics.uci.edu/ml/datasets/Covertype,"Predicting forest cover type from cartographic variables only (no remotely sensed data).  The actual forest cover type for a given observation (30 x 30 meter cell) was determined from US Forest Service (USFS) Region 2 Resource Information System (RIS) data.  Independent variables were derived from data originally obtained from US Geological Survey (USGS) and USFS data.  Data is in raw form (not scaled) and contains binary (0 or 1) columns of data for qualitative independent variables (wilderness areas and soil types).This study area includes four wilderness areas located in the Roosevelt National Forest of northern Colorado.  These areas represent forests with minimal human-caused disturbances, so that existing forest cover types are more a result of ecological processes rather than forest management practices.Some background information for these four wilderness areas: Neota (area 2) probably has the highest mean elevational value of the 4 wilderness areas. Rawah (area 1) and Comanche Peak (area 3) would have a lower mean elevational value, while Cache la Poudre (area 4) would have the lowest mean elevational value. As for primary major tree species in these areas, Neota would have spruce/fir (type 1), while Rawah and Comanche Peak would probably have lodgepole pine (type 2) as their primary species, followed by spruce/fir and aspen (type 5). Cache la Poudre would tend to have Ponderosa pine (type 3), Douglas-fir (type 6), and cottonwood/willow (type 4).  The Rawah and Comanche Peak areas would tend to be more typical of the overall dataset than either the Neota or Cache la Poudre, due to their assortment of tree species and range of predictive variable values (elevation, etc.)  Cache la Poudre would probably  be more unique than the others, due to its relatively low  elevation range and species composition. ",Life,"Given is the attribute name, attribute type, the measurement unit and a brief description.  The forest cover type is the classification  problem.  The order of this listing corresponds to the order of numerals along the rows of the database.Name / Data Type / Measurement / DescriptionElevation / quantitative /meters / Elevation in metersAspect / quantitative / azimuth / Aspect in degrees azimuthSlope / quantitative / degrees / Slope in degreesHorizontal_Distance_To_Hydrology / quantitative / meters / Horz Dist to nearest surface water featuresVertical_Distance_To_Hydrology / quantitative / meters / Vert Dist to nearest surface water featuresHorizontal_Distance_To_Roadways / quantitative / meters / Horz Dist to nearest roadwayHillshade_9am / quantitative / 0 to 255 index / Hillshade index at 9am, summer solsticeHillshade_Noon / quantitative / 0 to 255 index / Hillshade index at noon, summer solticeHillshade_3pm / quantitative / 0 to 255 index / Hillshade index at 3pm, summer solsticeHorizontal_Distance_To_Fire_Points / quantitative / meters / Horz Dist to nearest wildfire ignition pointsWilderness_Area (4 binary columns) / qualitative / 0 (absence) or 1 (presence) / Wilderness area designationSoil_Type (40 binary columns) / qualitative / 0 (absence) or 1 (presence) / Soil Type designationCover_Type (7 types) / integer / 1 to 7 / Forest Cover Type designation","Forest CoverType datasetPredicting forest cover type from cartographic variables only (no remotely sensed data).  The actual forest cover type for a given observation (30 x 30 meter cell) was determined from US Forest Service (USFS) Region 2 Resource Information System (RIS) data.  Independent variables were derived from data originally obtained from US Geological Survey (USGS) and USFS data.  Data is in raw form (not scaled) and contains binary (0 or 1) columns of data for qualitative independent variables (wilderness areas and soil types).This study area includes four wilderness areas located in the Roosevelt National Forest of northern Colorado.  These areas represent forests with minimal human-caused disturbances, so that existing forest cover types are more a result of ecological processes rather than forest management practices.Some background information for these four wilderness areas: Neota (area 2) probably has the highest mean elevational value of the 4 wilderness areas. Rawah (area 1) and Comanche Peak (area 3) would have a lower mean elevational value, while Cache la Poudre (area 4) would have the lowest mean elevational value. As for primary major tree species in these areas, Neota would have spruce/fir (type 1), while Rawah and Comanche Peak would probably have lodgepole pine (type 2) as their primary species, followed by spruce/fir and aspen (type 5). Cache la Poudre would tend to have Ponderosa pine (type 3), Douglas-fir (type 6), and cottonwood/willow (type 4).  The Rawah and Comanche Peak areas would tend to be more typical of the overall dataset than either the Neota or Cache la Poudre, due to their assortment of tree species and range of predictive variable values (elevation, etc.)  Cache la Poudre would probably  be more unique than the others, due to its relatively low  elevation range and species composition. Given is the attribute name, attribute type, the measurement unit and a brief description.  The forest cover type is the classification  problem.  The order of this listing corresponds to the order of numerals along the rows of the database.Name / Data Type / Measurement / DescriptionElevation / quantitative /meters / Elevation in metersAspect / quantitative / azimuth / Aspect in degrees azimuthSlope / quantitative / degrees / Slope in degreesHorizontal_Distance_To_Hydrology / quantitative / meters / Horz Dist to nearest surface water featuresVertical_Distance_To_Hydrology / quantitative / meters / Vert Dist to nearest surface water featuresHorizontal_Distance_To_Roadways / quantitative / meters / Horz Dist to nearest roadwayHillshade_9am / quantitative / 0 to 255 index / Hillshade index at 9am, summer solsticeHillshade_Noon / quantitative / 0 to 255 index / Hillshade index at noon, summer solticeHillshade_3pm / quantitative / 0 to 255 index / Hillshade index at 3pm, summer solsticeHorizontal_Distance_To_Fire_Points / quantitative / meters / Horz Dist to nearest wildfire ignition pointsWilderness_Area (4 binary columns) / qualitative / 0 (absence) or 1 (presence) / Wilderness area designationSoil_Type (40 binary columns) / qualitative / 0 (absence) or 1 (presence) / Soil Type designationCover_Type (7 types) / integer / 1 to 7 / Forest Cover Type designation"
Drug Review Dataset (Drugs.com),Drug Review Dataset (Drugs.com),The dataset provides patient reviews on specific drugs along with related conditions and a 10 star patient rating reflecting overall patient satisfaction.,Drug+Review+Dataset+%28Drugs.com%29,https://archive.ics.uci.edu/ml//machine-learning-databases/00462/,https://archive.ics.uci.edu/ml/datasets/Drug+Review+Dataset+%28Drugs.com%29,"The dataset provides patient reviews on specific drugs along with related conditions and a 10 star patient rating reflecting overall patient satisfaction. The data was obtained by crawling online pharmaceutical review sites. The intention was to study (1) sentiment analysis of drug experience over multiple facets, i.e. sentiments learned on specific aspects such as effectiveness and side effects,(2) the transferability of models among domains, i.e. conditions, and (3) the transferability of models among different data sources (see 'Drug Review Dataset (Druglib.com)').The data is split into a train (75%) a test (25%) partition (see publication) and stored in two .tsv (tab-separated-values) files, respectively.Important notes:When using this dataset, you agree that you1) only use the data for research purposes2) don't use the data for any commerical purposes3) don't distribute the data to anyone else4) cite us",Life,1. drugName (categorical): name of drug2. condition (categorical): name of condition3. review (text): patient review4. rating (numerical): 10 star patient rating5. date (date): date of review entry6. usefulCount (numerical): number of users who found review useful,"The dataset provides patient reviews on specific drugs along with related conditions and a 10 star patient rating reflecting overall patient satisfaction.The dataset provides patient reviews on specific drugs along with related conditions and a 10 star patient rating reflecting overall patient satisfaction. The data was obtained by crawling online pharmaceutical review sites. The intention was to study (1) sentiment analysis of drug experience over multiple facets, i.e. sentiments learned on specific aspects such as effectiveness and side effects,(2) the transferability of models among domains, i.e. conditions, and (3) the transferability of models among different data sources (see 'Drug Review Dataset (Druglib.com)').The data is split into a train (75%) a test (25%) partition (see publication) and stored in two .tsv (tab-separated-values) files, respectively.Important notes:When using this dataset, you agree that you1) only use the data for research purposes2) don't use the data for any commerical purposes3) don't distribute the data to anyone else4) cite us1. drugName (categorical): name of drug2. condition (categorical): name of condition3. review (text): patient review4. rating (numerical): 10 star patient rating5. date (date): date of review entry6. usefulCount (numerical): number of users who found review useful"
Dermatology,Dermatology,Aim for this dataset is to determine the type of Eryhemato-Squamous Disease.,Dermatology,https://archive.ics.uci.edu/ml//machine-learning-databases/dermatology/,https://archive.ics.uci.edu/ml/datasets/Dermatology,"This database contains 34 attributes, 33 of which are linear valued and one of them is nominal. The differential diagnosis of erythemato-squamous diseases is a real problem in dermatology. They all share the clinical features of erythema and scaling, with very little differences. The diseases in this group are psoriasis, seboreic dermatitis, lichen planus, pityriasis rosea, cronic dermatitis, and pityriasis rubra pilaris. Usually a biopsy is necessary for the diagnosis but unfortunately these diseases share many histopathological features as well. Another difficulty for the differential diagnosis is that a disease may show the features of another disease at the beginning stage and may have the characteristic features at the following stages. Patients were first evaluated clinically with 12 features. Afterwards, skin samples were taken for the evaluation of 22 histopathological features. The values of the histopathological features are determined by an analysis of the samples under a microscope. In the dataset constructed for this domain, the family history feature has the value 1 if any of these diseases has been observed in the family, and 0 otherwise. The age feature simply represents the age of the patient. Every other feature (clinical and histopathological) was given a degree in the range of 0 to 3. Here, 0 indicates that the feature was not present, 3 indicates the largest amount possible, and 1, 2 indicate the relative intermediate values.The names and id numbers of the patients were recently removed from the database.",Life,"      Clinical Attributes: (take values 0, 1, 2, 3, unless otherwise indicated)      1: erythema      2: scaling      3: definite borders      4: itching      5: koebner phenomenon      6: polygonal papules      7: follicular papules      8: oral mucosal involvement      9: knee and elbow involvement     10: scalp involvement     11: family history, (0 or 1)     34: Age (linear)     Histopathological Attributes: (take values 0, 1, 2, 3)     12: melanin incontinence     13: eosinophils in the infiltrate     14: PNL infiltrate     15: fibrosis of the papillary dermis     16: exocytosis     17: acanthosis     18: hyperkeratosis     19: parakeratosis     20: clubbing of the rete ridges     21: elongation of the rete ridges     22: thinning of the suprapapillary epidermis     23: spongiform pustule     24: munro microabcess     25: focal hypergranulosis     26: disappearance of the granular layer     27: vacuolisation and damage of basal layer     28: spongiosis     29: saw-tooth appearance of retes     30: follicular horn plug     31: perifollicular parakeratosis     32: inflammatory monoluclear inflitrate     33: band-like infiltrate","Aim for this dataset is to determine the type of Eryhemato-Squamous Disease.This database contains 34 attributes, 33 of which are linear valued and one of them is nominal. The differential diagnosis of erythemato-squamous diseases is a real problem in dermatology. They all share the clinical features of erythema and scaling, with very little differences. The diseases in this group are psoriasis, seboreic dermatitis, lichen planus, pityriasis rosea, cronic dermatitis, and pityriasis rubra pilaris. Usually a biopsy is necessary for the diagnosis but unfortunately these diseases share many histopathological features as well. Another difficulty for the differential diagnosis is that a disease may show the features of another disease at the beginning stage and may have the characteristic features at the following stages. Patients were first evaluated clinically with 12 features. Afterwards, skin samples were taken for the evaluation of 22 histopathological features. The values of the histopathological features are determined by an analysis of the samples under a microscope. In the dataset constructed for this domain, the family history feature has the value 1 if any of these diseases has been observed in the family, and 0 otherwise. The age feature simply represents the age of the patient. Every other feature (clinical and histopathological) was given a degree in the range of 0 to 3. Here, 0 indicates that the feature was not present, 3 indicates the largest amount possible, and 1, 2 indicate the relative intermediate values.The names and id numbers of the patients were recently removed from the database.      Clinical Attributes: (take values 0, 1, 2, 3, unless otherwise indicated)      1: erythema      2: scaling      3: definite borders      4: itching      5: koebner phenomenon      6: polygonal papules      7: follicular papules      8: oral mucosal involvement      9: knee and elbow involvement     10: scalp involvement     11: family history, (0 or 1)     34: Age (linear)     Histopathological Attributes: (take values 0, 1, 2, 3)     12: melanin incontinence     13: eosinophils in the infiltrate     14: PNL infiltrate     15: fibrosis of the papillary dermis     16: exocytosis     17: acanthosis     18: hyperkeratosis     19: parakeratosis     20: clubbing of the rete ridges     21: elongation of the rete ridges     22: thinning of the suprapapillary epidermis     23: spongiform pustule     24: munro microabcess     25: focal hypergranulosis     26: disappearance of the granular layer     27: vacuolisation and damage of basal layer     28: spongiosis     29: saw-tooth appearance of retes     30: follicular horn plug     31: perifollicular parakeratosis     32: inflammatory monoluclear inflitrate     33: band-like infiltrate"
Immunotherapy Dataset,Immunotherapy Dataset,This dataset contains information about wart treatment results of 90 patients using immunotherapy.,Immunotherapy+Dataset,https://archive.ics.uci.edu/ml//machine-learning-databases/00428/,https://archive.ics.uci.edu/ml/datasets/Immunotherapy+Dataset,Provide all relevant information about your data set.,Life,Provide information about each attribute in your data set.,This dataset contains information about wart treatment results of 90 patients using immunotherapy.Provide all relevant information about your data set.Provide information about each attribute in your data set.
extention of Z-Alizadeh sani dataset,extention of Z-Alizadeh sani dataset,It was collected for CAD diagnosis.,extention+of+Z-Alizadeh+sani+dataset,https://archive.ics.uci.edu/ml//machine-learning-databases/00411/,https://archive.ics.uci.edu/ml/datasets/extention+of+Z-Alizadeh+sani+dataset,"Each patient could be in two possible categories CAD or Normal. A patient is categorized as CAD, if his/her diameter narrowing is greater than or equal to 50%, and otherwise as Normal .Note 1: In this extension LAD, LCX, and RCA features have been added. CAD (Last column in dataset) happens when at least one of these three arteries is stenotic. To use this dataset only one of the LAD, LCX, RCA or Cath (Result of angiography) must be in dataset and the other ones must be eliminated for classification.Note 2: This dataset not only can be used for CAD detection, but also for stenosis diagnosis of each LAD, LCX and RCA arteries. ",Life,"The extension of Z-Alizadeh Sani dataset contains the records of 303 patients, each of which have 59 features.The features are arranged in four groups: demographic, symptom and examination, ECG, and laboratory and echo features.Note 1: In this extension LAD, LCX, and RCA features have been added. CAD (Last column in dataset) happens when at least one of these three arteries is stenotic. To use this dataset only one of the LAD, LCX, RCA or Cath (Result of angiography) must be in dataset and the other ones must be eliminated for classification.Note 2: This dataset not only can be used for CAD detection, but also for stenosis diagnosis of each LAD, LCX and RCA arteries. ","It was collected for CAD diagnosis.Each patient could be in two possible categories CAD or Normal. A patient is categorized as CAD, if his/her diameter narrowing is greater than or equal to 50%, and otherwise as Normal .Note 1: In this extension LAD, LCX, and RCA features have been added. CAD (Last column in dataset) happens when at least one of these three arteries is stenotic. To use this dataset only one of the LAD, LCX, RCA or Cath (Result of angiography) must be in dataset and the other ones must be eliminated for classification.Note 2: This dataset not only can be used for CAD detection, but also for stenosis diagnosis of each LAD, LCX and RCA arteries. The extension of Z-Alizadeh Sani dataset contains the records of 303 patients, each of which have 59 features.The features are arranged in four groups: demographic, symptom and examination, ECG, and laboratory and echo features.Note 1: In this extension LAD, LCX, and RCA features have been added. CAD (Last column in dataset) happens when at least one of these three arteries is stenotic. To use this dataset only one of the LAD, LCX, RCA or Cath (Result of angiography) must be in dataset and the other ones must be eliminated for classification.Note 2: This dataset not only can be used for CAD detection, but also for stenosis diagnosis of each LAD, LCX and RCA arteries. "
ILPD (Indian Liver Patient Dataset),ILPD (Indian Liver Patient Dataset),"This data set contains 10 variables that are age, gender, total Bilirubin, direct Bilirubin, total proteins, albumin, A/G ratio, SGPT, SGOT and Alkphos.",ILPD+%28Indian+Liver+Patient+Dataset%29,https://archive.ics.uci.edu/ml//machine-learning-databases/00225/,https://archive.ics.uci.edu/ml/datasets/ILPD+%28Indian+Liver+Patient+Dataset%29,"This data set contains 416 liver patient records and 167 non liver patient records.The data set was collected from north east of Andhra Pradesh, India. Selector is a class label used to divide into groups(liver patient or not). This data set contains 441 male patient records and 142 female patient records.  Any patient whose age exceeded 89 is listed as being of age ""90"".",Life,1.   Age		Age of the patient2.   Gender		Gender of the patient3.   TB			Total Bilirubin4.   DB		 	Direct Bilirubin5.   Alkphos 		Alkaline Phosphotase6.   Sgpt 		Alamine Aminotransferase7.   Sgot 		Aspartate Aminotransferase8.   TP			Total Protiens9.   ALB		Albumin10. A/G Ratio		Albumin and Globulin Ratio11. Selector field used to split the data into two sets (labeled by the experts),"This data set contains 10 variables that are age, gender, total Bilirubin, direct Bilirubin, total proteins, albumin, A/G ratio, SGPT, SGOT and Alkphos.This data set contains 416 liver patient records and 167 non liver patient records.The data set was collected from north east of Andhra Pradesh, India. Selector is a class label used to divide into groups(liver patient or not). This data set contains 441 male patient records and 142 female patient records.  Any patient whose age exceeded 89 is listed as being of age ""90"".1.   Age		Age of the patient2.   Gender		Gender of the patient3.   TB			Total Bilirubin4.   DB		 	Direct Bilirubin5.   Alkphos 		Alkaline Phosphotase6.   Sgpt 		Alamine Aminotransferase7.   Sgot 		Aspartate Aminotransferase8.   TP			Total Protiens9.   ALB		Albumin10. A/G Ratio		Albumin and Globulin Ratio11. Selector field used to split the data into two sets (labeled by the experts)"
Demospongiae,Demospongiae,Marine sponges of the Demospongiae class classification domain.,Demospongiae,https://archive.ics.uci.edu/ml//machine-learning-databases/demospongiae,https://archive.ics.uci.edu/ml/datasets/Demospongiae,"This dataset contains 503 sponges belonging to the Demospongiae class collected from the Mediterranean (451 sponges) and Atlantic oceans (52 sponges). Each sponge is classified according to a hierarchy formed by: order, family, genus and specie. Each order is subdivided in several families. Each family is also divided in several genus, and each genus in several species:- There are 7 different orders (between 42 to 117 sponges per order)- 42 different families (1 to 43 sponges per family)- 114 different genus (1 to 34 sponges per genus)- 230 different species (1 to 15 sponges per specie)Although classification at all these levels can be attempted, it has traditionally been used as a classification dataset, using 'order' as the target class. Moreover, a subset consisting of 280 sponges (orders astrophoricda, axinellida and hadromerida) is also commonly used.The data set is relational and is provided in two alternative formats (which are equivalent):- NOOS: NOOS is a lisp-like language to represent data as feature-terms. The following files contain the dataset in this format:	- sponge-ontology.noos: this defines the ontology (sorts and features)	- sponge-dm.noos: this file defines the different constants used in the examples	- sponge-cases-503.noos: this file contains the actual dataset- Horn Clauses: the dataset is also provided as a set of prolog clauses, equivalent to the feature-term representation in NOOS. The file sponges-503.pl contains the dataset in this format. Each predicate with head 'sponge-problem' defines a different sponge.",Life,"Each sponge defines 2 attributes:- description: which in itself defines up to 6 attributes (external-features, ecological-features, spikulate-skeleton, fibrous-skeleton, tracts-skeleton, and anatomy). Each of those attributes has additional attributes defined, and so on, forming a tree structure. The leaves of the tree contain both categorial as well as numerical features. Moreover, some features are multi-valued (i.e. a feature can contain more than one value)- solution: this attribute has 4 additional attributes defined (order, family, genus and specie), which are the target attributes. As explained above, typically 'order' is used as the target class, since there are not enough examples to predict family, genus and specie accurately.The trees representing the sponges vary in size: their depth varies form 5 to 8, and their number of leaves from 17 to 51.A graphical representation of a sponge is shown in the file sponge-220.pdf as an example.","Marine sponges of the Demospongiae class classification domain.This dataset contains 503 sponges belonging to the Demospongiae class collected from the Mediterranean (451 sponges) and Atlantic oceans (52 sponges). Each sponge is classified according to a hierarchy formed by: order, family, genus and specie. Each order is subdivided in several families. Each family is also divided in several genus, and each genus in several species:- There are 7 different orders (between 42 to 117 sponges per order)- 42 different families (1 to 43 sponges per family)- 114 different genus (1 to 34 sponges per genus)- 230 different species (1 to 15 sponges per specie)Although classification at all these levels can be attempted, it has traditionally been used as a classification dataset, using 'order' as the target class. Moreover, a subset consisting of 280 sponges (orders astrophoricda, axinellida and hadromerida) is also commonly used.The data set is relational and is provided in two alternative formats (which are equivalent):- NOOS: NOOS is a lisp-like language to represent data as feature-terms. The following files contain the dataset in this format:	- sponge-ontology.noos: this defines the ontology (sorts and features)	- sponge-dm.noos: this file defines the different constants used in the examples	- sponge-cases-503.noos: this file contains the actual dataset- Horn Clauses: the dataset is also provided as a set of prolog clauses, equivalent to the feature-term representation in NOOS. The file sponges-503.pl contains the dataset in this format. Each predicate with head 'sponge-problem' defines a different sponge.Each sponge defines 2 attributes:- description: which in itself defines up to 6 attributes (external-features, ecological-features, spikulate-skeleton, fibrous-skeleton, tracts-skeleton, and anatomy). Each of those attributes has additional attributes defined, and so on, forming a tree structure. The leaves of the tree contain both categorial as well as numerical features. Moreover, some features are multi-valued (i.e. a feature can contain more than one value)- solution: this attribute has 4 additional attributes defined (order, family, genus and specie), which are the target attributes. As explained above, typically 'order' is used as the target class, since there are not enough examples to predict family, genus and specie accurately.The trees representing the sponges vary in size: their depth varies form 5 to 8, and their number of leaves from 17 to 51.A graphical representation of a sponge is shown in the file sponge-220.pdf as an example."
Lab Test,Lab Test,"This data set consists of ALT, AST, urea, glucose, and creatine kinase laboratory values of the patients. Creatine Kinase values have been converted according to general reference values.",Lab+Test,https://archive.ics.uci.edu/ml//machine-learning-databases/00625/,https://archive.ics.uci.edu/ml/datasets/Lab+Test,Provide all relevant information about your data set.,Life,"1. patient_ age  between 4-89 2. gender  male - female3. ALT result     4. AST result5. urea6. glucose7. creatine kinase (safeforall, lowforall, highforall, highforwoman, lowforman)","This data set consists of ALT, AST, urea, glucose, and creatine kinase laboratory values of the patients. Creatine Kinase values have been converted according to general reference values.Provide all relevant information about your data set.1. patient_ age  between 4-89 2. gender  male - female3. ALT result     4. AST result5. urea6. glucose7. creatine kinase (safeforall, lowforall, highforall, highforwoman, lowforman)"
E. Coli Genes,E. Coli Genes,"Data giving characteristics of each ORF (potential gene) in the E. coli genome. Sequence, homology (similarity to other genes) and structural information, and function (if known) are provided.",E.+Coli+Genes,https://archive.ics.uci.edu/ml//machine-learning-databases/ecoli-mld/,https://archive.ics.uci.edu/ml/datasets/E.+Coli+Genes,"The data was collected from several sources, including GenProtEC ([Web Link]) and SWISSPROT ([Web Link]). Structure prediction was made by PROF ([Web Link]). Homology search was provided by PSI-BLAST ([Web Link]). The data is in Datalog format. Missing values are not explicit, but some genes have more relationships than others. E. coli genes (ORFs) are related to each other by the predicate ecoli_to_ecoli(EcoliNumber,E-value,Psi-blast_iteration). They are related to other (SWISSPROT) proteins by the predicate e_val(AccNo,E-value). All the data for a single gene (ORF) is enclosed between delimiters of the form: begin(model(EcoliNumber)).end(model(EcoliNumber)). The gene functional classes are in a hierarchy. See [Web Link] (note: the classes may have changed since original data collection). There are two datalog files: ecoli_data.pl and ecoli_functions.pl 1. ecoli_functions.plLists classes and ORF functions. Lines are of the following form:    class(5,1,1,'Colicin-related functions').   class(5,1,'Laterally acquirred elements').   class(5,'Extrachromosomal'). Arguments are up to 3 numbers (describing class at up to 3 different levels), followed by a string class description. For example:    function(ecoli210,7,0,0,'b0217','putative aminopeptidase').Arguments are ORF number, exactly 3 class numbers, gene name (or blattner number if no gene name), ORF description. 2. ecoli_data.plData for each ORF (gene) is delimited by    begin(model(ecoliX)).   end(model(ecoliX)).where X is the ORF number. Other predicates are as follows (examples):    ecoli_orf(ecoliX).    % X is ORF number   ecoli_mol_wt(176624.1).  % float   ecoli_theo_pI(5.81).     %float   ecoli_atomic_comp(c,7940).   % {c,h,n,o,s} , int   ecoli_aliphatic_index(69.57). % float   ecoli_hydro(-0.549).          % float   sec_struc(1,c,2).           % int (start), {a,b,c}, int (length)   sec_struc_coil(1,2).        % int (start), int (length)   sec_struc_beta(1,5).        % int (start), int (length)   sec_struc_alpha(1,7).       % int (start), int (length)   sequence_length(255).       % int   amino_acid_ratio(a,8.9).    % amino_acid_char, float   amino_acids(ecoli3013,a,70). % ORF_num, amino_acid_char, int   amino_acid_pair_ratio(a,a,9.0). % amino_acid_char, amino_acid_char, float   amino_acid_pairs(a,a,7).    % amino_acid_char, amino_acid_char, int   ecoli_to_ecoli(1170,1.0e-105,5).  % ORF_num, double (e-value), int (iteration)    e_val(o42893,2.0e-99).  % accession_number, double (e-value)   psi_iter(o42893,5).     % accession_number, int (iteration)   species(p52494,'candida_albicans__yeast_').  % accession_number, string   mol_wt(p52494,104022). % accession_number, int    classification(p52494,candida).  % accession_number, name   keyword(p25195,'plasmid').   % accession_number, string",Life,,"Data giving characteristics of each ORF (potential gene) in the E. coli genome. Sequence, homology (similarity to other genes) and structural information, and function (if known) are provided.The data was collected from several sources, including GenProtEC ([Web Link]) and SWISSPROT ([Web Link]). Structure prediction was made by PROF ([Web Link]). Homology search was provided by PSI-BLAST ([Web Link]). The data is in Datalog format. Missing values are not explicit, but some genes have more relationships than others. E. coli genes (ORFs) are related to each other by the predicate ecoli_to_ecoli(EcoliNumber,E-value,Psi-blast_iteration). They are related to other (SWISSPROT) proteins by the predicate e_val(AccNo,E-value). All the data for a single gene (ORF) is enclosed between delimiters of the form: begin(model(EcoliNumber)).end(model(EcoliNumber)). The gene functional classes are in a hierarchy. See [Web Link] (note: the classes may have changed since original data collection). There are two datalog files: ecoli_data.pl and ecoli_functions.pl 1. ecoli_functions.plLists classes and ORF functions. Lines are of the following form:    class(5,1,1,'Colicin-related functions').   class(5,1,'Laterally acquirred elements').   class(5,'Extrachromosomal'). Arguments are up to 3 numbers (describing class at up to 3 different levels), followed by a string class description. For example:    function(ecoli210,7,0,0,'b0217','putative aminopeptidase').Arguments are ORF number, exactly 3 class numbers, gene name (or blattner number if no gene name), ORF description. 2. ecoli_data.plData for each ORF (gene) is delimited by    begin(model(ecoliX)).   end(model(ecoliX)).where X is the ORF number. Other predicates are as follows (examples):    ecoli_orf(ecoliX).    % X is ORF number   ecoli_mol_wt(176624.1).  % float   ecoli_theo_pI(5.81).     %float   ecoli_atomic_comp(c,7940).   % {c,h,n,o,s} , int   ecoli_aliphatic_index(69.57). % float   ecoli_hydro(-0.549).          % float   sec_struc(1,c,2).           % int (start), {a,b,c}, int (length)   sec_struc_coil(1,2).        % int (start), int (length)   sec_struc_beta(1,5).        % int (start), int (length)   sec_struc_alpha(1,7).       % int (start), int (length)   sequence_length(255).       % int   amino_acid_ratio(a,8.9).    % amino_acid_char, float   amino_acids(ecoli3013,a,70). % ORF_num, amino_acid_char, int   amino_acid_pair_ratio(a,a,9.0). % amino_acid_char, amino_acid_char, float   amino_acid_pairs(a,a,7).    % amino_acid_char, amino_acid_char, int   ecoli_to_ecoli(1170,1.0e-105,5).  % ORF_num, double (e-value), int (iteration)    e_val(o42893,2.0e-99).  % accession_number, double (e-value)   psi_iter(o42893,5).     % accession_number, int (iteration)   species(p52494,'candida_albicans__yeast_').  % accession_number, string   mol_wt(p52494,104022). % accession_number, int    classification(p52494,candida).  % accession_number, name   keyword(p25195,'plasmid').   % accession_number, stringnan"
Mice Protein Expression,Mice Protein Expression,"Expression levels of 77 proteins measured in the cerebral cortex of 8 classes of control and Down syndrome mice exposed to context fear conditioning, a task used to assess associative learning.",Mice+Protein+Expression,https://archive.ics.uci.edu/ml//machine-learning-databases/00342/,https://archive.ics.uci.edu/ml/datasets/Mice+Protein+Expression,"The data set consists of the expression levels of 77 proteins/protein modifications that produced detectable signals in the nuclear fraction of cortex. There are 38 control mice and 34 trisomic mice (Down syndrome), for a total of 72 mice. In the experiments, 15 measurements were registered of each protein per sample/mouse. Therefore, for control mice, there are 38x15, or 570 measurements, and for trisomic mice, there are 34x15, or 510 measurements. The dataset contains a total of 1080 measurements per protein. Each measurement can be considered as an independent sample/mouse.The eight classes of mice are described based on features such as genotype, behavior and treatment. According to genotype, mice can be control or trisomic. According to behavior, some mice have been stimulated to learn (context-shock) and others have not (shock-context) and in order to assess the effect of the drug memantine in recovering the ability to learn in trisomic mice, some mice have been injected with the drug and others have not.Classes:c-CS-s: control mice, stimulated to learn, injected with saline (9 mice)c-CS-m: control mice, stimulated to learn, injected with memantine (10 mice)c-SC-s: control mice, not stimulated to learn, injected with saline (9 mice)c-SC-m: control mice, not stimulated to learn, injected with memantine (10 mice)t-CS-s: trisomy mice, stimulated to learn, injected with saline (7 mice)t-CS-m: trisomy mice, stimulated to learn, injected with memantine (9 mice)t-SC-s: trisomy mice, not stimulated to learn, injected with saline (9 mice)t-SC-m: trisomy mice, not stimulated to learn, injected with memantine (9 mice)The aim is to identify subsets of proteins that are discriminant between the classes.",Life,"1 Mouse ID 2..78 Values of expression levels of 77 proteins; the names of proteins are followed by Ã¢â‚¬Å“_nÃ¢â‚¬Â�  indicating that they were measured in the nuclear fraction. For example: DYRK1A_n79 Genotype: control (c) or trisomy (t)80 Treatment type: memantine (m) or saline (s)81 Behavior: context-shock (CS) or shock-context (SC)82 Class: c-CS-s, c-CS-m, c-SC-s, c-SC-m,  t-CS-s, t-CS-m, t-SC-s, t-SC-m ","Expression levels of 77 proteins measured in the cerebral cortex of 8 classes of control and Down syndrome mice exposed to context fear conditioning, a task used to assess associative learning.The data set consists of the expression levels of 77 proteins/protein modifications that produced detectable signals in the nuclear fraction of cortex. There are 38 control mice and 34 trisomic mice (Down syndrome), for a total of 72 mice. In the experiments, 15 measurements were registered of each protein per sample/mouse. Therefore, for control mice, there are 38x15, or 570 measurements, and for trisomic mice, there are 34x15, or 510 measurements. The dataset contains a total of 1080 measurements per protein. Each measurement can be considered as an independent sample/mouse.The eight classes of mice are described based on features such as genotype, behavior and treatment. According to genotype, mice can be control or trisomic. According to behavior, some mice have been stimulated to learn (context-shock) and others have not (shock-context) and in order to assess the effect of the drug memantine in recovering the ability to learn in trisomic mice, some mice have been injected with the drug and others have not.Classes:c-CS-s: control mice, stimulated to learn, injected with saline (9 mice)c-CS-m: control mice, stimulated to learn, injected with memantine (10 mice)c-SC-s: control mice, not stimulated to learn, injected with saline (9 mice)c-SC-m: control mice, not stimulated to learn, injected with memantine (10 mice)t-CS-s: trisomy mice, stimulated to learn, injected with saline (7 mice)t-CS-m: trisomy mice, stimulated to learn, injected with memantine (9 mice)t-SC-s: trisomy mice, not stimulated to learn, injected with saline (9 mice)t-SC-m: trisomy mice, not stimulated to learn, injected with memantine (9 mice)The aim is to identify subsets of proteins that are discriminant between the classes.1 Mouse ID 2..78 Values of expression levels of 77 proteins; the names of proteins are followed by Ã¢â‚¬Å“_nÃ¢â‚¬Â�  indicating that they were measured in the nuclear fraction. For example: DYRK1A_n79 Genotype: control (c) or trisomy (t)80 Treatment type: memantine (m) or saline (s)81 Behavior: context-shock (CS) or shock-context (SC)82 Class: c-CS-s, c-CS-m, c-SC-s, c-SC-m,  t-CS-s, t-CS-m, t-SC-s, t-SC-m "
Estimation of obesity levels based on eating habits and physical condition ,Estimation of obesity levels based on eating habits and physical condition ,"This dataset include data for the estimation of obesity levels in individuals from the countries of Mexico, Peru and Colombia, based on their eating habits and physical condition. ",Estimation+of+obesity+levels+based+on+eating+habits+and+physical+condition+,https://archive.ics.uci.edu/ml//machine-learning-databases/00544/,https://archive.ics.uci.edu/ml/datasets/Estimation+of+obesity+levels+based+on+eating+habits+and+physical+condition+,"This dataset include data for the estimation of obesity levels in individuals from the countries of Mexico, Peru and Colombia, based on their eating habits and physical condition. The data contains 17 attributes and 2111 records, the records are labeled with the class variable NObesity (Obesity Level), that allows classification of the data using the values of Insufficient Weight, Normal Weight, Overweight Level I, Overweight Level II, Obesity Type I, Obesity Type II and Obesity Type III. 77% of the data was generated synthetically using the Weka tool and the SMOTE filter, 23% of the data was collected directly from users through a web platform.",Life,Read the article ([Web Link]) to see the description of the attributes.,"This dataset include data for the estimation of obesity levels in individuals from the countries of Mexico, Peru and Colombia, based on their eating habits and physical condition. This dataset include data for the estimation of obesity levels in individuals from the countries of Mexico, Peru and Colombia, based on their eating habits and physical condition. The data contains 17 attributes and 2111 records, the records are labeled with the class variable NObesity (Obesity Level), that allows classification of the data using the values of Insufficient Weight, Normal Weight, Overweight Level I, Overweight Level II, Obesity Type I, Obesity Type II and Obesity Type III. 77% of the data was generated synthetically using the Weka tool and the SMOTE filter, 23% of the data was collected directly from users through a web platform.Read the article ([Web Link]) to see the description of the attributes."
MicroMass,MicroMass,A dataset to explore machine learning approaches for the identification of microorganisms from mass-spectrometry data.,MicroMass,https://archive.ics.uci.edu/ml//machine-learning-databases/00253/,https://archive.ics.uci.edu/ml/datasets/MicroMass,"This MALDI-TOF dataset consists in:A) A reference panel of 20 Gram positive and negative bacterial species covering 9 genera among which several species are known to be hard to discriminate by mass spectrometry (MALDI-TOF). Each species was represented by 11 to 60 mass spectra obtained from 7 to 20 bacterial strains, constituting altogether a dataset of 571 spectra obtained from 213 strains. The spectra were obtained according to the standard culture-based workflow used in clinical routine in which the microorganism was first grown on an agar plate for 24 to 48 hours, before a portion of colony was picked, spotted on a MALDI slide and a mass spectrum was acquired. B) Based on this reference panel, a dedicated in vitro mock-up mixture dataset was constituted. For that purpose we considered 10 pairs of species of various taxonomic proximity:   * 4 mixtures, labelled A, B, C and D, involved species that belong to the same genus,   * 2 mixtures, labelled E and F, involved species that belong to distinct genera, but to the same Gram type,   * 4 mixtures, labelled G, H, I and J, involved species that belong to distinct Gram types.Each mixture was represented by 2 pairs of strains, which were mixed according to the following 9 concentration ratios : 1:0, 10:1, 5:1, 2:1, 1:1, 1:2, 1:5, 1:10, 0:1. Two replicate spectra were acquired for each concentration ratio and each couple of strains, leading altogether to a dataset of 360 spectra, among which 80 are actually pure sample spectra.",Life,Provide information about each attribute in your data set.,"A dataset to explore machine learning approaches for the identification of microorganisms from mass-spectrometry data.This MALDI-TOF dataset consists in:A) A reference panel of 20 Gram positive and negative bacterial species covering 9 genera among which several species are known to be hard to discriminate by mass spectrometry (MALDI-TOF). Each species was represented by 11 to 60 mass spectra obtained from 7 to 20 bacterial strains, constituting altogether a dataset of 571 spectra obtained from 213 strains. The spectra were obtained according to the standard culture-based workflow used in clinical routine in which the microorganism was first grown on an agar plate for 24 to 48 hours, before a portion of colony was picked, spotted on a MALDI slide and a mass spectrum was acquired. B) Based on this reference panel, a dedicated in vitro mock-up mixture dataset was constituted. For that purpose we considered 10 pairs of species of various taxonomic proximity:   * 4 mixtures, labelled A, B, C and D, involved species that belong to the same genus,   * 2 mixtures, labelled E and F, involved species that belong to distinct genera, but to the same Gram type,   * 4 mixtures, labelled G, H, I and J, involved species that belong to distinct Gram types.Each mixture was represented by 2 pairs of strains, which were mixed according to the following 9 concentration ratios : 1:0, 10:1, 5:1, 2:1, 1:1, 1:2, 1:5, 1:10, 0:1. Two replicate spectra were acquired for each concentration ratio and each couple of strains, leading altogether to a dataset of 360 spectra, among which 80 are actually pure sample spectra.Provide information about each attribute in your data set."
Lymphography,Lymphography,"This lymphography domain was obtained from the University Medical Centre, Institute of Oncology, Ljubljana, Yugoslavia.  (Restricted access)",Lymphography,https://archive.ics.uci.edu/ml//machine-learning-databases/lymphography/,https://archive.ics.uci.edu/ml/datasets/Lymphography,This is one of three domains provided by the Oncology Institute that has repeatedly appeared in the machine learning literature. (See also breast-cancer and primary-tumor.),Life,"--- NOTE: All attribute values in the database have been entered as numeric values corresponding to their index in the list of attribute values for that attribute domain as given below.    1. class: normal find, metastases, malign lymph, fibrosis    2. lymphatics: normal, arched, deformed, displaced    3. block of affere: no, yes    4. bl. of lymph. c: no, yes    5. bl. of lymph. s: no, yes    6. by pass: no, yes    7. extravasates: no, yes    8. regeneration of: no, yes    9. early uptake in: no, yes   10. lym.nodes dimin: 0-3   11. lym.nodes enlar: 1-4   12. changes in lym.: bean, oval, round   13. defect in node: no, lacunar, lac. marginal, lac. central   14. changes in node: no, lacunar, lac. margin, lac. central   15. changes in stru: no, grainy, drop-like, coarse, diluted, reticular, stripped, faint,    16. special forms: no, chalices, vesicles   17. dislocation of: no, yes   18. exclusion of no: no, yes   19. no. of nodes in: 0-9, 10-19, 20-29, 30-39, 40-49, 50-59, 60-69, >=70","This lymphography domain was obtained from the University Medical Centre, Institute of Oncology, Ljubljana, Yugoslavia.  (Restricted access)This is one of three domains provided by the Oncology Institute that has repeatedly appeared in the machine learning literature. (See also breast-cancer and primary-tumor.)--- NOTE: All attribute values in the database have been entered as numeric values corresponding to their index in the list of attribute values for that attribute domain as given below.    1. class: normal find, metastases, malign lymph, fibrosis    2. lymphatics: normal, arched, deformed, displaced    3. block of affere: no, yes    4. bl. of lymph. c: no, yes    5. bl. of lymph. s: no, yes    6. by pass: no, yes    7. extravasates: no, yes    8. regeneration of: no, yes    9. early uptake in: no, yes   10. lym.nodes dimin: 0-3   11. lym.nodes enlar: 1-4   12. changes in lym.: bean, oval, round   13. defect in node: no, lacunar, lac. marginal, lac. central   14. changes in node: no, lacunar, lac. margin, lac. central   15. changes in stru: no, grainy, drop-like, coarse, diluted, reticular, stripped, faint,    16. special forms: no, chalices, vesicles   17. dislocation of: no, yes   18. exclusion of no: no, yes   19. no. of nodes in: 0-9, 10-19, 20-29, 30-39, 40-49, 50-59, 60-69, >=70"
Lung Cancer,Lung Cancer,Lung cancer data; no attribute definitions,Lung+Cancer,https://archive.ics.uci.edu/ml//machine-learning-databases/lung-cancer/,https://archive.ics.uci.edu/ml/datasets/Lung+Cancer,"This data was used by Hong and Young to illustrate the power of the optimal discriminant plane even in ill-posed settings. Applying the KNN method in the resulting plane gave 77% accuracy. However, these results are strongly biased (See Aeberhard's second ref. above, or email to stefan '@' coral.cs.jcu.edu.au). Results obtained by Aeberhard et al. are : RDA : 62.5%, KNN 53.1%, Opt. Disc. Plane 59.4%The data described 3 types of pathological lung cancers. The Authors give no information on the individual variables nor on where the data was originally used.Notes:-  In the original data 4 values for the fifth attribute were -1. These values have been changed to ? (unknown). (*)-  In the original data 1 value for the 39 attribute was 4.  This value has been changed to ? (unknown). (*)",Life,"Attribute 1 is the class label.All predictive attributes are nominal, taking on integer values 0-3","Lung cancer data; no attribute definitionsThis data was used by Hong and Young to illustrate the power of the optimal discriminant plane even in ill-posed settings. Applying the KNN method in the resulting plane gave 77% accuracy. However, these results are strongly biased (See Aeberhard's second ref. above, or email to stefan '@' coral.cs.jcu.edu.au). Results obtained by Aeberhard et al. are : RDA : 62.5%, KNN 53.1%, Opt. Disc. Plane 59.4%The data described 3 types of pathological lung cancers. The Authors give no information on the individual variables nor on where the data was originally used.Notes:-  In the original data 4 values for the fifth attribute were -1. These values have been changed to ? (unknown). (*)-  In the original data 1 value for the 39 attribute was 4.  This value has been changed to ? (unknown). (*)Attribute 1 is the class label.All predictive attributes are nominal, taking on integer values 0-3"
Z-Alizadeh Sani,Z-Alizadeh Sani,It was collected for CAD diagnosis.,Z-Alizadeh+Sani,https://archive.ics.uci.edu/ml//machine-learning-databases/00412/,https://archive.ics.uci.edu/ml/datasets/Z-Alizadeh+Sani,"Each patient could be in two possible categories CAD or Normal. A patient is categorized as CAD, if his/her diameter narrowing is greater than or equal to 50%, and otherwise as Normal .",Life,"The Z-Alizadeh Sani dataset contains the records of 303 patients, each of which have 54 features.The features are arranged in four groups: demographic, symptom and examination, ECG, and laboratory and echo features.","It was collected for CAD diagnosis.Each patient could be in two possible categories CAD or Normal. A patient is categorized as CAD, if his/her diameter narrowing is greater than or equal to 50%, and otherwise as Normal .The Z-Alizadeh Sani dataset contains the records of 303 patients, each of which have 54 features.The features are arranged in four groups: demographic, symptom and examination, ECG, and laboratory and echo features."
HCV data,HCV data,The data set contains laboratory values of blood donors and Hepatitis C patients and demographic values like age.,HCV+data,https://archive.ics.uci.edu/ml//machine-learning-databases/00571/,https://archive.ics.uci.edu/ml/datasets/HCV+data,"The target attribute for classification is Category (blood donors vs. Hepatitis C (including its progress ('just' Hepatitis C, Fibrosis, Cirrhosis).",Life,"All attributes except Category and Sex are numerical. The laboratory data are the attributes 5-14. 	 1) X (Patient ID/No.)	 2) Category (diagnosis) (values: '0=Blood Donor', '0s=suspect Blood Donor', '1=Hepatitis', '2=Fibrosis', '3=Cirrhosis')	 3) Age (in years)	 4) Sex (f,m)	 5) ALB	 6) ALP	 7) ALT	 8) AST	 9) BIL	10) CHE	11) CHOL	12) CREA	13) GGT	14) PROT","The data set contains laboratory values of blood donors and Hepatitis C patients and demographic values like age.The target attribute for classification is Category (blood donors vs. Hepatitis C (including its progress ('just' Hepatitis C, Fibrosis, Cirrhosis).All attributes except Category and Sex are numerical. The laboratory data are the attributes 5-14. 	 1) X (Patient ID/No.)	 2) Category (diagnosis) (values: '0=Blood Donor', '0s=suspect Blood Donor', '1=Hepatitis', '2=Fibrosis', '3=Cirrhosis')	 3) Age (in years)	 4) Sex (f,m)	 5) ALB	 6) ALP	 7) ALT	 8) AST	 9) BIL	10) CHE	11) CHOL	12) CREA	13) GGT	14) PROT"
Diabetes 130-US hospitals for years 1999-2008,Diabetes 130-US hospitals for years 1999-2008,"This data has been prepared to analyze factors related to readmission as well as other 

outcomes pertaining to patients with diabetes.",Diabetes+130-US+hospitals+for+years+1999-2008,https://archive.ics.uci.edu/ml//machine-learning-databases/00296/,https://archive.ics.uci.edu/ml/datasets/Diabetes+130-US+hospitals+for+years+1999-2008,"The dataset represents 10 years (1999-2008) of clinical care at 130 US hospitals and integrated delivery networks. It includes over 50 features representing patient and hospital outcomes. Information was extracted from the database for encounters that satisfied the following criteria.(1)	It is an inpatient encounter (a hospital admission).(2)	It is a diabetic encounter, that is, one during which any kind of diabetes was entered to the system as a diagnosis.(3)	The length of stay was at least 1 day and at most 14 days.(4)	Laboratory tests were performed during the encounter.(5)	Medications were administered during the encounter.The data contains such attributes as patient number, race, gender, age, admission type, time in hospital, medical specialty of admitting physician, number of lab test performed, HbA1c test result, diagnosis, number of medication, diabetic medications, number of outpatient, inpatient, and emergency visits in the year before the hospitalization, etc.",Life,"Detailed description of all the atrributes is provided in Table 1 Beata Strack, Jonathan P. DeShazo, Chris Gennings,  Juan L. Olmo, Sebastian Ventura,  Krzysztof J. Cios, and John N. Clore, â€œImpact of HbA1c Measurement on Hospital Readmission Rates: Analysis of 70,000 Clinical Database Patient Records,â€� BioMed Research International, vol. 2014, Article ID 781670, 11 pages, 2014.[Web Link]","This data has been prepared to analyze factors related to readmission as well as other 

outcomes pertaining to patients with diabetes.The dataset represents 10 years (1999-2008) of clinical care at 130 US hospitals and integrated delivery networks. It includes over 50 features representing patient and hospital outcomes. Information was extracted from the database for encounters that satisfied the following criteria.(1)	It is an inpatient encounter (a hospital admission).(2)	It is a diabetic encounter, that is, one during which any kind of diabetes was entered to the system as a diagnosis.(3)	The length of stay was at least 1 day and at most 14 days.(4)	Laboratory tests were performed during the encounter.(5)	Medications were administered during the encounter.The data contains such attributes as patient number, race, gender, age, admission type, time in hospital, medical specialty of admitting physician, number of lab test performed, HbA1c test result, diagnosis, number of medication, diabetic medications, number of outpatient, inpatient, and emergency visits in the year before the hospitalization, etc.Detailed description of all the atrributes is provided in Table 1 Beata Strack, Jonathan P. DeShazo, Chris Gennings,  Juan L. Olmo, Sebastian Ventura,  Krzysztof J. Cios, and John N. Clore, â€œImpact of HbA1c Measurement on Hospital Readmission Rates: Analysis of 70,000 Clinical Database Patient Records,â€� BioMed Research International, vol. 2014, Article ID 781670, 11 pages, 2014.[Web Link]"
KEGG Metabolic Relation Network (Directed),KEGG Metabolic Relation Network (Directed),KEGG Metabolic pathways modeled as directed relation network. Variety of graphical features presented.,KEGG+Metabolic+Relation+Network+%28Directed%29,https://archive.ics.uci.edu/ml//machine-learning-databases/00220/,https://archive.ics.uci.edu/ml/datasets/KEGG+Metabolic+Relation+Network+%28Directed%29,"KEGG Metabolic pathways can be realized into network. Two kinds of network / graph can be formed. These include Reaction Network and Relation Network. In Reaction network, Substrate or Product compound are considered as Node and genes are treated as edge. Whereas in the relation network, Substrate and Product componds are considered as Edges while enzyme and genes are placed as nodes. We tool large number of metabolic pathways from KEGG XML. They were modeled into the graph as described above. With the help of Cytoscape tool, variety of network features were compunted. ",Life,"a)	Pathway	textb)	Nodes 	integer (min:2, max:116)c)	Edges		integer (min:1, max:606)d)	Connected Components	integer (min:1, max:13)e)	Network Diameter		integer (min:1, max:30)f)	Network Radius	integer (min:1, max:2)g)	Shortest Path	integer (min:1, max:3277)h)	Characteristic Path Length	real (min:1, [Web Link])i)	Avg.num.Neighbours	real (min:1, [Web Link])j)	Isolated Nodes	integer (min:0, max:1)k)	Number of Self Loops	integer (min:0, max:0)l)	Multi-edge Node Pair	integer (min:0, max:57)m)	NeighborhoodConnectivity	real (min:1, [Web Link])n)	Outdegree	real (min:0.5, [Web Link])o)	Stress	real (min:0, [Web Link])p)	SelfLoops	integer (min:0, max:0)q)	PartnerOfMultiEdgedNodePairs	real (min:0, [Web Link])r)	EdgeCount	real (min:1, [Web Link])s)	BetweennessCentrality		real (min:0, [Web Link])t)	Indegree		real (min:0.5, [Web Link])u)	Eccentricity	real ([Web Link], [Web Link])v)	ClosenessCentrality	real ([Web Link], max:1)w)	AverageShortestPathLength	real ([Web Link], [Web Link])x)	ClusteringCoefficient		real (min:0, [Web Link])","KEGG Metabolic pathways modeled as directed relation network. Variety of graphical features presented.KEGG Metabolic pathways can be realized into network. Two kinds of network / graph can be formed. These include Reaction Network and Relation Network. In Reaction network, Substrate or Product compound are considered as Node and genes are treated as edge. Whereas in the relation network, Substrate and Product componds are considered as Edges while enzyme and genes are placed as nodes. We tool large number of metabolic pathways from KEGG XML. They were modeled into the graph as described above. With the help of Cytoscape tool, variety of network features were compunted. a)	Pathway	textb)	Nodes 	integer (min:2, max:116)c)	Edges		integer (min:1, max:606)d)	Connected Components	integer (min:1, max:13)e)	Network Diameter		integer (min:1, max:30)f)	Network Radius	integer (min:1, max:2)g)	Shortest Path	integer (min:1, max:3277)h)	Characteristic Path Length	real (min:1, [Web Link])i)	Avg.num.Neighbours	real (min:1, [Web Link])j)	Isolated Nodes	integer (min:0, max:1)k)	Number of Self Loops	integer (min:0, max:0)l)	Multi-edge Node Pair	integer (min:0, max:57)m)	NeighborhoodConnectivity	real (min:1, [Web Link])n)	Outdegree	real (min:0.5, [Web Link])o)	Stress	real (min:0, [Web Link])p)	SelfLoops	integer (min:0, max:0)q)	PartnerOfMultiEdgedNodePairs	real (min:0, [Web Link])r)	EdgeCount	real (min:1, [Web Link])s)	BetweennessCentrality		real (min:0, [Web Link])t)	Indegree		real (min:0.5, [Web Link])u)	Eccentricity	real ([Web Link], [Web Link])v)	ClosenessCentrality	real ([Web Link], max:1)w)	AverageShortestPathLength	real ([Web Link], [Web Link])x)	ClusteringCoefficient		real (min:0, [Web Link])"
EMG data for gestures,EMG data for gestures,These are files of raw EMG data recorded by MYO Thalmic bracelet,EMG+data+for+gestures,https://archive.ics.uci.edu/ml//machine-learning-databases/00481/,https://archive.ics.uci.edu/ml/datasets/EMG+data+for+gestures,"For recording patterns, we used a MYO Thalmic bracelet worn on a userÃ¢â‚¬â„¢s forearm, and a PC with a Bluetooth receiver. The bracelet is equipped with eight sensors equally spaced around the forearm that simultaneously acquire myographic signals. The signals are sent through a Bluetooth interface to a PC. We present raw EMG data for 36 subjects while they performed series of static hand gestures.The subject performs two series, each of which consists of six (seven) basic gestures. Each gesture was performed for 3 seconds with a pause of 3 seconds between gestures.Number of Instances is about 40000-50000 recordings in each column (30000 listed as guaranteed)",Life,"Description of raw_data _*** fileEach file consist of 10 columns:1) Time - time in ms;2-9) Channel - eightEMG channels of MYO Thalmic bracelet;10) Class  Ã¢â‚¬â€œthelabel of gestures: 0 - unmarked data,1 - hand at rest, 2 - hand clenched in a fist, 3 - wrist flexion,4 Ã¢â‚¬â€œ wrist extension,5 Ã¢â‚¬â€œ radial deviations,6 - ulnar deviations,7 - extended palm (the gesture was not performed by all subjects).","These are files of raw EMG data recorded by MYO Thalmic braceletFor recording patterns, we used a MYO Thalmic bracelet worn on a userÃ¢â‚¬â„¢s forearm, and a PC with a Bluetooth receiver. The bracelet is equipped with eight sensors equally spaced around the forearm that simultaneously acquire myographic signals. The signals are sent through a Bluetooth interface to a PC. We present raw EMG data for 36 subjects while they performed series of static hand gestures.The subject performs two series, each of which consists of six (seven) basic gestures. Each gesture was performed for 3 seconds with a pause of 3 seconds between gestures.Number of Instances is about 40000-50000 recordings in each column (30000 listed as guaranteed)Description of raw_data _*** fileEach file consist of 10 columns:1) Time - time in ms;2-9) Channel - eightEMG channels of MYO Thalmic bracelet;10) Class  Ã¢â‚¬â€œthelabel of gestures: 0 - unmarked data,1 - hand at rest, 2 - hand clenched in a fist, 3 - wrist flexion,4 Ã¢â‚¬â€œ wrist extension,5 Ã¢â‚¬â€œ radial deviations,6 - ulnar deviations,7 - extended palm (the gesture was not performed by all subjects)."
KEGG Metabolic Reaction Network (Undirected),KEGG Metabolic Reaction Network (Undirected),KEGG Metabolic pathways modeled as un-directed reaction network. Variety of graphical features presented.,KEGG+Metabolic+Reaction+Network+%28Undirected%29,https://archive.ics.uci.edu/ml//machine-learning-databases/00221/,https://archive.ics.uci.edu/ml/datasets/KEGG+Metabolic+Reaction+Network+%28Undirected%29,"KEGG Metabolic pathways can be realized into network. Two kinds of network / graph can be formed. These include Reaction Network and Relation Network. In Reaction network, Substrate or Product compound are considered as Node and genes are treated as edge. Whereas in the relation network, Substrate and Product componds are considered as Edges while enzyme and genes are placed as nodes. We tool large number of metabolic pathways from KEGG XML. They were modeled into the graph as described above. With the help of Cytoscape tool, variety of network features were compunted. ",Life,"a)	Pathway	text b)	Connected Components	Integer (min:1, max:39 )c)	Diameter	Integer (min:1, max:46 )d)	Radius	Integer (min:1, max:13 )e)	Centralization	Integer (min:0, max:1 )f)	Shortest Path	Integer (min:2, max:23420 )g)	Characteristic Path Length	Integer (min:1, [Web Link] )h)	Avg.num.Neighbours	real ([Web Link], [Web Link])i)	Density	real ([Web Link], max:1)j)	Heterogeneity	real (min:0, [Web Link])k)	Isolated Nodes	Integer (min:0, max:3)l)	Number of Self Loops	Integer (min:0, max:4)m)	Multi-edge Node Pair	Integer (min:0, max:220)n)	NeighborhoodConnectivity	real ([Web Link], [Web Link])o)	NumberOfDirectedEdges		real ([Web Link], [Web Link])p)	Stress		real (min:0, [Web Link])q)	SelfLoops		real (min:0, [Web Link])r)	Partner Of MultiEdged NodePairs		Integer (min:0, max:3)s)	Degree		real (min:1, [Web Link])t)	TopologicalCoefficient	real (min:0, max:1)u)	BetweennessCentrality		real (min:0, [Web Link])v)	Radiality		real ([Web Link], max:30744573457 )w)	Eccentricity	real ([Web Link], [Web Link])x)	NumberOfUndirectedEdges	real (min:0, [Web Link])y)	ClosenessCentrality	real ([Web Link], max:1)z)	AverageShortestPathLength	real ([Web Link], [Web Link] )aa)	ClusteringCoefficient		real (min:0, max:1)bb)	nodeCount		Integer (min:2, max:232)cc)	edgeCount	Integer (min:1, max:444)","KEGG Metabolic pathways modeled as un-directed reaction network. Variety of graphical features presented.KEGG Metabolic pathways can be realized into network. Two kinds of network / graph can be formed. These include Reaction Network and Relation Network. In Reaction network, Substrate or Product compound are considered as Node and genes are treated as edge. Whereas in the relation network, Substrate and Product componds are considered as Edges while enzyme and genes are placed as nodes. We tool large number of metabolic pathways from KEGG XML. They were modeled into the graph as described above. With the help of Cytoscape tool, variety of network features were compunted. a)	Pathway	text b)	Connected Components	Integer (min:1, max:39 )c)	Diameter	Integer (min:1, max:46 )d)	Radius	Integer (min:1, max:13 )e)	Centralization	Integer (min:0, max:1 )f)	Shortest Path	Integer (min:2, max:23420 )g)	Characteristic Path Length	Integer (min:1, [Web Link] )h)	Avg.num.Neighbours	real ([Web Link], [Web Link])i)	Density	real ([Web Link], max:1)j)	Heterogeneity	real (min:0, [Web Link])k)	Isolated Nodes	Integer (min:0, max:3)l)	Number of Self Loops	Integer (min:0, max:4)m)	Multi-edge Node Pair	Integer (min:0, max:220)n)	NeighborhoodConnectivity	real ([Web Link], [Web Link])o)	NumberOfDirectedEdges		real ([Web Link], [Web Link])p)	Stress		real (min:0, [Web Link])q)	SelfLoops		real (min:0, [Web Link])r)	Partner Of MultiEdged NodePairs		Integer (min:0, max:3)s)	Degree		real (min:1, [Web Link])t)	TopologicalCoefficient	real (min:0, max:1)u)	BetweennessCentrality		real (min:0, [Web Link])v)	Radiality		real ([Web Link], max:30744573457 )w)	Eccentricity	real ([Web Link], [Web Link])x)	NumberOfUndirectedEdges	real (min:0, [Web Link])y)	ClosenessCentrality	real ([Web Link], max:1)z)	AverageShortestPathLength	real ([Web Link], [Web Link] )aa)	ClusteringCoefficient		real (min:0, max:1)bb)	nodeCount		Integer (min:2, max:232)cc)	edgeCount	Integer (min:1, max:444)"
Diabetic Retinopathy Debrecen Data Set,Diabetic Retinopathy Debrecen Data Set,This dataset contains features extracted from the Messidor image set to predict whether an image contains signs of diabetic retinopathy or not. ,Diabetic+Retinopathy+Debrecen+Data+Set,https://archive.ics.uci.edu/ml//machine-learning-databases/00329/,https://archive.ics.uci.edu/ml/datasets/Diabetic+Retinopathy+Debrecen+Data+Set,"This dataset contains features extracted from the Messidor image set to predict whether an image contains signs of diabetic retinopathy or not. All features represent either a detected lesion, a descriptive feature of a anatomical part or an image-level descriptor. The underlying method image analysis and feature extraction as well as our classification technique is described in Balint Antal, Andras Hajdu: An ensemble-based system for automatic screening of diabetic retinopathy, Knowledge-Based Systems 60 (April 2014), 20-27. The image set (Messidor) is available at [Web Link].",Life,"0) The binary result of quality assessment. 0 = bad quality 1 = sufficient quality.1) The binary result of pre-screening, where 1 indicates severe retinal abnormality and 0 its lack.2-7) The results of MA detection. Each feature value stand for thenumber of MAs found at the confidence levels alpha = 0.5, . . . , 1, respectively.8-15) contain the same information as 2-7) for exudates. However,as exudates are represented by a set of points rather than the number ofpixels constructing the lesions, these features are normalized by dividing thenumber of lesions with the diameter of the ROI to compensate different imagesizes.16) The euclidean distance of the center ofthe macula and the center of the optic disc to provide important informationregarding the patientÃ¢â‚¬â„¢s condition. This featureis also normalized with the diameter of the ROI.17) The diameter of the optic disc.18) The binary result of the AM/FM-based classification.19) Class label. 1 = contains signs of DR (Accumulative label for the Messidor classes 1, 2, 3), 0 = no signs of DR.","This dataset contains features extracted from the Messidor image set to predict whether an image contains signs of diabetic retinopathy or not. This dataset contains features extracted from the Messidor image set to predict whether an image contains signs of diabetic retinopathy or not. All features represent either a detected lesion, a descriptive feature of a anatomical part or an image-level descriptor. The underlying method image analysis and feature extraction as well as our classification technique is described in Balint Antal, Andras Hajdu: An ensemble-based system for automatic screening of diabetic retinopathy, Knowledge-Based Systems 60 (April 2014), 20-27. The image set (Messidor) is available at [Web Link].0) The binary result of quality assessment. 0 = bad quality 1 = sufficient quality.1) The binary result of pre-screening, where 1 indicates severe retinal abnormality and 0 its lack.2-7) The results of MA detection. Each feature value stand for thenumber of MAs found at the confidence levels alpha = 0.5, . . . , 1, respectively.8-15) contain the same information as 2-7) for exudates. However,as exudates are represented by a set of points rather than the number ofpixels constructing the lesions, these features are normalized by dividing thenumber of lesions with the diameter of the ROI to compensate different imagesizes.16) The euclidean distance of the center ofthe macula and the center of the optic disc to provide important informationregarding the patientÃ¢â‚¬â„¢s condition. This featureis also normalized with the diameter of the ROI.17) The diameter of the optic disc.18) The binary result of the AM/FM-based classification.19) Class label. 1 = contains signs of DR (Accumulative label for the Messidor classes 1, 2, 3), 0 = no signs of DR."
KASANDR,KASANDR,"KASANDR is a novel, publicly available collection for recommendation systems that records the behavior of customers of the European leader in e-Commerce advertising, Kelkoo. ",KASANDR,https://archive.ics.uci.edu/ml//machine-learning-databases/00385/,https://archive.ics.uci.edu/ml/datasets/KASANDR,We created this data by sampling and processing the www.kelkoo.com logs. The data records offers which were clicked (or shown) to the users of the www.kelkoo.com (and partners) in Germany as well as meta-information of these users and offers and the objective is to predict if a given user will click on a given offer.,Life,"userid offerid countrycode category merchant utcdate implicit-feedback1. train_de.csv (3,14 GB)Instances: 15,844,718Attributes: 2,299,713userid: Categorical, 291,485offerid: Categorical, 2,158,859countrycode: Categorical, 1 (de - Germany)category: Integer, 271merchant: Integer, 703utcdate: Timestamp, 2016-06-01 02:00:17.0 to 2016-06-14 23:52:51.0implicit feedback (click): Binary, 0 or 12. test_de.csv (381,3 MB)Instances: 1,919,562Attributes: 2,299,713userid: Categorical, 278,293offerid: Categorical, 380,803countrycode: Categorical, 1category: Integer, 267merchant: Integer, 738utcdate: Timestamp, 2016-06-14 23:52:51.0 to 2016-07-01 01:59:36.0implicit feedback (click): Binary, 0 or 1","KASANDR is a novel, publicly available collection for recommendation systems that records the behavior of customers of the European leader in e-Commerce advertising, Kelkoo. We created this data by sampling and processing the www.kelkoo.com logs. The data records offers which were clicked (or shown) to the users of the www.kelkoo.com (and partners) in Germany as well as meta-information of these users and offers and the objective is to predict if a given user will click on a given offer.userid offerid countrycode category merchant utcdate implicit-feedback1. train_de.csv (3,14 GB)Instances: 15,844,718Attributes: 2,299,713userid: Categorical, 291,485offerid: Categorical, 2,158,859countrycode: Categorical, 1 (de - Germany)category: Integer, 271merchant: Integer, 703utcdate: Timestamp, 2016-06-01 02:00:17.0 to 2016-06-14 23:52:51.0implicit feedback (click): Binary, 0 or 12. test_de.csv (381,3 MB)Instances: 1,919,562Attributes: 2,299,713userid: Categorical, 278,293offerid: Categorical, 380,803countrycode: Categorical, 1category: Integer, 267merchant: Integer, 738utcdate: Timestamp, 2016-06-14 23:52:51.0 to 2016-07-01 01:59:36.0implicit feedback (click): Binary, 0 or 1"
Divorce Predictors data set,Divorce Predictors data set,Participants completed the Personal Information Form and Divorce Predictors Scale. ,Divorce+Predictors+data+set,https://archive.ics.uci.edu/ml//machine-learning-databases/00497/,https://archive.ics.uci.edu/ml/datasets/Divorce+Predictors+data+set,Provide all relevant information about your data set.,Life,"1. If one of us apologizes when our discussion deteriorates, the discussion ends.2. I know we can ignore our differences, even if things get hard sometimes.3. When we need it, we can take our discussions with my spouse from the beginning and correct it.4. When I discuss with my spouse, to contact him will eventually work.5. The time I spent with my wife is special for us.6. We don't have time at home as partners.7. We are like two strangers who share the same environment at home rather than family.8. I enjoy our holidays with my wife.9. I enjoy traveling with my wife.10. Most of our goals are common to my spouse.11. I think that one day in the future, when I look back, I see that my spouse and I have been in harmony with each other.12. My spouse and I have similar values in terms of personal freedom.13. My spouse and I have similar sense of entertainment.14. Most of our goals for people (children, friends, etc.) are the same.15. Our dreams with my spouse are similar and harmonious.16. We're compatible with my spouse about what love should be.17. We share the same views about being happy in our life with my spouse18. My spouse and I have similar ideas about how marriage should be19. My spouse and I have similar ideas about how roles should be in marriage20. My spouse and I have similar values in trust.21. I know exactly what my wife likes.22. I know how my spouse wants to be taken care of when she/he sick.23. I know my spouse's favorite food.24. I can tell you what kind of stress my spouse is facing in her/his life.25. I have knowledge of my spouse's inner world.26. I know my spouse's basic anxieties. 27. I know what my spouse's current sources of stress are.28. I know my spouse's hopes and wishes.29. I know my spouse very well.30. I know my spouse's friends and their social relationships.31. I feel aggressive when I argue with my spouse.32. When discussing with my spouse, I usually use expressions such as â€˜you alwaysâ€™ or â€˜you neverâ€™ .33. I can use negative statements about my spouse's personality during our discussions.34. I can use offensive expressions during our discussions.35. I can insult my spouse during our discussions.36. I can be humiliating when we discussions.37. My discussion with my spouse is not calm.38. I hate my spouse's way of open a subject.39. Our discussions often occur suddenly.40. We're just starting a discussion before I know what's going on.41. When I talk to my spouse about something, my calm suddenly breaks.42. When I argue with my spouse, Ä± only go out and I don't say a word.43. I mostly stay silent to calm the environment a little bit.44. Sometimes I think it's good for me to leave home for a while.45. I'd rather stay silent than discuss with my spouse.46. Even if I'm right in the discussion, I stay silent to hurt my spouse.47. When I discuss with my spouse, I stay silent because I am afraid of not being able to control my anger.48. I feel right in our discussions.49. I have nothing to do with what I've been accused of.50. I'm not actually the one who's guilty about what I'm accused of.51. I'm not the one who's wrong about problems at home.52. I wouldn't hesitate to tell my spouse about her/his inadequacy.53. When I discuss, I remind my spouse of her/his inadequacy.54. I'm not afraid to tell my spouse about her/his incompetence.","Participants completed the Personal Information Form and Divorce Predictors Scale. Provide all relevant information about your data set.1. If one of us apologizes when our discussion deteriorates, the discussion ends.2. I know we can ignore our differences, even if things get hard sometimes.3. When we need it, we can take our discussions with my spouse from the beginning and correct it.4. When I discuss with my spouse, to contact him will eventually work.5. The time I spent with my wife is special for us.6. We don't have time at home as partners.7. We are like two strangers who share the same environment at home rather than family.8. I enjoy our holidays with my wife.9. I enjoy traveling with my wife.10. Most of our goals are common to my spouse.11. I think that one day in the future, when I look back, I see that my spouse and I have been in harmony with each other.12. My spouse and I have similar values in terms of personal freedom.13. My spouse and I have similar sense of entertainment.14. Most of our goals for people (children, friends, etc.) are the same.15. Our dreams with my spouse are similar and harmonious.16. We're compatible with my spouse about what love should be.17. We share the same views about being happy in our life with my spouse18. My spouse and I have similar ideas about how marriage should be19. My spouse and I have similar ideas about how roles should be in marriage20. My spouse and I have similar values in trust.21. I know exactly what my wife likes.22. I know how my spouse wants to be taken care of when she/he sick.23. I know my spouse's favorite food.24. I can tell you what kind of stress my spouse is facing in her/his life.25. I have knowledge of my spouse's inner world.26. I know my spouse's basic anxieties. 27. I know what my spouse's current sources of stress are.28. I know my spouse's hopes and wishes.29. I know my spouse very well.30. I know my spouse's friends and their social relationships.31. I feel aggressive when I argue with my spouse.32. When discussing with my spouse, I usually use expressions such as â€˜you alwaysâ€™ or â€˜you neverâ€™ .33. I can use negative statements about my spouse's personality during our discussions.34. I can use offensive expressions during our discussions.35. I can insult my spouse during our discussions.36. I can be humiliating when we discussions.37. My discussion with my spouse is not calm.38. I hate my spouse's way of open a subject.39. Our discussions often occur suddenly.40. We're just starting a discussion before I know what's going on.41. When I talk to my spouse about something, my calm suddenly breaks.42. When I argue with my spouse, Ä± only go out and I don't say a word.43. I mostly stay silent to calm the environment a little bit.44. Sometimes I think it's good for me to leave home for a while.45. I'd rather stay silent than discuss with my spouse.46. Even if I'm right in the discussion, I stay silent to hurt my spouse.47. When I discuss with my spouse, I stay silent because I am afraid of not being able to control my anger.48. I feel right in our discussions.49. I have nothing to do with what I've been accused of.50. I'm not actually the one who's guilty about what I'm accused of.51. I'm not the one who's wrong about problems at home.52. I wouldn't hesitate to tell my spouse about her/his inadequacy.53. When I discuss, I remind my spouse of her/his inadequacy.54. I'm not afraid to tell my spouse about her/his incompetence."
gene expression cancer RNA-Seq,gene expression cancer RNA-Seq,"This collection of data is part of the RNA-Seq (HiSeq) PANCAN data set, it is a random extraction of gene expressions of patients having different types of tumor: BRCA, KIRC, COAD, LUAD and PRAD.",gene+expression+cancer+RNA-Seq,https://archive.ics.uci.edu/ml//machine-learning-databases/00401/,https://archive.ics.uci.edu/ml/datasets/gene+expression+cancer+RNA-Seq,Samples (instances) are stored row-wise. Variables (attributes) of each sample are RNA-Seq gene expression levels measured by illumina HiSeq platform.,Life,"A dummy name (gene_XX) is given to each attribute. Check the original submission ([Web Link]#!Synapse:syn4301332), or the platform specs for the complete list of probes name. The attributes are ordered consitently with the original submission.","This collection of data is part of the RNA-Seq (HiSeq) PANCAN data set, it is a random extraction of gene expressions of patients having different types of tumor: BRCA, KIRC, COAD, LUAD and PRAD.Samples (instances) are stored row-wise. Variables (attributes) of each sample are RNA-Seq gene expression levels measured by illumina HiSeq platform.A dummy name (gene_XX) is given to each attribute. Check the original submission ([Web Link]#!Synapse:syn4301332), or the platform specs for the complete list of probes name. The attributes are ordered consitently with the original submission."
Liver Disorders,Liver Disorders,BUPA Medical Research Ltd. database donated by Richard S. Forsyth,Liver+Disorders,https://archive.ics.uci.edu/ml//machine-learning-databases/liver-disorders/,https://archive.ics.uci.edu/ml/datasets/Liver+Disorders,"The first 5 variables are all blood tests which are thought to be sensitive to liver disorders that might arise from excessive alcohol consumption. Each line in the dataset constitutes the record of a single male individual.Important note: The 7th field (selector) has been widely misinterpreted in the past as a dependent variable representing presence or absence of a liver disorder. This is incorrect [1]. The 7th field was created by BUPA researchers as a train/test selector. It is not suitable as a dependent variable for classification. The dataset does not contain any variable representing presence or absence of a liver disorder. Researchers who wish to use this dataset as a classification benchmark should follow the method used in experiments by the donor (Forsyth & Rada, 1986, Machine learning: applications in expert systems and information retrieval) and others (e.g. Turney, 1995, Cost-sensitive classification: Empirical evaluation of a hybrid genetic decision tree induction algorithm), who used the 6th field (drinks), after dichotomising, as a dependent variable for classification. Because of widespread misinterpretation in the past, researchers should take care to state their method clearly.",Life,1. mcv mean corpuscular volume2. alkphos alkaline phosphotase3. sgpt alanine aminotransferase4. sgot aspartate aminotransferase5. gammagt gamma-glutamyl transpeptidase6. drinks number of half-pint equivalents of alcoholic beverages drunk per day7. selector field created by the BUPA researchers to split the data into train/test sets,"BUPA Medical Research Ltd. database donated by Richard S. ForsythThe first 5 variables are all blood tests which are thought to be sensitive to liver disorders that might arise from excessive alcohol consumption. Each line in the dataset constitutes the record of a single male individual.Important note: The 7th field (selector) has been widely misinterpreted in the past as a dependent variable representing presence or absence of a liver disorder. This is incorrect [1]. The 7th field was created by BUPA researchers as a train/test selector. It is not suitable as a dependent variable for classification. The dataset does not contain any variable representing presence or absence of a liver disorder. Researchers who wish to use this dataset as a classification benchmark should follow the method used in experiments by the donor (Forsyth & Rada, 1986, Machine learning: applications in expert systems and information retrieval) and others (e.g. Turney, 1995, Cost-sensitive classification: Empirical evaluation of a hybrid genetic decision tree induction algorithm), who used the 6th field (drinks), after dichotomising, as a dependent variable for classification. Because of widespread misinterpretation in the past, researchers should take care to state their method clearly.1. mcv mean corpuscular volume2. alkphos alkaline phosphotase3. sgpt alanine aminotransferase4. sgot aspartate aminotransferase5. gammagt gamma-glutamyl transpeptidase6. drinks number of half-pint equivalents of alcoholic beverages drunk per day7. selector field created by the BUPA researchers to split the data into train/test sets"
Iris,Iris,"Famous database; from Fisher, 1936",Iris,https://archive.ics.uci.edu/ml//machine-learning-databases/iris/,https://archive.ics.uci.edu/ml/datasets/Iris,"This is perhaps the best known database to be found in the pattern recognition literature.  Fisher's paper is a classic in the field and is referenced frequently to this day.  (See Duda & Hart, for example.)  The data set contains 3 classes of 50 instances each, where each class refers to a type of iris plant.  One class is linearly separable from the other 2; the latter are NOT linearly separable from each other.Predicted attribute: class of iris plant.This is an exceedingly simple domain.This data differs from the data presented in Fishers article (identified by Steve Chadwick,  spchadwick '@' espeedaz.net ).  The 35th sample should be: 4.9,3.1,1.5,0.2,""Iris-setosa"" where the error is in the fourth feature. The 38th sample: 4.9,3.6,1.4,0.1,""Iris-setosa"" where the errors are in the second and third features.  ",Life,   1. sepal length in cm   2. sepal width in cm   3. petal length in cm   4. petal width in cm   5. class:       -- Iris Setosa      -- Iris Versicolour      -- Iris Virginica,"Famous database; from Fisher, 1936This is perhaps the best known database to be found in the pattern recognition literature.  Fisher's paper is a classic in the field and is referenced frequently to this day.  (See Duda & Hart, for example.)  The data set contains 3 classes of 50 instances each, where each class refers to a type of iris plant.  One class is linearly separable from the other 2; the latter are NOT linearly separable from each other.Predicted attribute: class of iris plant.This is an exceedingly simple domain.This data differs from the data presented in Fishers article (identified by Steve Chadwick,  spchadwick '@' espeedaz.net ).  The 35th sample should be: 4.9,3.1,1.5,0.2,""Iris-setosa"" where the error is in the fourth feature. The 38th sample: 4.9,3.6,1.4,0.1,""Iris-setosa"" where the errors are in the second and third features.     1. sepal length in cm   2. sepal width in cm   3. petal length in cm   4. petal width in cm   5. class:       -- Iris Setosa      -- Iris Versicolour      -- Iris Virginica"
Localization Data for Person Activity,Localization Data for Person Activity,Data contains recordings of five people performing different activities. Each person wore four sensors (tags) while performing the same scenario five times. ,Localization+Data+for+Person+Activity,https://archive.ics.uci.edu/ml//machine-learning-databases/00196/,https://archive.ics.uci.edu/ml/datasets/Localization+Data+for+Person+Activity,"People used for recording of the data were wearing four tags (ankle left, ankle right, belt and chest). Each instance is a localization data for one of the tags. The tag can be identified by one of the attributes.",Life,"Instance example: A01,020-000-033-111,633790226057226795,27.05.2009 14:03:25:723,4.292500972747803,2.0738532543182373,1.36650812625885,walking   1) Sequence Name {A01,A02,A03,A04,A05,B01,B02,B03,B04,B05,C01,C02,C03,C04,C05,D01,D02,D03,D04,D05,E01,E02,E03,E04,E05} (Nominal)      - A, B, C, D, E  = 5 people   2) Tag identificator {010-000-024-033,020-000-033-111,020-000-032-221,010-000-030-096}	(Nominal)      - ANKLE_LEFT = 010-000-024-033      - ANKLE_RIGHT = 010-000-030-096      - CHEST = 020-000-033-111      - BELT = 020-000-032-221   3) timestamp (Numeric) all unique   4) date FORMAT = dd.MM.yyyy HH:mm:ss:SSS (Date)    5) x coordinate of the tag (Numeric)   6) y coordinate of the tag (Numeric)   7) z coordinate of the tag (Numeric)   8) activity  {walking,falling,'lying down',lying,'sitting down',sitting,'standing up from lying','on all fours','sitting on the ground','standing up from sitting','standing up from sitting on the ground'} (Nominal)  ","Data contains recordings of five people performing different activities. Each person wore four sensors (tags) while performing the same scenario five times. People used for recording of the data were wearing four tags (ankle left, ankle right, belt and chest). Each instance is a localization data for one of the tags. The tag can be identified by one of the attributes.Instance example: A01,020-000-033-111,633790226057226795,27.05.2009 14:03:25:723,4.292500972747803,2.0738532543182373,1.36650812625885,walking   1) Sequence Name {A01,A02,A03,A04,A05,B01,B02,B03,B04,B05,C01,C02,C03,C04,C05,D01,D02,D03,D04,D05,E01,E02,E03,E04,E05} (Nominal)      - A, B, C, D, E  = 5 people   2) Tag identificator {010-000-024-033,020-000-033-111,020-000-032-221,010-000-030-096}	(Nominal)      - ANKLE_LEFT = 010-000-024-033      - ANKLE_RIGHT = 010-000-030-096      - CHEST = 020-000-033-111      - BELT = 020-000-032-221   3) timestamp (Numeric) all unique   4) date FORMAT = dd.MM.yyyy HH:mm:ss:SSS (Date)    5) x coordinate of the tag (Numeric)   6) y coordinate of the tag (Numeric)   7) z coordinate of the tag (Numeric)   8) activity  {walking,falling,'lying down',lying,'sitting down',sitting,'standing up from lying','on all fours','sitting on the ground','standing up from sitting','standing up from sitting on the ground'} (Nominal)  "
Dorothea,Dorothea,DOROTHEA is a drug discovery dataset. Chemical compounds represented by structural molecular features must be classified as active (binding to thrombin) or inactive. This is one of 5 datasets of the NIPS 2003 feature selection challenge.,Dorothea,https://archive.ics.uci.edu/ml//machine-learning-databases/dorothea/,https://archive.ics.uci.edu/ml/datasets/Dorothea,"Drugs are typically small organic molecules that achieve their desired activity by binding to a target site on a receptor. The first step in the discovery of a new drug is usually to identify and isolate the receptor to which it should bind, followed by testing many small molecules for their ability to bind to the target site. This leaves researchers with the task of determining what separates the active (binding) compounds from the inactive (non-binding) ones. Such a determination can then be used in the design of new compounds that not only bind, but also have all the other properties required for a drug (solubility, oral absorption, lack of side effects, appropriate duration of action, toxicity, etc.). The original data were modified for the purpose of the feature selection challenge. In particular, we added a number of distractor feature called 'probes' having no predictive power. The order of the features and patterns were randomized. DOROTHEA -- Positive ex. -- Negative ex. -- Total		   Training set -- 78 -- 722 -- 800		   Validation set -- 34 -- 316 -- 350		   Test set -- 78 -- 722 -- 800		   All -- 190 -- 1760 -- 1950		 We mapped Active compounds to the target value +1 (positive examples) and Inactive compounds to the target value â€“1 (negative examples). Number of variables/features/attributes:Real: 50000Probes: 50000Total: 100000	 This dataset is one of five datasets used in the NIPS 2003 feature selection challenge. Our website [Web Link] is still open for post-challenge submissions. Information about other related challenges are found at: [Web Link]. The CLOP package includes sample code to process these data: [Web Link].All details about the preparation of the data are found in our technical report: Design of experiments for the NIPS 2003 variable selection benchmark, Isabelle Guyon, July 2003, [Web Link] (also included in the dataset archive). Such information was made available only after the end of the challenge.The data are split into training, validation, and test set. Target values are provided only for the 2 first sets. Test set performance results are obtained by submitting prediction results to: [Web Link].The data are in the following format:dataname.param: Parameters and statistics about the datadataname.feat: Identities of the features (withheld, to avoid biasing feature selection).dataname_train.data: Training set (a sparse binary matrix, patterns in lines, features in columns: the number of the non-zero features are provided).  dataname_valid.data: Validation set.    dataname_test.data: Test set. dataname_train.labels: Labels (truth values of the classes) for training examples.   dataname_valid.labels: Validation set labels (withheld during the benchmark, but provided now).dataname_test.labels: Test set labels  (withheld, so the data can still be use as a benchmark).",Life,We do not provide attribute information to avoid biasing feature selection.,"DOROTHEA is a drug discovery dataset. Chemical compounds represented by structural molecular features must be classified as active (binding to thrombin) or inactive. This is one of 5 datasets of the NIPS 2003 feature selection challenge.Drugs are typically small organic molecules that achieve their desired activity by binding to a target site on a receptor. The first step in the discovery of a new drug is usually to identify and isolate the receptor to which it should bind, followed by testing many small molecules for their ability to bind to the target site. This leaves researchers with the task of determining what separates the active (binding) compounds from the inactive (non-binding) ones. Such a determination can then be used in the design of new compounds that not only bind, but also have all the other properties required for a drug (solubility, oral absorption, lack of side effects, appropriate duration of action, toxicity, etc.). The original data were modified for the purpose of the feature selection challenge. In particular, we added a number of distractor feature called 'probes' having no predictive power. The order of the features and patterns were randomized. DOROTHEA -- Positive ex. -- Negative ex. -- Total		   Training set -- 78 -- 722 -- 800		   Validation set -- 34 -- 316 -- 350		   Test set -- 78 -- 722 -- 800		   All -- 190 -- 1760 -- 1950		 We mapped Active compounds to the target value +1 (positive examples) and Inactive compounds to the target value â€“1 (negative examples). Number of variables/features/attributes:Real: 50000Probes: 50000Total: 100000	 This dataset is one of five datasets used in the NIPS 2003 feature selection challenge. Our website [Web Link] is still open for post-challenge submissions. Information about other related challenges are found at: [Web Link]. The CLOP package includes sample code to process these data: [Web Link].All details about the preparation of the data are found in our technical report: Design of experiments for the NIPS 2003 variable selection benchmark, Isabelle Guyon, July 2003, [Web Link] (also included in the dataset archive). Such information was made available only after the end of the challenge.The data are split into training, validation, and test set. Target values are provided only for the 2 first sets. Test set performance results are obtained by submitting prediction results to: [Web Link].The data are in the following format:dataname.param: Parameters and statistics about the datadataname.feat: Identities of the features (withheld, to avoid biasing feature selection).dataname_train.data: Training set (a sparse binary matrix, patterns in lines, features in columns: the number of the non-zero features are provided).  dataname_valid.data: Validation set.    dataname_test.data: Test set. dataname_train.labels: Labels (truth values of the classes) for training examples.   dataname_valid.labels: Validation set labels (withheld during the benchmark, but provided now).dataname_test.labels: Test set labels  (withheld, so the data can still be use as a benchmark).We do not provide attribute information to avoid biasing feature selection."
LSVT Voice Rehabilitation,LSVT Voice Rehabilitation,"126 samples from 14 participants, 309 features. Aim: assess whether voice rehabilitation treatment lead to phonations considered 'acceptable' or 'unacceptable' (binary class classification problem).",LSVT+Voice+Rehabilitation,https://archive.ics.uci.edu/ml//machine-learning-databases/00282/,https://archive.ics.uci.edu/ml/datasets/LSVT+Voice+Rehabilitation,"The original paper demonstrated that it is possible to correctly replicate the experts' binary assessment with approximately 90% accuracy using both 10-fold cross-validation and leave-one-subject-out validation. We experimented with both random forests and support vector machines, using standard approaches for optimizing the SVM's hyperparameters. It will be interesting if researchers can improve on this finding using advanced machine learning tools.Details for the dataset can be found on the following paper.A. Tsanas, M.A. Little, C. Fox, L.O. Ramig: Ã¢â‚¬Å“Objective automatic assessment of rehabilitative speech treatment in ParkinsonÃ¢â‚¬â„¢s diseaseÃ¢â‚¬Â�, IEEE Transactions on Neural Systems and Rehabilitation Engineering, Vol. 22, pp. 181-190, January 2014A freely available preprint is availabe from the first author's website.",Life,"Each attribute (feature) corresponds to the application of a speech signal processing algorithm which aims to characterise objectively the signal. These algorithms include standard perturbation analysis methods, wavelet-based features, fundamental frequency-based features, and tools used to mine nonlinear time-series. Because of the extensive number of attributes we refer the interested readers to the relevant papers for further details.","126 samples from 14 participants, 309 features. Aim: assess whether voice rehabilitation treatment lead to phonations considered 'acceptable' or 'unacceptable' (binary class classification problem).The original paper demonstrated that it is possible to correctly replicate the experts' binary assessment with approximately 90% accuracy using both 10-fold cross-validation and leave-one-subject-out validation. We experimented with both random forests and support vector machines, using standard approaches for optimizing the SVM's hyperparameters. It will be interesting if researchers can improve on this finding using advanced machine learning tools.Details for the dataset can be found on the following paper.A. Tsanas, M.A. Little, C. Fox, L.O. Ramig: Ã¢â‚¬Å“Objective automatic assessment of rehabilitative speech treatment in ParkinsonÃ¢â‚¬â„¢s diseaseÃ¢â‚¬Â�, IEEE Transactions on Neural Systems and Rehabilitation Engineering, Vol. 22, pp. 181-190, January 2014A freely available preprint is availabe from the first author's website.Each attribute (feature) corresponds to the application of a speech signal processing algorithm which aims to characterise objectively the signal. These algorithms include standard perturbation analysis methods, wavelet-based features, fundamental frequency-based features, and tools used to mine nonlinear time-series. Because of the extensive number of attributes we refer the interested readers to the relevant papers for further details."
Epileptic Seizure Recognition,Epileptic Seizure Recognition,This dataset is a pre-processed and re-structured/reshaped version of a very commonly used dataset featuring epileptic seizure detection. ,Epileptic+Seizure+Recognition,https://archive.ics.uci.edu/ml//machine-learning-databases/00388/,https://archive.ics.uci.edu/ml/datasets/Epileptic+Seizure+Recognition,The version of the dataset hosted by our repository has been removed.Please find the original data at '[Web Link]',Life,"The original dataset from the reference consists of 5 different folders, each with 100 files, with each file representing a single subject/person. Each file is a recording of brain activity for 23.6 seconds. The corresponding time-series is sampled into 4097 data points. Each data point is the value of the EEG recording at a different point in time. So we have total 500 individuals with each has 4097 data points for 23.5 seconds.We divided and shuffled every 4097 data points into 23 chunks, each chunk contains 178 data points for 1 second, and each data point is the value of the EEG recording at a different point in time. So now we have 23 x 500 = 11500 pieces of information(row), each information contains 178 data points for 1 second(column), the last column represents the label y {1,2,3,4,5}. The response variable is y in column 179, the Explanatory variables X1, X2, ..., X178 y contains the category of the 178-dimensional input vector. Specifically y in {1, 2, 3, 4, 5}: 5 - eyes open, means when they were recording the EEG signal of the brain the patient had their eyes open 4 - eyes closed, means when they were recording the EEG signal the patient had their eyes closed 3 - Yes they identify where the region of the tumor was in the brain and recording the EEG activity from the healthy brain area 2 - They recorder the EEG from the area where the tumor was located 1 - Recording of seizure activity All subjects falling in classes 2, 3, 4, and 5 are subjects who did not have epileptic seizure. Only subjects in class 1 have epileptic seizure. Our motivation for creating this version of the data was to simplify access to the data via the creation of a .csv version of it. Although there are 5 classes most authors have done binary classification, namely class 1 (Epileptic seizure) against the rest.","This dataset is a pre-processed and re-structured/reshaped version of a very commonly used dataset featuring epileptic seizure detection. The version of the dataset hosted by our repository has been removed.Please find the original data at '[Web Link]'The original dataset from the reference consists of 5 different folders, each with 100 files, with each file representing a single subject/person. Each file is a recording of brain activity for 23.6 seconds. The corresponding time-series is sampled into 4097 data points. Each data point is the value of the EEG recording at a different point in time. So we have total 500 individuals with each has 4097 data points for 23.5 seconds.We divided and shuffled every 4097 data points into 23 chunks, each chunk contains 178 data points for 1 second, and each data point is the value of the EEG recording at a different point in time. So now we have 23 x 500 = 11500 pieces of information(row), each information contains 178 data points for 1 second(column), the last column represents the label y {1,2,3,4,5}. The response variable is y in column 179, the Explanatory variables X1, X2, ..., X178 y contains the category of the 178-dimensional input vector. Specifically y in {1, 2, 3, 4, 5}: 5 - eyes open, means when they were recording the EEG signal of the brain the patient had their eyes open 4 - eyes closed, means when they were recording the EEG signal the patient had their eyes closed 3 - Yes they identify where the region of the tumor was in the brain and recording the EEG activity from the healthy brain area 2 - They recorder the EEG from the area where the tumor was located 1 - Recording of seizure activity All subjects falling in classes 2, 3, 4, and 5 are subjects who did not have epileptic seizure. Only subjects in class 1 have epileptic seizure. Our motivation for creating this version of the data was to simplify access to the data via the creation of a .csv version of it. Although there are 5 classes most authors have done binary classification, namely class 1 (Epileptic seizure) against the rest."
Hungarian Chickenpox Cases,Hungarian Chickenpox Cases,A spatio-temporal dataset of weekly chickenpox cases from Hungary. The dataset consists of a county-level adjacency matrix and time series of the county-level reported cases between 2005 and 2015.,Hungarian+Chickenpox+Cases,https://archive.ics.uci.edu/ml//machine-learning-databases/00580/,https://archive.ics.uci.edu/ml/datasets/Hungarian+Chickenpox+Cases, A spatio-temporal dataset of weekly chickenpox (childhood disease) cases from Hungary. The dataset consists of a county-level adjacency matrix and time series of the county-level reported cases between 2005 and 2015. There are 2 specific related tasks: County level case count prediction and nation level case count prediction.,Life,Attributes are weekly counts of chickenpox cases in Hungarian counties.,A spatio-temporal dataset of weekly chickenpox cases from Hungary. The dataset consists of a county-level adjacency matrix and time series of the county-level reported cases between 2005 and 2015. A spatio-temporal dataset of weekly chickenpox (childhood disease) cases from Hungary. The dataset consists of a county-level adjacency matrix and time series of the county-level reported cases between 2005 and 2015. There are 2 specific related tasks: County level case count prediction and nation level case count prediction.Attributes are weekly counts of chickenpox cases in Hungarian counties.
ICU,ICU,Data set prepared for the use of participants for the 1994 AAAI Spring Symposium on Artificial Intelligence in Medicine.,ICU,https://archive.ics.uci.edu/ml//machine-learning-databases/icu/,https://archive.ics.uci.edu/ml/datasets/ICU,Please see documentation,Life,,Data set prepared for the use of participants for the 1994 AAAI Spring Symposium on Artificial Intelligence in Medicine.Please see documentationnan
Forest type mapping,Forest type mapping,Multi-temporal remote sensing data of a forested area in Japan. The goal is to map different forest types using spectral data.,Forest+type+mapping,https://archive.ics.uci.edu/ml//machine-learning-databases/00333/,https://archive.ics.uci.edu/ml/datasets/Forest+type+mapping,"This data set contains training and testing data from a remote sensing study which mapped different forest types based on their spectral characteristics at visible-to-near infrared wavelengths, using ASTER satellite imagery. The output (forest type map) can be used to identify and/or quantify the ecosystem services (e.g. carbon storage, erosion protection) provided by the forest.",Life,"Class: 's' ('Sugi' forest), 'h' ('Hinoki' forest), 'd' ('Mixed deciduous' forest), 'o' ('Other' non-forest land)b1 - b9: ASTER image bands containing spectral information in the green, red, and near infrared wavelengths for three dates (Sept. 26, 2010; March 19, 2011; May 08, 2011.pred_minus_obs_S_b1 - pred_minus_obs_S_b9: Predicted spectral values (based on spatial interpolation) minus actual spectral values for the 's' class (b1-b9).pred_minus_obs_H_b1 - pred_minus_obs_H_b9: Predicted spectral values (based on spatial interpolation) minus actual spectral values for the 'h' class (b1-b9).","Multi-temporal remote sensing data of a forested area in Japan. The goal is to map different forest types using spectral data.This data set contains training and testing data from a remote sensing study which mapped different forest types based on their spectral characteristics at visible-to-near infrared wavelengths, using ASTER satellite imagery. The output (forest type map) can be used to identify and/or quantify the ecosystem services (e.g. carbon storage, erosion protection) provided by the forest.Class: 's' ('Sugi' forest), 'h' ('Hinoki' forest), 'd' ('Mixed deciduous' forest), 'o' ('Other' non-forest land)b1 - b9: ASTER image bands containing spectral information in the green, red, and near infrared wavelengths for three dates (Sept. 26, 2010; March 19, 2011; May 08, 2011.pred_minus_obs_S_b1 - pred_minus_obs_S_b9: Predicted spectral values (based on spatial interpolation) minus actual spectral values for the 's' class (b1-b9).pred_minus_obs_H_b1 - pred_minus_obs_H_b9: Predicted spectral values (based on spatial interpolation) minus actual spectral values for the 'h' class (b1-b9)."
Echocardiogram,Echocardiogram,Data for classifying if patients will survive for at least one year after a heart attack,Echocardiogram,https://archive.ics.uci.edu/ml//machine-learning-databases/echocardiogram/,https://archive.ics.uci.edu/ml/datasets/Echocardiogram,"All the patients suffered heart attacks at some point in the past. Some are still alive and some are not.  The survival and still-alive variables, when taken together, indicate whether a patient survived for at least one year following the heart attack.  The problem addressed by past researchers was to predict from the other variables whether or not the patient will survive at least one year.  The most difficult part of this problem is correctly predicting that the patient will NOT survive.  (Part of the difficulty seems to be the size of the data set.)",Life,"   1. survival -- the number of months patient survived (has survived, if patient is still alive).  Because all the patients had their heart attacks at different times, it is possible that some patients have survived less than one year but they are still alive.  Check the second variable to confirm this.  Such patients cannot be used for the prediction task mentioned above.   2. still-alive -- a binary variable.  0=dead at end of survival period, 1 means still alive    3. age-at-heart-attack -- age in years when heart attack occurred   4. pericardial-effusion -- binary. Pericardial effusion is fluid around the heart.  0=no fluid, 1=fluid   5. fractional-shortening -- a measure of contracility around the heart lower numbers are increasingly abnormal   6. epss -- E-point septal separation, another measure of contractility.  Larger numbers are increasingly abnormal.   7. lvdd -- left ventricular end-diastolic dimension.  This is a measure of the size of the heart at end-diastole. Large hearts tend to be sick hearts.   8. wall-motion-score -- a measure of how the segments of the left ventricle are moving   9. wall-motion-index -- equals wall-motion-score divided by number of segments seen.  Usually 12-13 segments are seen in an echocardiogram.  Use this variable INSTEAD of the wall motion score.   10. mult -- a derivate var which can be ignored   11. name -- the name of the patient (I have replaced them with ""name"")   12. group -- meaningless, ignore it   13. alive-at-1 -- Boolean-valued. Derived from the first two attributes. 0 means patient was either dead after 1 year or had been followed for less than 1 year.  1 means patient was alive at 1 year.","Data for classifying if patients will survive for at least one year after a heart attackAll the patients suffered heart attacks at some point in the past. Some are still alive and some are not.  The survival and still-alive variables, when taken together, indicate whether a patient survived for at least one year following the heart attack.  The problem addressed by past researchers was to predict from the other variables whether or not the patient will survive at least one year.  The most difficult part of this problem is correctly predicting that the patient will NOT survive.  (Part of the difficulty seems to be the size of the data set.)   1. survival -- the number of months patient survived (has survived, if patient is still alive).  Because all the patients had their heart attacks at different times, it is possible that some patients have survived less than one year but they are still alive.  Check the second variable to confirm this.  Such patients cannot be used for the prediction task mentioned above.   2. still-alive -- a binary variable.  0=dead at end of survival period, 1 means still alive    3. age-at-heart-attack -- age in years when heart attack occurred   4. pericardial-effusion -- binary. Pericardial effusion is fluid around the heart.  0=no fluid, 1=fluid   5. fractional-shortening -- a measure of contracility around the heart lower numbers are increasingly abnormal   6. epss -- E-point septal separation, another measure of contractility.  Larger numbers are increasingly abnormal.   7. lvdd -- left ventricular end-diastolic dimension.  This is a measure of the size of the heart at end-diastole. Large hearts tend to be sick hearts.   8. wall-motion-score -- a measure of how the segments of the left ventricle are moving   9. wall-motion-index -- equals wall-motion-score divided by number of segments seen.  Usually 12-13 segments are seen in an echocardiogram.  Use this variable INSTEAD of the wall motion score.   10. mult -- a derivate var which can be ignored   11. name -- the name of the patient (I have replaced them with ""name"")   12. group -- meaningless, ignore it   13. alive-at-1 -- Boolean-valued. Derived from the first two attributes. 0 means patient was either dead after 1 year or had been followed for less than 1 year.  1 means patient was alive at 1 year."
Heart Disease,Heart Disease,"4 databases: Cleveland, Hungary, Switzerland, and the VA Long Beach",Heart+Disease,https://archive.ics.uci.edu/ml//machine-learning-databases/heart-disease/,https://archive.ics.uci.edu/ml/datasets/Heart+Disease,"This database contains 76 attributes, but all published experiments refer to using a subset of 14 of them.  In particular, the Cleveland database is the only one that has been used by ML researchers to this date.  The ""goal"" field refers to the presence of heart disease in the patient.  It is integer valued from 0 (no presence) to 4. Experiments with the Cleveland database have concentrated on simply attempting to distinguish presence (values 1,2,3,4) from absence (value 0).     The names and social security numbers of the patients were recently removed from the database, replaced with dummy values.One file has been ""processed"", that one containing the Cleveland database.  All four unprocessed files also exist in this directory.To see Test Costs (donated by Peter Turney), please see the folder ""Costs"" ",Life,"Only 14 attributes used:      1. #3  (age)             2. #4  (sex)             3. #9  (cp)              4. #10 (trestbps)        5. #12 (chol)            6. #16 (fbs)             7. #19 (restecg)         8. #32 (thalach)         9. #38 (exang)           10. #40 (oldpeak)         11. #41 (slope)           12. #44 (ca)              13. #51 (thal)            14. #58 (num)       (the predicted attribute)Complete attribute documentation:      1 id: patient identification number      2 ccf: social security number (I replaced this with a dummy value of 0)      3 age: age in years      4 sex: sex (1 = male; 0 = female)      5 painloc: chest pain location (1 = substernal; 0 = otherwise)      6 painexer (1 = provoked by exertion; 0 = otherwise)      7 relrest (1 = relieved after rest; 0 = otherwise)      8 pncaden (sum of 5, 6, and 7)      9 cp: chest pain type        -- Value 1: typical angina        -- Value 2: atypical angina        -- Value 3: non-anginal pain        -- Value 4: asymptomatic     10 trestbps: resting blood pressure (in mm Hg on admission to the hospital)     11 htn     12 chol: serum cholestoral in mg/dl     13 smoke: I believe this is 1 = yes; 0 = no (is or is not a smoker)     14 cigs (cigarettes per day)     15 years (number of years as a smoker)     16 fbs: (fasting blood sugar > 120 mg/dl)  (1 = true; 0 = false)     17 dm (1 = history of diabetes; 0 = no such history)     18 famhist: family history of coronary artery disease (1 = yes; 0 = no)     19 restecg: resting electrocardiographic results        -- Value 0: normal        -- Value 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV)        -- Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria     20 ekgmo (month of exercise ECG reading)     21 ekgday(day of exercise ECG reading)     22 ekgyr (year of exercise ECG reading)     23 dig (digitalis used furing exercise ECG: 1 = yes; 0 = no)     24 prop (Beta blocker used during exercise ECG: 1 = yes; 0 = no)     25 nitr (nitrates used during exercise ECG: 1 = yes; 0 = no)     26 pro (calcium channel blocker used during exercise ECG: 1 = yes; 0 = no)     27 diuretic (diuretic used used during exercise ECG: 1 = yes; 0 = no)     28 proto: exercise protocol          1 = Bruce               2 = Kottus          3 = McHenry          4 = fast Balke          5 = Balke          6 = Noughton           7 = bike 150 kpa min/min  (Not sure if ""kpa min/min"" is what was written!)          8 = bike 125 kpa min/min            9 = bike 100 kpa min/min         10 = bike 75 kpa min/min         11 = bike 50 kpa min/min         12 = arm ergometer     29 thaldur: duration of exercise test in minutes     30 thaltime: time when ST measure depression was noted     31 met: mets achieved     32 thalach: maximum heart rate achieved     33 thalrest: resting heart rate     34 tpeakbps: peak exercise blood pressure (first of 2 parts)     35 tpeakbpd: peak exercise blood pressure (second of 2 parts)     36 dummy     37 trestbpd: resting blood pressure     38 exang: exercise induced angina (1 = yes; 0 = no)     39 xhypo: (1 = yes; 0 = no)     40 oldpeak = ST depression induced by exercise relative to rest     41 slope: the slope of the peak exercise ST segment        -- Value 1: upsloping        -- Value 2: flat        -- Value 3: downsloping     42 rldv5: height at rest     43 rldv5e: height at peak exercise     44 ca: number of major vessels (0-3) colored by flourosopy     45 restckm: irrelevant     46 exerckm: irrelevant     47 restef: rest raidonuclid (sp?) ejection fraction     48 restwm: rest wall (sp?) motion abnormality        0 = none        1 = mild or moderate        2 = moderate or severe        3 = akinesis or dyskmem (sp?)     49 exeref: exercise radinalid (sp?) ejection fraction     50 exerwm: exercise wall (sp?) motion      51 thal: 3 = normal; 6 = fixed defect; 7 = reversable defect     52 thalsev: not used     53 thalpul: not used     54 earlobe: not used     55 cmo: month of cardiac cath (sp?)  (perhaps ""call"")     56 cday: day of cardiac cath (sp?)     57 cyr: year of cardiac cath (sp?)     58 num: diagnosis of heart disease (angiographic disease status)        -- Value 0: < 50% diameter narrowing        -- Value 1: > 50% diameter narrowing        (in any major vessel: attributes 59 through 68 are vessels)     59 lmt     60 ladprox     61 laddist     62 diag     63 cxmain     64 ramus     65 om1     66 om2     67 rcaprox     68 rcadist     69 lvx1: not used     70 lvx2: not used     71 lvx3: not used     72 lvx4: not used     73 lvf: not used     74 cathef: not used     75 junk: not used     76 name: last name of patient  (I replaced this with the dummy string ""name"")","4 databases: Cleveland, Hungary, Switzerland, and the VA Long BeachThis database contains 76 attributes, but all published experiments refer to using a subset of 14 of them.  In particular, the Cleveland database is the only one that has been used by ML researchers to this date.  The ""goal"" field refers to the presence of heart disease in the patient.  It is integer valued from 0 (no presence) to 4. Experiments with the Cleveland database have concentrated on simply attempting to distinguish presence (values 1,2,3,4) from absence (value 0).     The names and social security numbers of the patients were recently removed from the database, replaced with dummy values.One file has been ""processed"", that one containing the Cleveland database.  All four unprocessed files also exist in this directory.To see Test Costs (donated by Peter Turney), please see the folder ""Costs"" Only 14 attributes used:      1. #3  (age)             2. #4  (sex)             3. #9  (cp)              4. #10 (trestbps)        5. #12 (chol)            6. #16 (fbs)             7. #19 (restecg)         8. #32 (thalach)         9. #38 (exang)           10. #40 (oldpeak)         11. #41 (slope)           12. #44 (ca)              13. #51 (thal)            14. #58 (num)       (the predicted attribute)Complete attribute documentation:      1 id: patient identification number      2 ccf: social security number (I replaced this with a dummy value of 0)      3 age: age in years      4 sex: sex (1 = male; 0 = female)      5 painloc: chest pain location (1 = substernal; 0 = otherwise)      6 painexer (1 = provoked by exertion; 0 = otherwise)      7 relrest (1 = relieved after rest; 0 = otherwise)      8 pncaden (sum of 5, 6, and 7)      9 cp: chest pain type        -- Value 1: typical angina        -- Value 2: atypical angina        -- Value 3: non-anginal pain        -- Value 4: asymptomatic     10 trestbps: resting blood pressure (in mm Hg on admission to the hospital)     11 htn     12 chol: serum cholestoral in mg/dl     13 smoke: I believe this is 1 = yes; 0 = no (is or is not a smoker)     14 cigs (cigarettes per day)     15 years (number of years as a smoker)     16 fbs: (fasting blood sugar > 120 mg/dl)  (1 = true; 0 = false)     17 dm (1 = history of diabetes; 0 = no such history)     18 famhist: family history of coronary artery disease (1 = yes; 0 = no)     19 restecg: resting electrocardiographic results        -- Value 0: normal        -- Value 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV)        -- Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria     20 ekgmo (month of exercise ECG reading)     21 ekgday(day of exercise ECG reading)     22 ekgyr (year of exercise ECG reading)     23 dig (digitalis used furing exercise ECG: 1 = yes; 0 = no)     24 prop (Beta blocker used during exercise ECG: 1 = yes; 0 = no)     25 nitr (nitrates used during exercise ECG: 1 = yes; 0 = no)     26 pro (calcium channel blocker used during exercise ECG: 1 = yes; 0 = no)     27 diuretic (diuretic used used during exercise ECG: 1 = yes; 0 = no)     28 proto: exercise protocol          1 = Bruce               2 = Kottus          3 = McHenry          4 = fast Balke          5 = Balke          6 = Noughton           7 = bike 150 kpa min/min  (Not sure if ""kpa min/min"" is what was written!)          8 = bike 125 kpa min/min            9 = bike 100 kpa min/min         10 = bike 75 kpa min/min         11 = bike 50 kpa min/min         12 = arm ergometer     29 thaldur: duration of exercise test in minutes     30 thaltime: time when ST measure depression was noted     31 met: mets achieved     32 thalach: maximum heart rate achieved     33 thalrest: resting heart rate     34 tpeakbps: peak exercise blood pressure (first of 2 parts)     35 tpeakbpd: peak exercise blood pressure (second of 2 parts)     36 dummy     37 trestbpd: resting blood pressure     38 exang: exercise induced angina (1 = yes; 0 = no)     39 xhypo: (1 = yes; 0 = no)     40 oldpeak = ST depression induced by exercise relative to rest     41 slope: the slope of the peak exercise ST segment        -- Value 1: upsloping        -- Value 2: flat        -- Value 3: downsloping     42 rldv5: height at rest     43 rldv5e: height at peak exercise     44 ca: number of major vessels (0-3) colored by flourosopy     45 restckm: irrelevant     46 exerckm: irrelevant     47 restef: rest raidonuclid (sp?) ejection fraction     48 restwm: rest wall (sp?) motion abnormality        0 = none        1 = mild or moderate        2 = moderate or severe        3 = akinesis or dyskmem (sp?)     49 exeref: exercise radinalid (sp?) ejection fraction     50 exerwm: exercise wall (sp?) motion      51 thal: 3 = normal; 6 = fixed defect; 7 = reversable defect     52 thalsev: not used     53 thalpul: not used     54 earlobe: not used     55 cmo: month of cardiac cath (sp?)  (perhaps ""call"")     56 cday: day of cardiac cath (sp?)     57 cyr: year of cardiac cath (sp?)     58 num: diagnosis of heart disease (angiographic disease status)        -- Value 0: < 50% diameter narrowing        -- Value 1: > 50% diameter narrowing        (in any major vessel: attributes 59 through 68 are vessels)     59 lmt     60 ladprox     61 laddist     62 diag     63 cxmain     64 ramus     65 om1     66 om2     67 rcaprox     68 rcadist     69 lvx1: not used     70 lvx2: not used     71 lvx3: not used     72 lvx4: not used     73 lvf: not used     74 cathef: not used     75 junk: not used     76 name: last name of patient  (I replaced this with the dummy string ""name"")"
Haberman's Survival,Haberman's Survival,Dataset contains cases from study conducted on the survival of patients who had undergone surgery for breast cancer,Haberman%27s+Survival,https://archive.ics.uci.edu/ml//machine-learning-databases/haberman/,https://archive.ics.uci.edu/ml/datasets/Haberman%27s+Survival,The dataset contains cases from a study that was conducted between 1958 and 1970 at the University of Chicago's Billings Hospital on the survival of patients who had undergone surgery for breast cancer.,Life,"   1. Age of patient at time of operation (numerical)   2. Patient's year of operation (year - 1900, numerical)   3. Number of positive axillary nodes detected (numerical)   4. Survival status (class attribute)        -- 1 = the patient survived 5 years or longer        -- 2 = the patient died within 5 year","Dataset contains cases from study conducted on the survival of patients who had undergone surgery for breast cancerThe dataset contains cases from a study that was conducted between 1958 and 1970 at the University of Chicago's Billings Hospital on the survival of patients who had undergone surgery for breast cancer.   1. Age of patient at time of operation (numerical)   2. Patient's year of operation (year - 1900, numerical)   3. Number of positive axillary nodes detected (numerical)   4. Survival status (class attribute)        -- 1 = the patient survived 5 years or longer        -- 2 = the patient died within 5 year"
Heart failure clinical records,Heart failure clinical records,"This dataset contains the medical records of 299 patients who had heart failure, collected during their follow-up period, where each patient profile has 13 clinical features.",Heart+failure+clinical+records,https://archive.ics.uci.edu/ml//machine-learning-databases/00519/,https://archive.ics.uci.edu/ml/datasets/Heart+failure+clinical+records,"A detailed description of the dataset can be found in the Dataset section of the following paper: Davide Chicco, Giuseppe Jurman: ""Machine learning can predict survival of patients with heart failure from serum creatinine and ejection fraction alone"". BMC Medical Informatics and Decision Making 20, 16 (2020). [Web Link] ",Life,"Thirteen (13) clinical features:- age: age of the patient (years)- anaemia: decrease of red blood cells or hemoglobin (boolean)- high blood pressure: if the patient has hypertension (boolean)- creatinine phosphokinase  (CPK): level of the CPK enzyme in the blood (mcg/L)- diabetes: if the patient has diabetes (boolean)- ejection fraction: percentage of blood leaving the heart at each contraction  (percentage)- platelets: platelets in the blood (kiloplatelets/mL)- sex: woman or man (binary)- serum creatinine: level of serum creatinine in the blood (mg/dL)- serum sodium: level of serum sodium in the blood (mEq/L)- smoking: if the patient smokes or not (boolean)- time: follow-up period (days)- [target] death event: if the patient deceased during the follow-up period (boolean)For more information, please check Table 1, Table 2, and Table 3 of the following paper: Davide Chicco, Giuseppe Jurman: ""Machine learning can predict survival of patients with heart failure from serum creatinine and ejection fraction alone"". BMC Medical Informatics and Decision Making 20, 16 (2020). [Web Link] ","This dataset contains the medical records of 299 patients who had heart failure, collected during their follow-up period, where each patient profile has 13 clinical features.A detailed description of the dataset can be found in the Dataset section of the following paper: Davide Chicco, Giuseppe Jurman: ""Machine learning can predict survival of patients with heart failure from serum creatinine and ejection fraction alone"". BMC Medical Informatics and Decision Making 20, 16 (2020). [Web Link] Thirteen (13) clinical features:- age: age of the patient (years)- anaemia: decrease of red blood cells or hemoglobin (boolean)- high blood pressure: if the patient has hypertension (boolean)- creatinine phosphokinase  (CPK): level of the CPK enzyme in the blood (mcg/L)- diabetes: if the patient has diabetes (boolean)- ejection fraction: percentage of blood leaving the heart at each contraction  (percentage)- platelets: platelets in the blood (kiloplatelets/mL)- sex: woman or man (binary)- serum creatinine: level of serum creatinine in the blood (mg/dL)- serum sodium: level of serum sodium in the blood (mEq/L)- smoking: if the patient smokes or not (boolean)- time: follow-up period (days)- [target] death event: if the patient deceased during the follow-up period (boolean)For more information, please check Table 1, Table 2, and Table 3 of the following paper: Davide Chicco, Giuseppe Jurman: ""Machine learning can predict survival of patients with heart failure from serum creatinine and ejection fraction alone"". BMC Medical Informatics and Decision Making 20, 16 (2020). [Web Link] "
Hepatitis,Hepatitis,From G.Gong: CMU; Mostly Boolean or numeric-valued attribute types; Includes cost data (donated by Peter Turney),Hepatitis,https://archive.ics.uci.edu/ml//machine-learning-databases/hepatitis/,https://archive.ics.uci.edu/ml/datasets/Hepatitis,Please ask Gail Gong for further information on this database.,Life,"     1. Class: DIE, LIVE     2. AGE: 10, 20, 30, 40, 50, 60, 70, 80     3. SEX: male, female     4. STEROID: no, yes     5. ANTIVIRALS: no, yes     6. FATIGUE: no, yes     7. MALAISE: no, yes     8. ANOREXIA: no, yes     9. LIVER BIG: no, yes    10. LIVER FIRM: no, yes    11. SPLEEN PALPABLE: no, yes    12. SPIDERS: no, yes    13. ASCITES: no, yes    14. VARICES: no, yes    15. BILIRUBIN: 0.39, 0.80, 1.20, 2.00, 3.00, 4.00        -- see the note below    16. ALK PHOSPHATE: 33, 80, 120, 160, 200, 250    17. SGOT: 13, 100, 200, 300, 400, 500,     18. ALBUMIN: 2.1, 3.0, 3.8, 4.5, 5.0, 6.0    19. PROTIME: 10, 20, 30, 40, 50, 60, 70, 80, 90    20. HISTOLOGY: no, yesThe BILIRUBIN attribute appears to be continuously-valued.  I checked this with the donater, Bojan Cestnik, who replied: About the hepatitis database and BILIRUBIN problem I would like to say the following: BILIRUBIN is continuous attribute (= the number of it's ""values"" in the ASDOHEPA.DAT file is negative!!!); ""values"" are quoted because when speaking about the continuous attribute there is no such thing as all possible values. However, they represent so called ""boundary"" values; according to these ""boundary"" values the attribute can be discretized. At the same time, because of the continious attribute, one can perform some other test since the continuous information is preserved. I hope that these lines have at least roughly answered your question. ","From G.Gong: CMU; Mostly Boolean or numeric-valued attribute types; Includes cost data (donated by Peter Turney)Please ask Gail Gong for further information on this database.     1. Class: DIE, LIVE     2. AGE: 10, 20, 30, 40, 50, 60, 70, 80     3. SEX: male, female     4. STEROID: no, yes     5. ANTIVIRALS: no, yes     6. FATIGUE: no, yes     7. MALAISE: no, yes     8. ANOREXIA: no, yes     9. LIVER BIG: no, yes    10. LIVER FIRM: no, yes    11. SPLEEN PALPABLE: no, yes    12. SPIDERS: no, yes    13. ASCITES: no, yes    14. VARICES: no, yes    15. BILIRUBIN: 0.39, 0.80, 1.20, 2.00, 3.00, 4.00        -- see the note below    16. ALK PHOSPHATE: 33, 80, 120, 160, 200, 250    17. SGOT: 13, 100, 200, 300, 400, 500,     18. ALBUMIN: 2.1, 3.0, 3.8, 4.5, 5.0, 6.0    19. PROTIME: 10, 20, 30, 40, 50, 60, 70, 80, 90    20. HISTOLOGY: no, yesThe BILIRUBIN attribute appears to be continuously-valued.  I checked this with the donater, Bojan Cestnik, who replied: About the hepatitis database and BILIRUBIN problem I would like to say the following: BILIRUBIN is continuous attribute (= the number of it's ""values"" in the ASDOHEPA.DAT file is negative!!!); ""values"" are quoted because when speaking about the continuous attribute there is no such thing as all possible values. However, they represent so called ""boundary"" values; according to these ""boundary"" values the attribute can be discretized. At the same time, because of the continious attribute, one can perform some other test since the continuous information is preserved. I hope that these lines have at least roughly answered your question. "
Cryotherapy Dataset ,Cryotherapy Dataset ,This dataset contains information about wart treatment results of 90 patients using cryotherapy.,Cryotherapy+Dataset+,https://archive.ics.uci.edu/ml//machine-learning-databases/00429/,https://archive.ics.uci.edu/ml/datasets/Cryotherapy+Dataset+,Provide all relevant information about your data set.,Life,Provide information about each attribute in your data set.,This dataset contains information about wart treatment results of 90 patients using cryotherapy.Provide all relevant information about your data set.Provide information about each attribute in your data set.
Hepatitis C Virus (HCV) for Egyptian patients,Hepatitis C Virus (HCV) for Egyptian patients,Egyptian patients who underwent treatment dosages for HCV about 18 months. Discretization should be applied based on expert recommendations; there is an attached file shows how.,Hepatitis+C+Virus+%28HCV%29+for+Egyptian+patients,https://archive.ics.uci.edu/ml//machine-learning-databases/00503/,https://archive.ics.uci.edu/ml/datasets/Hepatitis+C+Virus+%28HCV%29+for+Egyptian+patients,Provide all relevant information about your data set.,Life,Age	AgeGender	GenderBMI	Body Mass IndexFever	FeverNausea/Vomting	Nausea/VomtingHeadache	HeadacheDiarrhea	DiarrheaFatigue & generalized bone ache	Fatigue & generalized bone acheJaundice	JaundiceEpigastric pain	Epigastric painWBC	White blood cellRBC	red blood cellsHGB	HemoglobinPlat	PlateletsAST 1	aspartate transaminase ratioALT 1	alanine transaminase ratio 1 weekALT 4	alanine transaminase ratio 12 weeksALT 12	alanine transaminase ratio 4 weeksALT 24	alanine transaminase ratio 24 weeksALT 36	alanine transaminase ratio 36 weeksALT 48	alanine transaminase ratio 48 weeksALT after 24 w	alanine transaminase ratio 24 weeksRNA Base	RNA BaseRNA 4	RNA 4RNA 12	RNA 12RNA EOT	RNA end-of-treatment RNA EF	RNA Elongation FactorBaseline histological Grading	Baseline histological GradingBaselinehistological staging	Baselinehistological staging,Egyptian patients who underwent treatment dosages for HCV about 18 months. Discretization should be applied based on expert recommendations; there is an attached file shows how.Provide all relevant information about your data set.Age	AgeGender	GenderBMI	Body Mass IndexFever	FeverNausea/Vomting	Nausea/VomtingHeadache	HeadacheDiarrhea	DiarrheaFatigue & generalized bone ache	Fatigue & generalized bone acheJaundice	JaundiceEpigastric pain	Epigastric painWBC	White blood cellRBC	red blood cellsHGB	HemoglobinPlat	PlateletsAST 1	aspartate transaminase ratioALT 1	alanine transaminase ratio 1 weekALT 4	alanine transaminase ratio 12 weeksALT 12	alanine transaminase ratio 4 weeksALT 24	alanine transaminase ratio 24 weeksALT 36	alanine transaminase ratio 36 weeksALT 48	alanine transaminase ratio 48 weeksALT after 24 w	alanine transaminase ratio 24 weeksRNA Base	RNA BaseRNA 4	RNA 4RNA 12	RNA 12RNA EOT	RNA end-of-treatment RNA EF	RNA Elongation FactorBaseline histological Grading	Baseline histological GradingBaselinehistological staging	Baselinehistological staging
Ecoli,Ecoli,This data contains protein localization sites,Ecoli,https://archive.ics.uci.edu/ml//machine-learning-databases/ecoli/,https://archive.ics.uci.edu/ml/datasets/Ecoli,"The references below describe a predecessor to this dataset and its development. They also give results (not cross-validated) for classification by a rule-based expert system with that version of the dataset.Reference: ""Expert Sytem for Predicting Protein Localization Sites in Gram-Negative Bacteria"", Kenta Nakai & Minoru Kanehisa,  PROTEINS: Structure, Function, and Genetics 11:95-110, 1991.Reference: ""A Knowledge Base for Predicting Protein Localization Sites in Eukaryotic Cells"", Kenta Nakai & Minoru Kanehisa, Genomics 14:897-911, 1992.",Life,  1.  Sequence Name: Accession number for the SWISS-PROT database  2.  mcg: McGeoch's method for signal sequence recognition.  3.  gvh: von Heijne's method for signal sequence recognition.  4.  lip: von Heijne's Signal Peptidase II consensus sequence score. Binary attribute.  5.  chg: Presence of charge on N-terminus of predicted lipoproteins. Binary attribute.  6.  aac: score of discriminant analysis of the amino acid content of outer membrane and periplasmic proteins.  7. alm1: score of the ALOM membrane spanning region prediction program.  8. alm2: score of ALOM program after excluding putative cleavable signal regions from the sequence.,"This data contains protein localization sitesThe references below describe a predecessor to this dataset and its development. They also give results (not cross-validated) for classification by a rule-based expert system with that version of the dataset.Reference: ""Expert Sytem for Predicting Protein Localization Sites in Gram-Negative Bacteria"", Kenta Nakai & Minoru Kanehisa,  PROTEINS: Structure, Function, and Genetics 11:95-110, 1991.Reference: ""A Knowledge Base for Predicting Protein Localization Sites in Eukaryotic Cells"", Kenta Nakai & Minoru Kanehisa, Genomics 14:897-911, 1992.  1.  Sequence Name: Accession number for the SWISS-PROT database  2.  mcg: McGeoch's method for signal sequence recognition.  3.  gvh: von Heijne's method for signal sequence recognition.  4.  lip: von Heijne's Signal Peptidase II consensus sequence score. Binary attribute.  5.  chg: Presence of charge on N-terminus of predicted lipoproteins. Binary attribute.  6.  aac: score of discriminant analysis of the amino acid content of outer membrane and periplasmic proteins.  7. alm1: score of the ALOM membrane spanning region prediction program.  8. alm2: score of ALOM program after excluding putative cleavable signal regions from the sequence."
Nasarian CAD Dataset,Nasarian CAD Dataset,This dataset comprises records of 150 subjects (all male employees in Iran have visited the Abadan Occupational (Industrial) Medicine Clinic) and 52 features.,Nasarian+CAD+Dataset,https://archive.ics.uci.edu/ml//machine-learning-databases/00557/,https://archive.ics.uci.edu/ml/datasets/Nasarian+CAD+Dataset,Provide all relevant information about your data set.,Life,Provide information about each attribute in your data set.,This dataset comprises records of 150 subjects (all male employees in Iran have visited the Abadan Occupational (Industrial) Medicine Clinic) and 52 features.Provide all relevant information about your data set.Provide information about each attribute in your data set.
Myocardial infarction complications,Myocardial infarction complications,Prediction of myocardial infarction complications,Myocardial+infarction+complications,https://archive.ics.uci.edu/ml//machine-learning-databases/00579/,https://archive.ics.uci.edu/ml/datasets/Myocardial+infarction+complications,"Problems of real-life complexity are needed to test and compare various data mining and pattern recognition methods. The proposed database can be used to solve two practically important problems: predicting complications of Myocardial Infarction (MI) based on information about the patient (i) at the time of admission and (ii) on the third day of the hospital period. Another important group of tasks is phenotyping of disease (cluster analysis), dynamic phenotyping (filament extraction and identification of disease trajectories) and visualisation (disease mapping). MI is one of the most challenging problems of modern medicine. Acute myocardial infarction is associated with high mortality in the first year after it. The incidence of MI remains high in all countries. This is especially true for the urban population of highly developed countries, which is exposed to chronic stress factors, irregular and not always balanced nutrition. In the United States, for example, more than a million people suffer from MI every year, and 200-300 thousand of them die from acute MI before arriving at the hospital. The course of the disease in patients with MI is different. MI can occur without complications or with complications that do not worsen the long-term prognosis. At the same time, about half of patients in the acute and subacute periods have complications that lead to worsening of the disease and even death. Even an experienced specialist can not always foresee the development of these complications. In this regard, predicting complications of myocardial infarction in order to timely carry out the necessary preventive measures is an important task. Problems to solveIn general columns 2-112 can be used as input data for prediction. Possible complications (outputs) are listed in columns 113-124.There are four possible time moments for complication prediction: on base of the information known at1.	the time of admission to hospital: all input columns (2-112) except 93, 94, 95, 100, 101, 102, 103, 104, 105 can be used for prediction;2.	the end of the first day (24 hours after admission to the hospital): all input columns (2-112) except 94, 95, 101, 102, 104, 105 can be used for prediction;3.	the end of the second day (48 hours after admission to the hospital) all input columns (2-112) except 95, 102, 105 can be used for prediction;4.	the end of the third day (72 hours after admission to the hospital) all input columns (2-112) can be used for prediction.You can find detailed description of database, descriptive statistics and csv version of database in DOI: 10.25392/leicester.data.12045261.v3",Life,"Table of abbreviationsFC is the functional class of angina pectoris in the last year according to Campeau, L., 1976. Grading of angina pectoris. Circulation, 54(3), pp.522-523.CHD is coronary heart disease.HF is heart failure.ECG is electrocardiogram.AV is atrioventricular block.LBBB is left bundle branch block.RBBB is right bundle branch block.QRS is QRS complex in ECGIU is international unit.ICU is intensive care unit.ESR is erythrocyte sedimentation rate.NSAID is non-steroidal anti-inflammatory drugs.List of attributes1. Record ID (ID): Unique identifier. Cannot be related to participant. It can be used for reference only.2. Age (AGE): Real. Age of patient.3. Gender (SEX): Nominal: 			Cases	Fraction0: female	635	37.35%1: male	1065	62.65%Missing		0	0%4. Quantity of myocardial infarctions in the anamnesis (INF_ANAM): Ordinal			Cases	Fraction0: zero		1060	62.35%1: one			410	24.12%2: two			147	8.65%3: three and more	79	4.65%Missing			4	0.24%5. Exertional angina pectoris in the anamnesis (STENOK_AN): Ordinal				Cases	Fraction0: never			661	38.88%1: during the last year	146	8.59%2: one year ago		137	8.06%3: two years ago		117	6.88%4: three years ago		76	4.47%5: 4-5 years ago		125	7.35%6: more than 5 years ago	332	19.53%Missing				106	6.24%6. Functional class (FC) of angina pectoris in the last year (FK_STENOK): Ordinal					Cases	Fraction0: there is no angina pectoris		661	38.88%1: I FC				47	2.76%2: II FC				854	50.24%3: III FC				54	3.18%4: IV FC				11	0.65%Missing					73	4.29%7. Coronary heart disease (CHD) in recent weeks, days before admission to hospital (IBS_POST): Ordinal					Cases	Fraction0: there was no Ã�Â¡HD			418	24.59%1: exertional angina pectoris		548	32.24%2: unstable angina pectoris		683	40.18%Missing					51	3.00%8. Heredity on CHD (IBS_NASL): Nominal			Cases	Fraction0: isnÃ¢â‚¬â„¢t burdened	45	2.65%1: burdened		27	1.59%Missing			1628	95.76%9. Presence of an essential hypertension (GB): Ordinal					Cases	Fraction0: there is no essential hypertension	605	35.59%1: Stage 1				11	0.65%2: Stage 2				880	51.76%3: Stage 3				195	11.47%Missing					9	0.53%10. Symptomatic hypertension (SIM_GIPERT): Nominal			Cases	Fraction0: no		1635	96.18%1: yes		57	3.35%Missing		8	0.47%11. Duration of arterial hypertension (DLIT_AG): Ordinal					Cases	Fraction0: there was no arterial hypertension	551	32.41%1: one year				93	5.47%2: two years				58	3.41%3: three years				58	3.41%4: four years				22	1.29%5: five years				73	4.29%6: 6-10 years				165	9.71%7: more than 10 years			432	25.41%Missing					248	14.59%12. Presence of chronic Heart failure (HF) in the anamnesis (ZSN_A): Partially ordered attribute: there are two lines of severities:0<1<2<4,0<1<3<4.State 4 means simultaneous states 2 and 3							Cases	Fraction0: there is no chronic heart failure			1468	86.35%1: I stage						103	6.06%2: IIÃ� stage (heart failure due to right ventricular systolic dysfunction)			27	1.59%3: IIÃ� stage (heart failure due to left ventricular systolic dysfunction)			29	1.71%4: IIB stage (heart failure due to left and right ventricular systolic dysfunction)		19	1.12%Missing							54	3.18%13. Observing of arrhythmia in the anamnesis (nr11): Nominal		Cases	Fraction0: no		1637	96.29%1: yes		42	2.47%Missing		21	1.24%14. Premature atrial contractions in the anamnesis (nr01): Nominal		Cases	Fraction0: no		1675	98.53%1: yes		4	0.24%Missing		21	1.24%15. Premature ventricular contractions in the anamnesis (nr02): Nominal		Cases	Fraction0: no		1660	97.65%1: yes		19	1.12%Missing		21	1.24%16. Paroxysms of atrial fibrillation in the anamnesis (nr03): Nominal		Cases	Fraction0: no		1644	96.71%1: yes		35	2.06%Missing		21	1.24%17. A persistent form of atrial fibrillation in the anamnesis (nr04): Nominal		Cases	Fraction0: no		1650	97.06%1: yes		29	1.71%Missing		21	1.24%18. Ventricular fibrillation in the anamnesis (nr07): Nominal		Cases	Fraction0: no		1678	98.71%1: yes		1	0.06%Missing		21	1.24%19. Ventricular paroxysmal tachycardia in the anamnesis (nr08): Nominal		Cases	Fraction0: no		1675	98.53%1: yes		4	0.24%Missing		21	1.24%20. First-degree AV block in the anamnesis (np01): Nominal		Cases	Fraction0: no		1680	98.82%1: yes		2	0.12%Missing		18	1.06%21. Third-degree AV block in the anamnesis (np04): Nominal		Cases	Fraction0: no		1679	98.76%1: yes		3	0.18%Missing		18	1.06%22. LBBB (anterior branch) in the anamnesis (np05): Nominal		Cases	Fraction0: no		1671	98.29%1: yes		11	0.65%Missing		18	1.06%23. Incomplete LBBB in the anamnesis (np07): Nominal		Cases	Fraction0: no		1681	98.88%1: yes		1	0.06%Missing		18	1.06%24. Complete LBBB in the anamnesis (np08): Nominal		Cases	Fraction0: no		1676	98.59%1: yes		6	0.35%Missing		18	1.06%25. Incomplete RBBB in the anamnesis (np09): Nominal		Cases	Fraction0: no		1680	98.82%1: yes		2	0.12%Missing		18	1.06%26. Complete RBBB in the anamnesis (np10): Nominal		Cases	Fraction0: no		1679	98.76%1: yes		3	0.18%Missing		18	1.06%27. Diabetes mellitus in the anamnesis (endocr_01): Nominal		Cases	Fraction0: no		1461	85.94%1: yes		228	13.41%Missing		11	0.65%28. Obesity in the anamnesis (endocr_02): Nominal		Cases	Fraction0: no		1648	96.94%1: yes		42	2.47%Missing		10	0.59%29. Thyrotoxicosis in the anamnesis (endocr_03): Nominal		Cases	Fraction0: no		1677	98.65%1: yes		13	0.76%Missing		10	0.59%	30. Chronic bronchitis in the anamnesis (zab_leg_01): Nominal		Cases	Fraction0: no		1559	91.71%1: yes		134	7.88%Missing		7	0.41%31.Obstructive chronic bronchitis in the anamnesis (zab_leg_02): Nominal		Cases	Fraction0: no		1572	92.47%1: yes		121	7.12%Missing		7	0.41%32. Bronchial asthma in the anamnesis (zab_leg_03): Nominal		Cases	Fraction0: no		1656	97.41%1: yes		37	2.18%Missing		7	0.41%33. Chronic pneumonia in the anamnesis (zab_leg_04): Nominal		Cases	Fraction0: no		1684	99.06%1: yes		9	0.53%Missing		7	0.41%34. Pulmonary tuberculosis in the anamnesis (zab_leg_06): Nominal		Cases	Fraction0: no		1684	99.06%1: yes		9	0.53%Missing		7	0.41%35. Systolic blood pressure according to Emergency Cardiology Team (S_AD_KBRIG) (mmHg): Real.36. Diastolic blood pressure according to Emergency Cardiology Team (D_AD_KBRIG) (mmHg): Real.37. Systolic blood pressure according to intensive care unit (S_AD_ORIT) (mmHg): Real.38. Diastolic blood pressure according to intensive care unit (D_AD_ORIT) (mmHg): Real.39. Pulmonary edema at the time of admission to intensive care unit (O_L_POST): Nominal		Cases	Fraction0: no		1578	92.82%1: yes		110	6.47%Missing		12	0.71%40. Cardiogenic shock at the time of admission to intensive care unit (K_SH_POST): Nominal		Cases	Fraction0: no		1639	96.41%1: yes		46	2.71%Missing		15	0.88%41. Paroxysms of atrial fibrillation at the time of admission to intensive care unit, (or at a pre-hospital stage) (MP_TP_POST): Nominal		Cases	Fraction0: no		1572	92.47%1: yes		114	6.71%Missing		14	0.82%42. Paroxysms of supraventricular tachycardia at the time of admission to intensive care unit, (or at a pre-hospital stage) (SVT_POST): Nominal		Cases	Fraction0: no		1680	98.82%1: yes		8	0.47%Missing		12	0.71%43. Paroxysms of ventricular tachycardia at the time of admission to intensive care unit, (or at a pre-hospital stage) (GT_POST): Nominal		Cases	Fraction0: no		1680	98.82%1: yes		8	0.47%Missing		12	0.71%44. Ventricular fibrillation at the time of admission to intensive care unit, (or at a pre-hospital stage) (FIB_G_POST): Nominal		Cases	Fraction0: no		1673	98.41%1: yes		15	0.88%Missing		12	0.71%45. Presence of an anterior myocardial infarction (left ventricular) (ECG changes in leads V1: V4 ) (ant_im): Ordinal						Cases	Fraction0: there is no infarct in this location	660	38.82%1: QRS has no changes				392	23.06%2: QRS is like QR-complex			39	2.29%3: QRS is like Qr-complex			34	2.00%4: QRS is like QS-complex			492	28.94%Missing						83	4.88%46. Presence of a lateral myocardial infarction (left ventricular) (ECG changes in leads V5: V6 , I, AVL) (lat_im): Ordinal					Cases	Fraction0: there is no infarct in this location	576	33.88%1: QRS has no changes			838	49.29%2: QRS is like QR-complex		97	5.71%3: QRS is like Qr-complex		72	4.24%4: QRS is like QS-complex		37	2.18%Missing					80	4.71%47. Presence of an inferior myocardial infarction (left ventricular) (ECG changes in leads III, AVF, II). (inf_im): Ordinal						Cases	Fraction0: there is no infarct in this location	937	55.12%1: QRS has no changes				195	11.47%2: QRS is like QR-complex			191	11.24%3: QRS is like Qr-complex			121	7.12%4: QRS is like QS-complex			176	10.35%Missing						80	4.71%48. Presence of a posterior myocardial infarction (left ventricular) (ECG changes in V7: V9, reciprocity changes in leads V1 Ã¢â‚¬â€œ V3) (post_im): Ordinal						Cases	Fraction0: there is no infarct in this location	1370	80.59%1: QRS has no changes				157	9.24%2: QRS is like QR-complex			52	3.06%3: QRS is like Qr-complex			35	2.06%4: QRS is like QS-complex			14	0.82%Missing						72	4.24%49. Presence of a right ventricular myocardial infarction (IM_PG_P): Nominal		Cases	Fraction0: no		1649	97.00%1: yes		50	2.94%Missing		1	0.06%50. ECG rhythm at the time of admission to hospital: sinus (with a heart rate 60-90) (ritm_ecg_p_01): Nominal		Cases	Fraction0: no		519	30.53%1: yes		1029	60.53%Missing		152	8.94%51. ECG rhythm at the time of admission to hospital: atrial fibrillation (ritm_ecg_p_02): Nominal		Cases	Fraction0: no		1453	85.47%1: yes		95	5.59%Missing		152	8.94%52. ECG rhythm at the time of admission to hospital: atrial (ritm_ecg_p_04): Nominal		Cases	Fraction0: no		1525	89.71%1: yes		23	1.35%Missing		152	8.94%53. ECG rhythm at the time of admission to hospital: idioventricular (ritm_ecg_p_06): Nominal		Cases	Fraction0: no		1547	91.00%1: yes		1	0.06%Missing		152	8.94%54. ECG rhythm at the time of admission to hospital: sinus with a heart rate above 90 (tachycardia) (ritm_ecg_p_07): Nominal		Cases	Fraction0: no		1195	70.29%1: yes		353	20.76%Missing		152	8.94%55. ECG rhythm at the time of admission to hospital: sinus with a heart rate below 60 (bradycardia) (ritm_ecg_p_08): Nominal		Cases	Fraction0: no		1502	88.35%1: yes		46	2.71%Missing		152	8.94%56. Premature atrial contractions on ECG at the time of admission to hospital (n_r_ecg_p_01): Nominal		Cases	Fraction0: no		1527	89.82%1: yes		58	3.41%Missing		115	6.76%57. Frequent premature atrial contractions on ECG at the time of admission to hospital (n_r_ecg_p_02): Nominal		Cases	Fraction0: no		1577	92.76%1: yes		8	0.47%Missing		115	6.76%58.Premature ventricular contractions on ECG at the time of admission to hospital (n_r_ecg_p_03): Nominal		Cases	Fraction0: no		1381	81.24%1: yes		204	12.00%Missing		115	6.76%59. Frequent premature ventricular contractions on ECG at the time of admission to hospital (n_r_ecg_p_04): Nominal		Cases	Fraction0: no		1516	89.18%1: yes		69	4.06%Missing		115	6.76%60. Paroxysms of atrial fibrillation on ECG at the time of admission to hospital (n_r_ecg_p_05): Nominal		Cases	Fraction0: no		1515	89.12%1: yes		70	4.12%Missing		115	6.76%61. Persistent form of atrial fibrillation on ECG at the time of admission to hospital (n_r_ecg_p_06): Nominal		Cases	Fraction0: no		1553	91.35%1: yes		32	1.88%Missing		115	6.76%62. Paroxysms of supraventricular tachycardia on ECG at the time of admission to hospital (n_r_ecg_p_08): Nominal 		Cases	Fraction0: no		1581	93.00%1: yes		4	0.24%Missing		115	6.76%63. Paroxysms of ventricular tachycardia on ECG at the time of admission to hospital (n_r_ecg_p_09): Nominal		Cases	Fraction0: no		1583	93.12%1: yes		2	0.12%Missing		115	6.76%64. Ventricular fibrillation on ECG at the time of admission to hospital (n_r_ecg_p_10): Nominal		Cases	Fraction0: no		1583	93.12%1: yes		2	0.12%Missing		115	6.76%65. Sinoatrial block on ECG at the time of admission to hospital (n_p_ecg_p_01): Nominal		Cases	Fraction0: no		1583	93.12%1: yes		2	0.12%Missing		115	6.76%66. First-degree AV block on ECG at the time of admission to hospital (n_p_ecg_p_03): Nominal		Cases	Fraction0: no		1553	91.35%1: yes		32	1.88%Missing		115	6.76%67. Type 1 Second-degree AV block (Mobitz I/Wenckebach) on ECG at the time of admission to hospital (n_p_ecg_p_04): Nominal		Cases	Fraction0: no		1580	92.94%1: yes		5	0.29%Missing		115	6.76%68. Type 2 Second-degree AV block (Mobitz II/Hay) on ECG at the time of admission to hospital (n_p_ecg_p_05): Nominal		Cases	Fraction0: no		1583	93.12%1: yes		2	0.12%Missing		115	6.76%69. Third-degree AV block on ECG at the time of admission to hospital (n_p_ecg_p_06): Nominal		Cases	Fraction0: no		1558	91.65%1: yes		27	1.59%Missing		115	6.76%70. LBBB (anterior branch) on ECG at the time of admission to hospital (n_p_ecg_p_07): Nominal		Cases	Fraction0: no		1483	87.24%1: yes		102	6.00%Missing		115	6.76%71. LBBB (posterior branch) on ECG at the time of admission to hospital (n_p_ecg_p_08): Nominal		Cases	Fraction0: no		1578	92.82%1: yes		7	0.41%Missing		115	6.76%72. Incomplete LBBB on ECG at the time of admission to hospital (n_p_ecg_p_09): Nominal		Cases	Fraction0: no		1575	92.65%1: yes		10	0.59%Missing		115	6.76%73. Complete LBBB on ECG at the time of admission to hospital (n_p_ecg_p_10): Nominal		Cases	Fraction0: no		1551	91.24%1: yes		34	2.00%Missing		115	6.76%74. Incomplete RBBB on ECG at the time of admission to hospital (n_p_ecg_p_11): Nominal		Cases	Fraction0: no		1557	91.59%1: yes		28	1.65%Missing		115	6.76%75. Complete RBBB on ECG at the time of admission to hospital (n_p_ecg_p_12):		Cases	Fraction0: no		1507	88.65%1: yes		78	4.59%Missing		115	6.76%76. Fibrinolytic therapy by Ã�Â¡Ã�Âµliasum 750k IU (fibr_ter_01): Nominal		Cases	Fraction0: no		1677	98.65%1: yes		13	0.76%Missing		10	0.59%77. Fibrinolytic therapy by Ã�Â¡Ã�Âµliasum 1m IU (fibr_ter_02): Nominal		Cases	Fraction0: no		1674	98.47%1: yes		16	0.94%Missing		10	0.59%78. Fibrinolytic therapy by Ã�Â¡Ã�Âµliasum 3m IU (fibr_ter_03): Nominal		Cases	Fraction0: no		1622	95.41%1: yes		68	4.00%Missing		10	0.59%79. Fibrinolytic therapy by Streptase (fibr_ter_05): Nominal		Cases	Fraction0: no		1686	99.18%1: yes		4	0.24%Missing		10	0.59%80. Fibrinolytic therapy by Ã�Â¡Ã�Âµliasum 500k IU (fibr_ter_06): Nominal		Cases	Fraction0: no		1681	98.88%1: yes		9	0.53%Missing		10	0.59%81. Fibrinolytic therapy by Ã�Â¡Ã�Âµliasum 250k IU (fibr_ter_07): Nominal		Cases	Fraction0: no		1684	99.06%1: yes		6	0.35%Missing		10	0.59%82. Fibrinolytic therapy by Streptodecase 1.5m IU (fibr_ter_08): Nominal		Cases	Fraction0: no		1688	99.29%1: yes		2	0.12%Missing		10	0.59%83. Hypokalemia ( < 4 mmol/L) (GIPO_K): Nominal		Cases	Fraction0: no		797	46.88%1: yes		534	31.41%Missing		369	21.71%84. Serum potassium content (K_BLOOD) (mmol/L): Real.85 Increase of sodium in serum (more than 150 mmol/L) (GIPER_Na): Nominal		Cases	Fraction0: no		1295	76.18%1: yes		30	1.76%Missing		375	22.06%86. Serum sodium content (Na_BLOOD) (mmol/L): Real.87. Serum AlAT content (ALT_BLOOD) (IU/L): Real.88. Serum AsAT content (AST_BLOOD) (IU/L): Real.89. Serum CPK content (KFK_BLOOD) (IU/L): Real.90. White blood cell count (billions per liter) (L_BLOOD): Real.91. ESR (Erythrocyte sedimentation rate) (ROE) (Ã�Â¼Ã�Â¼): Real.92. Time elapsed from the beginning of the attack of CHD to the hospital (TIME_B_S): Ordinal			Cases	Fraction1: less than 2 hours	198	11.65%2: 2-4 hours		360	21.18%3: 4-6 hours		175	10.29%4: 6-8 hours		87	5.12%5: 8-12 hours		92	5.41%6: 12-24 hours		151	8.88%7: more than 1 days	141	8.29%8: more than 2 days	101	5.94%9: more than 3 days	269	15.82%Missing			126	7.41%93. Relapse of the pain in the first hours of the hospital period (R_AB_1_n): Ordinal			Cases	Fraction0: there is no relapse	1282	75.41%1: only one		298	17.53%2: 2 times		78	4.59%3: 3 or more times 	26	1.53%Missing			16	0.94%94. Relapse of the pain in the second day of the hospital period (R_AB_2_n): Ordinal			Cases	Fraction0: there is no relapse	1414	83.18%1: only one		133	7.82%2: 2 times		44	2.59%3: 3 or more times 	1	0.06%Missing			108	6.35%95. Relapse of the pain in the third day of the hospital period (R_AB_3_n): Ordinal			Cases	Fraction0: there is no relapse	1469	86.41%1: only one		86	5.06%2: 2 times		15	0.88%3: 3 or more times	2	0.12%Missing			1469	86.41%96. Use of opioid drugs by the Emergency Cardiology Team (NA_KB): Nominal		Cases	Fraction0: no		425	25.00%1: yes		618	36.35%Missing		657	38.65%97. Use of NSAIDs by the Emergency Cardiology Team (NOT_NA_KB): Nominal		Cases	Fraction0: no		313	18.41%1: yes		701	41.23%Missing		375	22.06%98.Use of lidocaine by the Emergency Cardiology Team (LID_KB): Nominal		Cases	Fraction0: no		627	36.88%1: yes		396	23.29%Missing		677	39.82%99. Use of liquid nitrates in the ICU (NITR_S): Nominal		Cases	Fraction0: no		1496	88.00%1: yes		195	11.47%Missing		9	0.53%100. Use of opioid drugs in the ICU in the first hours of the hospital period (NA_R_1_n): Ordinal		Cases	Fraction0: no		1108	65.18%1: once	409	24.06%2: twice	132	7.76%3: three times	35	2.06%4: four times	11	0.65%Missing		5	0.29%	101. Use of opioid drugs in the ICU in the second day of the hospital period (NA_R_2_n): Ordinal		Cases	Fraction0: no		1474	86.71%1: once	87	5.12%2: twice	30	1.76%3: three times	1	0.06%Missing		108	6.35%102. Use of opioid drugs in the ICU in the third day of the hospital period (NA_R_3_n): Ordinal		Cases	Fraction0: no		1493	87.82%1: once	60	3.53%2: twice	16	0.94%Missing		131	7.71%103. Use of NSAIDs in the ICU in the first hours of the hospital period (NOT_NA_1_n): Ordinal			Cases	Fraction0: no			1237	72.76%1: once		376	22.12%2: twice		53	3.12%3: three times		17	1.00%4: four or more times	7	0.41%Missing			10	0.59%104. Use of NSAIDs in the ICU in the second day of the hospital period (NOT_NA_2_n): Ordinal		Cases	Fraction0: no		1454	85.53%1: once	95	5.59%2: twice	38	2.24%3: three times	3	0.18%Missing		110	6.47%105. Use of NSAIDs in the ICU in the third day of the hospital period (NOT_NA_3_n): Ordinal		Cases	Fraction0: no		1474	86.71%1: once	57	3.35%2: twice	38	2.24%Missing		131	7.71%106. Use of lidocaine in the ICU (LID_S_n): Nominal		Cases	Fraction0: no		1211	71.24%1: yes		479	28.18%Missing		10	0.59%107. Use of beta-blockers in the ICU (B_BLOK_S_n): Nominal		Cases	Fraction0: no		1474	86.71%1: yes		215	12.65%Missing		11	0.65%108. Use of calcium channel blockers in the ICU (ANT_CA_S_n): Nominal		Cases	Fraction0: no		562	33.06%1: yes		1125	66.18%Missing		13	0.76%109. Use of Ã�Â° anticoagulants (heparin) in the ICU (GEPAR_S_n): Nominal		Cases	Fraction0: no		480	28.24%1: yes		1203	70.76%Missing		17	1.00%110. Use of acetylsalicylic acid in the ICU (ASP_S_n): Nominal		Cases	Fraction0: no		431	25.35%1: yes		1252	73.65%Missing		17	1.00%111. Use of Ticlid in the ICU (TIKL_S_n): Nominal		Cases	Fraction0: no		1654	97.29%1: yes		30	1.76%Missing		16	0.94%112. Use of Trental in the ICU (TRENT_S_n): Nominal		Cases	Fraction0: no		1343	79.00%1: yes		341	20.06%Missing		16	0.94%Complications and outcomes of myocardial infarction: 113. Atrial fibrillation (FIBR_PREDS): Nominal		Cases	Fraction0: no		1530	90.00%1: yes 	170	10.00%Missing		0	0%114. Supraventricular tachycardia (PREDS_TAH): Nominal		Cases	Fraction0: no		1680	98.82%1: yes 	20	1.18%Missing		0	0%115. Ventricular tachycardia (JELUD_TAH): Nominal		Cases	Fraction0: no		1658	97.53%1: yes 	42	2.47%Missing		0	0%116. Ventricular fibrillation (FIBR_JELUD): Nominal		Cases	Fraction0: no		1629	95.82%1: yes 	71	4.18%Missing		0	0%117. Third-degree AV block (A_V_BLOK): Nominal		Cases	Fraction0: no		1643	96.65%1: yes 	57	3.35%Missing		0	0%118. Pulmonary edema (OTEK_LANC): Nominal		Cases	Fraction0: no		1541	90.65%1: yes 	159	9.35%Missing		0	0%119. Myocardial rupture (RAZRIV): Nominal		Cases	Fraction0: no		1646	96.82%1: yes 	54	3.18%Missing		0	0%120. Dressler syndrome (DRESSLER): Nominal		Cases	Fraction0: no		1625	95.59%1: yes 	75	4.41%Missing		0	0%121. Chronic heart failure (ZSN): Nominal		Cases	Fraction0: no		1306	76.82%1: yes 	394	23.18%Missing		0	0%122. Relapse of the myocardial infarction (REC_IM): Nominal		Cases	Fraction0: no		1541	90.65%1: yes 	159	9.35%Missing		0	0%123. Post-infarction angina (P_IM_STEN): Nominal		Cases	Fraction0: no		1552	91.29%1: yes 	148	8.71%Missing		0	0%124. Lethal outcome (cause) (LET_IS): Structure						Cases	Fraction0: unknown (alive)				1429	84.06%1: cardiogenic shock				110	6.47%2: pulmonary edema				18	1.06%3: myocardial rupture				54	3.18%4: progress of congestive heart failure	23	1.35%5: thromboembolism				12	0.71%6: asystole					27	1.59%7: ventricular fibrillation			27	1.59%Missing						0	0%Summary statistics for real attributesAttribute	Min	Max	Mean	STD	Missing cases	Missing fractionAge		26	92	61.86	11.26	8		0.47%S_AD_KBRIG	0	260	136.91	34.97	1076		63.29%D_AD_KBRIG	0	190	81.39	19.73	1076		63.29%S_AD_ORIT	0	260	134.59	31.34	267		15.71%D_AD_ORIT	0	190	82.75	18.31	267		15.71%K_BLOOD		2.3	8.2	4.19	0.75	371		21.82%Na_BLOOD	117	169	136.55	6.51	375		22.06%ALT_BLOOD	0.03	3	0.48	0.39	284		16.71%AST_BLOOD	0.04	2.15	0.26	0.2	285		16.67%KFK_BLOOD	1.2	3.6	2	0.95	1696		99.76%L_BLOOD		2	27.9	8.78	3.40	125		7.35%ROE		1	140	13.44	11.29	203		19.94%","Prediction of myocardial infarction complicationsProblems of real-life complexity are needed to test and compare various data mining and pattern recognition methods. The proposed database can be used to solve two practically important problems: predicting complications of Myocardial Infarction (MI) based on information about the patient (i) at the time of admission and (ii) on the third day of the hospital period. Another important group of tasks is phenotyping of disease (cluster analysis), dynamic phenotyping (filament extraction and identification of disease trajectories) and visualisation (disease mapping). MI is one of the most challenging problems of modern medicine. Acute myocardial infarction is associated with high mortality in the first year after it. The incidence of MI remains high in all countries. This is especially true for the urban population of highly developed countries, which is exposed to chronic stress factors, irregular and not always balanced nutrition. In the United States, for example, more than a million people suffer from MI every year, and 200-300 thousand of them die from acute MI before arriving at the hospital. The course of the disease in patients with MI is different. MI can occur without complications or with complications that do not worsen the long-term prognosis. At the same time, about half of patients in the acute and subacute periods have complications that lead to worsening of the disease and even death. Even an experienced specialist can not always foresee the development of these complications. In this regard, predicting complications of myocardial infarction in order to timely carry out the necessary preventive measures is an important task. Problems to solveIn general columns 2-112 can be used as input data for prediction. Possible complications (outputs) are listed in columns 113-124.There are four possible time moments for complication prediction: on base of the information known at1.	the time of admission to hospital: all input columns (2-112) except 93, 94, 95, 100, 101, 102, 103, 104, 105 can be used for prediction;2.	the end of the first day (24 hours after admission to the hospital): all input columns (2-112) except 94, 95, 101, 102, 104, 105 can be used for prediction;3.	the end of the second day (48 hours after admission to the hospital) all input columns (2-112) except 95, 102, 105 can be used for prediction;4.	the end of the third day (72 hours after admission to the hospital) all input columns (2-112) can be used for prediction.You can find detailed description of database, descriptive statistics and csv version of database in DOI: 10.25392/leicester.data.12045261.v3Table of abbreviationsFC is the functional class of angina pectoris in the last year according to Campeau, L., 1976. Grading of angina pectoris. Circulation, 54(3), pp.522-523.CHD is coronary heart disease.HF is heart failure.ECG is electrocardiogram.AV is atrioventricular block.LBBB is left bundle branch block.RBBB is right bundle branch block.QRS is QRS complex in ECGIU is international unit.ICU is intensive care unit.ESR is erythrocyte sedimentation rate.NSAID is non-steroidal anti-inflammatory drugs.List of attributes1. Record ID (ID): Unique identifier. Cannot be related to participant. It can be used for reference only.2. Age (AGE): Real. Age of patient.3. Gender (SEX): Nominal: 			Cases	Fraction0: female	635	37.35%1: male	1065	62.65%Missing		0	0%4. Quantity of myocardial infarctions in the anamnesis (INF_ANAM): Ordinal			Cases	Fraction0: zero		1060	62.35%1: one			410	24.12%2: two			147	8.65%3: three and more	79	4.65%Missing			4	0.24%5. Exertional angina pectoris in the anamnesis (STENOK_AN): Ordinal				Cases	Fraction0: never			661	38.88%1: during the last year	146	8.59%2: one year ago		137	8.06%3: two years ago		117	6.88%4: three years ago		76	4.47%5: 4-5 years ago		125	7.35%6: more than 5 years ago	332	19.53%Missing				106	6.24%6. Functional class (FC) of angina pectoris in the last year (FK_STENOK): Ordinal					Cases	Fraction0: there is no angina pectoris		661	38.88%1: I FC				47	2.76%2: II FC				854	50.24%3: III FC				54	3.18%4: IV FC				11	0.65%Missing					73	4.29%7. Coronary heart disease (CHD) in recent weeks, days before admission to hospital (IBS_POST): Ordinal					Cases	Fraction0: there was no Ã�Â¡HD			418	24.59%1: exertional angina pectoris		548	32.24%2: unstable angina pectoris		683	40.18%Missing					51	3.00%8. Heredity on CHD (IBS_NASL): Nominal			Cases	Fraction0: isnÃ¢â‚¬â„¢t burdened	45	2.65%1: burdened		27	1.59%Missing			1628	95.76%9. Presence of an essential hypertension (GB): Ordinal					Cases	Fraction0: there is no essential hypertension	605	35.59%1: Stage 1				11	0.65%2: Stage 2				880	51.76%3: Stage 3				195	11.47%Missing					9	0.53%10. Symptomatic hypertension (SIM_GIPERT): Nominal			Cases	Fraction0: no		1635	96.18%1: yes		57	3.35%Missing		8	0.47%11. Duration of arterial hypertension (DLIT_AG): Ordinal					Cases	Fraction0: there was no arterial hypertension	551	32.41%1: one year				93	5.47%2: two years				58	3.41%3: three years				58	3.41%4: four years				22	1.29%5: five years				73	4.29%6: 6-10 years				165	9.71%7: more than 10 years			432	25.41%Missing					248	14.59%12. Presence of chronic Heart failure (HF) in the anamnesis (ZSN_A): Partially ordered attribute: there are two lines of severities:0<1<2<4,0<1<3<4.State 4 means simultaneous states 2 and 3							Cases	Fraction0: there is no chronic heart failure			1468	86.35%1: I stage						103	6.06%2: IIÃ� stage (heart failure due to right ventricular systolic dysfunction)			27	1.59%3: IIÃ� stage (heart failure due to left ventricular systolic dysfunction)			29	1.71%4: IIB stage (heart failure due to left and right ventricular systolic dysfunction)		19	1.12%Missing							54	3.18%13. Observing of arrhythmia in the anamnesis (nr11): Nominal		Cases	Fraction0: no		1637	96.29%1: yes		42	2.47%Missing		21	1.24%14. Premature atrial contractions in the anamnesis (nr01): Nominal		Cases	Fraction0: no		1675	98.53%1: yes		4	0.24%Missing		21	1.24%15. Premature ventricular contractions in the anamnesis (nr02): Nominal		Cases	Fraction0: no		1660	97.65%1: yes		19	1.12%Missing		21	1.24%16. Paroxysms of atrial fibrillation in the anamnesis (nr03): Nominal		Cases	Fraction0: no		1644	96.71%1: yes		35	2.06%Missing		21	1.24%17. A persistent form of atrial fibrillation in the anamnesis (nr04): Nominal		Cases	Fraction0: no		1650	97.06%1: yes		29	1.71%Missing		21	1.24%18. Ventricular fibrillation in the anamnesis (nr07): Nominal		Cases	Fraction0: no		1678	98.71%1: yes		1	0.06%Missing		21	1.24%19. Ventricular paroxysmal tachycardia in the anamnesis (nr08): Nominal		Cases	Fraction0: no		1675	98.53%1: yes		4	0.24%Missing		21	1.24%20. First-degree AV block in the anamnesis (np01): Nominal		Cases	Fraction0: no		1680	98.82%1: yes		2	0.12%Missing		18	1.06%21. Third-degree AV block in the anamnesis (np04): Nominal		Cases	Fraction0: no		1679	98.76%1: yes		3	0.18%Missing		18	1.06%22. LBBB (anterior branch) in the anamnesis (np05): Nominal		Cases	Fraction0: no		1671	98.29%1: yes		11	0.65%Missing		18	1.06%23. Incomplete LBBB in the anamnesis (np07): Nominal		Cases	Fraction0: no		1681	98.88%1: yes		1	0.06%Missing		18	1.06%24. Complete LBBB in the anamnesis (np08): Nominal		Cases	Fraction0: no		1676	98.59%1: yes		6	0.35%Missing		18	1.06%25. Incomplete RBBB in the anamnesis (np09): Nominal		Cases	Fraction0: no		1680	98.82%1: yes		2	0.12%Missing		18	1.06%26. Complete RBBB in the anamnesis (np10): Nominal		Cases	Fraction0: no		1679	98.76%1: yes		3	0.18%Missing		18	1.06%27. Diabetes mellitus in the anamnesis (endocr_01): Nominal		Cases	Fraction0: no		1461	85.94%1: yes		228	13.41%Missing		11	0.65%28. Obesity in the anamnesis (endocr_02): Nominal		Cases	Fraction0: no		1648	96.94%1: yes		42	2.47%Missing		10	0.59%29. Thyrotoxicosis in the anamnesis (endocr_03): Nominal		Cases	Fraction0: no		1677	98.65%1: yes		13	0.76%Missing		10	0.59%	30. Chronic bronchitis in the anamnesis (zab_leg_01): Nominal		Cases	Fraction0: no		1559	91.71%1: yes		134	7.88%Missing		7	0.41%31.Obstructive chronic bronchitis in the anamnesis (zab_leg_02): Nominal		Cases	Fraction0: no		1572	92.47%1: yes		121	7.12%Missing		7	0.41%32. Bronchial asthma in the anamnesis (zab_leg_03): Nominal		Cases	Fraction0: no		1656	97.41%1: yes		37	2.18%Missing		7	0.41%33. Chronic pneumonia in the anamnesis (zab_leg_04): Nominal		Cases	Fraction0: no		1684	99.06%1: yes		9	0.53%Missing		7	0.41%34. Pulmonary tuberculosis in the anamnesis (zab_leg_06): Nominal		Cases	Fraction0: no		1684	99.06%1: yes		9	0.53%Missing		7	0.41%35. Systolic blood pressure according to Emergency Cardiology Team (S_AD_KBRIG) (mmHg): Real.36. Diastolic blood pressure according to Emergency Cardiology Team (D_AD_KBRIG) (mmHg): Real.37. Systolic blood pressure according to intensive care unit (S_AD_ORIT) (mmHg): Real.38. Diastolic blood pressure according to intensive care unit (D_AD_ORIT) (mmHg): Real.39. Pulmonary edema at the time of admission to intensive care unit (O_L_POST): Nominal		Cases	Fraction0: no		1578	92.82%1: yes		110	6.47%Missing		12	0.71%40. Cardiogenic shock at the time of admission to intensive care unit (K_SH_POST): Nominal		Cases	Fraction0: no		1639	96.41%1: yes		46	2.71%Missing		15	0.88%41. Paroxysms of atrial fibrillation at the time of admission to intensive care unit, (or at a pre-hospital stage) (MP_TP_POST): Nominal		Cases	Fraction0: no		1572	92.47%1: yes		114	6.71%Missing		14	0.82%42. Paroxysms of supraventricular tachycardia at the time of admission to intensive care unit, (or at a pre-hospital stage) (SVT_POST): Nominal		Cases	Fraction0: no		1680	98.82%1: yes		8	0.47%Missing		12	0.71%43. Paroxysms of ventricular tachycardia at the time of admission to intensive care unit, (or at a pre-hospital stage) (GT_POST): Nominal		Cases	Fraction0: no		1680	98.82%1: yes		8	0.47%Missing		12	0.71%44. Ventricular fibrillation at the time of admission to intensive care unit, (or at a pre-hospital stage) (FIB_G_POST): Nominal		Cases	Fraction0: no		1673	98.41%1: yes		15	0.88%Missing		12	0.71%45. Presence of an anterior myocardial infarction (left ventricular) (ECG changes in leads V1: V4 ) (ant_im): Ordinal						Cases	Fraction0: there is no infarct in this location	660	38.82%1: QRS has no changes				392	23.06%2: QRS is like QR-complex			39	2.29%3: QRS is like Qr-complex			34	2.00%4: QRS is like QS-complex			492	28.94%Missing						83	4.88%46. Presence of a lateral myocardial infarction (left ventricular) (ECG changes in leads V5: V6 , I, AVL) (lat_im): Ordinal					Cases	Fraction0: there is no infarct in this location	576	33.88%1: QRS has no changes			838	49.29%2: QRS is like QR-complex		97	5.71%3: QRS is like Qr-complex		72	4.24%4: QRS is like QS-complex		37	2.18%Missing					80	4.71%47. Presence of an inferior myocardial infarction (left ventricular) (ECG changes in leads III, AVF, II). (inf_im): Ordinal						Cases	Fraction0: there is no infarct in this location	937	55.12%1: QRS has no changes				195	11.47%2: QRS is like QR-complex			191	11.24%3: QRS is like Qr-complex			121	7.12%4: QRS is like QS-complex			176	10.35%Missing						80	4.71%48. Presence of a posterior myocardial infarction (left ventricular) (ECG changes in V7: V9, reciprocity changes in leads V1 Ã¢â‚¬â€œ V3) (post_im): Ordinal						Cases	Fraction0: there is no infarct in this location	1370	80.59%1: QRS has no changes				157	9.24%2: QRS is like QR-complex			52	3.06%3: QRS is like Qr-complex			35	2.06%4: QRS is like QS-complex			14	0.82%Missing						72	4.24%49. Presence of a right ventricular myocardial infarction (IM_PG_P): Nominal		Cases	Fraction0: no		1649	97.00%1: yes		50	2.94%Missing		1	0.06%50. ECG rhythm at the time of admission to hospital: sinus (with a heart rate 60-90) (ritm_ecg_p_01): Nominal		Cases	Fraction0: no		519	30.53%1: yes		1029	60.53%Missing		152	8.94%51. ECG rhythm at the time of admission to hospital: atrial fibrillation (ritm_ecg_p_02): Nominal		Cases	Fraction0: no		1453	85.47%1: yes		95	5.59%Missing		152	8.94%52. ECG rhythm at the time of admission to hospital: atrial (ritm_ecg_p_04): Nominal		Cases	Fraction0: no		1525	89.71%1: yes		23	1.35%Missing		152	8.94%53. ECG rhythm at the time of admission to hospital: idioventricular (ritm_ecg_p_06): Nominal		Cases	Fraction0: no		1547	91.00%1: yes		1	0.06%Missing		152	8.94%54. ECG rhythm at the time of admission to hospital: sinus with a heart rate above 90 (tachycardia) (ritm_ecg_p_07): Nominal		Cases	Fraction0: no		1195	70.29%1: yes		353	20.76%Missing		152	8.94%55. ECG rhythm at the time of admission to hospital: sinus with a heart rate below 60 (bradycardia) (ritm_ecg_p_08): Nominal		Cases	Fraction0: no		1502	88.35%1: yes		46	2.71%Missing		152	8.94%56. Premature atrial contractions on ECG at the time of admission to hospital (n_r_ecg_p_01): Nominal		Cases	Fraction0: no		1527	89.82%1: yes		58	3.41%Missing		115	6.76%57. Frequent premature atrial contractions on ECG at the time of admission to hospital (n_r_ecg_p_02): Nominal		Cases	Fraction0: no		1577	92.76%1: yes		8	0.47%Missing		115	6.76%58.Premature ventricular contractions on ECG at the time of admission to hospital (n_r_ecg_p_03): Nominal		Cases	Fraction0: no		1381	81.24%1: yes		204	12.00%Missing		115	6.76%59. Frequent premature ventricular contractions on ECG at the time of admission to hospital (n_r_ecg_p_04): Nominal		Cases	Fraction0: no		1516	89.18%1: yes		69	4.06%Missing		115	6.76%60. Paroxysms of atrial fibrillation on ECG at the time of admission to hospital (n_r_ecg_p_05): Nominal		Cases	Fraction0: no		1515	89.12%1: yes		70	4.12%Missing		115	6.76%61. Persistent form of atrial fibrillation on ECG at the time of admission to hospital (n_r_ecg_p_06): Nominal		Cases	Fraction0: no		1553	91.35%1: yes		32	1.88%Missing		115	6.76%62. Paroxysms of supraventricular tachycardia on ECG at the time of admission to hospital (n_r_ecg_p_08): Nominal 		Cases	Fraction0: no		1581	93.00%1: yes		4	0.24%Missing		115	6.76%63. Paroxysms of ventricular tachycardia on ECG at the time of admission to hospital (n_r_ecg_p_09): Nominal		Cases	Fraction0: no		1583	93.12%1: yes		2	0.12%Missing		115	6.76%64. Ventricular fibrillation on ECG at the time of admission to hospital (n_r_ecg_p_10): Nominal		Cases	Fraction0: no		1583	93.12%1: yes		2	0.12%Missing		115	6.76%65. Sinoatrial block on ECG at the time of admission to hospital (n_p_ecg_p_01): Nominal		Cases	Fraction0: no		1583	93.12%1: yes		2	0.12%Missing		115	6.76%66. First-degree AV block on ECG at the time of admission to hospital (n_p_ecg_p_03): Nominal		Cases	Fraction0: no		1553	91.35%1: yes		32	1.88%Missing		115	6.76%67. Type 1 Second-degree AV block (Mobitz I/Wenckebach) on ECG at the time of admission to hospital (n_p_ecg_p_04): Nominal		Cases	Fraction0: no		1580	92.94%1: yes		5	0.29%Missing		115	6.76%68. Type 2 Second-degree AV block (Mobitz II/Hay) on ECG at the time of admission to hospital (n_p_ecg_p_05): Nominal		Cases	Fraction0: no		1583	93.12%1: yes		2	0.12%Missing		115	6.76%69. Third-degree AV block on ECG at the time of admission to hospital (n_p_ecg_p_06): Nominal		Cases	Fraction0: no		1558	91.65%1: yes		27	1.59%Missing		115	6.76%70. LBBB (anterior branch) on ECG at the time of admission to hospital (n_p_ecg_p_07): Nominal		Cases	Fraction0: no		1483	87.24%1: yes		102	6.00%Missing		115	6.76%71. LBBB (posterior branch) on ECG at the time of admission to hospital (n_p_ecg_p_08): Nominal		Cases	Fraction0: no		1578	92.82%1: yes		7	0.41%Missing		115	6.76%72. Incomplete LBBB on ECG at the time of admission to hospital (n_p_ecg_p_09): Nominal		Cases	Fraction0: no		1575	92.65%1: yes		10	0.59%Missing		115	6.76%73. Complete LBBB on ECG at the time of admission to hospital (n_p_ecg_p_10): Nominal		Cases	Fraction0: no		1551	91.24%1: yes		34	2.00%Missing		115	6.76%74. Incomplete RBBB on ECG at the time of admission to hospital (n_p_ecg_p_11): Nominal		Cases	Fraction0: no		1557	91.59%1: yes		28	1.65%Missing		115	6.76%75. Complete RBBB on ECG at the time of admission to hospital (n_p_ecg_p_12):		Cases	Fraction0: no		1507	88.65%1: yes		78	4.59%Missing		115	6.76%76. Fibrinolytic therapy by Ã�Â¡Ã�Âµliasum 750k IU (fibr_ter_01): Nominal		Cases	Fraction0: no		1677	98.65%1: yes		13	0.76%Missing		10	0.59%77. Fibrinolytic therapy by Ã�Â¡Ã�Âµliasum 1m IU (fibr_ter_02): Nominal		Cases	Fraction0: no		1674	98.47%1: yes		16	0.94%Missing		10	0.59%78. Fibrinolytic therapy by Ã�Â¡Ã�Âµliasum 3m IU (fibr_ter_03): Nominal		Cases	Fraction0: no		1622	95.41%1: yes		68	4.00%Missing		10	0.59%79. Fibrinolytic therapy by Streptase (fibr_ter_05): Nominal		Cases	Fraction0: no		1686	99.18%1: yes		4	0.24%Missing		10	0.59%80. Fibrinolytic therapy by Ã�Â¡Ã�Âµliasum 500k IU (fibr_ter_06): Nominal		Cases	Fraction0: no		1681	98.88%1: yes		9	0.53%Missing		10	0.59%81. Fibrinolytic therapy by Ã�Â¡Ã�Âµliasum 250k IU (fibr_ter_07): Nominal		Cases	Fraction0: no		1684	99.06%1: yes		6	0.35%Missing		10	0.59%82. Fibrinolytic therapy by Streptodecase 1.5m IU (fibr_ter_08): Nominal		Cases	Fraction0: no		1688	99.29%1: yes		2	0.12%Missing		10	0.59%83. Hypokalemia ( < 4 mmol/L) (GIPO_K): Nominal		Cases	Fraction0: no		797	46.88%1: yes		534	31.41%Missing		369	21.71%84. Serum potassium content (K_BLOOD) (mmol/L): Real.85 Increase of sodium in serum (more than 150 mmol/L) (GIPER_Na): Nominal		Cases	Fraction0: no		1295	76.18%1: yes		30	1.76%Missing		375	22.06%86. Serum sodium content (Na_BLOOD) (mmol/L): Real.87. Serum AlAT content (ALT_BLOOD) (IU/L): Real.88. Serum AsAT content (AST_BLOOD) (IU/L): Real.89. Serum CPK content (KFK_BLOOD) (IU/L): Real.90. White blood cell count (billions per liter) (L_BLOOD): Real.91. ESR (Erythrocyte sedimentation rate) (ROE) (Ã�Â¼Ã�Â¼): Real.92. Time elapsed from the beginning of the attack of CHD to the hospital (TIME_B_S): Ordinal			Cases	Fraction1: less than 2 hours	198	11.65%2: 2-4 hours		360	21.18%3: 4-6 hours		175	10.29%4: 6-8 hours		87	5.12%5: 8-12 hours		92	5.41%6: 12-24 hours		151	8.88%7: more than 1 days	141	8.29%8: more than 2 days	101	5.94%9: more than 3 days	269	15.82%Missing			126	7.41%93. Relapse of the pain in the first hours of the hospital period (R_AB_1_n): Ordinal			Cases	Fraction0: there is no relapse	1282	75.41%1: only one		298	17.53%2: 2 times		78	4.59%3: 3 or more times 	26	1.53%Missing			16	0.94%94. Relapse of the pain in the second day of the hospital period (R_AB_2_n): Ordinal			Cases	Fraction0: there is no relapse	1414	83.18%1: only one		133	7.82%2: 2 times		44	2.59%3: 3 or more times 	1	0.06%Missing			108	6.35%95. Relapse of the pain in the third day of the hospital period (R_AB_3_n): Ordinal			Cases	Fraction0: there is no relapse	1469	86.41%1: only one		86	5.06%2: 2 times		15	0.88%3: 3 or more times	2	0.12%Missing			1469	86.41%96. Use of opioid drugs by the Emergency Cardiology Team (NA_KB): Nominal		Cases	Fraction0: no		425	25.00%1: yes		618	36.35%Missing		657	38.65%97. Use of NSAIDs by the Emergency Cardiology Team (NOT_NA_KB): Nominal		Cases	Fraction0: no		313	18.41%1: yes		701	41.23%Missing		375	22.06%98.Use of lidocaine by the Emergency Cardiology Team (LID_KB): Nominal		Cases	Fraction0: no		627	36.88%1: yes		396	23.29%Missing		677	39.82%99. Use of liquid nitrates in the ICU (NITR_S): Nominal		Cases	Fraction0: no		1496	88.00%1: yes		195	11.47%Missing		9	0.53%100. Use of opioid drugs in the ICU in the first hours of the hospital period (NA_R_1_n): Ordinal		Cases	Fraction0: no		1108	65.18%1: once	409	24.06%2: twice	132	7.76%3: three times	35	2.06%4: four times	11	0.65%Missing		5	0.29%	101. Use of opioid drugs in the ICU in the second day of the hospital period (NA_R_2_n): Ordinal		Cases	Fraction0: no		1474	86.71%1: once	87	5.12%2: twice	30	1.76%3: three times	1	0.06%Missing		108	6.35%102. Use of opioid drugs in the ICU in the third day of the hospital period (NA_R_3_n): Ordinal		Cases	Fraction0: no		1493	87.82%1: once	60	3.53%2: twice	16	0.94%Missing		131	7.71%103. Use of NSAIDs in the ICU in the first hours of the hospital period (NOT_NA_1_n): Ordinal			Cases	Fraction0: no			1237	72.76%1: once		376	22.12%2: twice		53	3.12%3: three times		17	1.00%4: four or more times	7	0.41%Missing			10	0.59%104. Use of NSAIDs in the ICU in the second day of the hospital period (NOT_NA_2_n): Ordinal		Cases	Fraction0: no		1454	85.53%1: once	95	5.59%2: twice	38	2.24%3: three times	3	0.18%Missing		110	6.47%105. Use of NSAIDs in the ICU in the third day of the hospital period (NOT_NA_3_n): Ordinal		Cases	Fraction0: no		1474	86.71%1: once	57	3.35%2: twice	38	2.24%Missing		131	7.71%106. Use of lidocaine in the ICU (LID_S_n): Nominal		Cases	Fraction0: no		1211	71.24%1: yes		479	28.18%Missing		10	0.59%107. Use of beta-blockers in the ICU (B_BLOK_S_n): Nominal		Cases	Fraction0: no		1474	86.71%1: yes		215	12.65%Missing		11	0.65%108. Use of calcium channel blockers in the ICU (ANT_CA_S_n): Nominal		Cases	Fraction0: no		562	33.06%1: yes		1125	66.18%Missing		13	0.76%109. Use of Ã�Â° anticoagulants (heparin) in the ICU (GEPAR_S_n): Nominal		Cases	Fraction0: no		480	28.24%1: yes		1203	70.76%Missing		17	1.00%110. Use of acetylsalicylic acid in the ICU (ASP_S_n): Nominal		Cases	Fraction0: no		431	25.35%1: yes		1252	73.65%Missing		17	1.00%111. Use of Ticlid in the ICU (TIKL_S_n): Nominal		Cases	Fraction0: no		1654	97.29%1: yes		30	1.76%Missing		16	0.94%112. Use of Trental in the ICU (TRENT_S_n): Nominal		Cases	Fraction0: no		1343	79.00%1: yes		341	20.06%Missing		16	0.94%Complications and outcomes of myocardial infarction: 113. Atrial fibrillation (FIBR_PREDS): Nominal		Cases	Fraction0: no		1530	90.00%1: yes 	170	10.00%Missing		0	0%114. Supraventricular tachycardia (PREDS_TAH): Nominal		Cases	Fraction0: no		1680	98.82%1: yes 	20	1.18%Missing		0	0%115. Ventricular tachycardia (JELUD_TAH): Nominal		Cases	Fraction0: no		1658	97.53%1: yes 	42	2.47%Missing		0	0%116. Ventricular fibrillation (FIBR_JELUD): Nominal		Cases	Fraction0: no		1629	95.82%1: yes 	71	4.18%Missing		0	0%117. Third-degree AV block (A_V_BLOK): Nominal		Cases	Fraction0: no		1643	96.65%1: yes 	57	3.35%Missing		0	0%118. Pulmonary edema (OTEK_LANC): Nominal		Cases	Fraction0: no		1541	90.65%1: yes 	159	9.35%Missing		0	0%119. Myocardial rupture (RAZRIV): Nominal		Cases	Fraction0: no		1646	96.82%1: yes 	54	3.18%Missing		0	0%120. Dressler syndrome (DRESSLER): Nominal		Cases	Fraction0: no		1625	95.59%1: yes 	75	4.41%Missing		0	0%121. Chronic heart failure (ZSN): Nominal		Cases	Fraction0: no		1306	76.82%1: yes 	394	23.18%Missing		0	0%122. Relapse of the myocardial infarction (REC_IM): Nominal		Cases	Fraction0: no		1541	90.65%1: yes 	159	9.35%Missing		0	0%123. Post-infarction angina (P_IM_STEN): Nominal		Cases	Fraction0: no		1552	91.29%1: yes 	148	8.71%Missing		0	0%124. Lethal outcome (cause) (LET_IS): Structure						Cases	Fraction0: unknown (alive)				1429	84.06%1: cardiogenic shock				110	6.47%2: pulmonary edema				18	1.06%3: myocardial rupture				54	3.18%4: progress of congestive heart failure	23	1.35%5: thromboembolism				12	0.71%6: asystole					27	1.59%7: ventricular fibrillation			27	1.59%Missing						0	0%Summary statistics for real attributesAttribute	Min	Max	Mean	STD	Missing cases	Missing fractionAge		26	92	61.86	11.26	8		0.47%S_AD_KBRIG	0	260	136.91	34.97	1076		63.29%D_AD_KBRIG	0	190	81.39	19.73	1076		63.29%S_AD_ORIT	0	260	134.59	31.34	267		15.71%D_AD_ORIT	0	190	82.75	18.31	267		15.71%K_BLOOD		2.3	8.2	4.19	0.75	371		21.82%Na_BLOOD	117	169	136.55	6.51	375		22.06%ALT_BLOOD	0.03	3	0.48	0.39	284		16.71%AST_BLOOD	0.04	2.15	0.26	0.2	285		16.67%KFK_BLOOD	1.2	3.6	2	0.95	1696		99.76%L_BLOOD		2	27.9	8.78	3.40	125		7.35%ROE		1	140	13.44	11.29	203		19.94%"
EEG Database,EEG Database,This data arises from a large study to examine EEG correlates of genetic predisposition to alcoholism. It contains measurements from 64 electrodes placed on the scalp sampled at 256 Hz,EEG+Database,https://archive.ics.uci.edu/ml//machine-learning-databases/eeg-mld/,https://archive.ics.uci.edu/ml/datasets/EEG+Database,"This data arises from a large study to examine EEG correlates of genetic predisposition to alcoholism. It contains measurements from 64 electrodes placed on subject's scalps which were sampled at 256 Hz (3.9-msec epoch) for 1 second. There were two groups of subjects: alcoholic and control. Each subject was exposed to either a single stimulus (S1) or to two stimuli (S1 and S2) which were pictures of objects chosen from the 1980 Snodgrass and Vanderwart picture set. When two stimuli were shown, they were presented in either a matched condition where S1 was identical to S2 or in a non-matched condition where S1 differed from S2. Shown here are example plots of a control ([Web Link]) and alcoholic ([Web Link]) subject. The plots indicate voltage, time, and channel and are averaged over 10 trials for the single stimulus condition. There were 122 subjects and each subject completed 120 trials where different stimuli were shown. The electrode positions were located at standard sites (Standard Electrode Position Nomenclature, American Electroencephalographic Association 1990). Zhang et al. (1995) describes in detail the data collection process. There are three versions of the EEG data set. 1. The Small Data SetThe small data set (smni97_eeg_data.tar.gz) contains data for the 2 subjects, alcoholic a_co2a0000364 and control c_co2c0000337. For each of the 3 matching paradigms, c_1 (one presentation only), c_m (match to previous presentation) and c_n (no-match to previous presentation), 10 runs are shown. 2.  The Large Data SetThe large data set (SMNI_CMI_TRAIN.tar.gz and SMNI_CMI_TEST.tar.gz) contains data for 10 alcoholic and 10 control subjects, with 10 runs per subject per paradigm. The test data used the same 10 alcoholic and 10 control subjects as with the training data, but with 10 out-of-sample runs per subject per paradigm. 3. The Full Data SetThis data set contains all 120 trials for 122 subjects. The entire set of data is about 700 MBytes. NOTE: There are 17 trials with empty files in co2c1000367. Some trials have ""err"" notices, e.g., search/grep for ""err"" and see ""S2 match err"" or ""S2 nomatch err"" etc. ",Life,"Each trial is stored in its own file and will appear in the following format. # co2a0000364.rd# 120 trials, 64 chans, 416 samples 368 post_stim samples# 3.906000 msecs uV# S1 obj , trial 0# FP1 chan 00 FP1 0 -8.9210 FP1 1 -8.4330 FP1 2 -2.5740 FP1 3 5.2390 FP1 4 11.5870 FP1 5 14.028     ...The first four lines are header information. Line 1 contains the subject identifier and indicates if the subject was an alcholic (a) or control (c) subject by the fourth letter. Line 4 identifies the matching conditions: a single object shown (S1 obj), object 2 shown in a matching condition (S2 match), and object 2 shown in a non matching condition (S2 nomatch). Line 5 identifies the start of the data from sensor FP1. The four columns of data are: the trial number, sensor position, sample number (0-255), and sensor value (in micro volts). ","This data arises from a large study to examine EEG correlates of genetic predisposition to alcoholism. It contains measurements from 64 electrodes placed on the scalp sampled at 256 HzThis data arises from a large study to examine EEG correlates of genetic predisposition to alcoholism. It contains measurements from 64 electrodes placed on subject's scalps which were sampled at 256 Hz (3.9-msec epoch) for 1 second. There were two groups of subjects: alcoholic and control. Each subject was exposed to either a single stimulus (S1) or to two stimuli (S1 and S2) which were pictures of objects chosen from the 1980 Snodgrass and Vanderwart picture set. When two stimuli were shown, they were presented in either a matched condition where S1 was identical to S2 or in a non-matched condition where S1 differed from S2. Shown here are example plots of a control ([Web Link]) and alcoholic ([Web Link]) subject. The plots indicate voltage, time, and channel and are averaged over 10 trials for the single stimulus condition. There were 122 subjects and each subject completed 120 trials where different stimuli were shown. The electrode positions were located at standard sites (Standard Electrode Position Nomenclature, American Electroencephalographic Association 1990). Zhang et al. (1995) describes in detail the data collection process. There are three versions of the EEG data set. 1. The Small Data SetThe small data set (smni97_eeg_data.tar.gz) contains data for the 2 subjects, alcoholic a_co2a0000364 and control c_co2c0000337. For each of the 3 matching paradigms, c_1 (one presentation only), c_m (match to previous presentation) and c_n (no-match to previous presentation), 10 runs are shown. 2.  The Large Data SetThe large data set (SMNI_CMI_TRAIN.tar.gz and SMNI_CMI_TEST.tar.gz) contains data for 10 alcoholic and 10 control subjects, with 10 runs per subject per paradigm. The test data used the same 10 alcoholic and 10 control subjects as with the training data, but with 10 out-of-sample runs per subject per paradigm. 3. The Full Data SetThis data set contains all 120 trials for 122 subjects. The entire set of data is about 700 MBytes. NOTE: There are 17 trials with empty files in co2c1000367. Some trials have ""err"" notices, e.g., search/grep for ""err"" and see ""S2 match err"" or ""S2 nomatch err"" etc. Each trial is stored in its own file and will appear in the following format. # co2a0000364.rd# 120 trials, 64 chans, 416 samples 368 post_stim samples# 3.906000 msecs uV# S1 obj , trial 0# FP1 chan 00 FP1 0 -8.9210 FP1 1 -8.4330 FP1 2 -2.5740 FP1 3 5.2390 FP1 4 11.5870 FP1 5 14.028     ...The first four lines are header information. Line 1 contains the subject identifier and indicates if the subject was an alcholic (a) or control (c) subject by the fourth letter. Line 4 identifies the matching conditions: a single object shown (S1 obj), object 2 shown in a matching condition (S2 match), and object 2 shown in a non matching condition (S2 nomatch). Line 5 identifies the start of the data from sensor FP1. The four columns of data are: the trial number, sensor position, sample number (0-255), and sensor value (in micro volts). "
Molecular Biology (Promoter Gene Sequences),Molecular Biology (Promoter Gene Sequences),E. Coli promoter gene sequences (DNA) with partial domain theory,Molecular+Biology+%28Promoter+Gene+Sequences%29,https://archive.ics.uci.edu/ml//machine-learning-databases/molecular-biology/promoter-gene-sequences/,https://archive.ics.uci.edu/ml/datasets/Molecular+Biology+%28Promoter+Gene+Sequences%29,"This dataset has been developed to help evaluate a ""hybrid"" learning algorithm (""KBANN"") that uses examples to inductively refine preexisting knowledge.  Using a ""leave-one-out"" methodology, the following errors were produced by various ML algorithms.  (See Towell, Shavlik, & Noordewier, 1990, for details.)System -- Errors -- Comments ----------------------------------------------------------------KBANN -- 4/106 -- a hybrid ML systemBP --  8/106 -- std backprop with one hidden layerO'Neill -- 12/106  -- ad hoc technique from the bio. lit.Near-Neigh -- 13/106 -- a nearest-neighbor algo (k=3)ID3 -- 19/106 -- Quinlan's decision-tree builder	     	Type of domain: non-numeric, nominal (one of A, G, T, C)Note: DNA nucleotides can be grouped into a hierarchy, as shown below:		      X (any)		    /   \	  (purine) R     Y (pyrimidine)		  / \   / \		 A   G T   CHere is that hierachy in a text-friendly format:X (any). R (purine). . A. . G. Y (pyrimidine). . T. . C",Life,"1.   One of {+/-}, indicating the class (""+"" = promoter).2.   The instance name (non-promoters named by position in the 1500-long nucleotide sequence provided by T. Record).3-59.   The remaining 57 fields are the sequence, starting at position -50 (p-50) and ending at position +7 (p7). Each of these fields is filled by one of {a, g, t, c}.","E. Coli promoter gene sequences (DNA) with partial domain theoryThis dataset has been developed to help evaluate a ""hybrid"" learning algorithm (""KBANN"") that uses examples to inductively refine preexisting knowledge.  Using a ""leave-one-out"" methodology, the following errors were produced by various ML algorithms.  (See Towell, Shavlik, & Noordewier, 1990, for details.)System -- Errors -- Comments ----------------------------------------------------------------KBANN -- 4/106 -- a hybrid ML systemBP --  8/106 -- std backprop with one hidden layerO'Neill -- 12/106  -- ad hoc technique from the bio. lit.Near-Neigh -- 13/106 -- a nearest-neighbor algo (k=3)ID3 -- 19/106 -- Quinlan's decision-tree builder	     	Type of domain: non-numeric, nominal (one of A, G, T, C)Note: DNA nucleotides can be grouped into a hierarchy, as shown below:		      X (any)		    /   \	  (purine) R     Y (pyrimidine)		  / \   / \		 A   G T   CHere is that hierachy in a text-friendly format:X (any). R (purine). . A. . G. Y (pyrimidine). . T. . C1.   One of {+/-}, indicating the class (""+"" = promoter).2.   The instance name (non-promoters named by position in the 1500-long nucleotide sequence provided by T. Record).3-59.   The remaining 57 fields are the sequence, starting at position -50 (p-50) and ending at position +7 (p7). Each of these fields is filled by one of {a, g, t, c}."
EEG Eye State,EEG Eye State,The data set consists of 14 EEG values and a value indicating the eye state.,EEG+Eye+State,https://archive.ics.uci.edu/ml//machine-learning-databases/00264/,https://archive.ics.uci.edu/ml/datasets/EEG+Eye+State,All data is from one continuous EEG measurement with the Emotiv EEG Neuroheadset. The duration of the measurement was 117 seconds. The eye state was detected via a camera during the EEG measurement and added later manually to the file after analysing the video frames. '1' indicates the eye-closed and '0' the eye-open state. All values are in chronological order with the first measured value at the top of the data.,Life,Provide information about each attribute in your data set.,The data set consists of 14 EEG values and a value indicating the eye state.All data is from one continuous EEG measurement with the Emotiv EEG Neuroheadset. The duration of the measurement was 117 seconds. The eye state was detected via a camera during the EEG measurement and added later manually to the file after analysing the video frames. '1' indicates the eye-closed and '0' the eye-open state. All values are in chronological order with the first measured value at the top of the data.Provide information about each attribute in your data set.
Mushroom,Mushroom,From Audobon Society Field Guide; mushrooms described in terms of physical characteristics; classification: poisonous or edible,Mushroom,https://archive.ics.uci.edu/ml//machine-learning-databases/mushroom/,https://archive.ics.uci.edu/ml/datasets/Mushroom,"This data set includes descriptions of hypothetical samples corresponding to 23 species of gilled mushrooms in the Agaricus and Lepiota Family (pp. 500-525).  Each species is identified as definitely edible, definitely poisonous, or of unknown edibility and not recommended.  This latter class was combined with the poisonous one.  The Guide clearly states that there is no simple rule for determining the edibility of a mushroom; no rule like ``leaflets three, let it be'' for Poisonous Oak and Ivy.",Life,"     1. cap-shape:                bell=b,conical=c,convex=x,flat=f, knobbed=k,sunken=s     2. cap-surface:              fibrous=f,grooves=g,scaly=y,smooth=s     3. cap-color:                brown=n,buff=b,cinnamon=c,gray=g,green=r, pink=p,purple=u,red=e,white=w,yellow=y     4. bruises?:                 bruises=t,no=f     5. odor:                     almond=a,anise=l,creosote=c,fishy=y,foul=f, musty=m,none=n,pungent=p,spicy=s     6. gill-attachment:          attached=a,descending=d,free=f,notched=n     7. gill-spacing:             close=c,crowded=w,distant=d     8. gill-size:                broad=b,narrow=n     9. gill-color:               black=k,brown=n,buff=b,chocolate=h,gray=g, green=r,orange=o,pink=p,purple=u,red=e, white=w,yellow=y    10. stalk-shape:              enlarging=e,tapering=t    11. stalk-root:               bulbous=b,club=c,cup=u,equal=e, rhizomorphs=z,rooted=r,missing=?    12. stalk-surface-above-ring: fibrous=f,scaly=y,silky=k,smooth=s    13. stalk-surface-below-ring: fibrous=f,scaly=y,silky=k,smooth=s    14. stalk-color-above-ring:   brown=n,buff=b,cinnamon=c,gray=g,orange=o, pink=p,red=e,white=w,yellow=y    15. stalk-color-below-ring:   brown=n,buff=b,cinnamon=c,gray=g,orange=o, pink=p,red=e,white=w,yellow=y    16. veil-type:                partial=p,universal=u    17. veil-color:               brown=n,orange=o,white=w,yellow=y    18. ring-number:              none=n,one=o,two=t    19. ring-type:                cobwebby=c,evanescent=e,flaring=f,large=l, none=n,pendant=p,sheathing=s,zone=z    20. spore-print-color:        black=k,brown=n,buff=b,chocolate=h,green=r, orange=o,purple=u,white=w,yellow=y    21. population:               abundant=a,clustered=c,numerous=n, scattered=s,several=v,solitary=y    22. habitat:                  grasses=g,leaves=l,meadows=m,paths=p, urban=u,waste=w,woods=d","From Audobon Society Field Guide; mushrooms described in terms of physical characteristics; classification: poisonous or edibleThis data set includes descriptions of hypothetical samples corresponding to 23 species of gilled mushrooms in the Agaricus and Lepiota Family (pp. 500-525).  Each species is identified as definitely edible, definitely poisonous, or of unknown edibility and not recommended.  This latter class was combined with the poisonous one.  The Guide clearly states that there is no simple rule for determining the edibility of a mushroom; no rule like ``leaflets three, let it be'' for Poisonous Oak and Ivy.     1. cap-shape:                bell=b,conical=c,convex=x,flat=f, knobbed=k,sunken=s     2. cap-surface:              fibrous=f,grooves=g,scaly=y,smooth=s     3. cap-color:                brown=n,buff=b,cinnamon=c,gray=g,green=r, pink=p,purple=u,red=e,white=w,yellow=y     4. bruises?:                 bruises=t,no=f     5. odor:                     almond=a,anise=l,creosote=c,fishy=y,foul=f, musty=m,none=n,pungent=p,spicy=s     6. gill-attachment:          attached=a,descending=d,free=f,notched=n     7. gill-spacing:             close=c,crowded=w,distant=d     8. gill-size:                broad=b,narrow=n     9. gill-color:               black=k,brown=n,buff=b,chocolate=h,gray=g, green=r,orange=o,pink=p,purple=u,red=e, white=w,yellow=y    10. stalk-shape:              enlarging=e,tapering=t    11. stalk-root:               bulbous=b,club=c,cup=u,equal=e, rhizomorphs=z,rooted=r,missing=?    12. stalk-surface-above-ring: fibrous=f,scaly=y,silky=k,smooth=s    13. stalk-surface-below-ring: fibrous=f,scaly=y,silky=k,smooth=s    14. stalk-color-above-ring:   brown=n,buff=b,cinnamon=c,gray=g,orange=o, pink=p,red=e,white=w,yellow=y    15. stalk-color-below-ring:   brown=n,buff=b,cinnamon=c,gray=g,orange=o, pink=p,red=e,white=w,yellow=y    16. veil-type:                partial=p,universal=u    17. veil-color:               brown=n,orange=o,white=w,yellow=y    18. ring-number:              none=n,one=o,two=t    19. ring-type:                cobwebby=c,evanescent=e,flaring=f,large=l, none=n,pendant=p,sheathing=s,zone=z    20. spore-print-color:        black=k,brown=n,buff=b,chocolate=h,green=r, orange=o,purple=u,white=w,yellow=y    21. population:               abundant=a,clustered=c,numerous=n, scattered=s,several=v,solitary=y    22. habitat:                  grasses=g,leaves=l,meadows=m,paths=p, urban=u,waste=w,woods=d"
Diabetes,Diabetes,This diabetes dataset is from AIM '94,Diabetes,https://archive.ics.uci.edu/ml//machine-learning-databases/diabetes/,https://archive.ics.uci.edu/ml/datasets/Diabetes,"Diabetes patient records were obtained from two sources:  an automatic electronic recording device and paper records.  The automatic device had an internal clock to timestamp events, whereas the paper records only provided ""logical time"" slots (breakfast, lunch, dinner, bedtime).  For paper records, fixed times were assigned to breakfast (08:00), lunch (12:00), dinner (18:00), and bedtime (22:00).  Thus paper records have fictitious uniform recording times whereas electronic records have more realistic time stamps.Diabetes files consist of four fields per record.  Each field is separated by a tab and each record is separated by a newline.File Names and format:(1) Date in MM-DD-YYYY format(2) Time in XX:YY format(3) Code(4) ValueThe Code field is deciphered as follows:33 = Regular insulin dose34 = NPH insulin dose35 = UltraLente insulin dose48 = Unspecified blood glucose measurement57 = Unspecified blood glucose measurement58 = Pre-breakfast blood glucose measurement59 = Post-breakfast blood glucose measurement60 = Pre-lunch blood glucose measurement61 = Post-lunch blood glucose measurement62 = Pre-supper blood glucose measurement63 = Post-supper blood glucose measurement64 = Pre-snack blood glucose measurement65 = Hypoglycemic symptoms66 = Typical meal ingestion67 = More-than-usual meal ingestion68 = Less-than-usual meal ingestion69 = Typical exercise activity70 = More-than-usual exercise activity71 = Less-than-usual exercise activity72 = Unspecified special event ",Life,Diabetes files consist of four fields per record.  Each field is separated by a tab and each record is separated by a newline.File Names and format:(1) Date in MM-DD-YYYY format(2) Time in XX:YY format(3) Code(4) Value,"This diabetes dataset is from AIM '94Diabetes patient records were obtained from two sources:  an automatic electronic recording device and paper records.  The automatic device had an internal clock to timestamp events, whereas the paper records only provided ""logical time"" slots (breakfast, lunch, dinner, bedtime).  For paper records, fixed times were assigned to breakfast (08:00), lunch (12:00), dinner (18:00), and bedtime (22:00).  Thus paper records have fictitious uniform recording times whereas electronic records have more realistic time stamps.Diabetes files consist of four fields per record.  Each field is separated by a tab and each record is separated by a newline.File Names and format:(1) Date in MM-DD-YYYY format(2) Time in XX:YY format(3) Code(4) ValueThe Code field is deciphered as follows:33 = Regular insulin dose34 = NPH insulin dose35 = UltraLente insulin dose48 = Unspecified blood glucose measurement57 = Unspecified blood glucose measurement58 = Pre-breakfast blood glucose measurement59 = Post-breakfast blood glucose measurement60 = Pre-lunch blood glucose measurement61 = Post-lunch blood glucose measurement62 = Pre-supper blood glucose measurement63 = Post-supper blood glucose measurement64 = Pre-snack blood glucose measurement65 = Hypoglycemic symptoms66 = Typical meal ingestion67 = More-than-usual meal ingestion68 = Less-than-usual meal ingestion69 = Typical exercise activity70 = More-than-usual exercise activity71 = Less-than-usual exercise activity72 = Unspecified special event Diabetes files consist of four fields per record.  Each field is separated by a tab and each record is separated by a newline.File Names and format:(1) Date in MM-DD-YYYY format(2) Time in XX:YY format(3) Code(4) Value"
Horton General Hospital,Horton General Hospital,"Horton General Hospital is in the town Banbury not far from Oxford, UK.",Horton+General+Hospital,https://archive.ics.uci.edu/ml//machine-learning-databases/00549/,https://archive.ics.uci.edu/ml/datasets/Horton+General+Hospital,"Cardio, Resp, Hypo are monthly numbers of transfers from Emergency Room into Critical Care classified in three exclusive categories at Horton General Hospital. Adm is the monthly total number of patients entering Emergency Room. In February 2004 nurse Ben Geen was arrested, accused of deliberately harming 18 patients in the 3 months December 2003 - February 2004. He later got a life sentence and is still in jail.The three categories are Cardio-respiratory arrest, Respiratory arrest, Hypoglycaemic arrest. The data has been analysed in a paper presently under preparation [Web Link] and the data of other hospitals was analysed in  [Web Link]",Life,Please read the cited papers,"Horton General Hospital is in the town Banbury not far from Oxford, UK.Cardio, Resp, Hypo are monthly numbers of transfers from Emergency Room into Critical Care classified in three exclusive categories at Horton General Hospital. Adm is the monthly total number of patients entering Emergency Room. In February 2004 nurse Ben Geen was arrested, accused of deliberately harming 18 patients in the 3 months December 2003 - February 2004. He later got a life sentence and is still in jail.The three categories are Cardio-respiratory arrest, Respiratory arrest, Hypoglycaemic arrest. The data has been analysed in a paper presently under preparation [Web Link] and the data of other hospitals was analysed in  [Web Link]Please read the cited papers"
HIV-1 protease cleavage,HIV-1 protease cleavage,The data contains lists of octamers (8 amino acids) and a flag (-1 or 1) depending on whether HIV-1 protease will cleave in the central position (between amino acids 4 and 5).,HIV-1+protease+cleavage,https://archive.ics.uci.edu/ml//machine-learning-databases/00330/,https://archive.ics.uci.edu/ml/datasets/HIV-1+protease+cleavage,"Past Usage:   (a) RÃ¶gnvaldsson, You and Garwicz (2015) 'State of the art prediction of HIV-1 protease        cleavage sites', Bioinformatics, vol 31 (8), pp. 1204-1210.       - Discusses the characteristics of the four data sets.       - It is shown that a linear SVM with standard orthogonal encoding is the best         predictor when tested across data sets. The AUC (Area Under the ROC Curve)         values are listed below:                     Test data  746         1625        Schilling   Impens   Train data   746                   -           0.982       0.870       0.833   1625                  0.981       -           0.855       0.811   Schilling             0.933       0.935       -           0.911   Impens                0.902       0.894       0.929       -   The 746 and 1625 data sets share many patterns.      (b) Kontijevskis, Wikberg and Komorowski (2007) 'Computational Proteomics Analysis of HIV-1 Protease        Interactome'. Proteins: Structure, Function, and Bioinformatics, 68, 305Ã¢â‚¬â€œ312.        Introduced the 1625 data set and used rough set theory on it.       Note: the 1625 data set used by Kontijevskis et al. is not identical to the 1625 data       set here, there is one octamer that has a different label (same octamer as for the       746 data set).   (c) You, Garwicz and RÃ¶gnvaldsson (2005) 'Comprehensive Bioinformatic Analysis of the Specificity        of Human Immunodeficiency Virus Type 1 Protease'. Journal of Virology, 79, 12477Ã¢â‚¬â€œ12486.        Introduced the 746 data set and explored linear classifiers plus representations       based on amino acid properties.       Note: the 746 data set used by You et al. is not identical to the 746 data       set here, there is one octamer that has a different label (same octamer as for the       1625 data set).Other relevant information   The data sets have appeared in earlier publications (see references in RÃ¶gnvaldsson et al. 2015).    However, corrections have been made to them here.      Details on references where data has been collected are provided for the 746 and the 1625 data set.    The origins of the Schilling data and the Impens data are described in the paper RÃ¶gnvaldsson et al., 2015.",Life,"Each attribute is a letter denoting an amino acid. G (Glycine, Gly); P (Proline, Pro); A (Alanine, Ala); V (Valine, Val); L (Leucine, Leu); I (Isoleucine, Ile); M (Methionine, Met); C (Cysteine, Cys); F (Phenylalanine, Phe); Y (Tyrosine, Tyr); W (Tryptophan, Trp); H (Histidine, His); K (Lysine, Lys); R (Arginine, Arg); Q (Glutamine, Gln); N (Asparagine, Asn); E (Glutamic Acid, Glu); D (Aspartic Acid, Asp); S (Serine, Ser); T (Threonine, Thr). The output denotes cleaved (+1) or not cleaved (-1).","The data contains lists of octamers (8 amino acids) and a flag (-1 or 1) depending on whether HIV-1 protease will cleave in the central position (between amino acids 4 and 5).Past Usage:   (a) RÃ¶gnvaldsson, You and Garwicz (2015) 'State of the art prediction of HIV-1 protease        cleavage sites', Bioinformatics, vol 31 (8), pp. 1204-1210.       - Discusses the characteristics of the four data sets.       - It is shown that a linear SVM with standard orthogonal encoding is the best         predictor when tested across data sets. The AUC (Area Under the ROC Curve)         values are listed below:                     Test data  746         1625        Schilling   Impens   Train data   746                   -           0.982       0.870       0.833   1625                  0.981       -           0.855       0.811   Schilling             0.933       0.935       -           0.911   Impens                0.902       0.894       0.929       -   The 746 and 1625 data sets share many patterns.      (b) Kontijevskis, Wikberg and Komorowski (2007) 'Computational Proteomics Analysis of HIV-1 Protease        Interactome'. Proteins: Structure, Function, and Bioinformatics, 68, 305Ã¢â‚¬â€œ312.        Introduced the 1625 data set and used rough set theory on it.       Note: the 1625 data set used by Kontijevskis et al. is not identical to the 1625 data       set here, there is one octamer that has a different label (same octamer as for the       746 data set).   (c) You, Garwicz and RÃ¶gnvaldsson (2005) 'Comprehensive Bioinformatic Analysis of the Specificity        of Human Immunodeficiency Virus Type 1 Protease'. Journal of Virology, 79, 12477Ã¢â‚¬â€œ12486.        Introduced the 746 data set and explored linear classifiers plus representations       based on amino acid properties.       Note: the 746 data set used by You et al. is not identical to the 746 data       set here, there is one octamer that has a different label (same octamer as for the       1625 data set).Other relevant information   The data sets have appeared in earlier publications (see references in RÃ¶gnvaldsson et al. 2015).    However, corrections have been made to them here.      Details on references where data has been collected are provided for the 746 and the 1625 data set.    The origins of the Schilling data and the Impens data are described in the paper RÃ¶gnvaldsson et al., 2015.Each attribute is a letter denoting an amino acid. G (Glycine, Gly); P (Proline, Pro); A (Alanine, Ala); V (Valine, Val); L (Leucine, Leu); I (Isoleucine, Ile); M (Methionine, Met); C (Cysteine, Cys); F (Phenylalanine, Phe); Y (Tyrosine, Tyr); W (Tryptophan, Trp); H (Histidine, His); K (Lysine, Lys); R (Arginine, Arg); Q (Glutamine, Gln); N (Asparagine, Asn); E (Glutamic Acid, Glu); D (Aspartic Acid, Asp); S (Serine, Ser); T (Threonine, Thr). The output denotes cleaved (+1) or not cleaved (-1)."
Daphnet Freezing of Gait,Daphnet Freezing of Gait,"This dataset contains the annotated readings of 3 acceleration sensors at the hip and leg of Parkinson's disease patients that experience freezing of gait (FoG) during walking tasks.
",Daphnet+Freezing+of+Gait,https://archive.ics.uci.edu/ml//machine-learning-databases/00245/,https://archive.ics.uci.edu/ml/datasets/Daphnet+Freezing+of+Gait,"The Daphnet Freezing of Gait Dataset is a dataset devised to benchmark automatic methods to recognize gait freeze from wearable acceleration sensors placed on legs and hip.The dataset was recorded in the lab with emphasis on generating many freeze events. Users performed there kinds of tasks: straight line walking, walking with numerous turns, and finally a more realistic activity of daily living (ADL) task, where users went into different rooms while fetching coffee, opening doors, etc.This dataset is the result of a collaboration between the Laboratory for Gait and Neurodynamics, Tel Aviv Sourasky Medical Center, Israel and the Wearable Computing Laboratory, ETH Zurich, Switzerland. Recordings were run at the Tel Aviv Sourasky Medical Center in 2008. The study was approved by the local Human Subjects Review Committee, and was performed in accordance with the ethical standards of the Declaration of Helsinki.",Life,"Each file comprises the data in a matrix format, with one line per sample, and one column per channel. The channels are as follows:    Time of sample in millisecond    Ankle (shank) acceleration - horizontal forward acceleration [mg]    Ankle (shank) acceleration - vertical [mg]    Ankle (shank) acceleration - horizontal lateral [mg]    Upper leg (thigh) acceleration - horizontal forward acceleration [mg]    Upper leg (thigh) acceleration - vertical [mg]    Upper leg (thigh) acceleration - horizontal lateral [mg]    Trunk acceleration - horizontal forward acceleration [mg]    Trunk acceleration - vertical [mg]    Trunk acceleration - horizontal lateral [mg]    Annotation [0, 1, or 2]The meaning of the annotations are as follows:    0: not part of the experiment. For instance the sensors are installed on the user or the user is performing activities unrelated to the experimental protocol, such as debriefing    1: experiment, no freeze (can be any of stand, walk, turn)    2: freeze","This dataset contains the annotated readings of 3 acceleration sensors at the hip and leg of Parkinson's disease patients that experience freezing of gait (FoG) during walking tasks.
The Daphnet Freezing of Gait Dataset is a dataset devised to benchmark automatic methods to recognize gait freeze from wearable acceleration sensors placed on legs and hip.The dataset was recorded in the lab with emphasis on generating many freeze events. Users performed there kinds of tasks: straight line walking, walking with numerous turns, and finally a more realistic activity of daily living (ADL) task, where users went into different rooms while fetching coffee, opening doors, etc.This dataset is the result of a collaboration between the Laboratory for Gait and Neurodynamics, Tel Aviv Sourasky Medical Center, Israel and the Wearable Computing Laboratory, ETH Zurich, Switzerland. Recordings were run at the Tel Aviv Sourasky Medical Center in 2008. The study was approved by the local Human Subjects Review Committee, and was performed in accordance with the ethical standards of the Declaration of Helsinki.Each file comprises the data in a matrix format, with one line per sample, and one column per channel. The channels are as follows:    Time of sample in millisecond    Ankle (shank) acceleration - horizontal forward acceleration [mg]    Ankle (shank) acceleration - vertical [mg]    Ankle (shank) acceleration - horizontal lateral [mg]    Upper leg (thigh) acceleration - horizontal forward acceleration [mg]    Upper leg (thigh) acceleration - vertical [mg]    Upper leg (thigh) acceleration - horizontal lateral [mg]    Trunk acceleration - horizontal forward acceleration [mg]    Trunk acceleration - vertical [mg]    Trunk acceleration - horizontal lateral [mg]    Annotation [0, 1, or 2]The meaning of the annotations are as follows:    0: not part of the experiment. For instance the sensors are installed on the user or the user is performing activities unrelated to the experimental protocol, such as debriefing    1: experiment, no freeze (can be any of stand, walk, turn)    2: freeze"
Horse Colic,Horse Colic,"Well documented attributes; 368 instances with 28 attributes (continuous, discrete, and nominal); 30% missing values",Horse+Colic,https://archive.ics.uci.edu/ml//machine-learning-databases/horse-colic/,https://archive.ics.uci.edu/ml/datasets/Horse+Colic,"2 data files:       -- horse-colic.data: 300 training instances      -- horse-colic.test: 68 test instancesPossible class attributes: 24 (whether lesion is surgical)     -- others include: 23, 25, 26, and 27Many Data types: (continuous, discrete, and nominal)",Life,"  1:  surgery?          1 = Yes, it had surgery          2 = It was treated without surgery  2:  Age           1 = Adult horse          2 = Young (< 6 months)  3:  Hospital Number           - numeric id          - the case number assigned to the horse (may not be unique if the horse is treated > 1 time)  4:  rectal temperature          - linear          - in degrees celsius.          - An elevated temp may occur due to infection.          - temperature may be reduced when the animal is in late shock          - normal temp is 37.8          - this parameter will usually change as the problem progresses, eg. may start out normal, then become elevated because of the lesion, passing back through the normal range as the horse goes into shock  5:  pulse           - linear          - the heart rate in beats per minute          - is a reflection of the heart condition: 30 -40 is normal for adults          - rare to have a lower than normal rate although athletic horses may have a rate of 20-25          - animals with painful lesions or suffering from circulatory shock may have an elevated heart rate  6:  respiratory rate          - linear          - normal rate is 8 to 10          - usefulness is doubtful due to the great fluctuations  7:  temperature of extremities          - a subjective indication of peripheral circulation          - possible values:               1 = Normal               2 = Warm               3 = Cool               4 = Cold          - cool to cold extremities indicate possible shock          - hot extremities should correlate with an elevated rectal temp.  8:  peripheral pulse          - subjective          - possible values are:               1 = normal               2 = increased               3 = reduced               4 = absent          - normal or increased p.p. are indicative of adequate circulation while reduced or absent indicate poor perfusion  9:  mucous membranes          - a subjective measurement of colour          - possible values are:               1 = normal pink               2 = bright pink               3 = pale pink               4 = pale cyanotic               5 = bright red / injected               6 = dark cyanotic          - 1 and 2 probably indicate a normal or slightly increased circulation          - 3 may occur in early shock          - 4 and 6 are indicative of serious circulatory compromise          - 5 is more indicative of a septicemia 10: capillary refill time          - a clinical judgement. The longer the refill, the poorer the circulation          - possible values               1 = < 3 seconds               2 = >= 3 seconds 11: pain - a subjective judgement of the horse's pain level          - possible values:               1 = alert, no pain               2 = depressed               3 = intermittent mild pain               4 = intermittent severe pain               5 = continuous severe pain          - should NOT be treated as a ordered or discrete variable!          - In general, the more painful, the more likely it is to require surgery          - prior treatment of pain may mask the pain level to some extent 12: peristalsis                                        - an indication of the activity in the horse's gut. As the gut becomes more distended or the horse becomes more toxic, the activity decreases          - possible values:               1 = hypermotile               2 = normal               3 = hypomotile               4 = absent 13: abdominal distension          - An IMPORTANT parameter.          - possible values               1 = none               2 = slight               3 = moderate               4 = severe          - an animal with abdominal distension is likely to be painful and have reduced gut motility.          - a horse with severe abdominal distension is likely to require surgery just tio relieve the pressure 14: nasogastric tube          - this refers to any gas coming out of the tube          - possible values:               1 = none               2 = slight               3 = significant          - a large gas cap in the stomach is likely to give the horse discomfort 15: nasogastric reflux          - possible values               1 = none               2 = > 1 liter               3 = < 1 liter          - the greater amount of reflux, the more likelihood that there is some serious obstruction to the fluid passage from the rest of the intestine 16: nasogastric reflux PH          - linear          - scale is from 0 to 14 with 7 being neutral          - normal values are in the 3 to 4 range 17: rectal examination - feces          - possible values               1 = normal               2 = increased               3 = decreased               4 = absent          - absent feces probably indicates an obstruction 18: abdomen          - possible values               1 = normal               2 = other               3 = firm feces in the large intestine               4 = distended small intestine               5 = distended large intestine          - 3 is probably an obstruction caused by a mechanical impaction and is normally treated medically          - 4 and 5 indicate a surgical lesion 19: packed cell volume          - linear          - the # of red cells by volume in the blood          - normal range is 30 to 50. The level rises as the circulation becomes compromised or as the animal becomes dehydrated. 20: total protein          - linear          - normal values lie in the 6-7.5 (gms/dL) range          - the higher the value the greater the dehydration 21: abdominocentesis appearance          - a needle is put in the horse's abdomen and fluid is obtained from            the abdominal cavity          - possible values:               1 = clear               2 = cloudy               3 = serosanguinous          - normal fluid is clear while cloudy or serosanguinous indicates a compromised gut 22: abdomcentesis total protein          - linear          - the higher the level of protein the more likely it is to have a compromised gut. Values are in gms/dL 23: outcome          - what eventually happened to the horse?          - possible values:               1 = lived               2 = died               3 = was euthanized 24: surgical lesion?          - retrospectively, was the problem (lesion) surgical?          - all cases are either operated upon or autopsied so that this value and the lesion type are always known          - possible values:               1 = Yes               2 = No 25, 26, 27: type of lesion          - first number is site of lesion               1 = gastric               2 = sm intestine               3 = lg colon               4 = lg colon and cecum               5 = cecum               6 = transverse colon               7 = retum/descending colon               8 = uterus               9 = bladder               11 = all intestinal sites               00 = none          - second number is type               1 = simple               2 = strangulation               3 = inflammation               4 = other          - third number is subtype               1 = mechanical               2 = paralytic               0 = n/a          - fourth number is specific code               1 = obturation               2 = intrinsic               3 = extrinsic               4 = adynamic               5 = volvulus/torsion               6 = intussuption               7 = thromboembolic               8 = hernia               9 = lipoma/slenic incarceration               10 = displacement               0 = n/a 28: cp_data          - is pathology data present for this case?               1 = Yes               2 = No          - this variable is of no significance since pathology data is not included or collected for these cases","Well documented attributes; 368 instances with 28 attributes (continuous, discrete, and nominal); 30% missing values2 data files:       -- horse-colic.data: 300 training instances      -- horse-colic.test: 68 test instancesPossible class attributes: 24 (whether lesion is surgical)     -- others include: 23, 25, 26, and 27Many Data types: (continuous, discrete, and nominal)  1:  surgery?          1 = Yes, it had surgery          2 = It was treated without surgery  2:  Age           1 = Adult horse          2 = Young (< 6 months)  3:  Hospital Number           - numeric id          - the case number assigned to the horse (may not be unique if the horse is treated > 1 time)  4:  rectal temperature          - linear          - in degrees celsius.          - An elevated temp may occur due to infection.          - temperature may be reduced when the animal is in late shock          - normal temp is 37.8          - this parameter will usually change as the problem progresses, eg. may start out normal, then become elevated because of the lesion, passing back through the normal range as the horse goes into shock  5:  pulse           - linear          - the heart rate in beats per minute          - is a reflection of the heart condition: 30 -40 is normal for adults          - rare to have a lower than normal rate although athletic horses may have a rate of 20-25          - animals with painful lesions or suffering from circulatory shock may have an elevated heart rate  6:  respiratory rate          - linear          - normal rate is 8 to 10          - usefulness is doubtful due to the great fluctuations  7:  temperature of extremities          - a subjective indication of peripheral circulation          - possible values:               1 = Normal               2 = Warm               3 = Cool               4 = Cold          - cool to cold extremities indicate possible shock          - hot extremities should correlate with an elevated rectal temp.  8:  peripheral pulse          - subjective          - possible values are:               1 = normal               2 = increased               3 = reduced               4 = absent          - normal or increased p.p. are indicative of adequate circulation while reduced or absent indicate poor perfusion  9:  mucous membranes          - a subjective measurement of colour          - possible values are:               1 = normal pink               2 = bright pink               3 = pale pink               4 = pale cyanotic               5 = bright red / injected               6 = dark cyanotic          - 1 and 2 probably indicate a normal or slightly increased circulation          - 3 may occur in early shock          - 4 and 6 are indicative of serious circulatory compromise          - 5 is more indicative of a septicemia 10: capillary refill time          - a clinical judgement. The longer the refill, the poorer the circulation          - possible values               1 = < 3 seconds               2 = >= 3 seconds 11: pain - a subjective judgement of the horse's pain level          - possible values:               1 = alert, no pain               2 = depressed               3 = intermittent mild pain               4 = intermittent severe pain               5 = continuous severe pain          - should NOT be treated as a ordered or discrete variable!          - In general, the more painful, the more likely it is to require surgery          - prior treatment of pain may mask the pain level to some extent 12: peristalsis                                        - an indication of the activity in the horse's gut. As the gut becomes more distended or the horse becomes more toxic, the activity decreases          - possible values:               1 = hypermotile               2 = normal               3 = hypomotile               4 = absent 13: abdominal distension          - An IMPORTANT parameter.          - possible values               1 = none               2 = slight               3 = moderate               4 = severe          - an animal with abdominal distension is likely to be painful and have reduced gut motility.          - a horse with severe abdominal distension is likely to require surgery just tio relieve the pressure 14: nasogastric tube          - this refers to any gas coming out of the tube          - possible values:               1 = none               2 = slight               3 = significant          - a large gas cap in the stomach is likely to give the horse discomfort 15: nasogastric reflux          - possible values               1 = none               2 = > 1 liter               3 = < 1 liter          - the greater amount of reflux, the more likelihood that there is some serious obstruction to the fluid passage from the rest of the intestine 16: nasogastric reflux PH          - linear          - scale is from 0 to 14 with 7 being neutral          - normal values are in the 3 to 4 range 17: rectal examination - feces          - possible values               1 = normal               2 = increased               3 = decreased               4 = absent          - absent feces probably indicates an obstruction 18: abdomen          - possible values               1 = normal               2 = other               3 = firm feces in the large intestine               4 = distended small intestine               5 = distended large intestine          - 3 is probably an obstruction caused by a mechanical impaction and is normally treated medically          - 4 and 5 indicate a surgical lesion 19: packed cell volume          - linear          - the # of red cells by volume in the blood          - normal range is 30 to 50. The level rises as the circulation becomes compromised or as the animal becomes dehydrated. 20: total protein          - linear          - normal values lie in the 6-7.5 (gms/dL) range          - the higher the value the greater the dehydration 21: abdominocentesis appearance          - a needle is put in the horse's abdomen and fluid is obtained from            the abdominal cavity          - possible values:               1 = clear               2 = cloudy               3 = serosanguinous          - normal fluid is clear while cloudy or serosanguinous indicates a compromised gut 22: abdomcentesis total protein          - linear          - the higher the level of protein the more likely it is to have a compromised gut. Values are in gms/dL 23: outcome          - what eventually happened to the horse?          - possible values:               1 = lived               2 = died               3 = was euthanized 24: surgical lesion?          - retrospectively, was the problem (lesion) surgical?          - all cases are either operated upon or autopsied so that this value and the lesion type are always known          - possible values:               1 = Yes               2 = No 25, 26, 27: type of lesion          - first number is site of lesion               1 = gastric               2 = sm intestine               3 = lg colon               4 = lg colon and cecum               5 = cecum               6 = transverse colon               7 = retum/descending colon               8 = uterus               9 = bladder               11 = all intestinal sites               00 = none          - second number is type               1 = simple               2 = strangulation               3 = inflammation               4 = other          - third number is subtype               1 = mechanical               2 = paralytic               0 = n/a          - fourth number is specific code               1 = obturation               2 = intrinsic               3 = extrinsic               4 = adynamic               5 = volvulus/torsion               6 = intussuption               7 = thromboembolic               8 = hernia               9 = lipoma/slenic incarceration               10 = displacement               0 = n/a 28: cp_data          - is pathology data present for this case?               1 = Yes               2 = No          - this variable is of no significance since pathology data is not included or collected for these cases"
Cuff-Less Blood Pressure Estimation,Cuff-Less Blood Pressure Estimation,This Data set provides preprocessed and cleaned vital signals which can be used in designing algorithms for cuff-less estimation of the blood pressure.,Cuff-Less+Blood+Pressure+Estimation,https://archive.ics.uci.edu/ml//machine-learning-databases/00340/,https://archive.ics.uci.edu/ml/datasets/Cuff-Less+Blood+Pressure+Estimation,"The main goal of this data set is providing clean and valid signals for designing cuff-less blood pressure estimation algorithms. The raw electrocardiogram (ECG), photoplethysmograph (PPG), and arterial blood pressure (ABP) signals are originally collected from the physionet.org and then some preprocessing and validation performed on them. (For more information about the process please refer to our paper)",Life,"The data set is in matlab's v7.3 mat file, accordingly it should be opened using new versions of matlab or HDF libraries in other environments.(Please refer to the Web for more information about this format)This database consist of a cell array of matrices, each cell is one record part.In each matrix each row corresponds to one signal channel: 1: PPG signal, FS=125Hz;  photoplethysmograph from fingertip2: ABP signal, FS=125Hz; invasive arterial blood pressure (mmHg)3: ECG signal, FS=125Hz; electrocardiogram from channel II","This Data set provides preprocessed and cleaned vital signals which can be used in designing algorithms for cuff-less estimation of the blood pressure.The main goal of this data set is providing clean and valid signals for designing cuff-less blood pressure estimation algorithms. The raw electrocardiogram (ECG), photoplethysmograph (PPG), and arterial blood pressure (ABP) signals are originally collected from the physionet.org and then some preprocessing and validation performed on them. (For more information about the process please refer to our paper)The data set is in matlab's v7.3 mat file, accordingly it should be opened using new versions of matlab or HDF libraries in other environments.(Please refer to the Web for more information about this format)This database consist of a cell array of matrices, each cell is one record part.In each matrix each row corresponds to one signal channel: 1: PPG signal, FS=125Hz;  photoplethysmograph from fingertip2: ABP signal, FS=125Hz; invasive arterial blood pressure (mmHg)3: ECG signal, FS=125Hz; electrocardiogram from channel II"
EEG Steady-State Visual Evoked Potential Signals,EEG Steady-State Visual Evoked Potential Signals,This database consists on 30 subjects performing Brain Computer Interface for Steady State Visual Evoked Potentials (BCI-SSVEP). ,EEG+Steady-State+Visual+Evoked+Potential+Signals,https://archive.ics.uci.edu/ml//machine-learning-databases/00457/,https://archive.ics.uci.edu/ml/datasets/EEG+Steady-State+Visual+Evoked+Potential+Signals,"The tests are explained in more detail in the articles attached to the databases. The tests are visual experiments, so the signal you may be more interested in are the electrodes O1 and O2 (Columns I and J) according to the extensive literature review and international standards. Each subject performed different tests which are provided in .csv format as follows: suppose you have a .csv which name is A001SB1_1 This means the data corresponds to group A (only Group A is provided at present), subject 001, Test SB1 (Five Box Visual Test), and first experiment (_1, there could be a repetition of the experiment which will be _2, _3, etc). The different tests are as follows: SB1 - Five Box Visual Test 1, SB2 - Five Box Visual Test 2, SB3 - Five Box Visual Test 3 (There are three different Five Box tests, these are not repetitions of the same test), SV1 - Visual Image Search, SM1 - Motor Images (Hand Shake Experiment). Since these experiments are visual tests, you may be interested in the electrodes O1 and O2. A file named Signal Database.xlsx is provided with a list of every experiment carried out and the subjects for each experiment. The real name of each subject are not provided due to confidentiality issues.",Life,"There are 16 attributes, of which the last 14 are the signals coming from the electrodes. They are named according to international standards (see the references). The first two are the time-domain and a signal called interpolated which is normally 0.","This database consists on 30 subjects performing Brain Computer Interface for Steady State Visual Evoked Potentials (BCI-SSVEP). The tests are explained in more detail in the articles attached to the databases. The tests are visual experiments, so the signal you may be more interested in are the electrodes O1 and O2 (Columns I and J) according to the extensive literature review and international standards. Each subject performed different tests which are provided in .csv format as follows: suppose you have a .csv which name is A001SB1_1 This means the data corresponds to group A (only Group A is provided at present), subject 001, Test SB1 (Five Box Visual Test), and first experiment (_1, there could be a repetition of the experiment which will be _2, _3, etc). The different tests are as follows: SB1 - Five Box Visual Test 1, SB2 - Five Box Visual Test 2, SB3 - Five Box Visual Test 3 (There are three different Five Box tests, these are not repetitions of the same test), SV1 - Visual Image Search, SM1 - Motor Images (Hand Shake Experiment). Since these experiments are visual tests, you may be interested in the electrodes O1 and O2. A file named Signal Database.xlsx is provided with a list of every experiment carried out and the subjects for each experiment. The real name of each subject are not provided due to confidentiality issues.There are 16 attributes, of which the last 14 are the signals coming from the electrodes. They are named according to international standards (see the references). The first two are the time-domain and a signal called interpolated which is normally 0."
Molecular Biology (Splice-junction Gene Sequences),Molecular Biology (Splice-junction Gene Sequences),Primate splice-junction gene sequences (DNA) with associated imperfect domain theory,Molecular+Biology+%28Splice-junction+Gene+Sequences%29,https://archive.ics.uci.edu/ml//machine-learning-databases/molecular-biology/splice-junction-gene-sequences/,https://archive.ics.uci.edu/ml/datasets/Molecular+Biology+%28Splice-junction+Gene+Sequences%29,"Problem Description:       Splice junctions are points on a DNA sequence at which `superfluous' DNA is removed during the process of protein creation in higher organisms.  The problem posed in this dataset is to recognize, given a sequence of DNA, the boundaries between exons (the parts of the DNA sequence retained after splicing) and introns (the parts of the DNA sequence that are spliced out). This problem consists of two subtasks: recognizing exon/intron boundaries (referred to as EI sites), and recognizing intron/exon boundaries (IE sites). (In the biological community, IE borders are referred to a ``acceptors'' while EI borders are referred to as ``donors''.)This dataset has been developed to help evaluate a ""hybrid"" learning algorithm (KBANN) that uses examples to inductively refine preexisting knowledge.  Using a ""ten-fold cross-validation"" methodology on 1000 examples randomly selected from the complete set of 3190, the following  error rates were produced by various ML algorithms (all experiments run at the Univ of Wisconsin, sometimes with local implementations of published algorithms). System -- Neither -- EI -- IE---------------------------------------------------KBANN -- 4.62 -- 7.56 --  8.47BACKPROP -- 5.29 --  5.74 -- 10.75PEBLS -- 6.86 -- 8.18 -- 7.55PERCEPTRON -- 3.99 -- 16.32 -- 17.41ID3 -- 8.84 -- 10.58 -- 13.99COBWEB  -- 11.80 -- 15.04 -- 9.46Near. Neighbor -- 31.11 -- 11.65 -- 9.09",Life,"1.   One of {n ei ie}, indicating the class.2.   The instance name.3-62.   The remaining 60 fields are the sequence, starting at position -30 and ending at position +30. Each of these fields is almost always filled by one of {a, g, t, c}. Other characters indicate ambiguity among the standard characters according to the following table:			character: meaningD:  A or G or TN:  A or G or C or TS:  C or GR:  A or G","Primate splice-junction gene sequences (DNA) with associated imperfect domain theoryProblem Description:       Splice junctions are points on a DNA sequence at which `superfluous' DNA is removed during the process of protein creation in higher organisms.  The problem posed in this dataset is to recognize, given a sequence of DNA, the boundaries between exons (the parts of the DNA sequence retained after splicing) and introns (the parts of the DNA sequence that are spliced out). This problem consists of two subtasks: recognizing exon/intron boundaries (referred to as EI sites), and recognizing intron/exon boundaries (IE sites). (In the biological community, IE borders are referred to a ``acceptors'' while EI borders are referred to as ``donors''.)This dataset has been developed to help evaluate a ""hybrid"" learning algorithm (KBANN) that uses examples to inductively refine preexisting knowledge.  Using a ""ten-fold cross-validation"" methodology on 1000 examples randomly selected from the complete set of 3190, the following  error rates were produced by various ML algorithms (all experiments run at the Univ of Wisconsin, sometimes with local implementations of published algorithms). System -- Neither -- EI -- IE---------------------------------------------------KBANN -- 4.62 -- 7.56 --  8.47BACKPROP -- 5.29 --  5.74 -- 10.75PEBLS -- 6.86 -- 8.18 -- 7.55PERCEPTRON -- 3.99 -- 16.32 -- 17.41ID3 -- 8.84 -- 10.58 -- 13.99COBWEB  -- 11.80 -- 15.04 -- 9.46Near. Neighbor -- 31.11 -- 11.65 -- 9.091.   One of {n ei ie}, indicating the class.2.   The instance name.3-62.   The remaining 60 fields are the sequence, starting at position -30 and ending at position +30. Each of these fields is almost always filled by one of {a, g, t, c}. Other characters indicate ambiguity among the standard characters according to the following table:			character: meaningD:  A or G or TN:  A or G or C or TS:  C or GR:  A or G"
Molecular Biology (Protein Secondary Structure),Molecular Biology (Protein Secondary Structure),From CMU connectionist bench repository; Classifies secondary structure of certain globular proteins,Molecular+Biology+%28Protein+Secondary+Structure%29,https://archive.ics.uci.edu/ml//machine-learning-databases/molecular-biology/protein-secondary-structure/,https://archive.ics.uci.edu/ml/datasets/Molecular+Biology+%28Protein+Secondary+Structure%29,"This is a data set used by Ning Qian and Terry Sejnowski in their study using a neural net to predict the secondary structure of certain globular proteins [1].  The idea is to take a linear sequence of amino acids and to predict, for each of these amino acids, what secondary structure it is a part of within the protein.  There are three choices: alpha-helix, beta-sheet, and random-coil.  The data set contains both a large set of training data and a distinct set of data that can be used for testing the resulting network.  Qian and Sejnowski use a Nettalk-like approach and report an accuracy of 64.3% on the test set, and they speculate that this is about the best that can be done using only local context.There is also a domain theory in the folder, donated and created by Jude Shavlik & Rich Maclin",Life,,"From CMU connectionist bench repository; Classifies secondary structure of certain globular proteinsThis is a data set used by Ning Qian and Terry Sejnowski in their study using a neural net to predict the secondary structure of certain globular proteins [1].  The idea is to take a linear sequence of amino acids and to predict, for each of these amino acids, what secondary structure it is a part of within the protein.  There are three choices: alpha-helix, beta-sheet, and random-coil.  The data set contains both a large set of training data and a distinct set of data that can be used for testing the resulting network.  Qian and Sejnowski use a Nettalk-like approach and report an accuracy of 64.3% on the test set, and they speculate that this is about the best that can be done using only local context.There is also a domain theory in the folder, donated and created by Jude Shavlik & Rich Maclinnan"
Multi-view Brain Networks,Multi-view Brain Networks,Multi-layer brain network datasets derived from the resting-state electroencephalography (EEG) data.,Multi-view+Brain+Networks,https://archive.ics.uci.edu/ml//machine-learning-databases/00598/,https://archive.ics.uci.edu/ml/datasets/Multi-view+Brain+Networks,"For constructing the multi-layer brain network datasets, we collect the resting-state electroencephalography (EEG) data from Department of Otolaryngology of Sun Yat-sen Memorial Hospital, Sun Yat-sen University. Three types of subjects participate the experiments, namely 51 deafness patients, 54 tinnitus patients and 42 normal controls. Since there may exist significant differences of brain network among the three types of subjects, a separate multi-layer brain network is constructed for each type of subjects. The EEG data are collected by the EEG analyzer with 128 scalp electrodes from Electrical Geodesics, Inc. The standard data acquisition and preprocessing procedure is applied, based on which 128 electrode EEG data can be obtained. On the datasets, only the 70 electrodes belonging to the ten regions of interest (ROI) are used as shown in the graphic file. Notice that the electrodes C17 and A23 in regions CF and CO are two reference electrodes that are not used in our study. These 70 electrodes are further divided into two classes corresponding to the upper and lower parts. That is, the 34 electrodes in the upper ROIs, namely CF, LAL, LAM, RAM and RAL are grouped into one class, while the 36 electrodes in the lower ROIs, namely CO, LOT, LPM, RPM and ROT are grouped into another class. Based on the class labels, the ground-truth community labels of the 70 nodes corresponding to the 70 electrodes can be obtained. After obtaining 70 electrodes, the STUDY module of EEGLAB2 is used to extract the features of the preprocessed data, i.e., extracting the power values of different frequency bands. In our study, 9 different frequency bands are used, including Delta (1-4Hz), Theta (4-8Hz), Alpha1 (8-10Hz), Alpha2 (10-12Hz), Beta1 (13-18Hz), Beta2 (18-21Hz), Beta3 (21-30Hz), Gamma1 (30.5-45Hz) and Gamma2 (55-70Hz). In each frequency band, the Pearson correlation coefficient is calculated between each pair of electrodes, based on which the interconnection between electrodes can be constructed. That is, for any two electrodes, the Pearson correlation coefficient between their EEG data is calculated for each subject. Then the average value over the 51 deafness patients (resp. 54 tinnitus patients and 42 normal controls) is calculated. If the average value is no smaller than 0.3, the two electrodes are interconnected. In this way, a 9-layer network is constructed for the deafness patients (resp. tinnitus patients and normal controls), where each layer corresponds to each frequency band and is named accordingly. For simplicity, the 9-layer network for the deafness patients (resp. tinnitus patients and normal controls) is called DBrain (resp. TBrain and NBrain).",Life,See the relevant information.,"Multi-layer brain network datasets derived from the resting-state electroencephalography (EEG) data.For constructing the multi-layer brain network datasets, we collect the resting-state electroencephalography (EEG) data from Department of Otolaryngology of Sun Yat-sen Memorial Hospital, Sun Yat-sen University. Three types of subjects participate the experiments, namely 51 deafness patients, 54 tinnitus patients and 42 normal controls. Since there may exist significant differences of brain network among the three types of subjects, a separate multi-layer brain network is constructed for each type of subjects. The EEG data are collected by the EEG analyzer with 128 scalp electrodes from Electrical Geodesics, Inc. The standard data acquisition and preprocessing procedure is applied, based on which 128 electrode EEG data can be obtained. On the datasets, only the 70 electrodes belonging to the ten regions of interest (ROI) are used as shown in the graphic file. Notice that the electrodes C17 and A23 in regions CF and CO are two reference electrodes that are not used in our study. These 70 electrodes are further divided into two classes corresponding to the upper and lower parts. That is, the 34 electrodes in the upper ROIs, namely CF, LAL, LAM, RAM and RAL are grouped into one class, while the 36 electrodes in the lower ROIs, namely CO, LOT, LPM, RPM and ROT are grouped into another class. Based on the class labels, the ground-truth community labels of the 70 nodes corresponding to the 70 electrodes can be obtained. After obtaining 70 electrodes, the STUDY module of EEGLAB2 is used to extract the features of the preprocessed data, i.e., extracting the power values of different frequency bands. In our study, 9 different frequency bands are used, including Delta (1-4Hz), Theta (4-8Hz), Alpha1 (8-10Hz), Alpha2 (10-12Hz), Beta1 (13-18Hz), Beta2 (18-21Hz), Beta3 (21-30Hz), Gamma1 (30.5-45Hz) and Gamma2 (55-70Hz). In each frequency band, the Pearson correlation coefficient is calculated between each pair of electrodes, based on which the interconnection between electrodes can be constructed. That is, for any two electrodes, the Pearson correlation coefficient between their EEG data is calculated for each subject. Then the average value over the 51 deafness patients (resp. 54 tinnitus patients and 42 normal controls) is calculated. If the average value is no smaller than 0.3, the two electrodes are interconnected. In this way, a 9-layer network is constructed for the deafness patients (resp. tinnitus patients and normal controls), where each layer corresponds to each frequency band and is named accordingly. For simplicity, the 9-layer network for the deafness patients (resp. tinnitus patients and normal controls) is called DBrain (resp. TBrain and NBrain).See the relevant information."
Greenhouse Gas Observing Network,Greenhouse Gas Observing Network,"Design an observing network to monitor emissions of a greenhouse gas (GHG) in California given time series of synthetic observations and tracers from weather model simulations.
",Greenhouse+Gas+Observing+Network,https://archive.ics.uci.edu/ml//machine-learning-databases/00328/,https://archive.ics.uci.edu/ml/datasets/Greenhouse+Gas+Observing+Network,"This data set contains time series of greenhouse gas (GHG) concentrations at 2921 grid cells in California created using simulations of the Weather Research and Forecast model with Chemistry (WRF-Chem). Each grid cell covers an area of 12 km by 12 km, and there is one data file per grid cell. Each file contains 16 time series of GHG concentrations. The data points in the time series are spaced 6 hours apart (4 samples per day) over the period May 10 Ã¢â‚¬â€œ July 31, 2010. The first 15 rows are time series of GHG tracers released from 14 distinct spatial regions in California and one outside of California. The last row corresponds to the time series of Ã¢â‚¬Å“synthetic GHG observationsÃ¢â‚¬Â� generated with EDGAR emissions of HFC-134a scaled by a factor 0.7 and with noise added.Using this data, the goals are to (1) use inverse methods to determine the optimal values of the weights in the weighted sum of 15 tracers that best matches the synthetic observations, (2) and use optimization methods to determine the best locations to observe GHGs to constrain the inversion. We used a Bayesian method for (1) and genetic algorithms for (2). Further details about the data and methods are given in the publication 'Designing optimal greenhouse gas observing networks that consider performance and cost,' Geoscientific Instrumentation Methods and Data Systems.",Physical,"Each file in the data set is labeled ghg.gid.siteWXYZ.dat, where WXYZ is an integer location ID described in our manuscript.At each location,        Rows 1-15: GHG concentrations of tracers emitted from regions 1-15        Row 16: GHG concentrations of synthetic observations        Columns 1-327: GHG concentrations every 6 hours from May 10 Ã¢â‚¬â€œ July 31, 2010.All GHG concentrations are in units of parts per trillion.","Design an observing network to monitor emissions of a greenhouse gas (GHG) in California given time series of synthetic observations and tracers from weather model simulations.
This data set contains time series of greenhouse gas (GHG) concentrations at 2921 grid cells in California created using simulations of the Weather Research and Forecast model with Chemistry (WRF-Chem). Each grid cell covers an area of 12 km by 12 km, and there is one data file per grid cell. Each file contains 16 time series of GHG concentrations. The data points in the time series are spaced 6 hours apart (4 samples per day) over the period May 10 Ã¢â‚¬â€œ July 31, 2010. The first 15 rows are time series of GHG tracers released from 14 distinct spatial regions in California and one outside of California. The last row corresponds to the time series of Ã¢â‚¬Å“synthetic GHG observationsÃ¢â‚¬Â� generated with EDGAR emissions of HFC-134a scaled by a factor 0.7 and with noise added.Using this data, the goals are to (1) use inverse methods to determine the optimal values of the weights in the weighted sum of 15 tracers that best matches the synthetic observations, (2) and use optimization methods to determine the best locations to observe GHGs to constrain the inversion. We used a Bayesian method for (1) and genetic algorithms for (2). Further details about the data and methods are given in the publication 'Designing optimal greenhouse gas observing networks that consider performance and cost,' Geoscientific Instrumentation Methods and Data Systems.Each file in the data set is labeled ghg.gid.siteWXYZ.dat, where WXYZ is an integer location ID described in our manuscript.At each location,        Rows 1-15: GHG concentrations of tracers emitted from regions 1-15        Row 16: GHG concentrations of synthetic observations        Columns 1-327: GHG concentrations every 6 hours from May 10 Ã¢â‚¬â€œ July 31, 2010.All GHG concentrations are in units of parts per trillion."
HTRU2,HTRU2,"Pulsar candidates collected during the HTRU survey. Pulsars are a type of star, of considerable scientific interest. Candidates must be classified in to pulsar and non-pulsar classes to aid discovery.",HTRU2,https://archive.ics.uci.edu/ml//machine-learning-databases/00372/,https://archive.ics.uci.edu/ml/datasets/HTRU2,"HTRU2 is a data set which describes a sample of pulsar candidates collected during the High Time Resolution Universe Survey (South) [1]. Pulsars are a rare type of Neutron star that produce radio emission detectable here on Earth. They are of considerable scientific interest as probes of space-time, the inter-stellar medium, and states of matter (see [2] for more uses). As pulsars rotate, their emission beam sweeps across the sky, and when this crosses our line of sight, produces a detectable pattern of broadband radio emission. As pulsarsrotate rapidly, this pattern repeats periodically. Thus pulsar search involves looking for periodic radio signals with large radio telescopes.Each pulsar produces a slightly different emission pattern, which varies slightly with each rotation (see [2] for an introduction to pulsar astrophysics to find out why). Thus a  potential signal detection known as a 'candidate', is averaged over many rotations of the pulsar, as determined by the length of an observation. In the absence of additional info, each candidate could potentially describe a real pulsar. However in practice almost all detections are caused by radio frequency interference (RFI) and noise, making legitimate signals hard to find.Machine learning tools are now being used to automatically label pulsar candidates to facilitate rapid analysis. Classification systems in particular are being widely adopted,(see [4,5,6,7,8,9]) which treat the candidate data sets  as binary classification problems. Here the legitimate pulsar examples are a minority positive class, and spurious examples the majority negative class. At present multi-class labels are unavailable, given the costs associated with data annotation.The data set shared here contains 16,259 spurious examples caused by RFI/noise, and 1,639 real pulsar examples. These examples have all been checked by human annotators. The data is presented in two formats: CSV and ARFF (used by the WEKA data mining tool). Candidates are stored in both files in separate rows. Each row lists the variables first, and the class label is the final entry. The class labels used are 0 (negative) and 1 (positive).Please note that the data contains no positional information or other astronomical details. It is simply feature data extracted from candidate files using the PulsarFeatureLab tool (see [10]).",Physical,"Each candidate is described by 8 continuous variables, and a single class variable. The first four are simple statistics obtained from the integrated pulse profile (folded profile). This is an array of continuous variables that describe a longitude-resolved version of the signal that has been averaged in both time and frequency (see [3] for more details). The remaining four variables are similarly obtained from the DM-SNR curve (again see [3] for more details). These are summarised below:1. Mean of the integrated profile.2. Standard deviation of the integrated profile.3. Excess kurtosis of the integrated profile.4. Skewness of the integrated profile.5. Mean of the DM-SNR curve.6. Standard deviation of the DM-SNR curve.7. Excess kurtosis of the DM-SNR curve.8. Skewness of the DM-SNR curve.9. ClassHTRU 2 Summary17,898 total examples.1,639 positive examples.16,259 negative examples.","Pulsar candidates collected during the HTRU survey. Pulsars are a type of star, of considerable scientific interest. Candidates must be classified in to pulsar and non-pulsar classes to aid discovery.HTRU2 is a data set which describes a sample of pulsar candidates collected during the High Time Resolution Universe Survey (South) [1]. Pulsars are a rare type of Neutron star that produce radio emission detectable here on Earth. They are of considerable scientific interest as probes of space-time, the inter-stellar medium, and states of matter (see [2] for more uses). As pulsars rotate, their emission beam sweeps across the sky, and when this crosses our line of sight, produces a detectable pattern of broadband radio emission. As pulsarsrotate rapidly, this pattern repeats periodically. Thus pulsar search involves looking for periodic radio signals with large radio telescopes.Each pulsar produces a slightly different emission pattern, which varies slightly with each rotation (see [2] for an introduction to pulsar astrophysics to find out why). Thus a  potential signal detection known as a 'candidate', is averaged over many rotations of the pulsar, as determined by the length of an observation. In the absence of additional info, each candidate could potentially describe a real pulsar. However in practice almost all detections are caused by radio frequency interference (RFI) and noise, making legitimate signals hard to find.Machine learning tools are now being used to automatically label pulsar candidates to facilitate rapid analysis. Classification systems in particular are being widely adopted,(see [4,5,6,7,8,9]) which treat the candidate data sets  as binary classification problems. Here the legitimate pulsar examples are a minority positive class, and spurious examples the majority negative class. At present multi-class labels are unavailable, given the costs associated with data annotation.The data set shared here contains 16,259 spurious examples caused by RFI/noise, and 1,639 real pulsar examples. These examples have all been checked by human annotators. The data is presented in two formats: CSV and ARFF (used by the WEKA data mining tool). Candidates are stored in both files in separate rows. Each row lists the variables first, and the class label is the final entry. The class labels used are 0 (negative) and 1 (positive).Please note that the data contains no positional information or other astronomical details. It is simply feature data extracted from candidate files using the PulsarFeatureLab tool (see [10]).Each candidate is described by 8 continuous variables, and a single class variable. The first four are simple statistics obtained from the integrated pulse profile (folded profile). This is an array of continuous variables that describe a longitude-resolved version of the signal that has been averaged in both time and frequency (see [3] for more details). The remaining four variables are similarly obtained from the DM-SNR curve (again see [3] for more details). These are summarised below:1. Mean of the integrated profile.2. Standard deviation of the integrated profile.3. Excess kurtosis of the integrated profile.4. Skewness of the integrated profile.5. Mean of the DM-SNR curve.6. Standard deviation of the DM-SNR curve.7. Excess kurtosis of the DM-SNR curve.8. Skewness of the DM-SNR curve.9. ClassHTRU 2 Summary17,898 total examples.1,639 positive examples.16,259 negative examples."
Amazon Commerce reviews set,Amazon Commerce reviews set,The dataset is used for authorship identification in online Writeprint which is a new research field of pattern recognition. ,Amazon+Commerce+reviews+set,https://archive.ics.uci.edu/ml//machine-learning-databases/00215/,https://archive.ics.uci.edu/ml/datasets/Amazon+Commerce+reviews+set,"dataset are  derived  from  the customersÃ¢â‚¬â„¢ reviews  in Amazon Commerce Website for authorship identification. Most previous studies conducted  the identification experiments for two to ten authors. But in the online context, reviews to be identified usually have more potential authors, and normally classification algorithms are not adapted to large number of target classes. To examine the robustness of clasification algorithms, we identified 50 of the most active users (represented by a unique ID and username) who frequently posted reviews in these newsgroups. The number of reviews we collected for each author is 30.",Physical,"attribution includes authors' lingustic style such as usage of digit, punctuation, words and sentences' length and usage frequency of words and so on","The dataset is used for authorship identification in online Writeprint which is a new research field of pattern recognition. dataset are  derived  from  the customersÃ¢â‚¬â„¢ reviews  in Amazon Commerce Website for authorship identification. Most previous studies conducted  the identification experiments for two to ten authors. But in the online context, reviews to be identified usually have more potential authors, and normally classification algorithms are not adapted to large number of target classes. To examine the robustness of clasification algorithms, we identified 50 of the most active users (represented by a unique ID and username) who frequently posted reviews in these newsgroups. The number of reviews we collected for each author is 30.attribution includes authors' lingustic style such as usage of digit, punctuation, words and sentences' length and usage frequency of words and so on"
Robot Execution Failures,Robot Execution Failures,This dataset contains force and torque measurements on a robot after failure detection. Each failure is characterized by 15 force/torque samples collected at regular time intervals,Robot+Execution+Failures,https://archive.ics.uci.edu/ml//machine-learning-databases/robotfailure-mld/,https://archive.ics.uci.edu/ml/datasets/Robot+Execution+Failures,"The donation includes 5 datasets, each of them defining a different learning problem:    * LP1: failures in approach to grasp position    * LP2: failures in transfer of a part    * LP3: position of part after a transfer failure    * LP4: failures in approach to ungrasp position    * LP5: failures in motion with partIn order to improve classification accuracy, a set of five feature transformation strategies (based on statistical summary features, discrete Fourier transform, etc.) was defined and evaluated. This enabled an average improvement of 20% in accuracy. The most accessible reference is [Seabra Lopes and Camarinha-Matos, 1998].",Physical,"All features are numeric although they are integer valued only. Each feature represents a force or a torque measured after failure detection; each failure instance is characterized in terms of 15 force/torque samples collected at regular time intervals starting immediately after failure detection; The total observation window for each failure instance was of 315 ms.Each example is described as follows:                 class                 Fx1	Fy1	Fz1	Tx1	Ty1	Tz1                 Fx2	Fy2	Fz2	Tx2	Ty2	Tz2                 ......                 Fx15	Fy15	Fz15	Tx15	Ty15	Tz15where Fx1 ... Fx15 is the evolution of force Fx in the observation window, the same for Fy, Fz and the torques; there is a total of 90 features. ","This dataset contains force and torque measurements on a robot after failure detection. Each failure is characterized by 15 force/torque samples collected at regular time intervalsThe donation includes 5 datasets, each of them defining a different learning problem:    * LP1: failures in approach to grasp position    * LP2: failures in transfer of a part    * LP3: position of part after a transfer failure    * LP4: failures in approach to ungrasp position    * LP5: failures in motion with partIn order to improve classification accuracy, a set of five feature transformation strategies (based on statistical summary features, discrete Fourier transform, etc.) was defined and evaluated. This enabled an average improvement of 20% in accuracy. The most accessible reference is [Seabra Lopes and Camarinha-Matos, 1998].All features are numeric although they are integer valued only. Each feature represents a force or a torque measured after failure detection; each failure instance is characterized in terms of 15 force/torque samples collected at regular time intervals starting immediately after failure detection; The total observation window for each failure instance was of 315 ms.Each example is described as follows:                 class                 Fx1	Fy1	Fz1	Tx1	Ty1	Tz1                 Fx2	Fy2	Fz2	Tx2	Ty2	Tz2                 ......                 Fx15	Fy15	Fz15	Tx15	Ty15	Tz15where Fx1 ... Fx15 is the evolution of force Fx in the observation window, the same for Fy, Fz and the torques; there is a total of 90 features. "
SUSY,SUSY,This is a classification problem to distinguish between a signal process which produces supersymmetric particles and a background process which does not.,SUSY,https://archive.ics.uci.edu/ml//machine-learning-databases/00279/,https://archive.ics.uci.edu/ml/datasets/SUSY,"Provide all relevant informatioThe data has been produced using Monte Carlo simulations. The first 8 features are kinematic properties measured by the particle detectors in the accelerator. The last ten features are functions of the first 8 features; these are high-level features derived by physicists to help discriminate between the two classes. There is an interest in using deep learning methods to obviate the need for physicists to manually develop such features. Benchmark results using Bayesian Decision Trees from a standard physics package and 5-layer neural networks and the dropout algorithm are presented in the original paper. The last 500,000 examples are used as a test set.n about your data set.",Physical,"The first column is the class label (1 for signal, 0 for background), followed by the 18 features (8 low-level features then 10 high-level features):: lepton  1 pT, lepton  1 eta, lepton  1 phi, lepton  2 pT, lepton  2 eta, lepton  2 phi, missing energy magnitude, missing energy phi, MET_rel, axial MET, M_R, M_TR_2, R, MT2, S_R, M_Delta_R, dPhi_r_b, cos(theta_r1). For detailed information about each feature see the original paper.","This is a classification problem to distinguish between a signal process which produces supersymmetric particles and a background process which does not.Provide all relevant informatioThe data has been produced using Monte Carlo simulations. The first 8 features are kinematic properties measured by the particle detectors in the accelerator. The last ten features are functions of the first 8 features; these are high-level features derived by physicists to help discriminate between the two classes. There is an interest in using deep learning methods to obviate the need for physicists to manually develop such features. Benchmark results using Bayesian Decision Trees from a standard physics package and 5-layer neural networks and the dropout algorithm are presented in the original paper. The last 500,000 examples are used as a test set.n about your data set.The first column is the class label (1 for signal, 0 for background), followed by the 18 features (8 low-level features then 10 high-level features):: lepton  1 pT, lepton  1 eta, lepton  1 phi, lepton  2 pT, lepton  2 eta, lepton  2 phi, missing energy magnitude, missing energy phi, MET_rel, axial MET, M_R, M_TR_2, R, MT2, S_R, M_Delta_R, dPhi_r_b, cos(theta_r1). For detailed information about each feature see the original paper."
Superconductivty Data,Superconductivty Data,Two file s contain data on 21263 superconductors and their relevant features.,Superconductivty+Data,https://archive.ics.uci.edu/ml//machine-learning-databases/00464/,https://archive.ics.uci.edu/ml/datasets/Superconductivty+Data,"There are two files: (1) train.csv contains 81 features extracted from 21263 superconductors along with the critical temperature in the 82nd column, (2) unique_m.csv contains the chemical formula broken up for all the 21263 superconductors from the train.csv file.  The last two columns have the critical temperature and chemical formula.  The original data comes from [Web Link] which is public.  The goal here is to predict the critical temperature based on the features extracted.",Physical,Please see the relevant paper for the feature explanations.,"Two file s contain data on 21263 superconductors and their relevant features.There are two files: (1) train.csv contains 81 features extracted from 21263 superconductors along with the critical temperature in the 82nd column, (2) unique_m.csv contains the chemical formula broken up for all the 21263 superconductors from the train.csv file.  The last two columns have the critical temperature and chemical formula.  The original data comes from [Web Link] which is public.  The goal here is to predict the critical temperature based on the features extracted.Please see the relevant paper for the feature explanations."
Solar Flare,Solar Flare,Each class attribute counts the number of solar flares of a certain class that occur in a 24 hour period,Solar+Flare,https://archive.ics.uci.edu/ml//machine-learning-databases/solar-flare/,https://archive.ics.uci.edu/ml/datasets/Solar+Flare,"Notes:   -- The database contains 3 potential classes, one for the number of times a certain type of solar flare occured in a 24 hour period.   -- Each instance represents captured features for 1 active region on the sun.   -- The data are divided into two sections. The second section (flare.data2) has had much more error correction applied to the it, and has consequently been treated as more reliable.",Physical,"   1. Code for class (modified Zurich class)  (A,B,C,D,E,F,H)   2. Code for largest spot size              (X,R,S,A,H,K)   3. Code for spot distribution              (X,O,I,C)   4. Activity                                (1 = reduced, 2 = unchanged)   5. Evolution                               (1 = decay, 2 = no growth, 3 = growth)   6. Previous 24 hour flare activity code    (1 = nothing as big as an M1, 2 = one M1, 3 = more activity than one M1)   7. Historically-complex                    (1 = Yes, 2 = No)   8. Did region become historically complex  on this pass across the sun's disk (1 = yes, 2 = no)    9. Area                                    (1 = small, 2 = large)  10. Area of the largest spot                (1 = <=5, 2 = >5) From all these predictors three classes of flares are predicted, which are represented in the last three columns.  11. C-class flares production by this region in the following 24 hours (common flares); Number  12. M-class flares production by this region in the following 24 hours (moderate flares);   Number  13. X-class flares production by this region in the following 24 hours (severe flares); Number     ","Each class attribute counts the number of solar flares of a certain class that occur in a 24 hour periodNotes:   -- The database contains 3 potential classes, one for the number of times a certain type of solar flare occured in a 24 hour period.   -- Each instance represents captured features for 1 active region on the sun.   -- The data are divided into two sections. The second section (flare.data2) has had much more error correction applied to the it, and has consequently been treated as more reliable.   1. Code for class (modified Zurich class)  (A,B,C,D,E,F,H)   2. Code for largest spot size              (X,R,S,A,H,K)   3. Code for spot distribution              (X,O,I,C)   4. Activity                                (1 = reduced, 2 = unchanged)   5. Evolution                               (1 = decay, 2 = no growth, 3 = growth)   6. Previous 24 hour flare activity code    (1 = nothing as big as an M1, 2 = one M1, 3 = more activity than one M1)   7. Historically-complex                    (1 = Yes, 2 = No)   8. Did region become historically complex  on this pass across the sun's disk (1 = yes, 2 = no)    9. Area                                    (1 = small, 2 = large)  10. Area of the largest spot                (1 = <=5, 2 = >5) From all these predictors three classes of flares are predicted, which are represented in the last three columns.  11. C-class flares production by this region in the following 24 hours (common flares); Number  12. M-class flares production by this region in the following 24 hours (moderate flares);   Number  13. X-class flares production by this region in the following 24 hours (severe flares); Number     "
Glass Identification,Glass Identification,"From USA Forensic Science Service; 6 types of glass; defined in terms of their oxide content (i.e. Na, Fe, K, etc)",Glass+Identification,https://archive.ics.uci.edu/ml//machine-learning-databases/glass/,https://archive.ics.uci.edu/ml/datasets/Glass+Identification,"Vina conducted a comparison test of her rule-based system, BEAGLE, the nearest-neighbor algorithm, and discriminant analysis.  BEAGLE is a product available through VRS Consulting, Inc.; 4676 Admiralty Way, Suite 206; Marina Del Ray, CA 90292 (213) 827-7890 and FAX: -3189. In determining whether the glass was a type of ""float"" glass or not, the following results were obtained (# incorrect answers):Type of Sample  -- Beagle -- NN -- DAWindows that were float processed (87)  -- 10 -- 12 -- 21Windows that were not:            (76) -- 19 -- 16 -- 22The study of classification of types of glass was motivated by criminological investigation.  At the scene of the crime, the glass left can be used as evidence...if it is correctly identified!",Physical,"1. Id number: 1 to 2142. RI: refractive index3. Na: Sodium (unit measurement: weight percent in corresponding oxide, as are attributes 4-10)4. Mg: Magnesium5. Al: Aluminum6. Si: Silicon7. K: Potassium8. Ca: Calcium9. Ba: Barium10. Fe: Iron11. Type of glass: (class attribute)     -- 1 building_windows_float_processed     -- 2 building_windows_non_float_processed     -- 3 vehicle_windows_float_processed     -- 4 vehicle_windows_non_float_processed (none in this database)     -- 5 containers     -- 6 tableware     -- 7 headlamps","From USA Forensic Science Service; 6 types of glass; defined in terms of their oxide content (i.e. Na, Fe, K, etc)Vina conducted a comparison test of her rule-based system, BEAGLE, the nearest-neighbor algorithm, and discriminant analysis.  BEAGLE is a product available through VRS Consulting, Inc.; 4676 Admiralty Way, Suite 206; Marina Del Ray, CA 90292 (213) 827-7890 and FAX: -3189. In determining whether the glass was a type of ""float"" glass or not, the following results were obtained (# incorrect answers):Type of Sample  -- Beagle -- NN -- DAWindows that were float processed (87)  -- 10 -- 12 -- 21Windows that were not:            (76) -- 19 -- 16 -- 22The study of classification of types of glass was motivated by criminological investigation.  At the scene of the crime, the glass left can be used as evidence...if it is correctly identified!1. Id number: 1 to 2142. RI: refractive index3. Na: Sodium (unit measurement: weight percent in corresponding oxide, as are attributes 4-10)4. Mg: Magnesium5. Al: Aluminum6. Si: Silicon7. K: Potassium8. Ca: Calcium9. Ba: Barium10. Fe: Iron11. Type of glass: (class attribute)     -- 1 building_windows_float_processed     -- 2 building_windows_non_float_processed     -- 3 vehicle_windows_float_processed     -- 4 vehicle_windows_non_float_processed (none in this database)     -- 5 containers     -- 6 tableware     -- 7 headlamps"
Annealing,Annealing,Steel annealing data,Annealing,https://archive.ics.uci.edu/ml//machine-learning-databases/annealing/,https://archive.ics.uci.edu/ml/datasets/Annealing,,Physical,"Attribute Listing:    1. family:		--,GB,GK,GS,TN,ZA,ZF,ZH,ZM,ZS    2. product-type:	C, H, G    3. steel:		-,R,A,U,K,M,S,W,V    4. carbon:		continuous    5. hardness:	continuous    6. temper_rolling:	-,T    7. condition:	-,S,A,X    8. formability:	-,1,2,3,4,5    9. strength:	continuous   10. non-ageing:	-,N   11. surface-finish:	P,M,-   12. surface-quality: -,D,E,F,G   13. enamelability:	-,1,2,3,4,5   14. bc:		Y,-   15. bf:		Y,-   16. bt:		Y,-   17. bw/me:		B,M,-   18. bl:		Y,-   19. m:		Y,-   20. chrom:		C,-   21. phos:		P,-   22. cbond:		Y,-   23. marvi:		Y,-   24. exptl:		Y,-   25. ferro:		Y,-   26. corr:		Y,-   27. blue/bright/varn/clean:		B,R,V,C,-   28. lustre:		Y,-   29. jurofm:		Y,-   30. s:		Y,-   31. p:		Y,-   32. shape:		COIL, SHEET   33. thick:		continuous   34. width:		continuous   35. len:		continuous   36. oil:		-,Y,N   37. bore:		0000,0500,0600,0760   38. packing:	-,1,2,3   classes:        1,2,3,4,5,U    -- The '-' values are actually 'not_applicable' values rather than 'missing_values' (and so can be treated as legal discrete values rather than as showing the absence of a discrete value).","Steel annealing datananAttribute Listing:    1. family:		--,GB,GK,GS,TN,ZA,ZF,ZH,ZM,ZS    2. product-type:	C, H, G    3. steel:		-,R,A,U,K,M,S,W,V    4. carbon:		continuous    5. hardness:	continuous    6. temper_rolling:	-,T    7. condition:	-,S,A,X    8. formability:	-,1,2,3,4,5    9. strength:	continuous   10. non-ageing:	-,N   11. surface-finish:	P,M,-   12. surface-quality: -,D,E,F,G   13. enamelability:	-,1,2,3,4,5   14. bc:		Y,-   15. bf:		Y,-   16. bt:		Y,-   17. bw/me:		B,M,-   18. bl:		Y,-   19. m:		Y,-   20. chrom:		C,-   21. phos:		P,-   22. cbond:		Y,-   23. marvi:		Y,-   24. exptl:		Y,-   25. ferro:		Y,-   26. corr:		Y,-   27. blue/bright/varn/clean:		B,R,V,C,-   28. lustre:		Y,-   29. jurofm:		Y,-   30. s:		Y,-   31. p:		Y,-   32. shape:		COIL, SHEET   33. thick:		continuous   34. width:		continuous   35. len:		continuous   36. oil:		-,Y,N   37. bore:		0000,0500,0600,0760   38. packing:	-,1,2,3   classes:        1,2,3,4,5,U    -- The '-' values are actually 'not_applicable' values rather than 'missing_values' (and so can be treated as legal discrete values rather than as showing the absence of a discrete value)."
Ionosphere,Ionosphere,Classification of radar returns from the ionosphere,Ionosphere,https://archive.ics.uci.edu/ml//machine-learning-databases/ionosphere/,https://archive.ics.uci.edu/ml/datasets/Ionosphere,"This radar data was collected by a system in Goose Bay, Labrador.  This system consists of a phased array of 16 high-frequency antennas with a total transmitted power on the order of 6.4 kilowatts.  See the paper for more details.  The targets were free electrons in the ionosphere. ""Good"" radar returns are those showing evidence of some type of structure in the ionosphere.  ""Bad"" returns are those that do not; their signals pass through the ionosphere.  Received signals were processed using an autocorrelation function whose arguments are the time of a pulse and the pulse number.  There were 17 pulse numbers for the Goose Bay system.  Instances in this databse are described by 2 attributes per pulse number, corresponding to the complex values returned by the function resulting from the complex electromagnetic signal.",Physical,"-- All 34 are continuous-- The 35th attribute is either ""good"" or ""bad"" according to the definition summarized above.  This is a binary classification task.","Classification of radar returns from the ionosphereThis radar data was collected by a system in Goose Bay, Labrador.  This system consists of a phased array of 16 high-frequency antennas with a total transmitted power on the order of 6.4 kilowatts.  See the paper for more details.  The targets were free electrons in the ionosphere. ""Good"" radar returns are those showing evidence of some type of structure in the ionosphere.  ""Bad"" returns are those that do not; their signals pass through the ionosphere.  Received signals were processed using an autocorrelation function whose arguments are the time of a pulse and the pulse number.  There were 17 pulse numbers for the Goose Bay system.  Instances in this databse are described by 2 attributes per pulse number, corresponding to the complex values returned by the function resulting from the complex electromagnetic signal.-- All 34 are continuous-- The 35th attribute is either ""good"" or ""bad"" according to the definition summarized above.  This is a binary classification task."
Intelligent Media Accelerometer and Gyroscope (IM-AccGyro) Dataset,Intelligent Media Accelerometer and Gyroscope (IM-AccGyro) Dataset,"The IM-AccGyro dataset is devised to benchmark techniques dealing with human activity recognition based on inertial sensors. 
	",Intelligent+Media+Accelerometer+and+Gyroscope+%28IM-AccGyro%29+Dataset,https://archive.ics.uci.edu/ml//machine-learning-databases/00578/,https://archive.ics.uci.edu/ml/datasets/Intelligent+Media+Accelerometer+and+Gyroscope+%28IM-AccGyro%29+Dataset,"We have introduced a Accelerometer and Gyroscope (IM-AccGyro) dataset using GY-521 sensors attached to the subject's arm, leg, and neck region to capture important aspects of human motion. The dataset represents motion data captured while subjects are involved in performing 6 human activity behaviors: boxing, clapping, running, sitting, standing, and walking. The ages of the participants range from 15 to 30 years with having weight ranging between 30-100 kgs. Due to multi-sensor environment and inter-behavioral similarity, the dataset itself poses adequate amount of challenges. ",Physical,Provide information about each attribute in your data set.,"The IM-AccGyro dataset is devised to benchmark techniques dealing with human activity recognition based on inertial sensors. 
	We have introduced a Accelerometer and Gyroscope (IM-AccGyro) dataset using GY-521 sensors attached to the subject's arm, leg, and neck region to capture important aspects of human motion. The dataset represents motion data captured while subjects are involved in performing 6 human activity behaviors: boxing, clapping, running, sitting, standing, and walking. The ages of the participants range from 15 to 30 years with having weight ranging between 30-100 kgs. Due to multi-sensor environment and inter-behavioral similarity, the dataset itself poses adequate amount of challenges. Provide information about each attribute in your data set."
El Nino,El Nino,The data set contains oceanographic and surface meteorological readings taken from a series of buoys positioned throughout the equatorial Pacific.,El+Nino,https://archive.ics.uci.edu/ml//machine-learning-databases/el_nino-mld/,https://archive.ics.uci.edu/ml/datasets/El+Nino,"This data was collected with the Tropical Atmosphere Ocean (TAO) array which was developed by the international Tropical Ocean Global Atmosphere (TOGA) program. The TAO array consists of nearly 70 moored buoys spanning the equatorial Pacific, measuring oceanographic and surface meteorological variables critical for improved detection, understanding and prediction of seasonal-to-interannual climate variations originating in the tropics, most notably those related to the El Nino/Southern Oscillation (ENSO) cycles. The moorings were developed by National Oceanic and Atmospheric Administration's (NOAA) Pacific Marine Environmental Laboratory (PMEL). Each mooring measures air temperature, relative humidity, surface winds, sea surface temperatures and subsurface temperatures down to a depth of 500 meters and a few a of the buoys measure currents, rainfall and solar radiation. The data from the array, and current updates, can be viewed on the web at the this address . The El Nino/Southern Oscillation (ENSO) cycle of 1982-1983, the strongest of the century, created many problems throughout the world. Parts of the world such as Peru and the Unites States experienced destructive flooding from increased rainfalls while the western Pacific areas experienced drought and devastating brush fires. The ENSO cycle was neither predicted nor detected until it was near its peak. This highlighted the need for an ocean observing system (i.e. the TAO array) to support studies of large scale ocean-atmosphere interactions on seasonal-to-interannual time scales. The TAO array provides real-time data to climate researchers, weather prediction centers and scientists around the world. Forcasts for tropical Pacific Ocean temperatures for one to two years in advance can be made using the ENSO cycle data. These forcasts are possible because of the moored buoys, along with drifting buoys, volunteer ship temperature probes, and sea level measurements. Research questions of interest include: - How can the data be used to predict weather conditions throughout the world? - How do the variables relate to each other? - Which variables have a greater effect on the climate variations? - Does the amount of movement of the buoy effect the reliability of the data? - When performing an analysis of the data, one should pay attention the possible affect of autocorrelation. Using a multiple regression approach to model the data would require a look at autoregression since the weather statistics of the previous days will affect today's weather. The data is stored in an ASCII files with one observation per line. Spaces separate fields and periods (.) denote missing values. More information and data from the TAO array can be found at the Pacific Marine Environmental Laboratory TAO data webpage: [Web Link]Information on storm data is available here: [Web Link]. This site contains data from January 1994 to April 1998 in a chronological listing by state provided by the National Weather Service. The data includes hurricanes, tornadoes, thunderstorms, hail, floods, drought conditions, lightning, high winds, snow, and temperature extremes. Hurricane tracking data for the Atlantic is available here: [Web Link]. The site contains a map showing the paths of the Atlantic hurricanes and also includes the storms winds (in knots), pressure (in millibars), and the category of the storm based on Saffir-Simpson scale. Another site of interest related to the ENSO cyles is available here: [Web Link]. This site contains information on twelve areas of the world that have demonstrated ENSO-precipitation relationships. Included in the site are maps of the areas and time series plots of actual daily precipitation and accumulated normal precipitation for the areas. ",Physical,"The data consists of the following variables: date, latitude, longitude, zonal winds (west<0, east>0), meridional winds (south<0, north>0), relative humidity, air temperature, sea surface temperature and subsurface temperatures down to a depth of 500 meters. Data taken from the buoys from as early as 1980 for some locations. Other data that was taken in various locations are rainfall, solar radiation, current levels, and subsurface temperatures. The latitude and longitude in the data showed that the bouys moved around to different locations. The latitude values stayed within a degree from the approximate location. Yet the longitude values were sometimes as far as five degrees off of the approximate location. Looking at the wind data, both the zonal and meridional winds fluctuated between -10 m/s and 10 m/s. The plot of the two wind variables showed no linear relationship. Also, the plots of each wind variable against the other three meteorolgical data showed no linear relationships. The relative humidity values in the tropical Pacific were typically between 70% and 90%. Both the air temperature and the sea surface temperature fluctuated between 20 and 30 degrees Celcius. The plot of the two temperatures variables shows a positive linear relationship existing. The two temperatures when each plotted against time also have similar plot designs. Plots of the other meteorological variables against the temperature variables showed no linear relationship. There are missing values in the data. As mentioned earlier, not all buoys are able to measure currents, rainfall, and solar radiation, so these values are missing dependent on the individual buoy. The amount of data available is also dependent on the buoy, as certain buoys were commissioned earlier than others. All readings were taken at the same time of day. ","The data set contains oceanographic and surface meteorological readings taken from a series of buoys positioned throughout the equatorial Pacific.This data was collected with the Tropical Atmosphere Ocean (TAO) array which was developed by the international Tropical Ocean Global Atmosphere (TOGA) program. The TAO array consists of nearly 70 moored buoys spanning the equatorial Pacific, measuring oceanographic and surface meteorological variables critical for improved detection, understanding and prediction of seasonal-to-interannual climate variations originating in the tropics, most notably those related to the El Nino/Southern Oscillation (ENSO) cycles. The moorings were developed by National Oceanic and Atmospheric Administration's (NOAA) Pacific Marine Environmental Laboratory (PMEL). Each mooring measures air temperature, relative humidity, surface winds, sea surface temperatures and subsurface temperatures down to a depth of 500 meters and a few a of the buoys measure currents, rainfall and solar radiation. The data from the array, and current updates, can be viewed on the web at the this address . The El Nino/Southern Oscillation (ENSO) cycle of 1982-1983, the strongest of the century, created many problems throughout the world. Parts of the world such as Peru and the Unites States experienced destructive flooding from increased rainfalls while the western Pacific areas experienced drought and devastating brush fires. The ENSO cycle was neither predicted nor detected until it was near its peak. This highlighted the need for an ocean observing system (i.e. the TAO array) to support studies of large scale ocean-atmosphere interactions on seasonal-to-interannual time scales. The TAO array provides real-time data to climate researchers, weather prediction centers and scientists around the world. Forcasts for tropical Pacific Ocean temperatures for one to two years in advance can be made using the ENSO cycle data. These forcasts are possible because of the moored buoys, along with drifting buoys, volunteer ship temperature probes, and sea level measurements. Research questions of interest include: - How can the data be used to predict weather conditions throughout the world? - How do the variables relate to each other? - Which variables have a greater effect on the climate variations? - Does the amount of movement of the buoy effect the reliability of the data? - When performing an analysis of the data, one should pay attention the possible affect of autocorrelation. Using a multiple regression approach to model the data would require a look at autoregression since the weather statistics of the previous days will affect today's weather. The data is stored in an ASCII files with one observation per line. Spaces separate fields and periods (.) denote missing values. More information and data from the TAO array can be found at the Pacific Marine Environmental Laboratory TAO data webpage: [Web Link]Information on storm data is available here: [Web Link]. This site contains data from January 1994 to April 1998 in a chronological listing by state provided by the National Weather Service. The data includes hurricanes, tornadoes, thunderstorms, hail, floods, drought conditions, lightning, high winds, snow, and temperature extremes. Hurricane tracking data for the Atlantic is available here: [Web Link]. The site contains a map showing the paths of the Atlantic hurricanes and also includes the storms winds (in knots), pressure (in millibars), and the category of the storm based on Saffir-Simpson scale. Another site of interest related to the ENSO cyles is available here: [Web Link]. This site contains information on twelve areas of the world that have demonstrated ENSO-precipitation relationships. Included in the site are maps of the areas and time series plots of actual daily precipitation and accumulated normal precipitation for the areas. The data consists of the following variables: date, latitude, longitude, zonal winds (west<0, east>0), meridional winds (south<0, north>0), relative humidity, air temperature, sea surface temperature and subsurface temperatures down to a depth of 500 meters. Data taken from the buoys from as early as 1980 for some locations. Other data that was taken in various locations are rainfall, solar radiation, current levels, and subsurface temperatures. The latitude and longitude in the data showed that the bouys moved around to different locations. The latitude values stayed within a degree from the approximate location. Yet the longitude values were sometimes as far as five degrees off of the approximate location. Looking at the wind data, both the zonal and meridional winds fluctuated between -10 m/s and 10 m/s. The plot of the two wind variables showed no linear relationship. Also, the plots of each wind variable against the other three meteorolgical data showed no linear relationships. The relative humidity values in the tropical Pacific were typically between 70% and 90%. Both the air temperature and the sea surface temperature fluctuated between 20 and 30 degrees Celcius. The plot of the two temperatures variables shows a positive linear relationship existing. The two temperatures when each plotted against time also have similar plot designs. Plots of the other meteorological variables against the temperature variables showed no linear relationship. There are missing values in the data. As mentioned earlier, not all buoys are able to measure currents, rainfall, and solar radiation, so these values are missing dependent on the individual buoy. The amount of data available is also dependent on the buoy, as certain buoys were commissioned earlier than others. All readings were taken at the same time of day. "
Airfoil Self-Noise,Airfoil Self-Noise,"NASA data set, obtained from a series of aerodynamic and acoustic tests of two and three-dimensional airfoil blade sections conducted in an anechoic wind tunnel.",Airfoil+Self-Noise,https://archive.ics.uci.edu/ml//machine-learning-databases/00291/,https://archive.ics.uci.edu/ml/datasets/Airfoil+Self-Noise,The NASA data set comprises different size NACA 0012 airfoils at various wind tunnel speeds and angles of attack. The span of the airfoil and the observer position were the same in all of the experiments. ,Physical,"This problem has the following inputs:1. Frequency, in Hertzs. 2. Angle of attack, in degrees. 3. Chord length, in meters.4. Free-stream velocity, in meters per second. 5. Suction side displacement thickness, in meters. The only output is:6. Scaled sound pressure level, in decibels. ","NASA data set, obtained from a series of aerodynamic and acoustic tests of two and three-dimensional airfoil blade sections conducted in an anechoic wind tunnel.The NASA data set comprises different size NACA 0012 airfoils at various wind tunnel speeds and angles of attack. The span of the airfoil and the observer position were the same in all of the experiments. This problem has the following inputs:1. Frequency, in Hertzs. 2. Angle of attack, in degrees. 3. Chord length, in meters.4. Free-stream velocity, in meters per second. 5. Suction side displacement thickness, in meters. The only output is:6. Scaled sound pressure level, in decibels. "
HEPMASS,HEPMASS,The search for exotic particles requires sorting through a large number of collisions to find the events of interest. This data set challenges one to detect a new particle of unknown mass.,HEPMASS,https://archive.ics.uci.edu/ml//machine-learning-databases/00347/,https://archive.ics.uci.edu/ml/datasets/HEPMASS,"Machine learning is used in high-energy physics experiments to search for the signatures of exotic particles. These signatures are learned from Monte Carlo simulations of the collisions that produce these particles and the resulting decay products. In each of the three data sets here, the goal is to separate particle-producing collisions from a background source. The mass of the new particle is unknown, so three separate data sets are provided. In each data set, 50% of the data is from a signal process, while 50% is from the background process. The data is separated into a training set of 7 million examples and a test set of 3.5 million for each.1) In the '1000' dataset, the signal particle has mass=1000. (Note: this dataset does not include a mass feature since all signal examples have the same mass.)2) In the 'not1000' dataset, the signal particle's mass is drawn uniformly from the set {500, 750, 1250, 1500}. The mass is included as an input feature; for the background examples, the mass is selected randomly from this same set.3) In the 'all' dataset, the signal particle's mass is drawn uniformly from the set {500, 750, 1000, 1250, 1500}. The mass is included as an input feature; for the background examples, the mass is selected randomly from this same set.",Physical,"The first column is the class label (1 for signal, 0 for background), followed by the 27 normalized features (22 low-level features then 5 high-level features), and a 28th mass feature for datasets 2 and 3. See the original paper for more detailed information. There is a header line in each file. ","The search for exotic particles requires sorting through a large number of collisions to find the events of interest. This data set challenges one to detect a new particle of unknown mass.Machine learning is used in high-energy physics experiments to search for the signatures of exotic particles. These signatures are learned from Monte Carlo simulations of the collisions that produce these particles and the resulting decay products. In each of the three data sets here, the goal is to separate particle-producing collisions from a background source. The mass of the new particle is unknown, so three separate data sets are provided. In each data set, 50% of the data is from a signal process, while 50% is from the background process. The data is separated into a training set of 7 million examples and a test set of 3.5 million for each.1) In the '1000' dataset, the signal particle has mass=1000. (Note: this dataset does not include a mass feature since all signal examples have the same mass.)2) In the 'not1000' dataset, the signal particle's mass is drawn uniformly from the set {500, 750, 1250, 1500}. The mass is included as an input feature; for the background examples, the mass is selected randomly from this same set.3) In the 'all' dataset, the signal particle's mass is drawn uniformly from the set {500, 750, 1000, 1250, 1500}. The mass is included as an input feature; for the background examples, the mass is selected randomly from this same set.The first column is the class label (1 for signal, 0 for background), followed by the 27 normalized features (22 low-level features then 5 high-level features), and a 28th mass feature for datasets 2 and 3. See the original paper for more detailed information. There is a header line in each file. "
Bias correction of numerical prediction model temperature forecast,Bias correction of numerical prediction model temperature forecast,"It contains fourteen numerical weather prediction (NWP)'s meteorological forecast data, two in-situ observations, and five geographical auxiliary variables over Seoul, South Korea in the summer. 
",Bias+correction+of+numerical+prediction+model+temperature+forecast,https://archive.ics.uci.edu/ml//machine-learning-databases/00514/,https://archive.ics.uci.edu/ml/datasets/Bias+correction+of+numerical+prediction+model+temperature+forecast,"This data is for the purpose of bias correction of next-day maximum and minimum air temperatures forecast of the LDAPS model operated by the Korea Meteorological Administration over Seoul, South Korea. This data consists of summer data from 2013 to 2017. The input data is largely composed of the LDAPS model's next-day forecast data, in-situ maximum and minimum temperatures of present-day, and geographic auxiliary variables. There are two outputs (i.e. next-day maximum and minimum air temperatures) in this data. Hindcast validation was conducted for the period from 2015 to 2017.",Physical,"For more information, read [Cho et al, 2020].1. station - used weather station number: 1 to 252. Date - Present day: yyyy-mm-dd ('2013-06-30' to '2017-08-30')3. Present_Tmax - Maximum air temperature between 0 and 21 h on the present day (Ã‚Â°C): 20 to 37.64. Present_Tmin - Minimum air temperature between 0 and 21 h on the present day (Ã‚Â°C): 11.3 to 29.95. LDAPS_RHmin - LDAPS model forecast of next-day minimum relative humidity (%): 19.8 to 98.56. LDAPS_RHmax - LDAPS model forecast of next-day maximum relative humidity (%): 58.9 to 1007. LDAPS_Tmax_lapse - LDAPS model forecast of next-day maximum air temperature applied lapse rate (Ã‚Â°C): 17.6 to 38.58. LDAPS_Tmin_lapse - LDAPS model forecast of next-day minimum air temperature applied lapse rate (Ã‚Â°C): 14.3 to 29.69. LDAPS_WS - LDAPS model forecast of next-day average wind speed (m/s): 2.9 to 21.910. LDAPS_LH - LDAPS model forecast of next-day average latent heat flux (W/m2): -13.6 to 213.411. LDAPS_CC1 - LDAPS model forecast of next-day 1st 6-hour split average cloud cover (0-5 h) (%): 0 to 0.9712. LDAPS_CC2 - LDAPS model forecast of next-day 2nd 6-hour split average cloud cover (6-11 h) (%): 0 to 0.9713. LDAPS_CC3 - LDAPS model forecast of next-day 3rd 6-hour split average cloud cover (12-17 h) (%): 0 to 0.9814. LDAPS_CC4 - LDAPS model forecast of next-day 4th 6-hour split average cloud cover (18-23 h) (%): 0 to 0.9715. LDAPS_PPT1 - LDAPS model forecast of next-day 1st 6-hour split average precipitation (0-5 h) (%): 0 to 23.716. LDAPS_PPT2 - LDAPS model forecast of next-day 2nd 6-hour split average precipitation (6-11 h) (%): 0 to 21.617. LDAPS_PPT3 - LDAPS model forecast of next-day 3rd 6-hour split average precipitation (12-17 h) (%): 0 to 15.818. LDAPS_PPT4 - LDAPS model forecast of next-day 4th 6-hour split average precipitation (18-23 h) (%): 0 to 16.719. lat - Latitude (Ã‚Â°): 37.456 to 37.64520. lon - Longitude (Ã‚Â°): 126.826 to 127.13521. DEM - Elevation (m): 12.4 to 212.322. Slope - Slope (Ã‚Â°): 0.1 to 5.223. Solar radiation - Daily incoming solar radiation (wh/m2): 4329.5 to 5992.924. Next_Tmax - The next-day maximum air temperature (Ã‚Â°C): 17.4 to 38.925. Next_Tmin - The next-day minimum air temperature (Ã‚Â°C): 11.3 to 29.8","It contains fourteen numerical weather prediction (NWP)'s meteorological forecast data, two in-situ observations, and five geographical auxiliary variables over Seoul, South Korea in the summer. 
This data is for the purpose of bias correction of next-day maximum and minimum air temperatures forecast of the LDAPS model operated by the Korea Meteorological Administration over Seoul, South Korea. This data consists of summer data from 2013 to 2017. The input data is largely composed of the LDAPS model's next-day forecast data, in-situ maximum and minimum temperatures of present-day, and geographic auxiliary variables. There are two outputs (i.e. next-day maximum and minimum air temperatures) in this data. Hindcast validation was conducted for the period from 2015 to 2017.For more information, read [Cho et al, 2020].1. station - used weather station number: 1 to 252. Date - Present day: yyyy-mm-dd ('2013-06-30' to '2017-08-30')3. Present_Tmax - Maximum air temperature between 0 and 21 h on the present day (Ã‚Â°C): 20 to 37.64. Present_Tmin - Minimum air temperature between 0 and 21 h on the present day (Ã‚Â°C): 11.3 to 29.95. LDAPS_RHmin - LDAPS model forecast of next-day minimum relative humidity (%): 19.8 to 98.56. LDAPS_RHmax - LDAPS model forecast of next-day maximum relative humidity (%): 58.9 to 1007. LDAPS_Tmax_lapse - LDAPS model forecast of next-day maximum air temperature applied lapse rate (Ã‚Â°C): 17.6 to 38.58. LDAPS_Tmin_lapse - LDAPS model forecast of next-day minimum air temperature applied lapse rate (Ã‚Â°C): 14.3 to 29.69. LDAPS_WS - LDAPS model forecast of next-day average wind speed (m/s): 2.9 to 21.910. LDAPS_LH - LDAPS model forecast of next-day average latent heat flux (W/m2): -13.6 to 213.411. LDAPS_CC1 - LDAPS model forecast of next-day 1st 6-hour split average cloud cover (0-5 h) (%): 0 to 0.9712. LDAPS_CC2 - LDAPS model forecast of next-day 2nd 6-hour split average cloud cover (6-11 h) (%): 0 to 0.9713. LDAPS_CC3 - LDAPS model forecast of next-day 3rd 6-hour split average cloud cover (12-17 h) (%): 0 to 0.9814. LDAPS_CC4 - LDAPS model forecast of next-day 4th 6-hour split average cloud cover (18-23 h) (%): 0 to 0.9715. LDAPS_PPT1 - LDAPS model forecast of next-day 1st 6-hour split average precipitation (0-5 h) (%): 0 to 23.716. LDAPS_PPT2 - LDAPS model forecast of next-day 2nd 6-hour split average precipitation (6-11 h) (%): 0 to 21.617. LDAPS_PPT3 - LDAPS model forecast of next-day 3rd 6-hour split average precipitation (12-17 h) (%): 0 to 15.818. LDAPS_PPT4 - LDAPS model forecast of next-day 4th 6-hour split average precipitation (18-23 h) (%): 0 to 16.719. lat - Latitude (Ã‚Â°): 37.456 to 37.64520. lon - Longitude (Ã‚Â°): 126.826 to 127.13521. DEM - Elevation (m): 12.4 to 212.322. Slope - Slope (Ã‚Â°): 0.1 to 5.223. Solar radiation - Daily incoming solar radiation (wh/m2): 4329.5 to 5992.924. Next_Tmax - The next-day maximum air temperature (Ã‚Â°C): 17.4 to 38.925. Next_Tmin - The next-day minimum air temperature (Ã‚Â°C): 11.3 to 29.8"
Beijing PM2.5 Data,Beijing PM2.5 Data,"This hourly data set contains the PM2.5 data of US Embassy in Beijing. Meanwhile, meteorological data from Beijing Capital International Airport are also included. ",Beijing+PM2.5+Data,https://archive.ics.uci.edu/ml//machine-learning-databases/00381/,https://archive.ics.uci.edu/ml/datasets/Beijing+PM2.5+Data,"The dataÃ¢â‚¬â„¢s time period is between Jan 1st, 2010 to Dec 31st, 2014. Missing data are denoted as Ã¢â‚¬Å“NAÃ¢â‚¬Â�.",Physical,No: row numberyear: year of data in this rowmonth: month of data in this rowday: day of data in this rowhour: hour of data in this rowpm2.5: PM2.5 concentration (ug/m^3)DEWP: Dew Point (Ã¢â€žÆ’)TEMP: Temperature (Ã¢â€žÆ’)PRES: Pressure (hPa)cbwd: Combined wind directionIws: Cumulated wind speed (m/s)Is: Cumulated hours of snowIr: Cumulated hours of rain,"This hourly data set contains the PM2.5 data of US Embassy in Beijing. Meanwhile, meteorological data from Beijing Capital International Airport are also included. The dataÃ¢â‚¬â„¢s time period is between Jan 1st, 2010 to Dec 31st, 2014. Missing data are denoted as Ã¢â‚¬Å“NAÃ¢â‚¬Â�.No: row numberyear: year of data in this rowmonth: month of data in this rowday: day of data in this rowhour: hour of data in this rowpm2.5: PM2.5 concentration (ug/m^3)DEWP: Dew Point (Ã¢â€žÆ’)TEMP: Temperature (Ã¢â€žÆ’)PRES: Pressure (hPa)cbwd: Combined wind directionIws: Cumulated wind speed (m/s)Is: Cumulated hours of snowIr: Cumulated hours of rain"
HIGGS,HIGGS,This is a classification problem to distinguish between a signal process which produces Higgs bosons and a background process which does not. ,HIGGS,https://archive.ics.uci.edu/ml//machine-learning-databases/00280/,https://archive.ics.uci.edu/ml/datasets/HIGGS,"The data has been produced using Monte Carlo simulations. The first 21 features (columns 2-22) are kinematic properties measured by the particle detectors in the accelerator. The last seven features are functions of the first 21 features; these are high-level features derived by physicists to help discriminate between the two classes. There is an interest in using deep learning methods to obviate the need for physicists to manually develop such features. Benchmark results using Bayesian Decision Trees from a standard physics package and 5-layer neural networks are presented in the original paper. The last 500,000 examples are used as a test set.",Physical,"The first column is the class label (1 for signal, 0 for background), followed by the 28 features (21 low-level features then 7 high-level features): lepton  pT, lepton  eta, lepton  phi, missing energy magnitude, missing energy phi, jet 1 pt, jet 1 eta, jet 1 phi, jet 1 b-tag, jet 2 pt, jet 2 eta, jet 2 phi, jet 2 b-tag, jet 3 pt, jet 3 eta, jet 3 phi, jet 3 b-tag, jet 4 pt, jet 4 eta, jet 4 phi, jet 4 b-tag, m_jj, m_jjj, m_lv, m_jlv, m_bb, m_wbb, m_wwbb. For more detailed information about each feature see the original paper.","This is a classification problem to distinguish between a signal process which produces Higgs bosons and a background process which does not. The data has been produced using Monte Carlo simulations. The first 21 features (columns 2-22) are kinematic properties measured by the particle detectors in the accelerator. The last seven features are functions of the first 21 features; these are high-level features derived by physicists to help discriminate between the two classes. There is an interest in using deep learning methods to obviate the need for physicists to manually develop such features. Benchmark results using Bayesian Decision Trees from a standard physics package and 5-layer neural networks are presented in the original paper. The last 500,000 examples are used as a test set.The first column is the class label (1 for signal, 0 for background), followed by the 28 features (21 low-level features then 7 high-level features): lepton  pT, lepton  eta, lepton  phi, missing energy magnitude, missing energy phi, jet 1 pt, jet 1 eta, jet 1 phi, jet 1 b-tag, jet 2 pt, jet 2 eta, jet 2 phi, jet 2 b-tag, jet 3 pt, jet 3 eta, jet 3 phi, jet 3 b-tag, jet 4 pt, jet 4 eta, jet 4 phi, jet 4 b-tag, m_jj, m_jjj, m_lv, m_jlv, m_bb, m_wbb, m_wwbb. For more detailed information about each feature see the original paper."
Beijing Multi-Site Air-Quality Data,Beijing Multi-Site Air-Quality Data,This hourly data set considers 6 main air pollutants and 6 relevant meteorological variables at multiple sites in Beijing.,Beijing+Multi-Site+Air-Quality+Data,https://archive.ics.uci.edu/ml//machine-learning-databases/00501/,https://archive.ics.uci.edu/ml/datasets/Beijing+Multi-Site+Air-Quality+Data,"This data set includes hourly air pollutants data from 12 nationally-controlled air-quality monitoring sites. The air-quality data are from the Beijing Municipal Environmental Monitoring Center. The meteorological data in each air-quality site are matched with the nearest weather station from the China Meteorological Administration. The time period is from March 1st, 2013 to February 28th, 2017. Missing data are denoted as NA.",Physical,No: row number year: year of data in this row month: month of data in this row day: day of data in this row hour: hour of data in this row PM2.5: PM2.5 concentration (ug/m^3)PM10: PM10 concentration (ug/m^3)SO2: SO2 concentration (ug/m^3)NO2: NO2 concentration (ug/m^3)CO: CO concentration (ug/m^3)O3: O3 concentration (ug/m^3)TEMP: temperature (degree Celsius) PRES: pressure (hPa)DEWP: dew point temperature (degree Celsius)RAIN: precipitation (mm)wd: wind directionWSPM: wind speed (m/s)station: name of the air-quality monitoring site,"This hourly data set considers 6 main air pollutants and 6 relevant meteorological variables at multiple sites in Beijing.This data set includes hourly air pollutants data from 12 nationally-controlled air-quality monitoring sites. The air-quality data are from the Beijing Municipal Environmental Monitoring Center. The meteorological data in each air-quality site are matched with the nearest weather station from the China Meteorological Administration. The time period is from March 1st, 2013 to February 28th, 2017. Missing data are denoted as NA.No: row number year: year of data in this row month: month of data in this row day: day of data in this row hour: hour of data in this row PM2.5: PM2.5 concentration (ug/m^3)PM10: PM10 concentration (ug/m^3)SO2: SO2 concentration (ug/m^3)NO2: NO2 concentration (ug/m^3)CO: CO concentration (ug/m^3)O3: O3 concentration (ug/m^3)TEMP: temperature (degree Celsius) PRES: pressure (hPa)DEWP: dew point temperature (degree Celsius)RAIN: precipitation (mm)wd: wind directionWSPM: wind speed (m/s)station: name of the air-quality monitoring site"
Urban Land Cover,Urban Land Cover,Classification of urban land cover using high resolution aerial imagery. Intended to assist sustainable urban planning efforts.,Urban+Land+Cover,https://archive.ics.uci.edu/ml//machine-learning-databases/00295/,https://archive.ics.uci.edu/ml/datasets/Urban+Land+Cover,"Contains training and testing data for classifying a high resolution aerial image into 9 types of urban land cover. Multi-scale spectral, size, shape, and texture information are used for classification. There are a low number of training samples for each class (14-30) and a high number of classification variables (148), so it may be an interesting data set for testing feature selection methods. The testing data set is from a random sampling of the image.Class is the target classification variable. The land cover classes are: trees, grass, soil, concrete, asphalt, buildings, cars, pools, shadows.",Physical,"LEGENDClass: Land cover class (nominal)BrdIndx: Border Index (shape variable)Area: Area in m2 (size variable)Round: Roundness (shape variable)Bright: Brightness (spectral variable)Compact: Compactness (shape variable)ShpIndx: Shape Index (shape variable)Mean_G: Green (spectral variable)Mean_R: Red (spectral variable)Mean_NIR: Near Infrared (spectral variable)SD_G: Standard deviation of Green (texture variable)SD_R: Standard deviation of Red (texture variable)SD_NIR: Standard deviation of Near Infrared (texture variable)LW: Length/Width (shape variable)GLCM1: Gray-Level Co-occurrence Matrix [i forget which type of GLCM metric this one is] (texture variable)Rect: Rectangularity (shape variable)GLCM2: Another Gray-Level Co-occurrence Matrix attribute (texture variable)Dens: Density (shape variable)Assym: Assymetry (shape variable)NDVI: Normalized Difference Vegetation Index (spectral variable)BordLngth: Border Length (shape variable)GLCM3: Another Gray-Level Co-occurrence Matrix attribute (texture variable)Note: These variables repeat for each coarser scale (i.e. variable_40, variable_60, ...variable_140).","Classification of urban land cover using high resolution aerial imagery. Intended to assist sustainable urban planning efforts.Contains training and testing data for classifying a high resolution aerial image into 9 types of urban land cover. Multi-scale spectral, size, shape, and texture information are used for classification. There are a low number of training samples for each class (14-30) and a high number of classification variables (148), so it may be an interesting data set for testing feature selection methods. The testing data set is from a random sampling of the image.Class is the target classification variable. The land cover classes are: trees, grass, soil, concrete, asphalt, buildings, cars, pools, shadows.LEGENDClass: Land cover class (nominal)BrdIndx: Border Index (shape variable)Area: Area in m2 (size variable)Round: Roundness (shape variable)Bright: Brightness (spectral variable)Compact: Compactness (shape variable)ShpIndx: Shape Index (shape variable)Mean_G: Green (spectral variable)Mean_R: Red (spectral variable)Mean_NIR: Near Infrared (spectral variable)SD_G: Standard deviation of Green (texture variable)SD_R: Standard deviation of Red (texture variable)SD_NIR: Standard deviation of Near Infrared (texture variable)LW: Length/Width (shape variable)GLCM1: Gray-Level Co-occurrence Matrix [i forget which type of GLCM metric this one is] (texture variable)Rect: Rectangularity (shape variable)GLCM2: Another Gray-Level Co-occurrence Matrix attribute (texture variable)Dens: Density (shape variable)Assym: Assymetry (shape variable)NDVI: Normalized Difference Vegetation Index (spectral variable)BordLngth: Border Length (shape variable)GLCM3: Another Gray-Level Co-occurrence Matrix attribute (texture variable)Note: These variables repeat for each coarser scale (i.e. variable_40, variable_60, ...variable_140)."
Statlog (Shuttle),Statlog (Shuttle),The shuttle dataset contains 9 attributes all of which are numerical. Approximately 80% of the data belongs to class 1,Statlog+%28Shuttle%29,https://archive.ics.uci.edu/ml//machine-learning-databases/statlog/shuttle/,https://archive.ics.uci.edu/ml/datasets/Statlog+%28Shuttle%29,"Approximately 80% of the data belongs to class 1. Therefore the default accuracy is about 80%. The aim here is to obtain an accuracy of 99 - 99.9%.The examples in the original dataset were in time order, and this time order could presumably be relevant in classification.   However, this was not deemed relevant for StatLog purposes, so the order of the examples in the original dataset was randomised, and a portion of the original dataset removed for validation purposes.",Physical,The shuttle dataset contains 9 attributes all of which are numerical. The first one being time.  The last column is the class which has been coded as follows :        1       Rad Flow        2       Fpv Close        3       Fpv Open        4       High        5       Bypass        6       Bpv Close        7       Bpv Open,"The shuttle dataset contains 9 attributes all of which are numerical. Approximately 80% of the data belongs to class 1Approximately 80% of the data belongs to class 1. Therefore the default accuracy is about 80%. The aim here is to obtain an accuracy of 99 - 99.9%.The examples in the original dataset were in time order, and this time order could presumably be relevant in classification.   However, this was not deemed relevant for StatLog purposes, so the order of the examples in the original dataset was randomised, and a portion of the original dataset removed for validation purposes.The shuttle dataset contains 9 attributes all of which are numerical. The first one being time.  The last column is the class which has been coded as follows :        1       Rad Flow        2       Fpv Close        3       Fpv Open        4       High        5       Bypass        6       Bpv Close        7       Bpv Open"
Statlog (Landsat Satellite),Statlog (Landsat Satellite),"Multi-spectral values of pixels in 3x3 neighbourhoods in a satellite image, and the classification associated with the central pixel in each neighbourhood",Statlog+%28Landsat+Satellite%29,https://archive.ics.uci.edu/ml//machine-learning-databases/statlog/satimage/,https://archive.ics.uci.edu/ml/datasets/Statlog+%28Landsat+Satellite%29,"The database consists of the multi-spectral values of pixels in 3x3 neighbourhoods in a satellite image, and the classification associated with the central pixel in each neighbourhood. The aim is to predict this classification, given the multi-spectral values. In the sample database, the class of a pixel is coded as a number.The Landsat satellite data is one of the many sources of information available for a scene. The interpretation of a scene by integrating spatial data of diverse types and resolutions including multispectral and radar data, maps indicating topography, land use etc. is expected to assume significant importance with the onset of an era characterised by integrative approaches to remote sensing (for example, NASA's Earth Observing System commencing this decade). Existing statistical methods are ill-equipped for handling such diverse data types. Note that this is not true for Landsat MSS data considered in isolation (as in this sample database). This data satisfies the important requirements of being numerical and at a single resolution, and standard maximum-likelihood classification performs very well. Consequently, for this data, it should be interesting to compare the performance of other methods against the statistical approach.One frame of Landsat MSS imagery consists of four digital images of the same scene in different spectral bands. Two of these are in the visible region (corresponding approximately to green and red regions of the visible spectrum) and two are in the (near) infra-red. Each pixel is a 8-bit binary word, with 0 corresponding to black and 255 to white. The spatial resolution of a pixel is about 80m x 80m. Each image contains 2340 x 3380 such pixels.The database is a (tiny) sub-area of a scene, consisting of 82 x 100 pixels. Each line of data corresponds to a 3x3 square neighbourhood of pixels completely contained within the 82x100 sub-area. Each line contains the pixel values in the four spectral bands (converted to ASCII) of each of the 9 pixels in the 3x3 neighbourhood and a number indicating the classification label of the central pixel. The number is a code for the following classes:Number			Class1			red soil2			cotton crop3			grey soil4			damp grey soil5			soil with vegetation stubble6			mixture class (all types present)7			very damp grey soil	NB. There are no examples with class 6 in this dataset.The data is given in random order and certain lines of data have been removed so you cannot reconstruct the original image from this dataset.In each line of data the four spectral values for the top-left pixel are given first followed by the four spectral values for the top-middle pixel and then those for the top-right pixel, and so on with the pixels read out in sequence left-to-right and top-to-bottom. Thus, the four spectral values for the central pixel are given by attributes 17,18,19 and 20. If you like you can use only these four attributes, while ignoring the others. This avoids the problem which arises when a 3x3 neighbourhood straddles a boundary.",Physical,"The attributes are numerical, in the range 0 to 255.","Multi-spectral values of pixels in 3x3 neighbourhoods in a satellite image, and the classification associated with the central pixel in each neighbourhoodThe database consists of the multi-spectral values of pixels in 3x3 neighbourhoods in a satellite image, and the classification associated with the central pixel in each neighbourhood. The aim is to predict this classification, given the multi-spectral values. In the sample database, the class of a pixel is coded as a number.The Landsat satellite data is one of the many sources of information available for a scene. The interpretation of a scene by integrating spatial data of diverse types and resolutions including multispectral and radar data, maps indicating topography, land use etc. is expected to assume significant importance with the onset of an era characterised by integrative approaches to remote sensing (for example, NASA's Earth Observing System commencing this decade). Existing statistical methods are ill-equipped for handling such diverse data types. Note that this is not true for Landsat MSS data considered in isolation (as in this sample database). This data satisfies the important requirements of being numerical and at a single resolution, and standard maximum-likelihood classification performs very well. Consequently, for this data, it should be interesting to compare the performance of other methods against the statistical approach.One frame of Landsat MSS imagery consists of four digital images of the same scene in different spectral bands. Two of these are in the visible region (corresponding approximately to green and red regions of the visible spectrum) and two are in the (near) infra-red. Each pixel is a 8-bit binary word, with 0 corresponding to black and 255 to white. The spatial resolution of a pixel is about 80m x 80m. Each image contains 2340 x 3380 such pixels.The database is a (tiny) sub-area of a scene, consisting of 82 x 100 pixels. Each line of data corresponds to a 3x3 square neighbourhood of pixels completely contained within the 82x100 sub-area. Each line contains the pixel values in the four spectral bands (converted to ASCII) of each of the 9 pixels in the 3x3 neighbourhood and a number indicating the classification label of the central pixel. The number is a code for the following classes:Number			Class1			red soil2			cotton crop3			grey soil4			damp grey soil5			soil with vegetation stubble6			mixture class (all types present)7			very damp grey soil	NB. There are no examples with class 6 in this dataset.The data is given in random order and certain lines of data have been removed so you cannot reconstruct the original image from this dataset.In each line of data the four spectral values for the top-left pixel are given first followed by the four spectral values for the top-middle pixel and then those for the top-right pixel, and so on with the pixels read out in sequence left-to-right and top-to-bottom. Thus, the four spectral values for the central pixel are given by attributes 17,18,19 and 20. If you like you can use only these four attributes, while ignoring the others. This avoids the problem which arises when a 3x3 neighbourhood straddles a boundary.The attributes are numerical, in the range 0 to 255."
Individual household electric power consumption,Individual household electric power consumption,Measurements of electric power consumption in one household with a one-minute sampling rate over a period of almost 4 years. Different electrical quantities and some sub-metering values are available.,Individual+household+electric+power+consumption,https://archive.ics.uci.edu/ml//machine-learning-databases/00235/,https://archive.ics.uci.edu/ml/datasets/Individual+household+electric+power+consumption,"This archive contains 2075259 measurements gathered in a house located in Sceaux (7km of Paris, France) between December 2006 and November 2010 (47 months).Notes: 1.(global_active_power*1000/60 - sub_metering_1 - sub_metering_2 - sub_metering_3) represents the active energy consumed every minute (in watt hour) in the household by electrical equipment not measured in sub-meterings 1, 2 and 3.2.The dataset contains some missing values in the measurements (nearly 1,25% of the rows). All calendar timestamps are present in the dataset but for some timestamps, the measurement values are missing: a missing value is represented by the absence of value between two consecutive semi-colon attribute separators. For instance, the dataset shows missing values on April 28, 2007.",Physical,"1.date: Date in format dd/mm/yyyy2.time: time in format hh:mm:ss3.global_active_power: household global minute-averaged active power (in kilowatt)4.global_reactive_power: household global minute-averaged reactive power (in kilowatt)5.voltage: minute-averaged voltage (in volt)6.global_intensity: household global minute-averaged current intensity (in ampere)7.sub_metering_1: energy sub-metering No. 1 (in watt-hour of active energy). It corresponds to the kitchen, containing mainly a dishwasher, an oven and a microwave (hot plates are not electric but gas powered).8.sub_metering_2: energy sub-metering No. 2 (in watt-hour of active energy). It corresponds to the laundry room, containing a washing-machine, a tumble-drier, a refrigerator and a light.9.sub_metering_3: energy sub-metering No. 3 (in watt-hour of active energy). It corresponds to an electric water-heater and an air-conditioner.","Measurements of electric power consumption in one household with a one-minute sampling rate over a period of almost 4 years. Different electrical quantities and some sub-metering values are available.This archive contains 2075259 measurements gathered in a house located in Sceaux (7km of Paris, France) between December 2006 and November 2010 (47 months).Notes: 1.(global_active_power*1000/60 - sub_metering_1 - sub_metering_2 - sub_metering_3) represents the active energy consumed every minute (in watt hour) in the household by electrical equipment not measured in sub-meterings 1, 2 and 3.2.The dataset contains some missing values in the measurements (nearly 1,25% of the rows). All calendar timestamps are present in the dataset but for some timestamps, the measurement values are missing: a missing value is represented by the absence of value between two consecutive semi-colon attribute separators. For instance, the dataset shows missing values on April 28, 2007.1.date: Date in format dd/mm/yyyy2.time: time in format hh:mm:ss3.global_active_power: household global minute-averaged active power (in kilowatt)4.global_reactive_power: household global minute-averaged reactive power (in kilowatt)5.voltage: minute-averaged voltage (in volt)6.global_intensity: household global minute-averaged current intensity (in ampere)7.sub_metering_1: energy sub-metering No. 1 (in watt-hour of active energy). It corresponds to the kitchen, containing mainly a dishwasher, an oven and a microwave (hot plates are not electric but gas powered).8.sub_metering_2: energy sub-metering No. 2 (in watt-hour of active energy). It corresponds to the laundry room, containing a washing-machine, a tumble-drier, a refrigerator and a light.9.sub_metering_3: energy sub-metering No. 3 (in watt-hour of active energy). It corresponds to an electric water-heater and an air-conditioner."
Steel Plates Faults,Steel Plates Faults,"A dataset of steel platesâ€™ faults, classified into 7 different types. 
The goal was to train machine learning for automatic pattern recognition.
",Steel+Plates+Faults,https://archive.ics.uci.edu/ml//machine-learning-databases/00198/,https://archive.ics.uci.edu/ml/datasets/Steel+Plates+Faults,Type of dependent variables (7 Types of Steel Plates Faults):1.Pastry2.Z_Scratch3.K_Scatch4.Stains5.Dirtiness6.Bumps7.Other_Faults,Physical,27 independent variables:X_MinimumX_MaximumY_MinimumY_MaximumPixels_AreasX_PerimeterY_PerimeterSum_of_LuminosityMinimum_of_LuminosityMaximum_of_LuminosityLength_of_ConveyerTypeOfSteel_A300TypeOfSteel_A400Steel_Plate_ThicknessEdges_IndexEmpty_IndexSquare_IndexOutside_X_IndexEdges_X_IndexEdges_Y_IndexOutside_Global_IndexLogOfAreasLog_X_IndexLog_Y_IndexOrientation_IndexLuminosity_IndexSigmoidOfAreas,"A dataset of steel platesâ€™ faults, classified into 7 different types. 
The goal was to train machine learning for automatic pattern recognition.
Type of dependent variables (7 Types of Steel Plates Faults):1.Pastry2.Z_Scratch3.K_Scatch4.Stains5.Dirtiness6.Bumps7.Other_Faults27 independent variables:X_MinimumX_MaximumY_MinimumY_MaximumPixels_AreasX_PerimeterY_PerimeterSum_of_LuminosityMinimum_of_LuminosityMaximum_of_LuminosityLength_of_ConveyerTypeOfSteel_A300TypeOfSteel_A400Steel_Plate_ThicknessEdges_IndexEmpty_IndexSquare_IndexOutside_X_IndexEdges_X_IndexEdges_Y_IndexOutside_Global_IndexLogOfAreasLog_X_IndexLog_Y_IndexOrientation_IndexLuminosity_IndexSigmoidOfAreas"
Shuttle Landing Control,Shuttle Landing Control,Tiny database; all nominal values,Shuttle+Landing+Control,https://archive.ics.uci.edu/ml//machine-learning-databases/shuttle-landing-control/,https://archive.ics.uci.edu/ml/datasets/Shuttle+Landing+Control,This is a tiny database.  Michie reports that Burke's group used RULEMASTER to generate comprehendable rules for determining the conditions under which an autolanding would be preferable to manual control of the spacecraft.,Physical,"    1. Class: noauto, auto       -- that is, advise using manual/automatic control    2. STABILITY: stab, xstab    3. ERROR: XL, LX, MM, SS    4. SIGN: pp, nn    5. WIND: head, tail    6. MAGNITUDE: Low, Medium, Strong, OutOfRange    7. VISIBILITY: yes, no","Tiny database; all nominal valuesThis is a tiny database.  Michie reports that Burke's group used RULEMASTER to generate comprehendable rules for determining the conditions under which an autolanding would be preferable to manual control of the spacecraft.    1. Class: noauto, auto       -- that is, advise using manual/automatic control    2. STABILITY: stab, xstab    3. ERROR: XL, LX, MM, SS    4. SIGN: pp, nn    5. WIND: head, tail    6. MAGNITUDE: Low, Medium, Strong, OutOfRange    7. VISIBILITY: yes, no"
Vicon Physical Action Data Set,Vicon Physical Action Data Set,The Physical Action Data Set includes 10 normal and 10 aggressive physical actions that measure the human activity. The data have been collected by 10 subjects using the Vicon 3D tracker.,Vicon+Physical+Action+Data+Set,https://archive.ics.uci.edu/ml//machine-learning-databases/00214/,https://archive.ics.uci.edu/ml/datasets/Vicon+Physical+Action+Data+Set,"1. Protocol:   Seven male and three female subjects (age 25 to 30), who have experienced aggression in scenarios such   as physical fighting, took part in the experiment. Throughout 20 individual experiments, each subject   had to perform ten normal and ten aggressive activities. Regarding the rights of the subjects involved,   ethical regulations have been followed based on the code of ethics of the British psychological society,   which explains the ethical legislations to conduct statistical experiments using human subjects. For safety   precaution issues, boxing hand wraps have been given to the subjects, and for the warm up the subjects   were instructed to familiarise with the bag by having a number of trial runs. The subjects were aware that   since their involvement in this series of experiments was voluntary, it was made clear that they could   withdraw at any time from the study.2. Instrumentation:   The Essex robotic arena was the main experimental hall where the data collection took place. With area   4x5.5m, the ten subjects expressed normal and aggressive physical activities at random locations. For the   normal actions, a human partner has been used as a focus target attracting the attention from the subjects   so as to perform more realistic activity. For the aggressive actions, the subjects made use of a professional   kick-boxing standing bag, 1.75m tall, with a human figure drawn on its body. The bag has cylindrical shape   made from soft material, which could bounce when hit. All the activities have been recorded from random   starting positions so that to have a variety of spatial 3D data. The subjectsÃ¢â‚¬â„¢ performance has been recorded   by the ViconÃ¢â‚¬â„¢s nine ubiquitous cameras, interfacing human activity with spatial coordinate points. Based on   this context, the data acquisition process involved four reflectable markers placed on the forearms (elbows   and wrists), four on the forelegs (knees and ankles), and one on the top of the head.3. Data Setup:   Each experimental trial has been taken separately for each physical activity. The duration of each action   was approximately ~10 seconds per subject, which corresponds to a time series of ~3000 samples, with   sampling frequency of 200Hz. Within this performance time, approximately 15 action trajectories were   extracted counting in average 15 normal (ex: handshaking), and 15 aggressive (ex: punching) actions.",Physical,"Each file in the dataset contains in overall 28 columns (the 1st is a counter), and is organised as follows:+---------+-------+---------------+---------------------+---------------------+---------------------+| Segment | Head  |     L-Arm     |        R-Arm        |        L-Leg        |        R-Leg        |+---------+-------+-------+-------+----------+----------+----------+----------+----------+----------+| Marker  | m1    | m2    | m3    | m4       | m5       | m6       | m7       | m8       | m9       || Coords  | x y z | x y z | x y z | x  y  z  | x  y  z  | x  y  z  | x  y  z  | x  y  z  | x  y  z  || Column  | 1,2,3 | 4,5,6 | 7,8,9 | 10,11,12 | 13,14,15 | 16,17,18 | 19,20,21 | 22,23,24 | 25,26,27 |+---------+-------+-------+-------+----------+----------+----------+----------+----------+----------+Segment: A segment defines a body segment or limb.         - Head	 - Left arm (L-Arm)	 - Right arm (R-Arm)	 - Left leg (L-Leg)	 - Right leg (R-Leg)Marker:  A pair of markers (except the head) is attached at each body segment for 3D data acquisition.	 - Arm markers: wrist (WRS), elbow (ELB)	 - Leg markers: ankle (ANK), knee (KNE)Coords:  The 3 coordinates (x,y,z) define the 3D position of each marker in space.	 - x: The x coordinate	 - y: The y coordinate	 - z: The z coordinate","The Physical Action Data Set includes 10 normal and 10 aggressive physical actions that measure the human activity. The data have been collected by 10 subjects using the Vicon 3D tracker.1. Protocol:   Seven male and three female subjects (age 25 to 30), who have experienced aggression in scenarios such   as physical fighting, took part in the experiment. Throughout 20 individual experiments, each subject   had to perform ten normal and ten aggressive activities. Regarding the rights of the subjects involved,   ethical regulations have been followed based on the code of ethics of the British psychological society,   which explains the ethical legislations to conduct statistical experiments using human subjects. For safety   precaution issues, boxing hand wraps have been given to the subjects, and for the warm up the subjects   were instructed to familiarise with the bag by having a number of trial runs. The subjects were aware that   since their involvement in this series of experiments was voluntary, it was made clear that they could   withdraw at any time from the study.2. Instrumentation:   The Essex robotic arena was the main experimental hall where the data collection took place. With area   4x5.5m, the ten subjects expressed normal and aggressive physical activities at random locations. For the   normal actions, a human partner has been used as a focus target attracting the attention from the subjects   so as to perform more realistic activity. For the aggressive actions, the subjects made use of a professional   kick-boxing standing bag, 1.75m tall, with a human figure drawn on its body. The bag has cylindrical shape   made from soft material, which could bounce when hit. All the activities have been recorded from random   starting positions so that to have a variety of spatial 3D data. The subjectsÃ¢â‚¬â„¢ performance has been recorded   by the ViconÃ¢â‚¬â„¢s nine ubiquitous cameras, interfacing human activity with spatial coordinate points. Based on   this context, the data acquisition process involved four reflectable markers placed on the forearms (elbows   and wrists), four on the forelegs (knees and ankles), and one on the top of the head.3. Data Setup:   Each experimental trial has been taken separately for each physical activity. The duration of each action   was approximately ~10 seconds per subject, which corresponds to a time series of ~3000 samples, with   sampling frequency of 200Hz. Within this performance time, approximately 15 action trajectories were   extracted counting in average 15 normal (ex: handshaking), and 15 aggressive (ex: punching) actions.Each file in the dataset contains in overall 28 columns (the 1st is a counter), and is organised as follows:+---------+-------+---------------+---------------------+---------------------+---------------------+| Segment | Head  |     L-Arm     |        R-Arm        |        L-Leg        |        R-Leg        |+---------+-------+-------+-------+----------+----------+----------+----------+----------+----------+| Marker  | m1    | m2    | m3    | m4       | m5       | m6       | m7       | m8       | m9       || Coords  | x y z | x y z | x y z | x  y  z  | x  y  z  | x  y  z  | x  y  z  | x  y  z  | x  y  z  || Column  | 1,2,3 | 4,5,6 | 7,8,9 | 10,11,12 | 13,14,15 | 16,17,18 | 19,20,21 | 22,23,24 | 25,26,27 |+---------+-------+-------+-------+----------+----------+----------+----------+----------+----------+Segment: A segment defines a body segment or limb.         - Head	 - Left arm (L-Arm)	 - Right arm (R-Arm)	 - Left leg (L-Leg)	 - Right leg (R-Leg)Marker:  A pair of markers (except the head) is attached at each body segment for 3D data acquisition.	 - Arm markers: wrist (WRS), elbow (ELB)	 - Leg markers: ankle (ANK), knee (KNE)Coords:  The 3 coordinates (x,y,z) define the 3D position of each marker in space.	 - x: The x coordinate	 - y: The y coordinate	 - z: The z coordinate"
Low Resolution Spectrometer,Low Resolution Spectrometer,From IRAS data -- NASA Ames Research Center,Low+Resolution+Spectrometer,https://archive.ics.uci.edu/ml//machine-learning-databases/spectrometer/,https://archive.ics.uci.edu/ml/datasets/Low+Resolution+Spectrometer,"The Infra-Red Astronomy Satellite (IRAS) was the first attempt to map the full sky at infra-red wavelengths.  This could not be done from ground observatories because large portions of the infra-red spectrum is absorbed by the atmosphere.  The primary observing program was the full high resolution sky mapping performed by scanning at 4 frequencies. The Low Resolution Observation (IRAS-LRS) program observed high intensity sources over two continuous spectral bands.  This database derives from a subset of the higher quality LRS observations taken between 12h and 24h right ascension. This database contains 531 high quality spectra derived from the IRAS-LRS database.  The original data contained 100 spectral measurements in each of two overlapping bands.  Of these, 44 blue band and 49 red band channels contain usable flux measurements.  Only these are included here.  The original spectral intensities values are compressed to 4-digits, and each spectrum includes 5 rescaling parameters.  We have used the LRS specified algorithm to rescale these to units of spectral intensity (Janskys).  Total intensity differences have been eliminated by normalizing each spectrum to a mean value of 5000.	This database was originally obtained for use in development and testing of our AutoClass system for Bayesian classification.  We have not retained any results from this development, having concentrated our efforts of a 5425 element version of the same data.  Our classifications were based upon simultaneous modeling of all 93 spectral intensities. With the larger database we were able to find classes that correspond well with known spectral types associated with particular stellar types. We also found classes that match with the spectra expected of certain stellar processes under investigation by Ames astronomers.  These classes have considerably enlarged the set of stars being investigated by those researchers.  Original Data:The original fortran data file is given in spectra-2.data.  The file spectra-2.head contains information about the .data file contents and how to rescale the compressed spectral intensities. ",Physical,"    1. LRS-name: (Suspected format: 5 digits, ""+"" or ""-"", 4 digits)    2. LRS-class: integer - The LRS-class values range from 0 - 99 with the 10's digit giving the basic class and the 1's digit giving the subclass. These classes are based on features (peaks, valleys, and trends) of the spectral curves.      3. ID-type: integer    4. Right-Ascension: float - Astronomical longitude. 1h = 15deg    5. Declination: float - Astronomical lattitude. -90 <= Dec <= 90    6. Scale Factor: float - Proportional to source strength    7. Blue base 1: integer - linear rescaling coefficient    8. Blue base 2: integer - linear rescaling coefficient    9. Red base 1: integer - linear rescaling coefficient   10. Red base 2: integer - linear rescaling coefficient   11-54: fluxes from the following 44 blue-band channel wavelengths: (all given as floating point numerals)     - 11. 7.8636     - 12. 8.0485     - 13. 8.2286     - 14. 8.4043     - 15. 8.5758     - 16. 8.7436     - 17. 8.9078     - 18. 9.0686     - 19. 9.2262     - 20. 9.3809      - 21. 9.5328     - 22. 9.6820     - 23. 9.8286      - 24. 9.9728      - 25. 10.1148      - 26. 10.2545      - 27. 10.3922      - 28. 10.5279      - 29. 10.6616      - 30. 10.7935      - 31. 10.9237      - 32. 11.0521      - 33. 11.1790      - 34. 11.3042      - 35. 11.4280      - 36. 11.5503      - 37. 11.6711      - 38. 11.7907      - 39. 11.9089      - 40. 12.0258      - 41. 12.1415      - 42. 12.2560      - 43. 12.3693      - 44. 12.4816      - 45. 12.5927      - 46. 12.7028      - 47. 12.8118      - 48. 12.9199      - 49. 13.0269      - 50. 13.1330      - 51. 13.2382      - 52. 13.3425      - 53. 13.4459      - 54. 13.5485    55-103: fluxes from the following 49 red-band channel wavelengths: (all given as floating point numerals)     - 55. 10.9929      - 56. 11.3704      - 57. 11.7357      - 58. 12.0899      - 59. 12.4339      - 60. 12.7687      - 61. 13.0948      - 62. 13.4131      - 63. 13.7239      - 64. 14.0278     - 65. 14.3252      - 66. 14.6166      - 67. 14.9022      - 68. 15.1825      - 69. 15.4576      - 70. 15.7280      - 71. 15.9937      - 72. 16.2551      - 73. 16.5123      - 74. 16.7656     - 75. 17.0151      - 76. 17.2610      - 77. 17.5034      - 78. 17.7425      - 79. 17.9784      - 80. 18.2113      - 81. 18.4412      - 82. 18.6682      - 83. 18.8925      - 84. 19.1142     - 85. 19.3334      - 86. 19.5500      - 87. 19.7643      - 88. 19.9763      - 89. 20.1861      - 90. 20.3937      - 91. 20.5992      - 92. 20.8026      - 93. 21.0041      - 94. 21.2037     - 95. 21.4014      - 96. 21.5973      - 97. 21.7914      - 98. 21.9838      - 99. 22.1745      - 100. 22.3636      - 101. 22.5511      - 102. 22.7371      - 103. 22.9216","From IRAS data -- NASA Ames Research CenterThe Infra-Red Astronomy Satellite (IRAS) was the first attempt to map the full sky at infra-red wavelengths.  This could not be done from ground observatories because large portions of the infra-red spectrum is absorbed by the atmosphere.  The primary observing program was the full high resolution sky mapping performed by scanning at 4 frequencies. The Low Resolution Observation (IRAS-LRS) program observed high intensity sources over two continuous spectral bands.  This database derives from a subset of the higher quality LRS observations taken between 12h and 24h right ascension. This database contains 531 high quality spectra derived from the IRAS-LRS database.  The original data contained 100 spectral measurements in each of two overlapping bands.  Of these, 44 blue band and 49 red band channels contain usable flux measurements.  Only these are included here.  The original spectral intensities values are compressed to 4-digits, and each spectrum includes 5 rescaling parameters.  We have used the LRS specified algorithm to rescale these to units of spectral intensity (Janskys).  Total intensity differences have been eliminated by normalizing each spectrum to a mean value of 5000.	This database was originally obtained for use in development and testing of our AutoClass system for Bayesian classification.  We have not retained any results from this development, having concentrated our efforts of a 5425 element version of the same data.  Our classifications were based upon simultaneous modeling of all 93 spectral intensities. With the larger database we were able to find classes that correspond well with known spectral types associated with particular stellar types. We also found classes that match with the spectra expected of certain stellar processes under investigation by Ames astronomers.  These classes have considerably enlarged the set of stars being investigated by those researchers.  Original Data:The original fortran data file is given in spectra-2.data.  The file spectra-2.head contains information about the .data file contents and how to rescale the compressed spectral intensities.     1. LRS-name: (Suspected format: 5 digits, ""+"" or ""-"", 4 digits)    2. LRS-class: integer - The LRS-class values range from 0 - 99 with the 10's digit giving the basic class and the 1's digit giving the subclass. These classes are based on features (peaks, valleys, and trends) of the spectral curves.      3. ID-type: integer    4. Right-Ascension: float - Astronomical longitude. 1h = 15deg    5. Declination: float - Astronomical lattitude. -90 <= Dec <= 90    6. Scale Factor: float - Proportional to source strength    7. Blue base 1: integer - linear rescaling coefficient    8. Blue base 2: integer - linear rescaling coefficient    9. Red base 1: integer - linear rescaling coefficient   10. Red base 2: integer - linear rescaling coefficient   11-54: fluxes from the following 44 blue-band channel wavelengths: (all given as floating point numerals)     - 11. 7.8636     - 12. 8.0485     - 13. 8.2286     - 14. 8.4043     - 15. 8.5758     - 16. 8.7436     - 17. 8.9078     - 18. 9.0686     - 19. 9.2262     - 20. 9.3809      - 21. 9.5328     - 22. 9.6820     - 23. 9.8286      - 24. 9.9728      - 25. 10.1148      - 26. 10.2545      - 27. 10.3922      - 28. 10.5279      - 29. 10.6616      - 30. 10.7935      - 31. 10.9237      - 32. 11.0521      - 33. 11.1790      - 34. 11.3042      - 35. 11.4280      - 36. 11.5503      - 37. 11.6711      - 38. 11.7907      - 39. 11.9089      - 40. 12.0258      - 41. 12.1415      - 42. 12.2560      - 43. 12.3693      - 44. 12.4816      - 45. 12.5927      - 46. 12.7028      - 47. 12.8118      - 48. 12.9199      - 49. 13.0269      - 50. 13.1330      - 51. 13.2382      - 52. 13.3425      - 53. 13.4459      - 54. 13.5485    55-103: fluxes from the following 49 red-band channel wavelengths: (all given as floating point numerals)     - 55. 10.9929      - 56. 11.3704      - 57. 11.7357      - 58. 12.0899      - 59. 12.4339      - 60. 12.7687      - 61. 13.0948      - 62. 13.4131      - 63. 13.7239      - 64. 14.0278     - 65. 14.3252      - 66. 14.6166      - 67. 14.9022      - 68. 15.1825      - 69. 15.4576      - 70. 15.7280      - 71. 15.9937      - 72. 16.2551      - 73. 16.5123      - 74. 16.7656     - 75. 17.0151      - 76. 17.2610      - 77. 17.5034      - 78. 17.7425      - 79. 17.9784      - 80. 18.2113      - 81. 18.4412      - 82. 18.6682      - 83. 18.8925      - 84. 19.1142     - 85. 19.3334      - 86. 19.5500      - 87. 19.7643      - 88. 19.9763      - 89. 20.1861      - 90. 20.3937      - 91. 20.5992      - 92. 20.8026      - 93. 21.0041      - 94. 21.2037     - 95. 21.4014      - 96. 21.5973      - 97. 21.7914      - 98. 21.9838      - 99. 22.1745      - 100. 22.3636      - 101. 22.5511      - 102. 22.7371      - 103. 22.9216"
Concrete Compressive Strength,Concrete Compressive Strength,Concrete is the most important material in civil engineering. The concrete compressive strength is a highly nonlinear function of age and ingredients. ,Concrete+Compressive+Strength,https://archive.ics.uci.edu/ml//machine-learning-databases/concrete/compressive/,https://archive.ics.uci.edu/ml/datasets/Concrete+Compressive+Strength,"Number of instances 	1030Number of Attributes	9Attribute breakdown	8 quantitative input variables, and 1 quantitative output variableMissing Attribute Values	None ",Physical,"Given are the variable name, variable type, the measurement unit and a brief description. The concrete compressive strength is the regression problem. The order of this listing corresponds to the order of numerals along the rows of the database. Name -- Data Type -- Measurement -- DescriptionCement (component 1) -- quantitative -- kg in a m3 mixture -- Input VariableBlast Furnace Slag (component 2) -- quantitative -- kg in a m3 mixture -- Input VariableFly Ash (component 3) -- quantitative  -- kg in a m3 mixture -- Input VariableWater  (component 4) -- quantitative  -- kg in a m3 mixture -- Input VariableSuperplasticizer (component 5) -- quantitative -- kg in a m3 mixture -- Input VariableCoarse Aggregate  (component 6) -- quantitative -- kg in a m3 mixture -- Input VariableFine Aggregate (component 7)	 -- quantitative  -- kg in a m3 mixture -- Input VariableAge -- quantitative  -- Day (1~365) -- Input VariableConcrete compressive strength -- quantitative -- MPa -- Output Variable","Concrete is the most important material in civil engineering. The concrete compressive strength is a highly nonlinear function of age and ingredients. Number of instances 	1030Number of Attributes	9Attribute breakdown	8 quantitative input variables, and 1 quantitative output variableMissing Attribute Values	None Given are the variable name, variable type, the measurement unit and a brief description. The concrete compressive strength is the regression problem. The order of this listing corresponds to the order of numerals along the rows of the database. Name -- Data Type -- Measurement -- DescriptionCement (component 1) -- quantitative -- kg in a m3 mixture -- Input VariableBlast Furnace Slag (component 2) -- quantitative -- kg in a m3 mixture -- Input VariableFly Ash (component 3) -- quantitative  -- kg in a m3 mixture -- Input VariableWater  (component 4) -- quantitative  -- kg in a m3 mixture -- Input VariableSuperplasticizer (component 5) -- quantitative -- kg in a m3 mixture -- Input VariableCoarse Aggregate  (component 6) -- quantitative -- kg in a m3 mixture -- Input VariableFine Aggregate (component 7)	 -- quantitative  -- kg in a m3 mixture -- Input VariableAge -- quantitative  -- Day (1~365) -- Input VariableConcrete compressive strength -- quantitative -- MPa -- Output Variable"
QSAR aquatic toxicity,QSAR aquatic toxicity,Data set containing values for 8 attributes (molecular descriptors) of 546 chemicals used to predict quantitative acute aquatic toxicity towards Daphnia Magna..,QSAR+aquatic+toxicity,https://archive.ics.uci.edu/ml//machine-learning-databases/00505/,https://archive.ics.uci.edu/ml/datasets/QSAR+aquatic+toxicity,"This dataset was used to develop quantitative regression QSAR models to predict acute aquatic toxicity towards the fish Pimephales promelas (fathead minnow) on a set of 908 chemicals. to predict acute aquatic toxicity towards Daphnia Magna. LC50 data, which is the concentration that causes death in 50% of test D. magna over a test duration of 48 hours, was used as model response. The model comprised 8 molecular descriptors: TPSA(Tot) (Molecular properties), SAacc (Molecular properties), H-050 (Atom-centred fragments), MLOGP (Molecular properties), RDCHI (Connectivity indices), GATS1p (2D autocorrelations), nN (Constitutional indices), C-040 (Atom-centred fragments). Details can be found in the quoted reference: M. Cassotti, D. Ballabio, V. Consonni, A. Mauri, I. V. Tetko, R. Todeschini (2014). Prediction of acute aquatic toxicity towards daphnia magna using GA-kNN method, Alternatives to Laboratory Animals (ATLA), 42,31:41; doi: 10.1177/026119291404200106",Physical,"8 molecular descriptors and 1 quantitative experimental response:1) TPSA(Tot)2) SAacc3) H-0504) MLOGP5) RDCHI6) GATS1p7) nN8) C-0409) quantitative response, LC50 [-LOG(mol/L)]","Data set containing values for 8 attributes (molecular descriptors) of 546 chemicals used to predict quantitative acute aquatic toxicity towards Daphnia Magna..This dataset was used to develop quantitative regression QSAR models to predict acute aquatic toxicity towards the fish Pimephales promelas (fathead minnow) on a set of 908 chemicals. to predict acute aquatic toxicity towards Daphnia Magna. LC50 data, which is the concentration that causes death in 50% of test D. magna over a test duration of 48 hours, was used as model response. The model comprised 8 molecular descriptors: TPSA(Tot) (Molecular properties), SAacc (Molecular properties), H-050 (Atom-centred fragments), MLOGP (Molecular properties), RDCHI (Connectivity indices), GATS1p (2D autocorrelations), nN (Constitutional indices), C-040 (Atom-centred fragments). Details can be found in the quoted reference: M. Cassotti, D. Ballabio, V. Consonni, A. Mauri, I. V. Tetko, R. Todeschini (2014). Prediction of acute aquatic toxicity towards daphnia magna using GA-kNN method, Alternatives to Laboratory Animals (ATLA), 42,31:41; doi: 10.1177/0261192914042001068 molecular descriptors and 1 quantitative experimental response:1) TPSA(Tot)2) SAacc3) H-0504) MLOGP5) RDCHI6) GATS1p7) nN8) C-0409) quantitative response, LC50 [-LOG(mol/L)]"
Musk (Version 1),Musk (Version 1),The goal is to learn to predict whether new molecules will be musks or non-musks,Musk+%28Version+1%29,https://archive.ics.uci.edu/ml//machine-learning-databases/musk/,https://archive.ics.uci.edu/ml/datasets/Musk+%28Version+1%29,"This dataset describes a set of 92 molecules of which 47 are judged by human experts to be musks and the remaining 45 molecules are judged to be non-musks.  The goal is to learn to predict whether new molecules will be musks or non-musks.  However, the 166 features that describe these molecules depend upon the exact shape, or conformation, of the molecule.  Because bonds can rotate, a single molecule can adopt many different shapes.  To generate this data set, the low-energy conformations of the molecules were generated and then filtered to remove highly similar conformations. This left 476 conformations.  Then, a feature vector was extracted that describes each conformation.This many-to-one relationship between feature vectors and molecules is called the ""multiple instance problem"".  When learning a classifier for this data, the classifier should classify a molecule as ""musk"" if ANY of its conformations is classified as a musk.  A molecule should be classified as ""non-musk"" if NONE of its conformations is classified as a musk.",Physical,"   molecule_name:       Symbolic name of each molecule.  Musks have names such as MUSK-188.  Non-musks have names such as NON-MUSK-jp13.   conformation_name:   Symbolic name of each conformation.  These have the format MOL_ISO+CONF, where MOL is the molecule number, ISO is the stereoisomer number (usually 1), and CONF is the conformation number.    f1 through f162:     These are ""distance features"" along rays (see paper cited above).  The distances are measured in hundredths of Angstroms.  The distances may be negative or positive, since they are actually measured relative to an origin placed along each ray.  The origin was defined by a ""consensus musk"" surface that is no longer used.  Hence, any experiments with the data should treat these feature values as lying on an arbitrary continuous scale.  In particular, the algorithm should not make any use of the zero point or the sign of each feature value.    f163:                This is the distance of the oxygen atom in the molecule to a designated point in 3-space. This is also called OXY-DIS.   f164:                OXY-X: X-displacement from the designated point.   f165:                OXY-Y: Y-displacement from the designated point.   f166:                OXY-Z: Z-displacement from the designated point.    class:               0 => non-musk, 1 => musk   Please note that the molecule_name and conformation_name attributes should not be used to predict the class.","The goal is to learn to predict whether new molecules will be musks or non-musksThis dataset describes a set of 92 molecules of which 47 are judged by human experts to be musks and the remaining 45 molecules are judged to be non-musks.  The goal is to learn to predict whether new molecules will be musks or non-musks.  However, the 166 features that describe these molecules depend upon the exact shape, or conformation, of the molecule.  Because bonds can rotate, a single molecule can adopt many different shapes.  To generate this data set, the low-energy conformations of the molecules were generated and then filtered to remove highly similar conformations. This left 476 conformations.  Then, a feature vector was extracted that describes each conformation.This many-to-one relationship between feature vectors and molecules is called the ""multiple instance problem"".  When learning a classifier for this data, the classifier should classify a molecule as ""musk"" if ANY of its conformations is classified as a musk.  A molecule should be classified as ""non-musk"" if NONE of its conformations is classified as a musk.   molecule_name:       Symbolic name of each molecule.  Musks have names such as MUSK-188.  Non-musks have names such as NON-MUSK-jp13.   conformation_name:   Symbolic name of each conformation.  These have the format MOL_ISO+CONF, where MOL is the molecule number, ISO is the stereoisomer number (usually 1), and CONF is the conformation number.    f1 through f162:     These are ""distance features"" along rays (see paper cited above).  The distances are measured in hundredths of Angstroms.  The distances may be negative or positive, since they are actually measured relative to an origin placed along each ray.  The origin was defined by a ""consensus musk"" surface that is no longer used.  Hence, any experiments with the data should treat these feature values as lying on an arbitrary continuous scale.  In particular, the algorithm should not make any use of the zero point or the sign of each feature value.    f163:                This is the distance of the oxygen atom in the molecule to a designated point in 3-space. This is also called OXY-DIS.   f164:                OXY-X: X-displacement from the designated point.   f165:                OXY-Y: Y-displacement from the designated point.   f166:                OXY-Z: Z-displacement from the designated point.    class:               0 => non-musk, 1 => musk   Please note that the molecule_name and conformation_name attributes should not be used to predict the class."
QSAR androgen receptor,QSAR androgen receptor,"1024 binary attributes (molecular fingerprints) used to classify 1687 chemicals into 2 classes (binder to androgen receptor/positive, non-binder to androgen receptor /negative)",QSAR+androgen+receptor,https://archive.ics.uci.edu/ml//machine-learning-databases/00509/,https://archive.ics.uci.edu/ml/datasets/QSAR+androgen+receptor,"This dataset was used to develop classification QSAR models for the discrimination of binder/positive (199) and non-binder/negative (1488) molecules by means of different machine learning methods. Details can be found in the quoted reference: F. Grisoni, V. Consonni, D. Ballabio, (2019) Machine Learning Consensus to Predict the Binding to the Androgen Receptor within the CoMPARA project, Journal of chemical information and modeling, 59, 1839-1848; doi: 10.1021/acs.jcim.8b00794. Attributes (molecular fingerprints) were calculated at the Milano Chemometrics and QSAR Research Group (UniversitÃƒÂ   degli Studi Milano - Bicocca, Milano, Italy) on a set of chemicals provided by the National Center of Computational Toxicology, at the U.S. Environmental Protection Agency in the framework of the  CoMPARA collaborative modelling project, which targeted the development of QSAR models to identify binders to the Androgen Receptor.",Physical,1024 binary molecular fingerprints and 1 experimental class:1-1024) binary molecular fingerprint1025) experimental class: positive (binder) and negative (non-binder),"1024 binary attributes (molecular fingerprints) used to classify 1687 chemicals into 2 classes (binder to androgen receptor/positive, non-binder to androgen receptor /negative)This dataset was used to develop classification QSAR models for the discrimination of binder/positive (199) and non-binder/negative (1488) molecules by means of different machine learning methods. Details can be found in the quoted reference: F. Grisoni, V. Consonni, D. Ballabio, (2019) Machine Learning Consensus to Predict the Binding to the Androgen Receptor within the CoMPARA project, Journal of chemical information and modeling, 59, 1839-1848; doi: 10.1021/acs.jcim.8b00794. Attributes (molecular fingerprints) were calculated at the Milano Chemometrics and QSAR Research Group (UniversitÃƒÂ   degli Studi Milano - Bicocca, Milano, Italy) on a set of chemicals provided by the National Center of Computational Toxicology, at the U.S. Environmental Protection Agency in the framework of the  CoMPARA collaborative modelling project, which targeted the development of QSAR models to identify binders to the Androgen Receptor.1024 binary molecular fingerprints and 1 experimental class:1-1024) binary molecular fingerprint1025) experimental class: positive (binder) and negative (non-binder)"
Coil 1999 Competition Data,Coil 1999 Competition Data,This data set is from the 1999 Computational Intelligence and Learning (COIL) competition. The data contains measurements of river chemical concentrations and algae densities.,Coil+1999+Competition+Data,https://archive.ics.uci.edu/ml//machine-learning-databases/coil-mld/,https://archive.ics.uci.edu/ml/datasets/Coil+1999+Competition+Data,"This data comes from a water quality study where samples were taken from sites on different European rivers of a period of approximately one year. These samples were analyzed for various chemical substances including: nitrogen in the form of nitrates, nitrites and ammonia, phosphate, pH, oxygen, chloride. In parallel, algae samples were collected to determine the algae population distributions. The competition involved the prediction of algal frequency distributions on the basis of the measured concentrations of the chemical substances and the global information concerning the season when the sample was taken, the river size and its flow velocity. The competition instructions contain additional information on the prediction task: [Web Link]",Physical,"There are a total of 340 examples each containing 17 values. The first 11 values of each data set are the season, the river size, the fluid velocity and 8 chemical concentrations which should be relevant for the algae population distribution. The last 8 values of each example are the distribution of different kinds of algae. These 8 kinds are only a very small part of the whole community, but for the competition we limited the number to 7. The value 0.0 means that the frequency is very low. The data set also contains some empty fields which are labeled with the string XXXXX. The training data are saved in the file: analysis.data (ASCII format).Table 1: Structure of the file analysis.dataA ... K  a ... gCC1,1  ... CC1,11  AG1,1 ... AG1,7 ... CC200,1 ... CC200,11  AG200,1 ... AG200,7  Explanation:CCi,j: Chemical concentration or river characteristicAGi,j: Algal frequencyThe chemical parameters are labeled as A, ..., K. The columns of the algaes are labeled as a, ..,g. ","This data set is from the 1999 Computational Intelligence and Learning (COIL) competition. The data contains measurements of river chemical concentrations and algae densities.This data comes from a water quality study where samples were taken from sites on different European rivers of a period of approximately one year. These samples were analyzed for various chemical substances including: nitrogen in the form of nitrates, nitrites and ammonia, phosphate, pH, oxygen, chloride. In parallel, algae samples were collected to determine the algae population distributions. The competition involved the prediction of algal frequency distributions on the basis of the measured concentrations of the chemical substances and the global information concerning the season when the sample was taken, the river size and its flow velocity. The competition instructions contain additional information on the prediction task: [Web Link]There are a total of 340 examples each containing 17 values. The first 11 values of each data set are the season, the river size, the fluid velocity and 8 chemical concentrations which should be relevant for the algae population distribution. The last 8 values of each example are the distribution of different kinds of algae. These 8 kinds are only a very small part of the whole community, but for the competition we limited the number to 7. The value 0.0 means that the frequency is very low. The data set also contains some empty fields which are labeled with the string XXXXX. The training data are saved in the file: analysis.data (ASCII format).Table 1: Structure of the file analysis.dataA ... K  a ... gCC1,1  ... CC1,11  AG1,1 ... AG1,7 ... CC200,1 ... CC200,11  AG200,1 ... AG200,7  Explanation:CCi,j: Chemical concentration or river characteristicAGi,j: Algal frequencyThe chemical parameters are labeled as A, ..., K. The columns of the algaes are labeled as a, ..,g. "
MAGIC Gamma Telescope,MAGIC Gamma Telescope,Data are MC generated to simulate registration of high energy gamma particles in an atmospheric Cherenkov telescope,MAGIC+Gamma+Telescope,https://archive.ics.uci.edu/ml//machine-learning-databases/magic/,https://archive.ics.uci.edu/ml/datasets/MAGIC+Gamma+Telescope,"The data are MC generated (see below) to simulate registration of high energy gamma particles in a ground-based atmospheric Cherenkov gamma telescope using the imaging technique. Cherenkov gamma telescope observes high energy gamma rays, taking advantage of the radiation emitted by charged particles produced inside the electromagnetic showers initiated by the gammas, and developing in the atmosphere. This Cherenkov radiation (of visible to UV wavelengths) leaks through the atmosphere and gets recorded in the detector, allowing reconstruction of the shower parameters. The available information consists of pulses left by the incoming Cherenkov photons on the photomultiplier tubes, arranged in a plane, the camera. Depending on the energy of the primary gamma, a total of few hundreds to some 10000 Cherenkov photons get collected, in patterns (called the shower image), allowing to discriminate statistically those caused by primary gammas (signal) from the images of hadronic showers initiated by cosmic rays in the upper atmosphere (background).Typically, the image of a shower after some pre-processing is an elongated cluster. Its long axis is oriented towards the camera center if the shower axis is parallel to the telescope's optical axis, i.e. if the telescope axis is directed towards a point source. A principal component analysis is performed in the camera plane, which results in a correlation axis and defines an ellipse. If the depositions were distributed as a bivariate Gaussian, this would be an equidensity ellipse. The characteristic parameters of this ellipse (often called Hillas parameters) are among the image parameters that can be used for discrimination. The energy depositions are typically asymmetric along the major axis, and this asymmetry can also be used in discrimination. There are, in addition, further discriminating characteristics, like the extent of the cluster in the image plane, or the total sum of depositions.The data set was generated by a Monte Carlo program, Corsika, described in:    D. Heck et al., CORSIKA, A Monte Carlo code to simulate extensive air showers,    Forschungszentrum Karlsruhe FZKA 6019 (1998).[Web Link]The program was run with parameters allowing to observe events with energies down to below 50 GeV.",Physical,"    1.  fLength:  continuous  # major axis of ellipse [mm]    2.  fWidth:   continuous  # minor axis of ellipse [mm]     3.  fSize:    continuous  # 10-log of sum of content of all pixels [in #phot]    4.  fConc:    continuous  # ratio of sum of two highest pixels over fSize  [ratio]    5.  fConc1:   continuous  # ratio of highest pixel over fSize  [ratio]    6.  fAsym:    continuous  # distance from highest pixel to center, projected onto major axis [mm]    7.  fM3Long:  continuous  # 3rd root of third moment along major axis  [mm]     8.  fM3Trans: continuous  # 3rd root of third moment along minor axis  [mm]    9.  fAlpha:   continuous  # angle of major axis with vector to origin [deg]   10.  fDist:    continuous  # distance from origin to center of ellipse [mm]   11.  class:    g,h         # gamma (signal), hadron (background)   g = gamma (signal):     12332   h = hadron (background): 6688   For technical reasons, the number of h events is underestimated. In the real data, the h class represents the majority of the events.   The simple classification accuracy is not meaningful for this data, since classifying a background event as signal is worse than classifying a signal event as background. For comparison of different classifiers an ROC curve has to be used. The relevant points on this curve are those, where the probability of accepting a background event as signal is below one of the following thresholds: 0.01, 0.02, 0.05, 0.1, 0.2 depending on the required quality of the sample of the accepted events for different experiments.","Data are MC generated to simulate registration of high energy gamma particles in an atmospheric Cherenkov telescopeThe data are MC generated (see below) to simulate registration of high energy gamma particles in a ground-based atmospheric Cherenkov gamma telescope using the imaging technique. Cherenkov gamma telescope observes high energy gamma rays, taking advantage of the radiation emitted by charged particles produced inside the electromagnetic showers initiated by the gammas, and developing in the atmosphere. This Cherenkov radiation (of visible to UV wavelengths) leaks through the atmosphere and gets recorded in the detector, allowing reconstruction of the shower parameters. The available information consists of pulses left by the incoming Cherenkov photons on the photomultiplier tubes, arranged in a plane, the camera. Depending on the energy of the primary gamma, a total of few hundreds to some 10000 Cherenkov photons get collected, in patterns (called the shower image), allowing to discriminate statistically those caused by primary gammas (signal) from the images of hadronic showers initiated by cosmic rays in the upper atmosphere (background).Typically, the image of a shower after some pre-processing is an elongated cluster. Its long axis is oriented towards the camera center if the shower axis is parallel to the telescope's optical axis, i.e. if the telescope axis is directed towards a point source. A principal component analysis is performed in the camera plane, which results in a correlation axis and defines an ellipse. If the depositions were distributed as a bivariate Gaussian, this would be an equidensity ellipse. The characteristic parameters of this ellipse (often called Hillas parameters) are among the image parameters that can be used for discrimination. The energy depositions are typically asymmetric along the major axis, and this asymmetry can also be used in discrimination. There are, in addition, further discriminating characteristics, like the extent of the cluster in the image plane, or the total sum of depositions.The data set was generated by a Monte Carlo program, Corsika, described in:    D. Heck et al., CORSIKA, A Monte Carlo code to simulate extensive air showers,    Forschungszentrum Karlsruhe FZKA 6019 (1998).[Web Link]The program was run with parameters allowing to observe events with energies down to below 50 GeV.    1.  fLength:  continuous  # major axis of ellipse [mm]    2.  fWidth:   continuous  # minor axis of ellipse [mm]     3.  fSize:    continuous  # 10-log of sum of content of all pixels [in #phot]    4.  fConc:    continuous  # ratio of sum of two highest pixels over fSize  [ratio]    5.  fConc1:   continuous  # ratio of highest pixel over fSize  [ratio]    6.  fAsym:    continuous  # distance from highest pixel to center, projected onto major axis [mm]    7.  fM3Long:  continuous  # 3rd root of third moment along major axis  [mm]     8.  fM3Trans: continuous  # 3rd root of third moment along minor axis  [mm]    9.  fAlpha:   continuous  # angle of major axis with vector to origin [deg]   10.  fDist:    continuous  # distance from origin to center of ellipse [mm]   11.  class:    g,h         # gamma (signal), hadron (background)   g = gamma (signal):     12332   h = hadron (background): 6688   For technical reasons, the number of h events is underestimated. In the real data, the h class represents the majority of the events.   The simple classification accuracy is not meaningful for this data, since classifying a background event as signal is worse than classifying a signal event as background. For comparison of different classifiers an ROC curve has to be used. The relevant points on this curve are those, where the probability of accepting a background event as signal is below one of the following thresholds: 0.01, 0.02, 0.05, 0.1, 0.2 depending on the required quality of the sample of the accepted events for different experiments."
Challenger USA Space Shuttle O-Ring,Challenger USA Space Shuttle O-Ring,Task: predict the number of O-rings that experience thermal distress on a flight at 31 degrees F given data on the previous 23 shuttle flights,Challenger+USA+Space+Shuttle+O-Ring,https://archive.ics.uci.edu/ml//machine-learning-databases/space-shuttle/,https://archive.ics.uci.edu/ml/datasets/Challenger+USA+Space+Shuttle+O-Ring,"There are two databases: (both use the same set of 5 attributes):1. Primary o-ring erosion and/or blowby2. Primary o-ring erosion onlyThe two databases are identical except for the 2nd attribute of the 21st instance (confirmed by David Draper on 8/5/93).Edited from (Draper, 1993):The motivation for collecting this database was the explosion of the USA Space Shuttle Challenger on 28 January, 1986.  An investigation ensued into the reliability of the shuttle's propulsion system.  The explosion was eventually traced to the failure of one of the three field joints on one of the two solid booster rockets.  Each of these six field joints includes two O-rings, designated as primary and secondary, which fail when phenomena called erosion and blowby both occur. The night before the launch a decision had to be made regarding launch safety.  The discussion among engineers and managers leading to this decision included concern that the probability of failure of the O-rings depended on the temperature t at launch, which was forecase to be 31 degrees F. There are strong engineering reasons based on the composition of O-rings to support the judgment that failure probability may rise monotonically as temperature drops.  One other variable, the pressure s at which safety testing for field join leaks was performed, was available, but its relevance to the failure process was unclear.       Draper's paper includes a menacing figure graphing the number of field joints experiencing stress vs. liftoff temperature for the 23 shuttle flights previous to the Challenger disaster.  No previous liftoff temperature was under 53 degrees F.  Although tremendous extrapolation must be done from the given data to assess risk at 31 degrees F, it is obvious even to the layman ""to foresee the unacceptably high risk created by launching at 31 degrees F.""  For more information, see Draper (1993) or the other previous analyses.       The task is to predict the number of O-rings that will experience thermal distress for a given flight when the launch temperature is below freezing.",Physical,     1. Number of O-rings at risk on a given flight     2. Number experiencing thermal distress     3. Launch temperature (degrees F)     4. Leak-check pressure (psi)     5. Temporal order of flight,"Task: predict the number of O-rings that experience thermal distress on a flight at 31 degrees F given data on the previous 23 shuttle flightsThere are two databases: (both use the same set of 5 attributes):1. Primary o-ring erosion and/or blowby2. Primary o-ring erosion onlyThe two databases are identical except for the 2nd attribute of the 21st instance (confirmed by David Draper on 8/5/93).Edited from (Draper, 1993):The motivation for collecting this database was the explosion of the USA Space Shuttle Challenger on 28 January, 1986.  An investigation ensued into the reliability of the shuttle's propulsion system.  The explosion was eventually traced to the failure of one of the three field joints on one of the two solid booster rockets.  Each of these six field joints includes two O-rings, designated as primary and secondary, which fail when phenomena called erosion and blowby both occur. The night before the launch a decision had to be made regarding launch safety.  The discussion among engineers and managers leading to this decision included concern that the probability of failure of the O-rings depended on the temperature t at launch, which was forecase to be 31 degrees F. There are strong engineering reasons based on the composition of O-rings to support the judgment that failure probability may rise monotonically as temperature drops.  One other variable, the pressure s at which safety testing for field join leaks was performed, was available, but its relevance to the failure process was unclear.       Draper's paper includes a menacing figure graphing the number of field joints experiencing stress vs. liftoff temperature for the 23 shuttle flights previous to the Challenger disaster.  No previous liftoff temperature was under 53 degrees F.  Although tremendous extrapolation must be done from the given data to assess risk at 31 degrees F, it is obvious even to the layman ""to foresee the unacceptably high risk created by launching at 31 degrees F.""  For more information, see Draper (1993) or the other previous analyses.       The task is to predict the number of O-rings that will experience thermal distress for a given flight when the launch temperature is below freezing.     1. Number of O-rings at risk on a given flight     2. Number experiencing thermal distress     3. Launch temperature (degrees F)     4. Leak-check pressure (psi)     5. Temporal order of flight"
QSAR fish toxicity,QSAR fish toxicity,Data set containing values for 6 attributes (molecular descriptors) of 908 chemicals used to predict quantitative acute aquatic toxicity towards the fish Pimephales promelas (fathead minnow).,QSAR+fish+toxicity,https://archive.ics.uci.edu/ml//machine-learning-databases/00504/,https://archive.ics.uci.edu/ml/datasets/QSAR+fish+toxicity,"This dataset was used to develop quantitative regression QSAR models to predict acute aquatic toxicity towards the fish Pimephales promelas (fathead minnow) on a set of 908 chemicals. LC50 data, which is the concentration that causes death in 50% of test fish over a test duration of 96 hours, was used as model response. The model comprised 6 molecular descriptors: MLOGP (molecular properties), CIC0 (information indices), GATS1i (2D autocorrelations), NdssC (atom-type counts), NdsCH ((atom-type counts), SM1_Dz(Z) (2D matrix-based descriptors). Details can be found in the quoted reference: M. Cassotti, D. Ballabio, R. Todeschini, V. Consonni. A similarity-based QSAR model for predicting acute toxicity towards the fathead minnow (Pimephales promelas), SAR and QSAR in Environmental Research (2015), 26, 217-243; doi: 10.1080/1062936X.2015.1018938",Physical,"6 molecular descriptors and 1 quantitative experimental response:1) CIC02) SM1_Dz(Z)3) GATS1i4) NdsCH5) NdssC6) MLOGP7) quantitative response, LC50 [-LOG(mol/L)]","Data set containing values for 6 attributes (molecular descriptors) of 908 chemicals used to predict quantitative acute aquatic toxicity towards the fish Pimephales promelas (fathead minnow).This dataset was used to develop quantitative regression QSAR models to predict acute aquatic toxicity towards the fish Pimephales promelas (fathead minnow) on a set of 908 chemicals. LC50 data, which is the concentration that causes death in 50% of test fish over a test duration of 96 hours, was used as model response. The model comprised 6 molecular descriptors: MLOGP (molecular properties), CIC0 (information indices), GATS1i (2D autocorrelations), NdssC (atom-type counts), NdsCH ((atom-type counts), SM1_Dz(Z) (2D matrix-based descriptors). Details can be found in the quoted reference: M. Cassotti, D. Ballabio, R. Todeschini, V. Consonni. A similarity-based QSAR model for predicting acute toxicity towards the fathead minnow (Pimephales promelas), SAR and QSAR in Environmental Research (2015), 26, 217-243; doi: 10.1080/1062936X.2015.10189386 molecular descriptors and 1 quantitative experimental response:1) CIC02) SM1_Dz(Z)3) GATS1i4) NdsCH5) NdssC6) MLOGP7) quantitative response, LC50 [-LOG(mol/L)]"
PM2.5 Data of Five Chinese Cities,PM2.5 Data of Five Chinese Cities,"This hourly data set contains the PM2.5 data in Beijing, Shanghai, Guangzhou, Chengdu and Shenyang. Meanwhile, meteorological data for each city are also included.",PM2.5+Data+of+Five+Chinese+Cities,https://archive.ics.uci.edu/ml//machine-learning-databases/00394/,https://archive.ics.uci.edu/ml/datasets/PM2.5+Data+of+Five+Chinese+Cities,"The time period is between Jan 1st, 2010 to Dec 31st, 2015. Missing data are denoted as NA.",Physical,No: row number year: year of data in this row month: month of data in this row day: day of data in this row hour: hour of data in this row season: season of data in this rowPM: PM2.5 concentration (ug/m^3) DEWP: Dew Point (Celsius Degree)TEMP: Temperature (Celsius Degree)HUMI: Humidity (%)PRES: Pressure (hPa) cbwd: Combined wind direction Iws: Cumulated wind speed (m/s) precipitation: hourly precipitation (mm)Iprec: Cumulated precipitation (mm),"This hourly data set contains the PM2.5 data in Beijing, Shanghai, Guangzhou, Chengdu and Shenyang. Meanwhile, meteorological data for each city are also included.The time period is between Jan 1st, 2010 to Dec 31st, 2015. Missing data are denoted as NA.No: row number year: year of data in this row month: month of data in this row day: day of data in this row hour: hour of data in this row season: season of data in this rowPM: PM2.5 concentration (ug/m^3) DEWP: Dew Point (Celsius Degree)TEMP: Temperature (Celsius Degree)HUMI: Humidity (%)PRES: Pressure (hPa) cbwd: Combined wind direction Iws: Cumulated wind speed (m/s) precipitation: hourly precipitation (mm)Iprec: Cumulated precipitation (mm)"
Wine,Wine,Using chemical analysis determine the origin of wines,Wine,https://archive.ics.uci.edu/ml//machine-learning-databases/wine/,https://archive.ics.uci.edu/ml/datasets/Wine,"These data are the results of a chemical analysis of wines grown in the same region in Italy but derived from three different cultivars. The analysis determined the quantities of 13 constituents found in each of the three types of wines. I think that the initial data set had around 30 variables, but for some reason I only have the 13 dimensional version. I had a list of what the 30 or so variables were, but a.)  I lost it, and b.), I would not know which 13 variables are included in the set.The attributes are (dontated by Riccardo Leardi, riclea '@' anchem.unige.it )1) Alcohol2) Malic acid3) Ash4) Alcalinity of ash  5) Magnesium6) Total phenols7) Flavanoids8) Nonflavanoid phenols9) Proanthocyanins10)Color intensity11)Hue12)OD280/OD315 of diluted wines13)Proline In a classification context, this is a well posed problem with ""well behaved"" class structures. A good data set for first testing of a new classifier, but not very challenging.           ",Physical,"All attributes are continuous	No statistics available, but suggest to standardise variables for certain uses (e.g. for us with classifiers which are NOT scale invariant)NOTE: 1st attribute is class identifier (1-3)","Using chemical analysis determine the origin of winesThese data are the results of a chemical analysis of wines grown in the same region in Italy but derived from three different cultivars. The analysis determined the quantities of 13 constituents found in each of the three types of wines. I think that the initial data set had around 30 variables, but for some reason I only have the 13 dimensional version. I had a list of what the 30 or so variables were, but a.)  I lost it, and b.), I would not know which 13 variables are included in the set.The attributes are (dontated by Riccardo Leardi, riclea '@' anchem.unige.it )1) Alcohol2) Malic acid3) Ash4) Alcalinity of ash  5) Magnesium6) Total phenols7) Flavanoids8) Nonflavanoid phenols9) Proanthocyanins10)Color intensity11)Hue12)OD280/OD315 of diluted wines13)Proline In a classification context, this is a well posed problem with ""well behaved"" class structures. A good data set for first testing of a new classifier, but not very challenging.           All attributes are continuous	No statistics available, but suggest to standardise variables for certain uses (e.g. for us with classifiers which are NOT scale invariant)NOTE: 1st attribute is class identifier (1-3)"
Chemical Composition of Ceramic Samples,Chemical Composition of Ceramic Samples,Classify ceramic samples based on their chemical composition from energy dispersive X-ray fluorescence,Chemical+Composition+of+Ceramic+Samples,https://archive.ics.uci.edu/ml//machine-learning-databases/00583/,https://archive.ics.uci.edu/ml/datasets/Chemical+Composition+of+Ceramic+Samples,The energy dispersive X-ray fluorescence (EDXRF) was used to determine the chemical composition of celadon body and glaze in Longquan kiln (at Dayao County) and Jingdezhen kiln. Forty typical shards in four cultural eras were selected to investigate the raw materials and firing technology. We hope to identify chemical elements that are strongest explanatory variables to classify samples into different cultural eras and kilns.,Physical,Ceramic.Name: name of ceramic types from Longquan and JindgezhenPart: a binary categorical variable ('Body' or 'Glaze')Na2O:  percentage of Na2O (wt%)MgO:  percentage of MgO (wt%)Al2O3:  percentage of  AI2O3 (wt%)SiO2:  percentage of SiO2 (wt%)K2O:  percentage of  K2O (wt%)CaO:  percentage of CaO (wt%)TiO2:  percentage of TiO2 (wt%)Fe2O3:  percentage of Fe2O3 (wt%)MnO:  percentage of MnO  (ppm)CuO:  percentage of  CuO (ppm)ZnO:  percentage of  ZnO (ppm)PbO2:  percentage of PbO2  (ppm)Rb2O:  percentage of  Rb2O (ppm)SrO:  percentage of SrO (ppm)Y2O3:  percentage of Y2O3 (ppm)ZrO2: percentage of ZrO2  (ppm)P2O5: percentage of P2O5  (ppm),Classify ceramic samples based on their chemical composition from energy dispersive X-ray fluorescenceThe energy dispersive X-ray fluorescence (EDXRF) was used to determine the chemical composition of celadon body and glaze in Longquan kiln (at Dayao County) and Jingdezhen kiln. Forty typical shards in four cultural eras were selected to investigate the raw materials and firing technology. We hope to identify chemical elements that are strongest explanatory variables to classify samples into different cultural eras and kilns.Ceramic.Name: name of ceramic types from Longquan and JindgezhenPart: a binary categorical variable ('Body' or 'Glaze')Na2O:  percentage of Na2O (wt%)MgO:  percentage of MgO (wt%)Al2O3:  percentage of  AI2O3 (wt%)SiO2:  percentage of SiO2 (wt%)K2O:  percentage of  K2O (wt%)CaO:  percentage of CaO (wt%)TiO2:  percentage of TiO2 (wt%)Fe2O3:  percentage of Fe2O3 (wt%)MnO:  percentage of MnO  (ppm)CuO:  percentage of  CuO (ppm)ZnO:  percentage of  ZnO (ppm)PbO2:  percentage of PbO2  (ppm)Rb2O:  percentage of  Rb2O (ppm)SrO:  percentage of SrO (ppm)Y2O3:  percentage of Y2O3 (ppm)ZrO2: percentage of ZrO2  (ppm)P2O5: percentage of P2O5  (ppm)
Function Finding,Function Finding,Cases collected mostly from investigations in physical science; intention is to evaluate function-finding algorithms,Function+Finding,https://archive.ics.uci.edu/ml//machine-learning-databases/function-finding/,https://archive.ics.uci.edu/ml/datasets/Function+Finding,"[Please note the use of Latex format here for algebraic expressions. See Leslie Lamport, Latex: A Document Preparation System, Addison-Wesley, 1986 for details.]This database contains 352 bivariate numeric data sets collected from diverse sources and resulting, with a few exceptions, from investigations in physical science. For each data set, the collection includes:1. Source: Bibliographic information for the source of the data.2. Description: Identification of the variables $x$ and $y$.  Except in a few clearly identified instances, the abbreviated format $y$ vs. $x$ is employed.  An entry of the formDescription: Force vs. separation.  indicates that $x$ is a separation and $y$ is a force.  In some cases--when the information was readily available--the description also includes the units in which the data was originally reported.     3. Reference relation: The functional relationship proposed by the reporting scientist in the original source.4. Comments (optional): Additional information pertaining to the case.In recording reference relations, the database often omits details of parameter values.  If a scientist proposes $y=23.1x-.0014$, the reference relation may be given as just $y=k_{1}x+k_{2}$.  Also, since algebraic transformations have been employed freely, the same relation might be given as $y/x=k_{2}/x+k_{1}$.In general, data collected here is given in full as it appeared in the original source.  Fractions have been converted to decimals, numbers have been freely translated to and from scientific notation and zeros have sometimes been added to decimal numbers to facilitate tabulation. Any additional deviations from verbatim transcription are noted in the Comments entry of the associated case.  Note in particular that, in a few clearly identified cases, apparent typographical errors have been corrected and that, in others, data points identified by the reporting scientist as *not* conforming to the proposed relationship have been omitted.",Physical,,"Cases collected mostly from investigations in physical science; intention is to evaluate function-finding algorithms[Please note the use of Latex format here for algebraic expressions. See Leslie Lamport, Latex: A Document Preparation System, Addison-Wesley, 1986 for details.]This database contains 352 bivariate numeric data sets collected from diverse sources and resulting, with a few exceptions, from investigations in physical science. For each data set, the collection includes:1. Source: Bibliographic information for the source of the data.2. Description: Identification of the variables $x$ and $y$.  Except in a few clearly identified instances, the abbreviated format $y$ vs. $x$ is employed.  An entry of the formDescription: Force vs. separation.  indicates that $x$ is a separation and $y$ is a force.  In some cases--when the information was readily available--the description also includes the units in which the data was originally reported.     3. Reference relation: The functional relationship proposed by the reporting scientist in the original source.4. Comments (optional): Additional information pertaining to the case.In recording reference relations, the database often omits details of parameter values.  If a scientist proposes $y=23.1x-.0014$, the reference relation may be given as just $y=k_{1}x+k_{2}$.  Also, since algebraic transformations have been employed freely, the same relation might be given as $y/x=k_{2}/x+k_{1}$.In general, data collected here is given in full as it appeared in the original source.  Fractions have been converted to decimals, numbers have been freely translated to and from scientific notation and zeros have sometimes been added to decimal numbers to facilitate tabulation. Any additional deviations from verbatim transcription are noted in the Comments entry of the associated case.  Note in particular that, in a few clearly identified cases, apparent typographical errors have been corrected and that, in others, data points identified by the reporting scientist as *not* conforming to the proposed relationship have been omitted.nan"
MiniBooNE particle identification,MiniBooNE particle identification,This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background).,MiniBooNE+particle+identification,https://archive.ics.uci.edu/ml//machine-learning-databases/00199/,https://archive.ics.uci.edu/ml/datasets/MiniBooNE+particle+identification,"The submitted file is set up as follows. In the first line is the the number of signal events followed by the number of background events. The signal events come first, followed by the background events. Each line, after the first line has the 50 particle ID variables for one event.",Physical,50 particle ID variables (real) for each event.,"This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background).The submitted file is set up as follows. In the first line is the the number of signal events followed by the number of background events. The signal events come first, followed by the background events. Each line, after the first line has the 50 particle ID variables for one event.50 particle ID variables (real) for each event."
Cylinder Bands,Cylinder Bands,"Used in decision tree induction for mitigating process delays known as ""cylinder bands"" in rotogravure printing",Cylinder+Bands,https://archive.ics.uci.edu/ml//machine-learning-databases/cylinder-bands/,https://archive.ics.uci.edu/ml/datasets/Cylinder+Bands,"Here's the abstract from the above reference:ABSTRACT: Machine learning tools show significant promise for knowledge acquisition, particularly when human expertise is inadequate. Recently, process delays known as cylinder banding in rotogravure printing were substantially mitigated using control rules discovered by decision tree induction. Our work exemplifies a more general methodology which transforms the knowledge acquisition task from one in which rules are directly elicited from an expert, to one in which a learning system is responsible for rule generation. The primary responsibilities of the human expert are to evaluate the merits of generated rules, and to guide the acquisition and classification of data necessary for machine induction. These responsibilities require the expert to do what an expert does best: to exercise his or her expertise. This seems a more natural fit to an expert's capabilities than the requirements of traditional methodologies that experts explicitly enumerate the rules that they employ.",Physical,"	 1. timestamp: numeric;19500101 - 21001231 	 2. cylinder number: nominal	 3. customer: nominal; 	 4. job number: nominal; 	 5. grain screened: nominal; yes, no 	 6. ink color: nominal;  key, type 	 7. proof on ctd ink:  nominal;  yes, no  	 8. blade mfg: nominal;  benton, daetwyler, uddeholm 	 9. cylinder division: nominal;  gallatin, warsaw, mattoon 	10. paper type: nominal;  uncoated, coated, super 	11. ink type: nominal;  uncoated, coated, cover 	12. direct steam: nominal; use; yes, no *	13. solvent type: nominal;  xylol, lactol, naptha, line, other 	14. type on cylinder:  nominal;  yes, no  	15. press type: nominal; use; 70 wood hoe, 70 motter, 70 albert, 94 motter 	16. press: nominal;  821, 802, 813, 824, 815, 816, 827, 828 	17. unit number: nominal;  1, 2, 3, 4, 5, 6, 7, 8, 9, 10 	18. cylinder size: nominal;  catalog, spiegel, tabloid 	19. paper mill location: nominal; north us, south us, canadian, scandanavian, mid european	20. plating tank: nominal; 1910, 1911, other 	21. proof cut: numeric;  0-100 	22. viscosity: numeric;  0-100 	23. caliper: numeric;  0-1.0 	24. ink temperature: numeric;  5-30 	25. humifity: numeric;  5-120 	26. roughness: numeric;  0-2 	27. blade pressure: numeric;  10-75 	28. varnish pct: numeric;  0-100 	29. press speed: numeric;  0-4000 	30. ink pct: numeric;  0-100 	31. solvent pct: numeric;  0-100 	32. ESA Voltage: numeric;  0-16 	33. ESA Amperage: numeric;  0-10 	34. wax: numeric ;  0-4.0	35. hardener:  numeric; 0-3.0 	36. roller durometer:  numeric;  15-120 	37. current density:  numeric;  20-50 	38. anode space ratio:  numeric;  70-130 	39. chrome content: numeric; 80-120 	40. band type: nominal; class; band, no band *","Used in decision tree induction for mitigating process delays known as ""cylinder bands"" in rotogravure printingHere's the abstract from the above reference:ABSTRACT: Machine learning tools show significant promise for knowledge acquisition, particularly when human expertise is inadequate. Recently, process delays known as cylinder banding in rotogravure printing were substantially mitigated using control rules discovered by decision tree induction. Our work exemplifies a more general methodology which transforms the knowledge acquisition task from one in which rules are directly elicited from an expert, to one in which a learning system is responsible for rule generation. The primary responsibilities of the human expert are to evaluate the merits of generated rules, and to guide the acquisition and classification of data necessary for machine induction. These responsibilities require the expert to do what an expert does best: to exercise his or her expertise. This seems a more natural fit to an expert's capabilities than the requirements of traditional methodologies that experts explicitly enumerate the rules that they employ.	 1. timestamp: numeric;19500101 - 21001231 	 2. cylinder number: nominal	 3. customer: nominal; 	 4. job number: nominal; 	 5. grain screened: nominal; yes, no 	 6. ink color: nominal;  key, type 	 7. proof on ctd ink:  nominal;  yes, no  	 8. blade mfg: nominal;  benton, daetwyler, uddeholm 	 9. cylinder division: nominal;  gallatin, warsaw, mattoon 	10. paper type: nominal;  uncoated, coated, super 	11. ink type: nominal;  uncoated, coated, cover 	12. direct steam: nominal; use; yes, no *	13. solvent type: nominal;  xylol, lactol, naptha, line, other 	14. type on cylinder:  nominal;  yes, no  	15. press type: nominal; use; 70 wood hoe, 70 motter, 70 albert, 94 motter 	16. press: nominal;  821, 802, 813, 824, 815, 816, 827, 828 	17. unit number: nominal;  1, 2, 3, 4, 5, 6, 7, 8, 9, 10 	18. cylinder size: nominal;  catalog, spiegel, tabloid 	19. paper mill location: nominal; north us, south us, canadian, scandanavian, mid european	20. plating tank: nominal; 1910, 1911, other 	21. proof cut: numeric;  0-100 	22. viscosity: numeric;  0-100 	23. caliper: numeric;  0-1.0 	24. ink temperature: numeric;  5-30 	25. humifity: numeric;  5-120 	26. roughness: numeric;  0-2 	27. blade pressure: numeric;  10-75 	28. varnish pct: numeric;  0-100 	29. press speed: numeric;  0-4000 	30. ink pct: numeric;  0-100 	31. solvent pct: numeric;  0-100 	32. ESA Voltage: numeric;  0-16 	33. ESA Amperage: numeric;  0-10 	34. wax: numeric ;  0-4.0	35. hardener:  numeric; 0-3.0 	36. roller durometer:  numeric;  15-120 	37. current density:  numeric;  20-50 	38. anode space ratio:  numeric;  70-130 	39. chrome content: numeric; 80-120 	40. band type: nominal; class; band, no band *"
Yacht Hydrodynamics,Yacht Hydrodynamics,"Delft data set, used to predict the hydodynamic performance of sailing yachts from dimensions and velocity.",Yacht+Hydrodynamics,https://archive.ics.uci.edu/ml//machine-learning-databases/00243/,https://archive.ics.uci.edu/ml/datasets/Yacht+Hydrodynamics,"Prediction of residuary resistance of sailing yachts at the initial design stage is of a great value for evaluating the shipÃ¢â‚¬â„¢s performance and for estimating the required propulsive power. Essential inputs include the basic hull dimensions and the boat velocity. The Delft data set comprises 308 full-scale experiments, which were performed at the Delft Ship Hydromechanics Laboratory for that purpose. These experiments include 22 different hull forms, derived from a parent form closely related to the Ã¢â‚¬ËœStandfast 43Ã¢â‚¬â„¢ designed by Frans Maas.",Physical,"Variations concern hull geometry coefficients and the Froude number:1. Longitudinal position of the center of buoyancy, adimensional.2. Prismatic coefficient, adimensional.3. Length-displacement ratio, adimensional.4. Beam-draught ratio, adimensional.5. Length-beam ratio, adimensional.6. Froude number, adimensional.The measured variable is the residuary resistance per unit weight of displacement:7. Residuary resistance per unit weight of displacement, adimensional.","Delft data set, used to predict the hydodynamic performance of sailing yachts from dimensions and velocity.Prediction of residuary resistance of sailing yachts at the initial design stage is of a great value for evaluating the shipÃ¢â‚¬â„¢s performance and for estimating the required propulsive power. Essential inputs include the basic hull dimensions and the boat velocity. The Delft data set comprises 308 full-scale experiments, which were performed at the Delft Ship Hydromechanics Laboratory for that purpose. These experiments include 22 different hull forms, derived from a parent form closely related to the Ã¢â‚¬ËœStandfast 43Ã¢â‚¬â„¢ designed by Frans Maas.Variations concern hull geometry coefficients and the Froude number:1. Longitudinal position of the center of buoyancy, adimensional.2. Prismatic coefficient, adimensional.3. Length-displacement ratio, adimensional.4. Beam-draught ratio, adimensional.5. Length-beam ratio, adimensional.6. Froude number, adimensional.The measured variable is the residuary resistance per unit weight of displacement:7. Residuary resistance per unit weight of displacement, adimensional."
Cloud,Cloud,Little Documentation,Cloud,https://archive.ics.uci.edu/ml//machine-learning-databases/undocumented/taylor/,https://archive.ics.uci.edu/ml/datasets/Cloud,"The data sets we propose to analyse are constituted of 1024 vectors, each vector includes 10 parameters. You can think of it as a 1024*10 matrix. To produce these vectors, we proceed as follows:1. we start with two 512*512 AVHRR images  (1 in the visible, 1 in the IR)2. each images is divided in super-pixels 16*16 and in each  super-pixel we compute a set of parameters:(a) visible: mean, max, min, mean distribution, contrast, entropy, second angular momentum(b) IR: mean, max, minThe set of 10 parameters we picked to form the vectors is a compromised between various constraints. Actually we are still working on the choice of parameters for the data vectors. The data set I send you has not been normalized. The normalization of the data set is required by our classification scheme but that may not be true for yours. To normalize the data we compute the mean and standard deviation for each parameter on the entire data set then for each parameter of each vector we compute: Norm. value = (un-norm value - mean)/SD	wheremean = mean value for this particular parameter over the data setSD   = standard deviation .....",Physical,,"Little DocumentationThe data sets we propose to analyse are constituted of 1024 vectors, each vector includes 10 parameters. You can think of it as a 1024*10 matrix. To produce these vectors, we proceed as follows:1. we start with two 512*512 AVHRR images  (1 in the visible, 1 in the IR)2. each images is divided in super-pixels 16*16 and in each  super-pixel we compute a set of parameters:(a) visible: mean, max, min, mean distribution, contrast, entropy, second angular momentum(b) IR: mean, max, minThe set of 10 parameters we picked to form the vectors is a compromised between various constraints. Actually we are still working on the choice of parameters for the data vectors. The data set I send you has not been normalized. The normalization of the data set is required by our classification scheme but that may not be true for yours. To normalize the data we compute the mean and standard deviation for each parameter on the entire data set then for each parameter of each vector we compute: Norm. value = (un-norm value - mean)/SD	wheremean = mean value for this particular parameter over the data setSD   = standard deviation .....nan"
Climate Model Simulation Crashes,Climate Model Simulation Crashes,"Given Latin hypercube samples of 18 climate model input parameter values, predict climate model simulation crashes and determine the parameter value combinations that cause the failures.",Climate+Model+Simulation+Crashes,https://archive.ics.uci.edu/ml//machine-learning-databases/00252/,https://archive.ics.uci.edu/ml/datasets/Climate+Model+Simulation+Crashes,"This dataset contains records of simulation crashes encountered during climate model uncertainty quantification (UQ) ensembles. Ensemble members were constructed using a Latin hypercube method in LLNL's UQ Pipeline software system to sample the uncertainties of 18 model parameters within the Parallel Ocean Program (POP2) component of the Community Climate System Model (CCSM4). Three separate Latin hypercube ensembles were conducted, each containing 180 ensemble members. 46 out of the 540 simulations failed for numerical reasons at combinations of parameter values. The goal is to use classification to predict simulation outcomes (fail or succeed) from input parameter values, and to use sensitivity analysis and feature selection to determine the causes of simulation crashes. Further details about the data and methods are given in the publication 'Failure Analysis of Parameter-Induced Simulation Crashes in Climate Models,' Geoscientific Model Development ([Web Link]).",Physical,"The goal is to predict climate model simulation outcomes (column 21, fail or succeed) given scaled values of climate model input parameters (columns 3-20).Column 1: Latin hypercube study ID (study 1 to study 3)Column 2: simulation ID (run 1 to run 180)Columns 3-20: values of 18 climate model parameters scaled in the interval [0, 1]Column 21: simulation outcome (0 = failure, 1 = success)","Given Latin hypercube samples of 18 climate model input parameter values, predict climate model simulation crashes and determine the parameter value combinations that cause the failures.This dataset contains records of simulation crashes encountered during climate model uncertainty quantification (UQ) ensembles. Ensemble members were constructed using a Latin hypercube method in LLNL's UQ Pipeline software system to sample the uncertainties of 18 model parameters within the Parallel Ocean Program (POP2) component of the Community Climate System Model (CCSM4). Three separate Latin hypercube ensembles were conducted, each containing 180 ensemble members. 46 out of the 540 simulations failed for numerical reasons at combinations of parameter values. The goal is to use classification to predict simulation outcomes (fail or succeed) from input parameter values, and to use sensitivity analysis and feature selection to determine the causes of simulation crashes. Further details about the data and methods are given in the publication 'Failure Analysis of Parameter-Induced Simulation Crashes in Climate Models,' Geoscientific Model Development ([Web Link]).The goal is to predict climate model simulation outcomes (column 21, fail or succeed) given scaled values of climate model input parameters (columns 3-20).Column 1: Latin hypercube study ID (study 1 to study 3)Column 2: simulation ID (run 1 to run 180)Columns 3-20: values of 18 climate model parameters scaled in the interval [0, 1]Column 21: simulation outcome (0 = failure, 1 = success)"
Ozone Level Detection,Ozone Level Detection,"Two ground ozone level data sets are included in this collection. One is the eight hour peak set (eighthr.data), the other is the one hour peak set (onehr.data). Those data were collected from 1998 to 2004 at the Houston, Galveston and Brazoria area.",Ozone+Level+Detection,https://archive.ics.uci.edu/ml//machine-learning-databases/ozone/,https://archive.ics.uci.edu/ml/datasets/Ozone+Level+Detection,"For a list of attributes, please refer to those two .names files.  They use the following naming convention:All the attribute start with T means the temperature measured at different time throughout the day; and those starts with WS indicate the wind speed at various time.WSR_PK:     continuous. peek wind speed -- resultant (meaning average of wind vector)WSR_AV:     continuous. average wind speedT_PK:     continuous. Peak TT_AV:     continuous. Average TT85:     continuous. T at 850 hpa level (or about 1500 m height)RH85:     continuous. Relative Humidity at 850 hpaU85:     continuous. (U wind - east-west direction wind at 850 hpa)V85:     continuous. V wind - N-S direction wind at 850HT85:     continuous. Geopotential height at 850 hpa, it is about the same as height at low altitudeT70:     continuous. T at 700 hpa level (roughly 3100 m height)RH70:     continuous.U70:     continuous.V70:     continuous.HT70:     continuous.T50:     continuous. T at 500 hpa level (roughly at 5500 m height)RH50:     continuous.U50:     continuous.V50:     continuous.HT50:     continuous.KI:     continuous. K-Index [Web Link]TT:     continuous. T-Totals [Web Link]SLP:     continuous. Sea level pressureSLP_:     continuous. SLP change from previous dayPrecp:    continuous. -- precipitation",Physical,The following are specifications for several most important attributes that are highly valued by Texas Commission on Environmental Quality (TCEQ). More details can be found in the two relevant papers. O 3 - Local ozone peak predictionUpwind - Upwind ozone background levelEmFactor - Precursor emissions related factorTmax - Maximum temperature in degrees FTb - Base temperature where net ozone production begins (50 F)SRd - Solar radiation total for the dayWSa - Wind speed near sunrise (using 09-12 UTC forecast mode)WSp - Wind speed mid-day (using 15-21 UTC forecast mode) Please refer to those two .names files.,"Two ground ozone level data sets are included in this collection. One is the eight hour peak set (eighthr.data), the other is the one hour peak set (onehr.data). Those data were collected from 1998 to 2004 at the Houston, Galveston and Brazoria area.For a list of attributes, please refer to those two .names files.  They use the following naming convention:All the attribute start with T means the temperature measured at different time throughout the day; and those starts with WS indicate the wind speed at various time.WSR_PK:     continuous. peek wind speed -- resultant (meaning average of wind vector)WSR_AV:     continuous. average wind speedT_PK:     continuous. Peak TT_AV:     continuous. Average TT85:     continuous. T at 850 hpa level (or about 1500 m height)RH85:     continuous. Relative Humidity at 850 hpaU85:     continuous. (U wind - east-west direction wind at 850 hpa)V85:     continuous. V wind - N-S direction wind at 850HT85:     continuous. Geopotential height at 850 hpa, it is about the same as height at low altitudeT70:     continuous. T at 700 hpa level (roughly 3100 m height)RH70:     continuous.U70:     continuous.V70:     continuous.HT70:     continuous.T50:     continuous. T at 500 hpa level (roughly at 5500 m height)RH50:     continuous.U50:     continuous.V50:     continuous.HT50:     continuous.KI:     continuous. K-Index [Web Link]TT:     continuous. T-Totals [Web Link]SLP:     continuous. Sea level pressureSLP_:     continuous. SLP change from previous dayPrecp:    continuous. -- precipitationThe following are specifications for several most important attributes that are highly valued by Texas Commission on Environmental Quality (TCEQ). More details can be found in the two relevant papers. O 3 - Local ozone peak predictionUpwind - Upwind ozone background levelEmFactor - Precursor emissions related factorTmax - Maximum temperature in degrees FTb - Base temperature where net ozone production begins (50 F)SRd - Solar radiation total for the dayWSa - Wind speed near sunrise (using 09-12 UTC forecast mode)WSp - Wind speed mid-day (using 15-21 UTC forecast mode) Please refer to those two .names files."
QSAR oral toxicity,QSAR oral toxicity,"Data set containing values for 1024 binary attributes (molecular fingerprints) used to classify 8992 chemicals into 2 classes (very toxic/positive, not very toxic/negative)",QSAR+oral+toxicity,https://archive.ics.uci.edu/ml//machine-learning-databases/00508/,https://archive.ics.uci.edu/ml/datasets/QSAR+oral+toxicity,"This dataset was used to develop classification QSAR models for the discrimination of very toxic/positive (741) and not very toxic/negative (8251) molecules by means of different machine learning methods. Details can be found in the quoted reference: D. Ballabio, F. Grisoni, V. Consonni, R. Todeschini (2019), Integrated QSAR models to predict acute oral systemic toxicity, Molecular Informatics, 38, 180012; doi: 10.1002/minf.201800124. Attributes (molecular fingerprints) were calculated at the Milano Chemometrics and QSAR Research Group (UniversitÃƒÂ   degli Studi Milano - Bicocca, Milano, Italy) on a set of chemicals provided by the ICCVAM Acute Toxicity Workgroup (U.S. Department of Health and Human Services), in collaboration with the U.S. Environmental Protection Agency (U.S. EPA, National Center for Computational Toxicology), which coordinated the Ã¢â‚¬Å“Predictive Models for Acute Oral Systemic ToxicityÃ¢â‚¬Â� collaborative project to develop in silico models to predict acute oral systemic toxicity for filling regulatory needs.",Physical,1024 binary molecular fingerprints and 1 experimental class:1-1024) binary molecular fingerprint1025) experimental class: positive (very toxic) and negative (not very toxic),"Data set containing values for 1024 binary attributes (molecular fingerprints) used to classify 8992 chemicals into 2 classes (very toxic/positive, not very toxic/negative)This dataset was used to develop classification QSAR models for the discrimination of very toxic/positive (741) and not very toxic/negative (8251) molecules by means of different machine learning methods. Details can be found in the quoted reference: D. Ballabio, F. Grisoni, V. Consonni, R. Todeschini (2019), Integrated QSAR models to predict acute oral systemic toxicity, Molecular Informatics, 38, 180012; doi: 10.1002/minf.201800124. Attributes (molecular fingerprints) were calculated at the Milano Chemometrics and QSAR Research Group (UniversitÃƒÂ   degli Studi Milano - Bicocca, Milano, Italy) on a set of chemicals provided by the ICCVAM Acute Toxicity Workgroup (U.S. Department of Health and Human Services), in collaboration with the U.S. Environmental Protection Agency (U.S. EPA, National Center for Computational Toxicology), which coordinated the Ã¢â‚¬Å“Predictive Models for Acute Oral Systemic ToxicityÃ¢â‚¬Â� collaborative project to develop in silico models to predict acute oral systemic toxicity for filling regulatory needs.1024 binary molecular fingerprints and 1 experimental class:1-1024) binary molecular fingerprint1025) experimental class: positive (very toxic) and negative (not very toxic)"
Weight Lifting Exercises monitored with Inertial Measurement Units,Weight Lifting Exercises monitored with Inertial Measurement Units,Six young health subjects were asked to perform 5 variations of the biceps curl weight lifting exercise. One of the variations is the one predicted by the health professional.,Weight+Lifting+Exercises+monitored+with+Inertial+Measurement+Units,https://archive.ics.uci.edu/ml//machine-learning-databases/00273/,https://archive.ics.uci.edu/ml/datasets/Weight+Lifting+Exercises+monitored+with+Inertial+Measurement+Units,"Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13) . Stuttgart, Germany: ACM SIGCHI, 2013.Read more: [Web Link]#ixzz2lZizjhaF",Physical,"Each IMU has x, y, and z values + euler angles (roll, pitch and yaw). For each time window (1s of data), there are several statistics calculations, like Kurtosis, Variance, etc.","Six young health subjects were asked to perform 5 variations of the biceps curl weight lifting exercise. One of the variations is the one predicted by the health professional.Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13) . Stuttgart, Germany: ACM SIGCHI, 2013.Read more: [Web Link]#ixzz2lZizjhaFEach IMU has x, y, and z values + euler angles (roll, pitch and yaw). For each time window (1s of data), there are several statistics calculations, like Kurtosis, Variance, etc."
Electrical Grid Stability Simulated Data ,Electrical Grid Stability Simulated Data ,The local stability analysis of the 4-node star system (electricity producer is in the center) implementing Decentral Smart Grid Control concept. ,Electrical+Grid+Stability+Simulated+Data+,https://archive.ics.uci.edu/ml//machine-learning-databases/00471/,https://archive.ics.uci.edu/ml/datasets/Electrical+Grid+Stability+Simulated+Data+,"The analysis is performed for different sets of input values using the methodology similar to that described in [SchÃƒÂ¤fer, Benjamin, et al. 'Taming instabilities in power grid networks by decentralized control.' The European Physical Journal Special Topics 225.3 (2016): 569-582.]. Several input values are kept the same: averaging time: 2 s; coupling strength: 8 s^-2; damping: 0.1 s^-1",Physical,"11 predictive attributes, 1 non-predictive(p1), 2 goal fields:1. tau[x]: reaction time of participant (real from the range [0.5,10]s). Tau1 - the value for electricity producer.   2. p[x]: nominal power consumed(negative)/produced(positive)(real). For consumers from the range [-0.5,-2]s^-2; p1 = abs(p2 + p3 + p4)   3. g[x]: coefficient (gamma) proportional to price elasticity (real from the range [0.05,1]s^-1). g1 - the value for electricity producer.   4. stab: the maximal real part of the characteristic equation root (if positive - the system is linearly unstable)(real)   5. stabf: the stability label of the system (categorical: stable/unstable)","The local stability analysis of the 4-node star system (electricity producer is in the center) implementing Decentral Smart Grid Control concept. The analysis is performed for different sets of input values using the methodology similar to that described in [SchÃƒÂ¤fer, Benjamin, et al. 'Taming instabilities in power grid networks by decentralized control.' The European Physical Journal Special Topics 225.3 (2016): 569-582.]. Several input values are kept the same: averaging time: 2 s; coupling strength: 8 s^-2; damping: 0.1 s^-111 predictive attributes, 1 non-predictive(p1), 2 goal fields:1. tau[x]: reaction time of participant (real from the range [0.5,10]s). Tau1 - the value for electricity producer.   2. p[x]: nominal power consumed(negative)/produced(positive)(real). For consumers from the range [-0.5,-2]s^-2; p1 = abs(p2 + p3 + p4)   3. g[x]: coefficient (gamma) proportional to price elasticity (real from the range [0.05,1]s^-1). g1 - the value for electricity producer.   4. stab: the maximal real part of the characteristic equation root (if positive - the system is linearly unstable)(real)   5. stabf: the stability label of the system (categorical: stable/unstable)"
Waveform Database Generator (Version 1),Waveform Database Generator (Version 1),CART book's waveform domains,Waveform+Database+Generator+%28Version+1%29,https://archive.ics.uci.edu/ml//machine-learning-databases/waveform/,https://archive.ics.uci.edu/ml/datasets/Waveform+Database+Generator+%28Version+1%29,"Notes:     -- 3 classes of waves     -- 21 attributes, all of which include noise     -- See the book for details (49-55, 169)     -- waveform.data.Z contains 5000 instances",Physical,"    -- Each class is generated from a combination of 2 of 3 ""base"" waves    -- Each instance is generated f added noise (mean 0, variance 1) in each attribute     -- See the book for details (49-55, 169)","CART book's waveform domainsNotes:     -- 3 classes of waves     -- 21 attributes, all of which include noise     -- See the book for details (49-55, 169)     -- waveform.data.Z contains 5000 instances    -- Each class is generated from a combination of 2 of 3 ""base"" waves    -- Each instance is generated f added noise (mean 0, variance 1) in each attribute     -- See the book for details (49-55, 169)"
Musk (Version 2),Musk (Version 2),The goal is to learn to predict whether new molecules will be musks or non-musks,Musk+%28Version+2%29,https://archive.ics.uci.edu/ml//machine-learning-databases/musk/,https://archive.ics.uci.edu/ml/datasets/Musk+%28Version+2%29,"This dataset describes a set of 102 molecules of which 39 are judged by human experts to be musks and the remaining 63 molecules are judged to be non-musks.  The goal is to learn to predict whether new molecules will be musks or non-musks.  However, the 166 features that describe these molecules depend upon the exact shape, or conformation, of the molecule.  Because bonds can rotate, a single molecule can adopt many different shapes.  To generate this data set, all the low-energy conformations of the molecules were generated to produce 6,598 conformations.  Then, a feature vector was extracted that describes each conformation. This many-to-one relationship between feature vectors and molecules is called the ""multiple instance problem"".  When learning a classifier for this data, the classifier should classify a molecule as ""musk"" if ANY of its conformations is classified as a musk.  A molecule should be classified as ""non-musk"" if NONE of its conformations is classified as a musk.",Physical,"   molecule_name:       Symbolic name of each molecule.  Musks have names such as MUSK-188.  Non-musks have names such as NON-MUSK-jp13.   conformation_name:   Symbolic name of each conformation.  These have the format MOL_ISO+CONF, where MOL is the molecule number, ISO is the stereoisomer number (usually 1), and CONF is the conformation number.    f1 through f162:     These are ""distance features"" along rays (see paper cited above).  The distances are measured in hundredths of Angstroms.  The distances may be negative or positive, since they are actually measured relative to an origin placed along each ray.  The origin was defined by a ""consensus musk"" surface that is no longer used.  Hence, any experiments with the data should treat these feature values as lying on an arbitrary continuous scale.  In particular, the algorithm should not make any use of the zero point or the sign of each feature value.    f163:                This is the distance of the oxygen atom in the molecule to a designated point in 3-space. This is also called OXY-DIS.   f164:                OXY-X: X-displacement from the designated point.   f165:                OXY-Y: Y-displacement from the designated point.   f166:                OXY-Z: Z-displacement from the designated point.    class:               0 => non-musk, 1 => musk   Please note that the molecule_name and conformation_name attributes should not be used to predict the class.","The goal is to learn to predict whether new molecules will be musks or non-musksThis dataset describes a set of 102 molecules of which 39 are judged by human experts to be musks and the remaining 63 molecules are judged to be non-musks.  The goal is to learn to predict whether new molecules will be musks or non-musks.  However, the 166 features that describe these molecules depend upon the exact shape, or conformation, of the molecule.  Because bonds can rotate, a single molecule can adopt many different shapes.  To generate this data set, all the low-energy conformations of the molecules were generated to produce 6,598 conformations.  Then, a feature vector was extracted that describes each conformation. This many-to-one relationship between feature vectors and molecules is called the ""multiple instance problem"".  When learning a classifier for this data, the classifier should classify a molecule as ""musk"" if ANY of its conformations is classified as a musk.  A molecule should be classified as ""non-musk"" if NONE of its conformations is classified as a musk.   molecule_name:       Symbolic name of each molecule.  Musks have names such as MUSK-188.  Non-musks have names such as NON-MUSK-jp13.   conformation_name:   Symbolic name of each conformation.  These have the format MOL_ISO+CONF, where MOL is the molecule number, ISO is the stereoisomer number (usually 1), and CONF is the conformation number.    f1 through f162:     These are ""distance features"" along rays (see paper cited above).  The distances are measured in hundredths of Angstroms.  The distances may be negative or positive, since they are actually measured relative to an origin placed along each ray.  The origin was defined by a ""consensus musk"" surface that is no longer used.  Hence, any experiments with the data should treat these feature values as lying on an arbitrary continuous scale.  In particular, the algorithm should not make any use of the zero point or the sign of each feature value.    f163:                This is the distance of the oxygen atom in the molecule to a designated point in 3-space. This is also called OXY-DIS.   f164:                OXY-X: X-displacement from the designated point.   f165:                OXY-Y: Y-displacement from the designated point.   f166:                OXY-Z: Z-displacement from the designated point.    class:               0 => non-musk, 1 => musk   Please note that the molecule_name and conformation_name attributes should not be used to predict the class."
Crowdsourced Mapping,Crowdsourced Mapping,"Crowdsourced data from OpenStreetMap is used to automate the classification of satellite images into different land cover classes (impervious, farm, forest, grass, orchard, water). ",Crowdsourced+Mapping,https://archive.ics.uci.edu/ml//machine-learning-databases/00400/,https://archive.ics.uci.edu/ml/datasets/Crowdsourced+Mapping,"This dataset was derived from geospatial data from two sources: 1) Landsat time-series satellite imagery from the years 2014-2015, and 2) crowdsourced georeferenced polygons with land cover labels obtained from OpenStreetMap. The crowdsourced polygons cover only a small part of the image area, and are used used to extract training data from the image for classifying the rest of the image. The main challenge with the dataset is that both the imagery and the crowdsourced data contain noise (due to cloud cover in the images and innaccurate labeling/digitizing of polygons). Files in zip folder-The 'training.csv' file contains the training data for classification. Do not use this file to evaluate classification accuracy because it contains noise (many class labeling errors).-The 'testing.csv' file contains testing data to evaluate the classification accuracy. This file does not contain any class labeling errors.",Physical,"class: The land cover class (impervious, farm, forest, grass, orchard, water) [note: this is the target variable to classify].max_ndvi: the maximum NDVI (normalized difference vegetation index) value derived from the time-series of satellite images.20150720_N - 20140101_N : NDVI values extracted from satellite images acquired between January 2014 and July 2015, in reverse chronological order (dates given in the format yyyymmdd).","Crowdsourced data from OpenStreetMap is used to automate the classification of satellite images into different land cover classes (impervious, farm, forest, grass, orchard, water). This dataset was derived from geospatial data from two sources: 1) Landsat time-series satellite imagery from the years 2014-2015, and 2) crowdsourced georeferenced polygons with land cover labels obtained from OpenStreetMap. The crowdsourced polygons cover only a small part of the image area, and are used used to extract training data from the image for classifying the rest of the image. The main challenge with the dataset is that both the imagery and the crowdsourced data contain noise (due to cloud cover in the images and innaccurate labeling/digitizing of polygons). Files in zip folder-The 'training.csv' file contains the training data for classification. Do not use this file to evaluate classification accuracy because it contains noise (many class labeling errors).-The 'testing.csv' file contains testing data to evaluate the classification accuracy. This file does not contain any class labeling errors.class: The land cover class (impervious, farm, forest, grass, orchard, water) [note: this is the target variable to classify].max_ndvi: the maximum NDVI (normalized difference vegetation index) value derived from the time-series of satellite images.20150720_N - 20140101_N : NDVI values extracted from satellite images acquired between January 2014 and July 2015, in reverse chronological order (dates given in the format yyyymmdd)."
Waveform Database Generator (Version 2),Waveform Database Generator (Version 2),CART book's waveform domains,Waveform+Database+Generator+%28Version+2%29,https://archive.ics.uci.edu/ml//machine-learning-databases/waveform/,https://archive.ics.uci.edu/ml/datasets/Waveform+Database+Generator+%28Version+2%29,"Notes:     -- 3 classes of waves     -- 40 attributes, all of which include noise        -- The latter 19 attributes are all noise attributes with mean 0 and variance 1     -- See the book for details (49-55, 169)     -- waveform-+noise.data.Z contains 5000 instances",Physical,"    -- Each class is generated from a combination of 2 of 3 ""base"" waves    -- Each instance is generated f added noise (mean 0, variance 1) in each attribute     -- See the book for details (49-55, 169)","CART book's waveform domainsNotes:     -- 3 classes of waves     -- 40 attributes, all of which include noise        -- The latter 19 attributes are all noise attributes with mean 0 and variance 1     -- See the book for details (49-55, 169)     -- waveform-+noise.data.Z contains 5000 instances    -- Each class is generated from a combination of 2 of 3 ""base"" waves    -- Each instance is generated f added noise (mean 0, variance 1) in each attribute     -- See the book for details (49-55, 169)"
Water Treatment Plant,Water Treatment Plant,Multiple classes predict plant state,Water+Treatment+Plant,https://archive.ics.uci.edu/ml//machine-learning-databases/water-treatment/,https://archive.ics.uci.edu/ml/datasets/Water+Treatment+Plant,This dataset comes from the daily measures of sensors in a urban waste water treatment plant. The objective is to classify the operational state of the plant in order to predict faults through the state variables of the plant at each of the stages of the treatment process.  This domain has been stated as an ill-structured domain. ,Physical, All atrributes are numeric and continuousN.  Attrib.     1  Q-E        (input flow to plant)   2  ZN-E       (input Zinc to plant) 3  PH-E       (input pH to plant)  4  DBO-E      (input Biological demand of oxygen to plant)  5  DQO-E      (input chemical demand of oxygen to plant) 6  SS-E       (input suspended solids to plant)   7  SSV-E      (input volatile supended solids to plant) 8  SED-E      (input sediments to plant)  9  COND-E     (input conductivity to plant) 10  PH-P       (input pH to primary settler)11  DBO-P      (input Biological demand of oxygen to primary settler)12  SS-P       (input suspended solids to primary settler)13  SSV-P      (input volatile supended solids to primary settler)14  SED-P      (input sediments to primary settler) 15  COND-P     (input conductivity to primary settler)16  PH-D       (input pH to secondary settler) 17  DBO-D      (input Biological demand of oxygen to secondary settler)18  DQO-D      (input chemical demand of oxygen to secondary settler)19  SS-D       (input suspended solids to secondary settler)20  SSV-D      (input volatile supended solids to secondary settler)21  SED-D      (input sediments to secondary settler)  22  COND-D     (input conductivity to secondary settler) 23  PH-S       (output pH)   24  DBO-S      (output Biological demand of oxygen)25  DQO-S      (output chemical demand of oxygen)26  SS-S       (output suspended solids)27  SSV-S      (output volatile supended solids) 28  SED-S      (output sediments) 29  COND-S     (output conductivity)30  RD-DBO-P   (performance input Biological demand of oxygen in primary settler)31  RD-SS-P    (performance input suspended solids to primary settler)32  RD-SED-P   (performance input sediments to primary settler)33  RD-DBO-S   (performance input Biological demand of oxygen to secondary settler)34  RD-DQO-S   (performance input chemical demand of oxygen to secondary settler)35  RD-DBO-G   (global performance input Biological demand of oxygen)36  RD-DQO-G   (global performance input chemical demand of oxygen)37  RD-SS-G    (global performance input suspended solids) 38  RD-SED-G   (global performance input sediments),Multiple classes predict plant stateThis dataset comes from the daily measures of sensors in a urban waste water treatment plant. The objective is to classify the operational state of the plant in order to predict faults through the state variables of the plant at each of the stages of the treatment process.  This domain has been stated as an ill-structured domain.  All atrributes are numeric and continuousN.  Attrib.     1  Q-E        (input flow to plant)   2  ZN-E       (input Zinc to plant) 3  PH-E       (input pH to plant)  4  DBO-E      (input Biological demand of oxygen to plant)  5  DQO-E      (input chemical demand of oxygen to plant) 6  SS-E       (input suspended solids to plant)   7  SSV-E      (input volatile supended solids to plant) 8  SED-E      (input sediments to plant)  9  COND-E     (input conductivity to plant) 10  PH-P       (input pH to primary settler)11  DBO-P      (input Biological demand of oxygen to primary settler)12  SS-P       (input suspended solids to primary settler)13  SSV-P      (input volatile supended solids to primary settler)14  SED-P      (input sediments to primary settler) 15  COND-P     (input conductivity to primary settler)16  PH-D       (input pH to secondary settler) 17  DBO-D      (input Biological demand of oxygen to secondary settler)18  DQO-D      (input chemical demand of oxygen to secondary settler)19  SS-D       (input suspended solids to secondary settler)20  SSV-D      (input volatile supended solids to secondary settler)21  SED-D      (input sediments to secondary settler)  22  COND-D     (input conductivity to secondary settler) 23  PH-S       (output pH)   24  DBO-S      (output Biological demand of oxygen)25  DQO-S      (output chemical demand of oxygen)26  SS-S       (output suspended solids)27  SSV-S      (output volatile supended solids) 28  SED-S      (output sediments) 29  COND-S     (output conductivity)30  RD-DBO-P   (performance input Biological demand of oxygen in primary settler)31  RD-SS-P    (performance input suspended solids to primary settler)32  RD-SED-P   (performance input sediments to primary settler)33  RD-DBO-S   (performance input Biological demand of oxygen to secondary settler)34  RD-DQO-S   (performance input chemical demand of oxygen to secondary settler)35  RD-DBO-G   (global performance input Biological demand of oxygen)36  RD-DQO-G   (global performance input chemical demand of oxygen)37  RD-SS-G    (global performance input suspended solids) 38  RD-SED-G   (global performance input sediments)
EMG Physical Action Data Set,EMG Physical Action Data Set,The Physical Action Data Set includes 10 normal and 10 aggressive physical actions that measure the human activity. The data have been collected by 4 subjects using the Delsys EMG wireless apparatus.,EMG+Physical+Action+Data+Set,https://archive.ics.uci.edu/ml//machine-learning-databases/00213/,https://archive.ics.uci.edu/ml/datasets/EMG+Physical+Action+Data+Set,"1. Protocol:   Three male and one female subjects (age 25 to 30), who have experienced aggression in scenarios   such as physical fighting, took part in the experiment. Throughout 20 individual experiments,   each subject had to perform ten normal and ten aggressive activities. Regarding the rights of the   subjects involved, ethical regulations and safety precaution have been followed based on the code   of ethics of the British psychological society. The regulations explain the ethical legislations   to be applied when experiments with human subjects are conducted. According to the experimental   setup and the precautions taken, the ultimate risk of injuries was minimal. The subjects were aware   that since their involvement in this series of experiments was voluntary, it was made clear that   they could withdraw at any time from the study.2. Instrumentation:   The Essex robotic arena was the main experimental hall where the data collection took place.   With area 4x5.5m, the subjects expressed aggressive physical activities at random locations. A   professional kick-boxing standing bag has been used, 1.75m tall, with a human figure drawn on   its body. The subjectsÃ¢â‚¬â„¢ performance has been recorded by the Delsys EMG apparatus, interfacing   human activity with myoelectrical contractions. Based on this context, the data acquisition process   involved eight skin-surface electrodes placed on the upper arms (biceps and triceps), and upper legs   (thighs and hamstrings).3. Data Setup:   The overall number of electrodes is 8, which corresponds to 8 input time series one for a muscle   channel (ch1-8). Each time series contains ~10000 samples (~15 actions per experimental session   for each subject).",Physical,"Each file in the dataset contains in overall 8 columns, and is organised as follows:+---------+---------------+---------------+---------------+---------------+| Segment |     R-Arm     |     L-Arm     |     R-Leg     |     L-Leg     |+---------+-------+-------+-------+-------+-------+-------+-------+-------+| Channel | ch1   | ch2   | ch3   | ch4   | ch5   | ch6   | ch7   | ch8   || Muscle  | R-Bic | R-Tri | L-Bic | L-Tri | R-Thi | R-Ham | L-Thi | L-Ham || Column  | 0     | 1     | 2     | 3     | 4     | 5     | 6     | 7     |+---------+-------+-------+-------+-------+-------+-------+-------+-------+Segment: A segment defines a body segment or limb.         - Right arm (R-Arm)	 - Left arm (L-Arm)	 - Right leg (R-Leg)	 - Left leg (L-Leg)Channel: A channel corresponds to an electrode attached on a muscle.Muscle:  A pair of muscles that corresponds to a segment.	 - R-Bic: right bicep (C1)	 - R-Tri: right tricep (C2)	 - L-Bic: left bicep (C3)	 - L-Tri: left tricep (C4)	 - R-Thi: right thigh (C5)	 - R-Ham: right hamstring (C6)	 - L-Thi: left thigh (C7)	 - L-Ham: left hamstring (C8)","The Physical Action Data Set includes 10 normal and 10 aggressive physical actions that measure the human activity. The data have been collected by 4 subjects using the Delsys EMG wireless apparatus.1. Protocol:   Three male and one female subjects (age 25 to 30), who have experienced aggression in scenarios   such as physical fighting, took part in the experiment. Throughout 20 individual experiments,   each subject had to perform ten normal and ten aggressive activities. Regarding the rights of the   subjects involved, ethical regulations and safety precaution have been followed based on the code   of ethics of the British psychological society. The regulations explain the ethical legislations   to be applied when experiments with human subjects are conducted. According to the experimental   setup and the precautions taken, the ultimate risk of injuries was minimal. The subjects were aware   that since their involvement in this series of experiments was voluntary, it was made clear that   they could withdraw at any time from the study.2. Instrumentation:   The Essex robotic arena was the main experimental hall where the data collection took place.   With area 4x5.5m, the subjects expressed aggressive physical activities at random locations. A   professional kick-boxing standing bag has been used, 1.75m tall, with a human figure drawn on   its body. The subjectsÃ¢â‚¬â„¢ performance has been recorded by the Delsys EMG apparatus, interfacing   human activity with myoelectrical contractions. Based on this context, the data acquisition process   involved eight skin-surface electrodes placed on the upper arms (biceps and triceps), and upper legs   (thighs and hamstrings).3. Data Setup:   The overall number of electrodes is 8, which corresponds to 8 input time series one for a muscle   channel (ch1-8). Each time series contains ~10000 samples (~15 actions per experimental session   for each subject).Each file in the dataset contains in overall 8 columns, and is organised as follows:+---------+---------------+---------------+---------------+---------------+| Segment |     R-Arm     |     L-Arm     |     R-Leg     |     L-Leg     |+---------+-------+-------+-------+-------+-------+-------+-------+-------+| Channel | ch1   | ch2   | ch3   | ch4   | ch5   | ch6   | ch7   | ch8   || Muscle  | R-Bic | R-Tri | L-Bic | L-Tri | R-Thi | R-Ham | L-Thi | L-Ham || Column  | 0     | 1     | 2     | 3     | 4     | 5     | 6     | 7     |+---------+-------+-------+-------+-------+-------+-------+-------+-------+Segment: A segment defines a body segment or limb.         - Right arm (R-Arm)	 - Left arm (L-Arm)	 - Right leg (R-Leg)	 - Left leg (L-Leg)Channel: A channel corresponds to an electrode attached on a muscle.Muscle:  A pair of muscles that corresponds to a segment.	 - R-Bic: right bicep (C1)	 - R-Tri: right tricep (C2)	 - L-Bic: left bicep (C3)	 - L-Tri: left tricep (C4)	 - R-Thi: right thigh (C5)	 - R-Ham: right hamstring (C6)	 - L-Thi: left thigh (C7)	 - L-Ham: left hamstring (C8)"
Forest Fires,Forest Fires,"This is a difficult regression task, where the aim is to predict the burned area of forest fires, in the northeast region of Portugal, by using meteorological and other data (see details at: http://www.dsi.uminho.pt/~pcortez/forestfires).",Forest+Fires,https://archive.ics.uci.edu/ml//machine-learning-databases/forest-fires/,https://archive.ics.uci.edu/ml/datasets/Forest+Fires,"In [Cortez and Morais, 2007], the output 'area' was first transformed with a ln(x+1) function.   Then, several Data Mining methods were applied. After fitting the models, the outputs were   post-processed with the inverse of the ln(x+1) transform. Four different input setups were   used. The experiments were conducted using a 10-fold (cross-validation) x 30 runs. Two   regression metrics were measured: MAD and RMSE. A Gaussian support vector machine (SVM) fed   with only 4 direct weather conditions (temp, RH, wind and rain) obtained the best MAD value:   12.71 +- 0.01 (mean and confidence interval within 95% using a t-student distribution). The   best RMSE was attained by the naive mean predictor. An analysis to the regression error curve   (REC) shows that the SVM model predicts more examples within a lower admitted error. In effect,   the SVM model predicts better small fires, which are the majority. ",Physical,"For more information, read [Cortez and Morais, 2007].   1. X - x-axis spatial coordinate within the Montesinho park map: 1 to 9   2. Y - y-axis spatial coordinate within the Montesinho park map: 2 to 9   3. month - month of the year: 'jan' to 'dec'    4. day - day of the week: 'mon' to 'sun'   5. FFMC - FFMC index from the FWI system: 18.7 to 96.20   6. DMC - DMC index from the FWI system: 1.1 to 291.3    7. DC - DC index from the FWI system: 7.9 to 860.6    8. ISI - ISI index from the FWI system: 0.0 to 56.10   9. temp - temperature in Celsius degrees: 2.2 to 33.30   10. RH - relative humidity in %: 15.0 to 100   11. wind - wind speed in km/h: 0.40 to 9.40    12. rain - outside rain in mm/m2 : 0.0 to 6.4    13. area - the burned area of the forest (in ha): 0.00 to 1090.84    (this output variable is very skewed towards 0.0, thus it may make    sense to model with the logarithm transform).","This is a difficult regression task, where the aim is to predict the burned area of forest fires, in the northeast region of Portugal, by using meteorological and other data (see details at: http://www.dsi.uminho.pt/~pcortez/forestfires).In [Cortez and Morais, 2007], the output 'area' was first transformed with a ln(x+1) function.   Then, several Data Mining methods were applied. After fitting the models, the outputs were   post-processed with the inverse of the ln(x+1) transform. Four different input setups were   used. The experiments were conducted using a 10-fold (cross-validation) x 30 runs. Two   regression metrics were measured: MAD and RMSE. A Gaussian support vector machine (SVM) fed   with only 4 direct weather conditions (temp, RH, wind and rain) obtained the best MAD value:   12.71 +- 0.01 (mean and confidence interval within 95% using a t-student distribution). The   best RMSE was attained by the naive mean predictor. An analysis to the regression error curve   (REC) shows that the SVM model predicts more examples within a lower admitted error. In effect,   the SVM model predicts better small fires, which are the majority. For more information, read [Cortez and Morais, 2007].   1. X - x-axis spatial coordinate within the Montesinho park map: 1 to 9   2. Y - y-axis spatial coordinate within the Montesinho park map: 2 to 9   3. month - month of the year: 'jan' to 'dec'    4. day - day of the week: 'mon' to 'sun'   5. FFMC - FFMC index from the FWI system: 18.7 to 96.20   6. DMC - DMC index from the FWI system: 1.1 to 291.3    7. DC - DC index from the FWI system: 7.9 to 860.6    8. ISI - ISI index from the FWI system: 0.0 to 56.10   9. temp - temperature in Celsius degrees: 2.2 to 33.30   10. RH - relative humidity in %: 15.0 to 100   11. wind - wind speed in km/h: 0.40 to 9.40    12. rain - outside rain in mm/m2 : 0.0 to 6.4    13. area - the burned area of the forest (in ha): 0.00 to 1090.84    (this output variable is very skewed towards 0.0, thus it may make    sense to model with the logarithm transform)."
Volcanoes on Venus - JARtool experiment,Volcanoes on Venus - JARtool experiment,The JARtool project was a pioneering effort to develop an automatic system for cataloging small volcanoes in the large set of Venus images returned by the Magellan spacecraft.,Volcanoes+on+Venus+-+JARtool+experiment,https://archive.ics.uci.edu/ml//machine-learning-databases/volcanoes-mld/,https://archive.ics.uci.edu/ml/datasets/Volcanoes+on+Venus+-+JARtool+experiment,"The data was collected by the Magellan spacecraft over an approximately four year period from 1990--1994. The objective of the mission was to obtain global mapping of the surface of Venus using synthetic aperture radar (SAR). A more detailed discussion of the mission and objectives is available at  JPL's Magellan webpage.There are some spatial dependencies. For example, background patches from with in a single image are likely to be more similar than background patches taken across different images.In addition to the images, there are ""ground truth"" files that specify the locations of volcanoes within the images. The quotes around ""ground truth"" are intended as a reminder that there is no absolute ground truth for this data set. No one has been to Venus and the image quality does not permit 100%, unambiguous identification of the volcanoes, even by human experts. There are labels that provide some measure of subjective uncertainty (1 = definitely a volcano, 2 = probably, 3 = possibly, 4 = only a pit is visible). See reference [Smyth95] for more information on the labeling uncertainty problem.There are also files that specify the exact set of experiments using in the published evaluations of the JARtool system. The image files are in a format called VIEW. This format consists of two files, a binary file with extension .sdt (the image data) and an ascii file with extension .spr (header information). There is a MATLAB utility function included in the data package that can be used to read the data. If you want to use something other than Matlab, you are on your own, but the format is fairly simple and can be understood by looking at the Matlab code.The labeling files are provided in two forms. The .lxyr files are simple space-separated ascii containing label, x-location of center, y-location of center, and radius. ",Physical,"The images are 1024X1024 pixels. The pixel values are in the range [0,255]. The pixel value is related to the amount of energy backscattered to the radar from a given spatial location. Higher pixel values indicate greater backscatter. Lower pixel values indicate lesser backscatter. Both topography and surface roughness relative to the radar wavelength affect the amount of backscatter.","The JARtool project was a pioneering effort to develop an automatic system for cataloging small volcanoes in the large set of Venus images returned by the Magellan spacecraft.The data was collected by the Magellan spacecraft over an approximately four year period from 1990--1994. The objective of the mission was to obtain global mapping of the surface of Venus using synthetic aperture radar (SAR). A more detailed discussion of the mission and objectives is available at  JPL's Magellan webpage.There are some spatial dependencies. For example, background patches from with in a single image are likely to be more similar than background patches taken across different images.In addition to the images, there are ""ground truth"" files that specify the locations of volcanoes within the images. The quotes around ""ground truth"" are intended as a reminder that there is no absolute ground truth for this data set. No one has been to Venus and the image quality does not permit 100%, unambiguous identification of the volcanoes, even by human experts. There are labels that provide some measure of subjective uncertainty (1 = definitely a volcano, 2 = probably, 3 = possibly, 4 = only a pit is visible). See reference [Smyth95] for more information on the labeling uncertainty problem.There are also files that specify the exact set of experiments using in the published evaluations of the JARtool system. The image files are in a format called VIEW. This format consists of two files, a binary file with extension .sdt (the image data) and an ascii file with extension .spr (header information). There is a MATLAB utility function included in the data package that can be used to read the data. If you want to use something other than Matlab, you are on your own, but the format is fairly simple and can be understood by looking at the Matlab code.The labeling files are provided in two forms. The .lxyr files are simple space-separated ascii containing label, x-location of center, y-location of center, and radius. The images are 1024X1024 pixels. The pixel values are in the range [0,255]. The pixel value is related to the amount of energy backscattered to the radar from a given spatial location. Higher pixel values indicate greater backscatter. Lower pixel values indicate lesser backscatter. Both topography and surface roughness relative to the radar wavelength affect the amount of backscatter."
Qualitative Structure Activity Relationships,Qualitative Structure Activity Relationships,Two sets of datasets are given: pyrimidines and triazines,Qualitative+Structure+Activity+Relationships,https://archive.ics.uci.edu/ml//machine-learning-databases/qsar/,https://archive.ics.uci.edu/ml/datasets/Qualitative+Structure+Activity+Relationships,,Physical,,Two sets of datasets are given: pyrimidines and triazinesnannan
"Connectionist Bench (Sonar, Mines vs. Rocks)","Connectionist Bench (Sonar, Mines vs. Rocks)",The task is to train a network to discriminate between sonar signals bounced off a metal cylinder and those bounced off a roughly cylindrical rock.,Connectionist+Bench+%28Sonar%2C+Mines+vs.+Rocks%29,https://archive.ics.uci.edu/ml//machine-learning-databases/undocumented/connectionist-bench/sonar/,https://archive.ics.uci.edu/ml/datasets/Connectionist+Bench+%28Sonar%2C+Mines+vs.+Rocks%29,"The file ""sonar.mines"" contains 111 patterns obtained by bouncing sonar signals off a metal cylinder at various angles and under various conditions.  The file ""sonar.rocks"" contains 97 patterns obtained from rocks under similar conditions.  The transmitted sonar signal is a frequency-modulated chirp, rising in frequency.  The data set contains signals obtained from a variety of different aspect angles, spanning 90 degrees for the cylinder and 180 degrees for the rock.Each pattern is a set of 60 numbers in the range 0.0 to 1.0.  Each number represents the energy within a particular frequency band, integrated over a certain period of time.  The integration aperture for higher frequencies occur later in time, since these frequencies are transmitted later during the chirp.The label associated with each record contains the letter ""R"" if the object is a rock and ""M"" if it is a mine (metal cylinder).  The numbers in the labels are in increasing order of aspect angle, but they do not encode the angle directly.",Physical,,"The task is to train a network to discriminate between sonar signals bounced off a metal cylinder and those bounced off a roughly cylindrical rock.The file ""sonar.mines"" contains 111 patterns obtained by bouncing sonar signals off a metal cylinder at various angles and under various conditions.  The file ""sonar.rocks"" contains 97 patterns obtained from rocks under similar conditions.  The transmitted sonar signal is a frequency-modulated chirp, rising in frequency.  The data set contains signals obtained from a variety of different aspect angles, spanning 90 degrees for the cylinder and 180 degrees for the rock.Each pattern is a set of 60 numbers in the range 0.0 to 1.0.  Each number represents the energy within a particular frequency band, integrated over a certain period of time.  The integration aperture for higher frequencies occur later in time, since these frequencies are transmitted later during the chirp.The label associated with each record contains the letter ""R"" if the object is a rock and ""M"" if it is a mine (metal cylinder).  The numbers in the labels are in increasing order of aspect angle, but they do not encode the angle directly.nan"
Sports articles for objectivity analysis,Sports articles for objectivity analysis,"1000 sports articles were labeled using Amazon Mechanical Turk as objective or subjective. The raw texts, extracted features, and the URLs from which the articles were retrieved are provided.",Sports+articles+for+objectivity+analysis,https://archive.ics.uci.edu/ml//machine-learning-databases/00450/,https://archive.ics.uci.edu/ml/datasets/Sports+articles+for+objectivity+analysis,Some of the features are retrieved using the Stanford POS tagger and the tags are as defined in Penn Treebank Project:  [Web Link],Social,TextID	text file nameURL	link to articleLabel	objective vs. subjectivetotalWordsCount	total number of words in the articlesemanticobjscore	Frequency of words with an objective SENTIWORDNET scoresemanticsubjscore	Frequency of words with a subjective SENTIWORDNET scoreCC	Frequency of coordinating conjunctionsCD	Frequency of numerals and cardinalsDT	Frequency of determinersEX	Frequency of existential thereFW	Frequency of foreign wordsINs	Frequency of subordinating preposition or conjunctionJJ	Frequency of ordinal adjectives or numeralsJJR	Frequency of comparative adjectivesJJS	Frequency of superlative adjectivesLS	Frequency of list item markersMD	Frequency of modal auxiliariesNN	Frequency of singular common nounsNNP	Frequency of singular proper nounsNNPS	Frequency of plural proper nounsNNS	Frequency of plural common nounsPDT	Frequency of pre-determinersPOS	Frequency of genitive markersPRP	Frequency of personal pronounsPRP$	Frequency of possessive pronounsRB	Frequency of adverbsRBR	Frequency of comparative adverbsRBS	Frequency of superlative adverbsRP	Frequency of particlesSYM	Frequency of symbolsTOs	Frequency of 'to' as preposition or infinitive markerUH	Frequency of interjectionsVB	Frequency of base form verbsVBD	Frequency of past tense verbsVBG	Frequency of present participle or gerund verbsVBN	Frequency of past participle verbsVBP	Frequency of present tense verbs with plural 3rd person subjectsVBZ	Frequency of present tense verbs with singular 3rd person subjectsWDT	Frequency of WH-determinersWP	Frequency of WH-pronounsWP$	Frequency of possessive WH-pronounsWRB	Frequency of WH-adverbsbaseform	Frequency of infinitive verbs (base form verbs preceded by Ã¢â‚¬Å“toÃ¢â‚¬Â�)Quotes	Frequency of quotation pairs in the entire articlequestionmarks	Frequency of questions marks in the entire articleexclamationmarks	Frequency of exclamation marks in the entire articlefullstops	Frequency of full stopscommas	Frequency of commassemicolon	Frequency of semicolonscolon	Frequency of colonsellipsis	Frequency of ellipsispronouns1st	Frequency of first person pronouns (personal and possessive)pronouns2nd	Frequency of second person pronouns (personal and possessive)pronouns3rd	Frequency of third person pronouns (personal and possessive)compsupadjadv	Frequency of comparative and superlative adjectives and adverbspast	Frequency of past tense verbs with 1st and 2nd person pronounsimperative	Frequency of imperative verbspresent3rd	Frequency of present tense verbs with 3rd person pronounspresent1st2nd	Frequency of present tense verbs with 1st and 2nd person pronounssentence1st	First sentence classsentencelast	Last sentence classtxtcomplexity	Text complexity score,"1000 sports articles were labeled using Amazon Mechanical Turk as objective or subjective. The raw texts, extracted features, and the URLs from which the articles were retrieved are provided.Some of the features are retrieved using the Stanford POS tagger and the tags are as defined in Penn Treebank Project:  [Web Link]TextID	text file nameURL	link to articleLabel	objective vs. subjectivetotalWordsCount	total number of words in the articlesemanticobjscore	Frequency of words with an objective SENTIWORDNET scoresemanticsubjscore	Frequency of words with a subjective SENTIWORDNET scoreCC	Frequency of coordinating conjunctionsCD	Frequency of numerals and cardinalsDT	Frequency of determinersEX	Frequency of existential thereFW	Frequency of foreign wordsINs	Frequency of subordinating preposition or conjunctionJJ	Frequency of ordinal adjectives or numeralsJJR	Frequency of comparative adjectivesJJS	Frequency of superlative adjectivesLS	Frequency of list item markersMD	Frequency of modal auxiliariesNN	Frequency of singular common nounsNNP	Frequency of singular proper nounsNNPS	Frequency of plural proper nounsNNS	Frequency of plural common nounsPDT	Frequency of pre-determinersPOS	Frequency of genitive markersPRP	Frequency of personal pronounsPRP$	Frequency of possessive pronounsRB	Frequency of adverbsRBR	Frequency of comparative adverbsRBS	Frequency of superlative adverbsRP	Frequency of particlesSYM	Frequency of symbolsTOs	Frequency of 'to' as preposition or infinitive markerUH	Frequency of interjectionsVB	Frequency of base form verbsVBD	Frequency of past tense verbsVBG	Frequency of present participle or gerund verbsVBN	Frequency of past participle verbsVBP	Frequency of present tense verbs with plural 3rd person subjectsVBZ	Frequency of present tense verbs with singular 3rd person subjectsWDT	Frequency of WH-determinersWP	Frequency of WH-pronounsWP$	Frequency of possessive WH-pronounsWRB	Frequency of WH-adverbsbaseform	Frequency of infinitive verbs (base form verbs preceded by Ã¢â‚¬Å“toÃ¢â‚¬Â�)Quotes	Frequency of quotation pairs in the entire articlequestionmarks	Frequency of questions marks in the entire articleexclamationmarks	Frequency of exclamation marks in the entire articlefullstops	Frequency of full stopscommas	Frequency of commassemicolon	Frequency of semicolonscolon	Frequency of colonsellipsis	Frequency of ellipsispronouns1st	Frequency of first person pronouns (personal and possessive)pronouns2nd	Frequency of second person pronouns (personal and possessive)pronouns3rd	Frequency of third person pronouns (personal and possessive)compsupadjadv	Frequency of comparative and superlative adjectives and adverbspast	Frequency of past tense verbs with 1st and 2nd person pronounsimperative	Frequency of imperative verbspresent3rd	Frequency of present tense verbs with 3rd person pronounspresent1st2nd	Frequency of present tense verbs with 1st and 2nd person pronounssentence1st	First sentence classsentencelast	Last sentence classtxtcomplexity	Text complexity score"
Higher Education Students Performance Evaluation Dataset,Higher Education Students Performance Evaluation Dataset,The data was collected from the Faculty of Engineering and Faculty of Educational Sciences students in 2019. The purpose is to predict students' end-of-term performances using ML techniques.,Higher+Education+Students+Performance+Evaluation+Dataset,https://archive.ics.uci.edu/ml//machine-learning-databases/00623/,https://archive.ics.uci.edu/ml/datasets/Higher+Education+Students+Performance+Evaluation+Dataset,"1-10 of the data are the personal questions, 11-16. questions include family questions, and the remaining questions include education habits.",Social,"Student ID1-	Student Age (1: 18-21, 2: 22-25, 3: above 26)2-	Sex (1: female, 2: male)3-	Graduated high-school type: (1: private, 2: state, 3: other)4-	Scholarship type: (1: None, 2: 25%, 3: 50%, 4: 75%, 5: Full)5-	Additional work: (1: Yes, 2: No)6-	Regular artistic or sports activity: (1: Yes, 2: No)7-	Do you have a partner: (1: Yes, 2: No)8-	Total salary if available (1: USD 135-200, 2: USD 201-270, 3: USD 271-340, 4: USD 341-410, 5: above 410)9-	Transportation to the university: (1: Bus, 2: Private car/taxi, 3: bicycle, 4: Other)10-	Accommodation type in Cyprus: (1: rental, 2: dormitory, 3: with family, 4: Other)11-	MothersÃ¢â‚¬â„¢ education: (1: primary school, 2: secondary school, 3: high school, 4: university, 5: MSc., 6: Ph.D.)12-	FathersÃ¢â‚¬â„¢ education: (1: primary school, 2: secondary school, 3: high school, 4: university, 5: MSc., 6: Ph.D.)13-	Number of sisters/brothers (if available): (1: 1, 2:, 2, 3: 3, 4: 4, 5: 5 or above)14-	Parental status: (1: married, 2: divorced, 3: died - one of them or both)15-	MothersÃ¢â‚¬â„¢ occupation: (1: retired, 2: housewife, 3: government officer, 4: private sector employee, 5: self-employment, 6: other)16-	FathersÃ¢â‚¬â„¢ occupation: (1: retired, 2: government officer, 3: private sector employee, 4: self-employment, 5: other)17-	Weekly study hours: (1: None, 2: <5 hours, 3: 6-10 hours, 4: 11-20 hours, 5: more than 20 hours)18-	Reading frequency (non-scientific books/journals): (1: None, 2: Sometimes, 3: Often)19-	Reading frequency (scientific books/journals): (1: None, 2: Sometimes, 3: Often)20-	Attendance to the seminars/conferences related to the department: (1: Yes, 2: No)21-	Impact of your projects/activities on your success: (1: positive, 2: negative, 3: neutral)22-	Attendance to classes (1: always, 2: sometimes, 3: never)23-	Preparation to midterm exams 1: (1: alone, 2: with friends, 3: not applicable)24-	Preparation to midterm exams 2: (1: closest date to the exam, 2: regularly during the semester, 3: never)25-	Taking notes in classes: (1: never, 2: sometimes, 3: always)26-	Listening in classes: (1: never, 2: sometimes, 3: always)27-	Discussion improves my interest and success in the course: (1: never, 2: sometimes, 3: always)28-	Flip-classroom: (1: not useful, 2: useful, 3: not applicable)29-	Cumulative grade point average in the last semester (/4.00): (1: <2.00, 2: 2.00-2.49, 3: 2.50-2.99, 4: 3.00-3.49, 5: above 3.49)30-	Expected Cumulative grade point average in the graduation (/4.00): (1: <2.00, 2: 2.00-2.49, 3: 2.50-2.99, 4: 3.00-3.49, 5: above 3.49)31-	Course ID32-	OUTPUT Grade (0: Fail, 1: DD, 2: DC, 3: CC, 4: CB, 5: BB, 6: BA, 7: AA)","The data was collected from the Faculty of Engineering and Faculty of Educational Sciences students in 2019. The purpose is to predict students' end-of-term performances using ML techniques.1-10 of the data are the personal questions, 11-16. questions include family questions, and the remaining questions include education habits.Student ID1-	Student Age (1: 18-21, 2: 22-25, 3: above 26)2-	Sex (1: female, 2: male)3-	Graduated high-school type: (1: private, 2: state, 3: other)4-	Scholarship type: (1: None, 2: 25%, 3: 50%, 4: 75%, 5: Full)5-	Additional work: (1: Yes, 2: No)6-	Regular artistic or sports activity: (1: Yes, 2: No)7-	Do you have a partner: (1: Yes, 2: No)8-	Total salary if available (1: USD 135-200, 2: USD 201-270, 3: USD 271-340, 4: USD 341-410, 5: above 410)9-	Transportation to the university: (1: Bus, 2: Private car/taxi, 3: bicycle, 4: Other)10-	Accommodation type in Cyprus: (1: rental, 2: dormitory, 3: with family, 4: Other)11-	MothersÃ¢â‚¬â„¢ education: (1: primary school, 2: secondary school, 3: high school, 4: university, 5: MSc., 6: Ph.D.)12-	FathersÃ¢â‚¬â„¢ education: (1: primary school, 2: secondary school, 3: high school, 4: university, 5: MSc., 6: Ph.D.)13-	Number of sisters/brothers (if available): (1: 1, 2:, 2, 3: 3, 4: 4, 5: 5 or above)14-	Parental status: (1: married, 2: divorced, 3: died - one of them or both)15-	MothersÃ¢â‚¬â„¢ occupation: (1: retired, 2: housewife, 3: government officer, 4: private sector employee, 5: self-employment, 6: other)16-	FathersÃ¢â‚¬â„¢ occupation: (1: retired, 2: government officer, 3: private sector employee, 4: self-employment, 5: other)17-	Weekly study hours: (1: None, 2: <5 hours, 3: 6-10 hours, 4: 11-20 hours, 5: more than 20 hours)18-	Reading frequency (non-scientific books/journals): (1: None, 2: Sometimes, 3: Often)19-	Reading frequency (scientific books/journals): (1: None, 2: Sometimes, 3: Often)20-	Attendance to the seminars/conferences related to the department: (1: Yes, 2: No)21-	Impact of your projects/activities on your success: (1: positive, 2: negative, 3: neutral)22-	Attendance to classes (1: always, 2: sometimes, 3: never)23-	Preparation to midterm exams 1: (1: alone, 2: with friends, 3: not applicable)24-	Preparation to midterm exams 2: (1: closest date to the exam, 2: regularly during the semester, 3: never)25-	Taking notes in classes: (1: never, 2: sometimes, 3: always)26-	Listening in classes: (1: never, 2: sometimes, 3: always)27-	Discussion improves my interest and success in the course: (1: never, 2: sometimes, 3: always)28-	Flip-classroom: (1: not useful, 2: useful, 3: not applicable)29-	Cumulative grade point average in the last semester (/4.00): (1: <2.00, 2: 2.00-2.49, 3: 2.50-2.99, 4: 3.00-3.49, 5: above 3.49)30-	Expected Cumulative grade point average in the graduation (/4.00): (1: <2.00, 2: 2.00-2.49, 3: 2.50-2.99, 4: 3.00-3.49, 5: above 3.49)31-	Course ID32-	OUTPUT Grade (0: Fail, 1: DD, 2: DC, 3: CC, 4: CB, 5: BB, 6: BA, 7: AA)"
GitHub MUSAE,GitHub MUSAE,"A social network of GitHub users with user-level attributes, connectivity data and a binary target variable.",GitHub+MUSAE,https://archive.ics.uci.edu/ml//machine-learning-databases/00588/,https://archive.ics.uci.edu/ml/datasets/GitHub+MUSAE,"A large social network of GitHub developers which was collected from the public API in June 2019. Nodes are developers who have starred at least 10 repositories and edges are mutual follower relationships between them. The vertex features are extracted based on the location, repositories starred, employer and e-mail address. The task related to the graph is binary node classification - one has to predict whether the GitHub user is a web or a machine learning developer. This target feature was derived from the job title of each user.",Social,"Attributes are binary indicators extracted based on the location, repositories starred, employer and e-mail address.","A social network of GitHub users with user-level attributes, connectivity data and a binary target variable.A large social network of GitHub developers which was collected from the public API in June 2019. Nodes are developers who have starred at least 10 repositories and edges are mutual follower relationships between them. The vertex features are extracted based on the location, repositories starred, employer and e-mail address. The task related to the graph is binary node classification - one has to predict whether the GitHub user is a web or a machine learning developer. This target feature was derived from the job title of each user.Attributes are binary indicators extracted based on the location, repositories starred, employer and e-mail address."
Nursery,Nursery, Nursery Database was derived from a hierarchical decision model originally developed to rank applications for nursery schools.,Nursery,https://archive.ics.uci.edu/ml//machine-learning-databases/nursery/,https://archive.ics.uci.edu/ml/datasets/Nursery,"Nursery Database was derived from a hierarchical decision model originally developed to rank applications for nursery schools. It was used during several years in 1980's when there was excessive enrollment to these schools in Ljubljana, Slovenia, and the rejected applications frequently needed an objective explanation. The final decision depended on three subproblems: occupation of parents and child's nursery, family structure and financial standing, and social and health picture of the family. The model was developed within expert system shell for decision making DEX (M. Bohanec, V. Rajkovic: Expert system for decision making. Sistemica 1(1), pp. 145-157, 1990.).The hierarchical model ranks nursery-school applications according to the following concept structure: NURSERY            Evaluation of applications for nursery schools . EMPLOY           Employment of parents and child's nursery . . parents        Parents' occupation . . has_nurs       Child's nursery . STRUCT_FINAN     Family structure and financial standings . . STRUCTURE      Family structure . . . form         Form of the family . . . children     Number of children . . housing        Housing conditions . . finance        Financial standing of the family . SOC_HEALTH       Social and health picture of the family . . social         Social conditions . . health         Health conditionsInput attributes are printed in lowercase. Besides the target concept (NURSERY) the model includes four intermediate concepts: EMPLOY, STRUCT_FINAN, STRUCTURE, SOC_HEALTH. Every concept is in the original model related to its lower level descendants by a set of examples (for these examples sets see [Web Link]).The Nursery Database contains examples with the structural information removed, i.e., directly relates NURSERY to the eight input attributes: parents, has_nurs, form, children, housing, finance, social, health.Because of known underlying concept structure, this database may be particularly useful for testing constructive induction and structure discovery methods.",Social,"   parents:        usual, pretentious, great_pret   has_nurs:       proper, less_proper, improper, critical, very_crit   form:           complete, completed, incomplete, foster   children:       1, 2, 3, more   housing:        convenient, less_conv, critical   finance:        convenient, inconv   social:         non-prob, slightly_prob, problematic   health:         recommended, priority, not_recom"," Nursery Database was derived from a hierarchical decision model originally developed to rank applications for nursery schools.Nursery Database was derived from a hierarchical decision model originally developed to rank applications for nursery schools. It was used during several years in 1980's when there was excessive enrollment to these schools in Ljubljana, Slovenia, and the rejected applications frequently needed an objective explanation. The final decision depended on three subproblems: occupation of parents and child's nursery, family structure and financial standing, and social and health picture of the family. The model was developed within expert system shell for decision making DEX (M. Bohanec, V. Rajkovic: Expert system for decision making. Sistemica 1(1), pp. 145-157, 1990.).The hierarchical model ranks nursery-school applications according to the following concept structure: NURSERY            Evaluation of applications for nursery schools . EMPLOY           Employment of parents and child's nursery . . parents        Parents' occupation . . has_nurs       Child's nursery . STRUCT_FINAN     Family structure and financial standings . . STRUCTURE      Family structure . . . form         Form of the family . . . children     Number of children . . housing        Housing conditions . . finance        Financial standing of the family . SOC_HEALTH       Social and health picture of the family . . social         Social conditions . . health         Health conditionsInput attributes are printed in lowercase. Besides the target concept (NURSERY) the model includes four intermediate concepts: EMPLOY, STRUCT_FINAN, STRUCTURE, SOC_HEALTH. Every concept is in the original model related to its lower level descendants by a set of examples (for these examples sets see [Web Link]).The Nursery Database contains examples with the structural information removed, i.e., directly relates NURSERY to the eight input attributes: parents, has_nurs, form, children, housing, finance, social, health.Because of known underlying concept structure, this database may be particularly useful for testing constructive induction and structure discovery methods.   parents:        usual, pretentious, great_pret   has_nurs:       proper, less_proper, improper, critical, very_crit   form:           complete, completed, incomplete, foster   children:       1, 2, 3, more   housing:        convenient, less_conv, critical   finance:        convenient, inconv   social:         non-prob, slightly_prob, problematic   health:         recommended, priority, not_recom"
Hayes-Roth,Hayes-Roth,Topic: human subjects study,Hayes-Roth,https://archive.ics.uci.edu/ml//machine-learning-databases/hayes-roth/,https://archive.ics.uci.edu/ml/datasets/Hayes-Roth,"This database contains 5 numeric-valued attributes.  Only a subset of 3 are used during testing (the latter 3).  Furthermore, only 2 of the 3 concepts are ""used"" during testing (i.e., those with the prototypes 000 and 111).  I've mapped all values to their zero-indexing equivalents.Some instances could be placed in either category 0 or 1.  I've followed the authors' suggestion, placing them in each category with equal probability.I've replaced the actual values of the attributes (i.e., hobby has values chess, sports and stamps) with numeric values.  I think this is how the authors' did this when testing the categorization models described in the paper.  I find this unfair.  While the subjects were able to bring background knowledge to bear on the attribute values and their relationships, the algorithms were provided with no such knowledge.  I'm uncertain whether the 2 distractor attributes (name and hobby) are presented to the authors' algorithms during testing.  However, it is clear that only the age, educational status, and marital status attributes are given during the human subjects' transfer tests.  ",Social,      -- 1. name: distinct for each instance and represented numerically      -- 2. hobby: nominal values ranging between 1 and 3      -- 3. age: nominal values ranging between 1 and 4      -- 4. educational level: nominal values ranging between 1 and 4      -- 5. marital status: nominal values ranging between 1 and 4      -- 6. class: nominal value between 1 and 3,"Topic: human subjects studyThis database contains 5 numeric-valued attributes.  Only a subset of 3 are used during testing (the latter 3).  Furthermore, only 2 of the 3 concepts are ""used"" during testing (i.e., those with the prototypes 000 and 111).  I've mapped all values to their zero-indexing equivalents.Some instances could be placed in either category 0 or 1.  I've followed the authors' suggestion, placing them in each category with equal probability.I've replaced the actual values of the attributes (i.e., hobby has values chess, sports and stamps) with numeric values.  I think this is how the authors' did this when testing the categorization models described in the paper.  I find this unfair.  While the subjects were able to bring background knowledge to bear on the attribute values and their relationships, the algorithms were provided with no such knowledge.  I'm uncertain whether the 2 distractor attributes (name and hobby) are presented to the authors' algorithms during testing.  However, it is clear that only the age, educational status, and marital status attributes are given during the human subjects' transfer tests.        -- 1. name: distinct for each instance and represented numerically      -- 2. hobby: nominal values ranging between 1 and 3      -- 3. age: nominal values ranging between 1 and 4      -- 4. educational level: nominal values ranging between 1 and 4      -- 5. marital status: nominal values ranging between 1 and 4      -- 6. class: nominal value between 1 and 3"
Facebook Large Page-Page Network,Facebook Large Page-Page Network,This webgraph is a page-page graph of verified Facebook sites. Nodes represent official Facebook pages while the links are mutual likes between sites.,Facebook+Large+Page-Page+Network,https://archive.ics.uci.edu/ml//machine-learning-databases/00527/,https://archive.ics.uci.edu/ml/datasets/Facebook+Large+Page-Page+Network," Node features are extracted from the site descriptions that the page owners created to summarize the purpose of the site. This graph was collected through the Facebook Graph API in November 2017 and restricted to pages from 4 categories which are defined by Facebook. These categories are: politicians, governmental organizations, television shows and companies. The task related to this dataset is multi-class node classification for the 4 site categories. Provide all relevant information about your data set.",Social,Features are words that appear in the page descriptions.,"This webgraph is a page-page graph of verified Facebook sites. Nodes represent official Facebook pages while the links are mutual likes between sites. Node features are extracted from the site descriptions that the page owners created to summarize the purpose of the site. This graph was collected through the Facebook Graph API in November 2017 and restricted to pages from 4 categories which are defined by Facebook. These categories are: politicians, governmental organizations, television shows and companies. The task related to this dataset is multi-class node classification for the 4 site categories. Provide all relevant information about your data set.Features are words that appear in the page descriptions."
Congressional Voting Records,Congressional Voting Records,1984 United Stated Congressional Voting Records; Classify as Republican or Democrat,Congressional+Voting+Records,https://archive.ics.uci.edu/ml//machine-learning-databases/voting-records/,https://archive.ics.uci.edu/ml/datasets/Congressional+Voting+Records,"This data set includes votes for each of the U.S. House of Representatives Congressmen on the 16 key votes identified by the CQA.  The CQA lists nine different types of votes: voted for, paired for, and announced for (these three simplified to yea), voted against, paired against, and announced against (these three simplified to nay), voted present, voted present to avoid conflict of interest, and did not vote or otherwise make a position known (these three simplified to an unknown disposition).",Social,"   1. Class Name: 2 (democrat, republican)   2. handicapped-infants: 2 (y,n)   3. water-project-cost-sharing: 2 (y,n)   4. adoption-of-the-budget-resolution: 2 (y,n)   5. physician-fee-freeze: 2 (y,n)   6. el-salvador-aid: 2 (y,n)   7. religious-groups-in-schools: 2 (y,n)   8. anti-satellite-test-ban: 2 (y,n)   9. aid-to-nicaraguan-contras: 2 (y,n)  10. mx-missile: 2 (y,n)  11. immigration: 2 (y,n)  12. synfuels-corporation-cutback: 2 (y,n)  13. education-spending: 2 (y,n)  14. superfund-right-to-sue: 2 (y,n)  15. crime: 2 (y,n)  16. duty-free-exports: 2 (y,n)  17. export-administration-act-south-africa: 2 (y,n)","1984 United Stated Congressional Voting Records; Classify as Republican or DemocratThis data set includes votes for each of the U.S. House of Representatives Congressmen on the 16 key votes identified by the CQA.  The CQA lists nine different types of votes: voted for, paired for, and announced for (these three simplified to yea), voted against, paired against, and announced against (these three simplified to nay), voted present, voted present to avoid conflict of interest, and did not vote or otherwise make a position known (these three simplified to an unknown disposition).   1. Class Name: 2 (democrat, republican)   2. handicapped-infants: 2 (y,n)   3. water-project-cost-sharing: 2 (y,n)   4. adoption-of-the-budget-resolution: 2 (y,n)   5. physician-fee-freeze: 2 (y,n)   6. el-salvador-aid: 2 (y,n)   7. religious-groups-in-schools: 2 (y,n)   8. anti-satellite-test-ban: 2 (y,n)   9. aid-to-nicaraguan-contras: 2 (y,n)  10. mx-missile: 2 (y,n)  11. immigration: 2 (y,n)  12. synfuels-corporation-cutback: 2 (y,n)  13. education-spending: 2 (y,n)  14. superfund-right-to-sue: 2 (y,n)  15. crime: 2 (y,n)  16. duty-free-exports: 2 (y,n)  17. export-administration-act-south-africa: 2 (y,n)"
Multimodal Damage Identification for Humanitarian Computing,Multimodal Damage Identification for Humanitarian Computing,"5879 captioned images (image and text) from social media related to damage during natural disasters/wars, and belong to 6 classes: Fires, Floods, Natural landscape, Infrastructural, Human, Non-damage.",Multimodal+Damage+Identification+for+Humanitarian+Computing,https://archive.ics.uci.edu/ml//machine-learning-databases/00456/,https://archive.ics.uci.edu/ml/datasets/Multimodal+Damage+Identification+for+Humanitarian+Computing,Samples were retrieved from social media posts including Instagram and Twitter. ,Social,640x640 RGB images and raw text,"5879 captioned images (image and text) from social media related to damage during natural disasters/wars, and belong to 6 classes: Fires, Floods, Natural landscape, Infrastructural, Human, Non-damage.Samples were retrieved from social media posts including Instagram and Twitter. 640x640 RGB images and raw text"
Autism Screening Adult,Autism Screening Adult,Autistic Spectrum Disorder Screening Data for Adult. This dataset is related to classification and predictive tasks.,Autism+Screening+Adult,https://archive.ics.uci.edu/ml//machine-learning-databases/00426/,https://archive.ics.uci.edu/ml/datasets/Autism+Screening+Adult,See attached variables' description file ,Social,See attached variables' description file ,Autistic Spectrum Disorder Screening Data for Adult. This dataset is related to classification and predictive tasks.See attached variables' description file See attached variables' description file 
Turkish Spam V01,Turkish Spam V01,The TurkishSpam data set contains spam and normal emails written in Turkish.,Turkish+Spam+V01,https://archive.ics.uci.edu/ml//machine-learning-databases/00530/,https://archive.ics.uci.edu/ml/datasets/Turkish+Spam+V01,A total of 330 spam and 496 normal e-mails were collected from several personal accounts,Social,text=Contains spam messagesclassification=contains classification information,The TurkishSpam data set contains spam and normal emails written in Turkish.A total of 330 spam and 496 normal e-mails were collected from several personal accountstext=Contains spam messagesclassification=contains classification information
Communities and Crime,Communities and Crime,"Communities within the United States. The data combines socio-economic data from the 1990 US Census, law enforcement data from the 1990 US LEMAS survey, and crime data from the 1995 FBI UCR.",Communities+and+Crime,https://archive.ics.uci.edu/ml//machine-learning-databases/communities/,https://archive.ics.uci.edu/ml/datasets/Communities+and+Crime,"  Many variables are included so that algorithms that select or learn weights for attributes could be tested. However, clearly unrelated attributes were not included; attributes were picked if there was any plausible connection to crime (N=122), plus the attribute to be predicted (Per Capita Violent Crimes). The variables included in the dataset involve the community, such as the percent of the population considered urban, and the median family income, and involving law enforcement, such as per capita number of police officers, and percent of officers assigned to drug units.   The per capita violent crimes variable was calculated using population and the sum of crime variables considered violent crimes in the United States: murder, rape, robbery, and assault. There was apparently some controversy in some states concerning the counting of rapes. These resulted in missing values for rape, which resulted in incorrect values for per capita violent crime. These cities are not included in the dataset. Many of these omitted communities were from the midwestern USA.  Data is described below based on original values. All numeric data was normalized into the decimal range  0.00-1.00 using an Unsupervised, equal-interval binning method. Attributes retain their distribution and skew (hence for example the population attribute has a mean value of  0.06 because most communities are small). E.g. An attribute described as 'mean people per household' is actually the normalized (0-1) version of that value.  The normalization preserves rough ratios of values WITHIN an attribute (e.g. double the value for double the population within the available precision - except for extreme values (all values more than 3 SD above the mean are normalized to 1.00; all values more than 3 SD below the mean are nromalized to  0.00)).  However, the normalization does not preserve relationships between values BETWEEN attributes (e.g. it would not be meaningful to compare the value for whitePerCap with the value for blackPerCap for a community)  A limitation was that the LEMAS survey was of the police departments with at least 100 officers, plus a random sample of smaller departments. For our purposes, communities not found in both census and crime datasets were omitted. Many communities are missing LEMAS data..arff header for Weka:@relation crimepredict@attribute state numeric@attribute county numeric@attribute community numeric@attribute communityname string@attribute fold numeric@attribute population numeric@attribute householdsize numeric@attribute racepctblack numeric@attribute racePctWhite numeric@attribute racePctAsian numeric@attribute racePctHisp numeric@attribute agePct12t21 numeric@attribute agePct12t29 numeric@attribute agePct16t24 numeric@attribute agePct65up numeric@attribute numbUrban numeric@attribute pctUrban numeric@attribute medIncome numeric@attribute pctWWage numeric@attribute pctWFarmSelf numeric@attribute pctWInvInc numeric@attribute pctWSocSec numeric@attribute pctWPubAsst numeric@attribute pctWRetire numeric@attribute medFamInc numeric@attribute perCapInc numeric@attribute whitePerCap numeric@attribute blackPerCap numeric@attribute indianPerCap numeric@attribute AsianPerCap numeric@attribute OtherPerCap numeric@attribute HispPerCap numeric@attribute NumUnderPov numeric@attribute PctPopUnderPov numeric@attribute PctLess9thGrade numeric@attribute PctNotHSGrad numeric@attribute PctBSorMore numeric@attribute PctUnemployed numeric@attribute PctEmploy numeric@attribute PctEmplManu numeric@attribute PctEmplProfServ numeric@attribute PctOccupManu numeric@attribute PctOccupMgmtProf numeric@attribute MalePctDivorce numeric@attribute MalePctNevMarr numeric@attribute FemalePctDiv numeric@attribute TotalPctDiv numeric@attribute PersPerFam numeric@attribute PctFam2Par numeric@attribute PctKids2Par numeric@attribute PctYoungKids2Par numeric@attribute PctTeen2Par numeric@attribute PctWorkMomYoungKids numeric@attribute PctWorkMom numeric@attribute NumIlleg numeric@attribute PctIlleg numeric@attribute NumImmig numeric@attribute PctImmigRecent numeric@attribute PctImmigRec5 numeric@attribute PctImmigRec8 numeric@attribute PctImmigRec10 numeric@attribute PctRecentImmig numeric@attribute PctRecImmig5 numeric@attribute PctRecImmig8 numeric@attribute PctRecImmig10 numeric@attribute PctSpeakEnglOnly numeric@attribute PctNotSpeakEnglWell numeric@attribute PctLargHouseFam numeric@attribute PctLargHouseOccup numeric@attribute PersPerOccupHous numeric@attribute PersPerOwnOccHous numeric@attribute PersPerRentOccHous numeric@attribute PctPersOwnOccup numeric@attribute PctPersDenseHous numeric@attribute PctHousLess3BR numeric@attribute MedNumBR numeric@attribute HousVacant numeric@attribute PctHousOccup numeric@attribute PctHousOwnOcc numeric@attribute PctVacantBoarded numeric@attribute PctVacMore6Mos numeric@attribute MedYrHousBuilt numeric@attribute PctHousNoPhone numeric@attribute PctWOFullPlumb numeric@attribute OwnOccLowQuart numeric@attribute OwnOccMedVal numeric@attribute OwnOccHiQuart numeric@attribute RentLowQ numeric@attribute RentMedian numeric@attribute RentHighQ numeric@attribute MedRent numeric@attribute MedRentPctHousInc numeric@attribute MedOwnCostPctInc numeric@attribute MedOwnCostPctIncNoMtg numeric@attribute NumInShelters numeric@attribute NumStreet numeric@attribute PctForeignBorn numeric@attribute PctBornSameState numeric@attribute PctSameHouse85 numeric@attribute PctSameCity85 numeric@attribute PctSameState85 numeric@attribute LemasSwornFT numeric@attribute LemasSwFTPerPop numeric@attribute LemasSwFTFieldOps numeric@attribute LemasSwFTFieldPerPop numeric@attribute LemasTotalReq numeric@attribute LemasTotReqPerPop numeric@attribute PolicReqPerOffic numeric@attribute PolicPerPop numeric@attribute RacialMatchCommPol numeric@attribute PctPolicWhite numeric@attribute PctPolicBlack numeric@attribute PctPolicHisp numeric@attribute PctPolicAsian numeric@attribute PctPolicMinor numeric@attribute OfficAssgnDrugUnits numeric@attribute NumKindsDrugsSeiz numeric@attribute PolicAveOTWorked numeric@attribute LandArea numeric@attribute PopDens numeric@attribute PctUsePubTrans numeric@attribute PolicCars numeric@attribute PolicOperBudg numeric@attribute LemasPctPolicOnPatr numeric@attribute LemasGangUnitDeploy numeric@attribute LemasPctOfficDrugUn numeric@attribute PolicBudgPerPop numeric@attribute ViolentCrimesPerPop numeric@data  ",Social,"Attribute Information: (122 predictive, 5 non-predictive, 1 goal)  -- state: US state (by number) - not counted as predictive above, but if considered, should be consided nominal (nominal)   -- county: numeric code for county - not predictive, and many missing values (numeric)  -- community: numeric code for community - not predictive and many missing values (numeric)  -- communityname: community name - not predictive - for information only (string)  -- fold: fold number for non-random 10 fold cross validation, potentially useful for debugging, paired tests - not predictive (numeric)  -- population: population for community: (numeric - decimal)  -- householdsize: mean people per household (numeric - decimal)  -- racepctblack: percentage of population that is african american (numeric - decimal)  -- racePctWhite: percentage of population that is caucasian (numeric - decimal)  -- racePctAsian: percentage of population that is of asian heritage (numeric - decimal)  -- racePctHisp: percentage of population that is of hispanic heritage (numeric - decimal)  -- agePct12t21: percentage of population that is 12-21 in age (numeric - decimal)  -- agePct12t29: percentage of population that is 12-29 in age (numeric - decimal)  -- agePct16t24: percentage of population that is 16-24 in age (numeric - decimal)  -- agePct65up: percentage of population that is 65 and over in age (numeric - decimal)  -- numbUrban: number of people living in areas classified as urban (numeric - decimal)  -- pctUrban: percentage of people living in areas classified as urban (numeric - decimal)  -- medIncome: median household income (numeric - decimal)  -- pctWWage: percentage of households with wage or salary income in 1989 (numeric - decimal)  -- pctWFarmSelf: percentage of households with farm or self employment income in 1989 (numeric - decimal)  -- pctWInvInc: percentage of households with investment / rent income in 1989 (numeric - decimal)  -- pctWSocSec: percentage of households with social security income in 1989 (numeric - decimal)  -- pctWPubAsst: percentage of households with public assistance income in 1989 (numeric - decimal)  -- pctWRetire: percentage of households with retirement income in 1989 (numeric - decimal)  -- medFamInc: median family income (differs from household income for non-family households) (numeric - decimal)  -- perCapInc: per capita income (numeric - decimal)  -- whitePerCap: per capita income for caucasians (numeric - decimal)  -- blackPerCap: per capita income for african americans (numeric - decimal)  -- indianPerCap: per capita income for native americans (numeric - decimal)  -- AsianPerCap: per capita income for people with asian heritage (numeric - decimal)  -- OtherPerCap: per capita income for people with 'other' heritage (numeric - decimal)  -- HispPerCap: per capita income for people with hispanic heritage (numeric - decimal)  -- NumUnderPov: number of people under the poverty level (numeric - decimal)  -- PctPopUnderPov: percentage of people under the poverty level (numeric - decimal)  -- PctLess9thGrade: percentage of people 25 and over with less than a 9th grade education (numeric - decimal)  -- PctNotHSGrad: percentage of people 25 and over that are not high school graduates (numeric - decimal)  -- PctBSorMore: percentage of people 25 and over with a bachelors degree or higher education (numeric - decimal)  -- PctUnemployed: percentage of people 16 and over, in the labor force, and unemployed (numeric - decimal)  -- PctEmploy: percentage of people 16 and over who are employed (numeric - decimal)  -- PctEmplManu: percentage of people 16 and over who are employed in manufacturing (numeric - decimal)  -- PctEmplProfServ: percentage of people 16 and over who are employed in professional services (numeric - decimal)  -- PctOccupManu: percentage of people 16 and over who are employed in manufacturing (numeric - decimal)   ########  -- PctOccupMgmtProf: percentage of people 16 and over who are employed in management or professional occupations (numeric - decimal)  -- MalePctDivorce: percentage of males who are divorced (numeric - decimal)  -- MalePctNevMarr: percentage of males who have never married (numeric - decimal)  -- FemalePctDiv: percentage of females who are divorced (numeric - decimal)  -- TotalPctDiv: percentage of population who are divorced (numeric - decimal)  -- PersPerFam: mean number of people per family (numeric - decimal)  -- PctFam2Par: percentage of families (with kids) that are headed by two parents (numeric - decimal)  -- PctKids2Par: percentage of kids in family housing with two parents (numeric - decimal)  -- PctYoungKids2Par: percent of kids 4 and under in two parent households (numeric - decimal)  -- PctTeen2Par: percent of kids age 12-17 in two parent households (numeric - decimal)  -- PctWorkMomYoungKids: percentage of moms of kids 6 and under in labor force (numeric - decimal)  -- PctWorkMom: percentage of moms of kids under 18 in labor force (numeric - decimal)  -- NumIlleg: number of kids born to never married (numeric - decimal)  -- PctIlleg: percentage of kids born to never married (numeric - decimal)  -- NumImmig: total number of people known to be foreign born (numeric - decimal)  -- PctImmigRecent: percentage of _immigrants_ who immigated within last 3 years (numeric - decimal)  -- PctImmigRec5: percentage of _immigrants_ who immigated within last 5 years (numeric - decimal)  -- PctImmigRec8: percentage of _immigrants_ who immigated within last 8 years (numeric - decimal)  -- PctImmigRec10: percentage of _immigrants_ who immigated within last 10 years (numeric - decimal)  -- PctRecentImmig: percent of _population_ who have immigrated within the last 3 years (numeric - decimal)  -- PctRecImmig5: percent of _population_ who have immigrated within the last 5 years (numeric - decimal)  -- PctRecImmig8: percent of _population_ who have immigrated within the last 8 years (numeric - decimal)  -- PctRecImmig10: percent of _population_ who have immigrated within the last 10 years (numeric - decimal)  -- PctSpeakEnglOnly: percent of people who speak only English (numeric - decimal)  -- PctNotSpeakEnglWell: percent of people who do not speak English well (numeric - decimal)  -- PctLargHouseFam: percent of family households that are large (6 or more) (numeric - decimal)  -- PctLargHouseOccup: percent of all occupied households that are large (6 or more people) (numeric - decimal)  -- PersPerOccupHous: mean persons per household (numeric - decimal)  -- PersPerOwnOccHous: mean persons per owner occupied household (numeric - decimal)  -- PersPerRentOccHous: mean persons per rental household (numeric - decimal)  -- PctPersOwnOccup: percent of people in owner occupied households (numeric - decimal)  -- PctPersDenseHous: percent of persons in dense housing (more than 1 person per room) (numeric - decimal)  -- PctHousLess3BR: percent of housing units with less than 3 bedrooms (numeric - decimal)  -- MedNumBR: median number of bedrooms (numeric - decimal)  -- HousVacant: number of vacant households (numeric - decimal)  -- PctHousOccup: percent of housing occupied (numeric - decimal)  -- PctHousOwnOcc: percent of households owner occupied (numeric - decimal)  -- PctVacantBoarded: percent of vacant housing that is boarded up (numeric - decimal)  -- PctVacMore6Mos: percent of vacant housing that has been vacant more than 6 months (numeric - decimal)  -- MedYrHousBuilt: median year housing units built (numeric - decimal)  -- PctHousNoPhone: percent of occupied housing units without phone (in 1990, this was rare!) (numeric - decimal)  -- PctWOFullPlumb: percent of housing without complete plumbing facilities (numeric - decimal)  -- OwnOccLowQuart: owner occupied housing - lower quartile value (numeric - decimal)  -- OwnOccMedVal: owner occupied housing - median value (numeric - decimal)  -- OwnOccHiQuart: owner occupied housing - upper quartile value (numeric - decimal)  -- RentLowQ: rental housing - lower quartile rent (numeric - decimal)  -- RentMedian: rental housing - median rent (Census variable H32B from file STF1A) (numeric - decimal)  -- RentHighQ: rental housing - upper quartile rent (numeric - decimal)  -- MedRent: median gross rent (Census variable H43A from file STF3A - includes utilities) (numeric - decimal)  -- MedRentPctHousInc: median gross rent as a percentage of household income (numeric - decimal)  -- MedOwnCostPctInc: median owners cost as a percentage of household income - for owners with a mortgage (numeric - decimal)  -- MedOwnCostPctIncNoMtg: median owners cost as a percentage of household income - for owners without a mortgage (numeric - decimal)  -- NumInShelters: number of people in homeless shelters (numeric - decimal)  -- NumStreet: number of homeless people counted in the street (numeric - decimal)  -- PctForeignBorn: percent of people foreign born (numeric - decimal)  -- PctBornSameState: percent of people born in the same state as currently living (numeric - decimal)  -- PctSameHouse85: percent of people living in the same house as in 1985 (5 years before) (numeric - decimal)  -- PctSameCity85: percent of people living in the same city as in 1985 (5 years before) (numeric - decimal)  -- PctSameState85: percent of people living in the same state as in 1985 (5 years before) (numeric - decimal)  -- LemasSwornFT: number of sworn full time police officers (numeric - decimal)  -- LemasSwFTPerPop: sworn full time police officers per 100K population (numeric - decimal)  -- LemasSwFTFieldOps: number of sworn full time police officers in field operations (on the street as opposed to administrative etc) (numeric - decimal)  -- LemasSwFTFieldPerPop: sworn full time police officers in field operations (on the street as opposed to administrative etc) per 100K population (numeric - decimal)  -- LemasTotalReq: total requests for police (numeric - decimal)  -- LemasTotReqPerPop: total requests for police per 100K popuation (numeric - decimal)  -- PolicReqPerOffic: total requests for police per police officer (numeric - decimal)  -- PolicPerPop: police officers per 100K population (numeric - decimal)  -- RacialMatchCommPol: a measure of the racial match between the community and the police force. High values indicate proportions in community and police force are similar (numeric - decimal)  -- PctPolicWhite: percent of police that are caucasian (numeric - decimal)  -- PctPolicBlack: percent of police that are african american (numeric - decimal)  -- PctPolicHisp: percent of police that are hispanic (numeric - decimal)  -- PctPolicAsian: percent of police that are asian (numeric - decimal)  -- PctPolicMinor: percent of police that are minority of any kind (numeric - decimal)  -- OfficAssgnDrugUnits: number of officers assigned to special drug units (numeric - decimal)  -- NumKindsDrugsSeiz: number of different kinds of drugs seized (numeric - decimal)  -- PolicAveOTWorked: police average overtime worked (numeric - decimal)  -- LandArea: land area in square miles (numeric - decimal)  -- PopDens: population density in persons per square mile (numeric - decimal)  -- PctUsePubTrans: percent of people using public transit for commuting (numeric - decimal)  -- PolicCars: number of police cars (numeric - decimal)  -- PolicOperBudg: police operating budget (numeric - decimal)  -- LemasPctPolicOnPatr: percent of sworn full time police officers on patrol (numeric - decimal)  -- LemasGangUnitDeploy: gang unit deployed (numeric - decimal - but really ordinal - 0 means NO, 1 means YES,  0.5 means Part Time)  -- LemasPctOfficDrugUn: percent of officers assigned to drug units (numeric - decimal)  -- PolicBudgPerPop: police operating budget per population (numeric - decimal)  -- ViolentCrimesPerPop: total number of violent crimes per 100K popuation (numeric - decimal) GOAL attribute (to be predicted)Summary Statistics:			Min	Max	 Mean	 SD	Correl	Median	 Mode	Missingpopulation		0	1	 0.06	 0.13	 0.37	 0.02	 0.01	0householdsize		0	1	 0.46	 0.16	-0.03	 0.44	 0.41	0racepctblack		0	1	 0.18	 0.25	 0.63	 0.06	 0.01	0racePctWhite		0	1	 0.75	 0.24	-0.68	 0.85	 0.98	0racePctAsian		0	1	 0.15	 0.21	 0.04	 0.07	 0.02	0racePctHisp		0	1	 0.14	 0.23	 0.29	 0.04	 0.01	0agePct12t21		0	1	 0.42	 0.16	 0.06	 0.4	 0.38	0agePct12t29		0	1	 0.49	 0.14	 0.15	 0.48	 0.49	0agePct16t24		0	1	 0.34	 0.17	 0.10	 0.29	 0.29	0agePct65up		0	1	 0.42	 0.18	 0.07	 0.42	 0.47	0numbUrban		0	1	 0.06	 0.13	 0.36	 0.03	 0	0pctUrban		0	1	 0.70	 0.44	 0.08	 1	 1	0medIncome		0	1	 0.36	 0.21	-0.42	 0.32	 0.23	0pctWWage		0	1	 0.56	 0.18	-0.31	 0.56	 0.58	0pctWFarmSelf		0	1	 0.29	 0.20	-0.15	 0.23	 0.16	0pctWInvInc		0	1	 0.50	 0.18	-0.58	 0.48	 0.41	0pctWSocSec		0	1	 0.47	 0.17	 0.12	 0.475	 0.56	0pctWPubAsst		0	1	 0.32	 0.22	 0.57	 0.26	 0.1	0pctWRetire		0	1	 0.48	 0.17	-0.10	 0.47	 0.44	0medFamInc		0	1	 0.38	 0.20	-0.44	 0.33	 0.25	0perCapInc		0	1	 0.35	 0.19	-0.35	 0.3	 0.23	0whitePerCap		0	1	 0.37	 0.19	-0.21	 0.32	 0.3	0blackPerCap		0	1	 0.29	 0.17	-0.28	 0.25	 0.18	0indianPerCap		0	1	 0.20	 0.16	-0.09	 0.17	 0	0AsianPerCap		0	1	 0.32	 0.20	-0.16	 0.28	 0.18	0OtherPerCap		0	1	 0.28	 0.19	-0.13	 0.25	 0	1HispPerCap		0	1	 0.39	 0.18	-0.24	 0.345	 0.3	0NumUnderPov		0	1	 0.06	 0.13	 0.45	 0.02	 0.01	0PctPopUnderPov		0	1	 0.30	 0.23	 0.52	 0.25	 0.08	0PctLess9thGrade		0	1	 0.32	 0.21	 0.41	 0.27	 0.19	0PctNotHSGrad		0	1	 0.38	 0.20	 0.48	 0.36	 0.39	0PctBSorMore		0	1	 0.36	 0.21	-0.31	 0.31	 0.18	0PctUnemployed		0	1	 0.36	 0.20	 0.50	 0.32	 0.24	0PctEmploy		0	1	 0.50	 0.17	-0.33	 0.51	 0.56	0PctEmplManu		0	1	 0.40	 0.20	-0.04	 0.37	 0.26	0PctEmplProfServ		0	1	 0.44	 0.18	-0.07	 0.41	 0.36	0PctOccupManu		0	1	 0.39	 0.20	 0.30	 0.37	 0.32	0PctOccupMgmtProf	0	1	 0.44	 0.19	-0.34	 0.4	 0.36	0MalePctDivorce		0	1	 0.46	 0.18	 0.53	 0.47	 0.56	0MalePctNevMarr		0	1	 0.43	 0.18	 0.30	 0.4	 0.38	0FemalePctDiv		0	1	 0.49	 0.18	 0.56	 0.5	 0.54	0TotalPctDiv		0	1	 0.49	 0.18	 0.55	 0.5	 0.57	0PersPerFam		0	1	 0.49	 0.15	 0.14	 0.47	 0.44	0PctFam2Par		0	1	 0.61	 0.20	-0.71	 0.63	 0.7	0PctKids2Par		0	1	 0.62	 0.21	-0.74	 0.64	 0.72	0PctYoungKids2Par	0	1	 0.66	 0.22	-0.67	 0.7	 0.91	0PctTeen2Par		0	1	 0.58	 0.19	-0.66	 0.61	 0.6	0PctWorkMomYoungKids	0	1	 0.50	 0.17	-0.02	 0.51	 0.51	0PctWorkMom		0	1	 0.53	 0.18	-0.15	 0.54	 0.57	0NumIlleg		0	1	 0.04	 0.11	 0.47	 0.01	 0	0PctIlleg		0	1	 0.25	 0.23	 0.74	 0.17	 0.09	0NumImmig		0	1	 0.03	 0.09	 0.29	 0.01	 0	0PctImmigRecent		0	1	 0.32	 0.22	 0.17	 0.29	 0	0PctImmigRec5		0	1	 0.36	 0.21	 0.22	 0.34	 0	0PctImmigRec8		0	1	 0.40	 0.20	 0.25	 0.39	 0.26	0PctImmigRec10		0	1	 0.43	 0.19	 0.29	 0.43	 0.43	0PctRecentImmig		0	1	 0.18	 0.24	 0.23	 0.09	 0.01	0PctRecImmig5		0	1	 0.18	 0.24	 0.25	 0.08	 0.02	0PctRecImmig8		0	1	 0.18	 0.24	 0.25	 0.09	 0.02	0PctRecImmig10		0	1	 0.18	 0.23	 0.26	 0.09	 0.02	0PctSpeakEnglOnly	0	1	 0.79	 0.23	-0.24	 0.87	 0.96	0PctNotSpeakEnglWell	0	1	 0.15	 0.22	 0.30	 0.06	 0.03	0PctLargHouseFam		0	1	 0.27	 0.20	 0.38	 0.2	 0.17	0PctLargHouseOccup	0	1	 0.25	 0.19	 0.29	 0.19	 0.19	0PersPerOccupHous	0	1	 0.46	 0.17	-0.04	 0.44	 0.37	0PersPerOwnOccHous	0	1	 0.49	 0.16	-0.12	 0.48	 0.45	0PersPerRentOccHous	0	1	 0.40	 0.19	 0.25	 0.36	 0.32	0PctPersOwnOccup		0	1	 0.56	 0.20	-0.53	 0.56	 0.54	0PctPersDenseHous	0	1	 0.19	 0.21	 0.45	 0.11	 0.06	0PctHousLess3BR		0	1	 0.50	 0.17	 0.47	 0.51	 0.53	0MedNumBR		0	1	 0.31	 0.26	-0.36	 0.5	 0.5	0HousVacant		0	1	 0.08	 0.15	 0.42	 0.03	 0.01	0PctHousOccup		0	1	 0.72	 0.19	-0.32	 0.77	 0.88	0PctHousOwnOcc		0	1	 0.55	 0.19	-0.47	 0.54	 0.52	0PctVacantBoarded	0	1	 0.20	 0.22	 0.48	 0.13	 0	0PctVacMore6Mos		0	1	 0.43	 0.19	 0.02	 0.42	 0.44	0MedYrHousBuilt		0	1	 0.49	 0.23	-0.11	 0.52	 0	0PctHousNoPhone		0	1	 0.26	 0.24	 0.49	 0.185	 0.01	0PctWOFullPlumb		0	1	 0.24	 0.21	 0.36	 0.19	 0	0OwnOccLowQuart		0	1	 0.26	 0.22	-0.21	 0.18	 0.09	0OwnOccMedVal		0	1	 0.26	 0.23	-0.19	 0.17	 0.08	0OwnOccHiQuart		0	1	 0.27	 0.24	-0.17	 0.18	 0.08	0RentLowQ		0	1	 0.35	 0.22	-0.25	 0.31	 0.13	0RentMedian		0	1	 0.37	 0.21	-0.24	 0.33	 0.19	0RentHighQ		0	1	 0.42	 0.25	-0.23	 0.37	 1	0MedRent			0	1	 0.38	 0.21	-0.24	 0.34	 0.17	0MedRentPctHousInc	0	1	 0.49	 0.17	 0.33	 0.48	 0.4	0MedOwnCostPctInc	0	1	 0.45	 0.19	 0.06	 0.45	 0.41	0MedOwnCostPctIncNoMtg	0	1	 0.40	 0.19	 0.05	 0.37	 0.24	0NumInShelters		0	1	 0.03	 0.10	 0.38	 0	 0	0NumStreet		0	1	 0.02	 0.10	 0.34	 0	 0	0PctForeignBorn		0	1	 0.22	 0.23	 0.19	 0.13	 0.03	0PctBornSameState	0	1	 0.61	 0.20	-0.08	 0.63	 0.78	0PctSameHouse85		0	1	 0.54	 0.18	-0.16	 0.54	 0.59	0PctSameCity85		0	1	 0.63	 0.20	 0.08	 0.67	 0.74	0PctSameState85		0	1	 0.65	 0.20	-0.02	 0.7	 0.79	0LemasSwornFT		0	1	 0.07	 0.14	 0.34	 0.02	 0.02	1675LemasSwFTPerPop		0	1	 0.22	 0.16	 0.15	 0.18	 0.2	1675LemasSwFTFieldOps	0	1	 0.92	 0.13	-0.33	 0.97	 0.98	1675LemasSwFTFieldPerPop	0	1	 0.25	 0.16	 0.16	 0.21	 0.19	1675LemasTotalReq		0	1	 0.10	 0.16	 0.35	 0.04	 0.02	1675LemasTotReqPerPop	0	1	 0.22	 0.16	 0.27	 0.17	 0.14	1675PolicReqPerOffic	0	1	 0.34	 0.20	 0.17	 0.29	 0.23	1675PolicPerPop		0	1	 0.22	 0.16	 0.15	 0.18	 0.2	1675RacialMatchCommPol	0	1	 0.69	 0.23	-0.46	 0.74	 0.78	1675PctPolicWhite		0	1	 0.73	 0.22	-0.44	 0.78	 0.72	1675PctPolicBlack		0	1	 0.22	 0.24	 0.54	 0.12	 0	1675PctPolicHisp		0	1	 0.13	 0.20	 0.12	 0.06	 0	1675PctPolicAsian		0	1	 0.11	 0.23	 0.10	 0	 0	1675PctPolicMinor		0	1	 0.26	 0.23	 0.49	 0.2	 0.07	1675OfficAssgnDrugUnits	0	1	 0.08	 0.12	 0.34	 0.04	 0.03	1675NumKindsDrugsSeiz	0	1	 0.56	 0.20	 0.13	 0.57	 0.57	1675PolicAveOTWorked	0	1	 0.31	 0.23	 0.03	 0.26	 0.19	1675LandArea		0	1	 0.07	 0.11	 0.20	 0.04	 0.01	0PopDens			0	1	 0.23	 0.20	 0.28	 0.17	 0.09	0PctUsePubTrans		0	1	 0.16	 0.23	 0.15	 0.07	 0.01	0PolicCars		0	1	 0.16	 0.21	 0.38	 0.08	 0.02	1675PolicOperBudg		0	1	 0.08	 0.14	 0.34	 0.03	 0.02	1675LemasPctPolicOnPatr	0	1	 0.70	 0.21	-0.08	 0.75	 0.74	1675LemasGangUnitDeploy	0	1	 0.44	 0.41	 0.12	 0.5	 0	1675LemasPctOfficDrugUn	0	1	 0.09	 0.24	 0.35	 0	 0	0PolicBudgPerPop		0	1	 0.20	 0.16	 0.10	 0.15	 0.12	1675ViolentCrimesPerPop	0	1	 0.24	 0.23	 1.00	 0.15	 0.03	0Distribution of the Goal Variable (Violent Crimes per Population):   Range	Frequency0.000-0.067	4840.067-0.133	4200.133-0.200	2840.200-0.267	1770.267-0.333	1420.333-0.400	1130.400-0.467	 590.467-0.533	 760.533-0.600	 570.600-0.667	 380.667-0.733	 370.733-0.800	 200.800-0.867	 230.867-0.933	 140.933-1.000	 50","Communities within the United States. The data combines socio-economic data from the 1990 US Census, law enforcement data from the 1990 US LEMAS survey, and crime data from the 1995 FBI UCR.  Many variables are included so that algorithms that select or learn weights for attributes could be tested. However, clearly unrelated attributes were not included; attributes were picked if there was any plausible connection to crime (N=122), plus the attribute to be predicted (Per Capita Violent Crimes). The variables included in the dataset involve the community, such as the percent of the population considered urban, and the median family income, and involving law enforcement, such as per capita number of police officers, and percent of officers assigned to drug units.   The per capita violent crimes variable was calculated using population and the sum of crime variables considered violent crimes in the United States: murder, rape, robbery, and assault. There was apparently some controversy in some states concerning the counting of rapes. These resulted in missing values for rape, which resulted in incorrect values for per capita violent crime. These cities are not included in the dataset. Many of these omitted communities were from the midwestern USA.  Data is described below based on original values. All numeric data was normalized into the decimal range  0.00-1.00 using an Unsupervised, equal-interval binning method. Attributes retain their distribution and skew (hence for example the population attribute has a mean value of  0.06 because most communities are small). E.g. An attribute described as 'mean people per household' is actually the normalized (0-1) version of that value.  The normalization preserves rough ratios of values WITHIN an attribute (e.g. double the value for double the population within the available precision - except for extreme values (all values more than 3 SD above the mean are normalized to 1.00; all values more than 3 SD below the mean are nromalized to  0.00)).  However, the normalization does not preserve relationships between values BETWEEN attributes (e.g. it would not be meaningful to compare the value for whitePerCap with the value for blackPerCap for a community)  A limitation was that the LEMAS survey was of the police departments with at least 100 officers, plus a random sample of smaller departments. For our purposes, communities not found in both census and crime datasets were omitted. Many communities are missing LEMAS data..arff header for Weka:@relation crimepredict@attribute state numeric@attribute county numeric@attribute community numeric@attribute communityname string@attribute fold numeric@attribute population numeric@attribute householdsize numeric@attribute racepctblack numeric@attribute racePctWhite numeric@attribute racePctAsian numeric@attribute racePctHisp numeric@attribute agePct12t21 numeric@attribute agePct12t29 numeric@attribute agePct16t24 numeric@attribute agePct65up numeric@attribute numbUrban numeric@attribute pctUrban numeric@attribute medIncome numeric@attribute pctWWage numeric@attribute pctWFarmSelf numeric@attribute pctWInvInc numeric@attribute pctWSocSec numeric@attribute pctWPubAsst numeric@attribute pctWRetire numeric@attribute medFamInc numeric@attribute perCapInc numeric@attribute whitePerCap numeric@attribute blackPerCap numeric@attribute indianPerCap numeric@attribute AsianPerCap numeric@attribute OtherPerCap numeric@attribute HispPerCap numeric@attribute NumUnderPov numeric@attribute PctPopUnderPov numeric@attribute PctLess9thGrade numeric@attribute PctNotHSGrad numeric@attribute PctBSorMore numeric@attribute PctUnemployed numeric@attribute PctEmploy numeric@attribute PctEmplManu numeric@attribute PctEmplProfServ numeric@attribute PctOccupManu numeric@attribute PctOccupMgmtProf numeric@attribute MalePctDivorce numeric@attribute MalePctNevMarr numeric@attribute FemalePctDiv numeric@attribute TotalPctDiv numeric@attribute PersPerFam numeric@attribute PctFam2Par numeric@attribute PctKids2Par numeric@attribute PctYoungKids2Par numeric@attribute PctTeen2Par numeric@attribute PctWorkMomYoungKids numeric@attribute PctWorkMom numeric@attribute NumIlleg numeric@attribute PctIlleg numeric@attribute NumImmig numeric@attribute PctImmigRecent numeric@attribute PctImmigRec5 numeric@attribute PctImmigRec8 numeric@attribute PctImmigRec10 numeric@attribute PctRecentImmig numeric@attribute PctRecImmig5 numeric@attribute PctRecImmig8 numeric@attribute PctRecImmig10 numeric@attribute PctSpeakEnglOnly numeric@attribute PctNotSpeakEnglWell numeric@attribute PctLargHouseFam numeric@attribute PctLargHouseOccup numeric@attribute PersPerOccupHous numeric@attribute PersPerOwnOccHous numeric@attribute PersPerRentOccHous numeric@attribute PctPersOwnOccup numeric@attribute PctPersDenseHous numeric@attribute PctHousLess3BR numeric@attribute MedNumBR numeric@attribute HousVacant numeric@attribute PctHousOccup numeric@attribute PctHousOwnOcc numeric@attribute PctVacantBoarded numeric@attribute PctVacMore6Mos numeric@attribute MedYrHousBuilt numeric@attribute PctHousNoPhone numeric@attribute PctWOFullPlumb numeric@attribute OwnOccLowQuart numeric@attribute OwnOccMedVal numeric@attribute OwnOccHiQuart numeric@attribute RentLowQ numeric@attribute RentMedian numeric@attribute RentHighQ numeric@attribute MedRent numeric@attribute MedRentPctHousInc numeric@attribute MedOwnCostPctInc numeric@attribute MedOwnCostPctIncNoMtg numeric@attribute NumInShelters numeric@attribute NumStreet numeric@attribute PctForeignBorn numeric@attribute PctBornSameState numeric@attribute PctSameHouse85 numeric@attribute PctSameCity85 numeric@attribute PctSameState85 numeric@attribute LemasSwornFT numeric@attribute LemasSwFTPerPop numeric@attribute LemasSwFTFieldOps numeric@attribute LemasSwFTFieldPerPop numeric@attribute LemasTotalReq numeric@attribute LemasTotReqPerPop numeric@attribute PolicReqPerOffic numeric@attribute PolicPerPop numeric@attribute RacialMatchCommPol numeric@attribute PctPolicWhite numeric@attribute PctPolicBlack numeric@attribute PctPolicHisp numeric@attribute PctPolicAsian numeric@attribute PctPolicMinor numeric@attribute OfficAssgnDrugUnits numeric@attribute NumKindsDrugsSeiz numeric@attribute PolicAveOTWorked numeric@attribute LandArea numeric@attribute PopDens numeric@attribute PctUsePubTrans numeric@attribute PolicCars numeric@attribute PolicOperBudg numeric@attribute LemasPctPolicOnPatr numeric@attribute LemasGangUnitDeploy numeric@attribute LemasPctOfficDrugUn numeric@attribute PolicBudgPerPop numeric@attribute ViolentCrimesPerPop numeric@data  Attribute Information: (122 predictive, 5 non-predictive, 1 goal)  -- state: US state (by number) - not counted as predictive above, but if considered, should be consided nominal (nominal)   -- county: numeric code for county - not predictive, and many missing values (numeric)  -- community: numeric code for community - not predictive and many missing values (numeric)  -- communityname: community name - not predictive - for information only (string)  -- fold: fold number for non-random 10 fold cross validation, potentially useful for debugging, paired tests - not predictive (numeric)  -- population: population for community: (numeric - decimal)  -- householdsize: mean people per household (numeric - decimal)  -- racepctblack: percentage of population that is african american (numeric - decimal)  -- racePctWhite: percentage of population that is caucasian (numeric - decimal)  -- racePctAsian: percentage of population that is of asian heritage (numeric - decimal)  -- racePctHisp: percentage of population that is of hispanic heritage (numeric - decimal)  -- agePct12t21: percentage of population that is 12-21 in age (numeric - decimal)  -- agePct12t29: percentage of population that is 12-29 in age (numeric - decimal)  -- agePct16t24: percentage of population that is 16-24 in age (numeric - decimal)  -- agePct65up: percentage of population that is 65 and over in age (numeric - decimal)  -- numbUrban: number of people living in areas classified as urban (numeric - decimal)  -- pctUrban: percentage of people living in areas classified as urban (numeric - decimal)  -- medIncome: median household income (numeric - decimal)  -- pctWWage: percentage of households with wage or salary income in 1989 (numeric - decimal)  -- pctWFarmSelf: percentage of households with farm or self employment income in 1989 (numeric - decimal)  -- pctWInvInc: percentage of households with investment / rent income in 1989 (numeric - decimal)  -- pctWSocSec: percentage of households with social security income in 1989 (numeric - decimal)  -- pctWPubAsst: percentage of households with public assistance income in 1989 (numeric - decimal)  -- pctWRetire: percentage of households with retirement income in 1989 (numeric - decimal)  -- medFamInc: median family income (differs from household income for non-family households) (numeric - decimal)  -- perCapInc: per capita income (numeric - decimal)  -- whitePerCap: per capita income for caucasians (numeric - decimal)  -- blackPerCap: per capita income for african americans (numeric - decimal)  -- indianPerCap: per capita income for native americans (numeric - decimal)  -- AsianPerCap: per capita income for people with asian heritage (numeric - decimal)  -- OtherPerCap: per capita income for people with 'other' heritage (numeric - decimal)  -- HispPerCap: per capita income for people with hispanic heritage (numeric - decimal)  -- NumUnderPov: number of people under the poverty level (numeric - decimal)  -- PctPopUnderPov: percentage of people under the poverty level (numeric - decimal)  -- PctLess9thGrade: percentage of people 25 and over with less than a 9th grade education (numeric - decimal)  -- PctNotHSGrad: percentage of people 25 and over that are not high school graduates (numeric - decimal)  -- PctBSorMore: percentage of people 25 and over with a bachelors degree or higher education (numeric - decimal)  -- PctUnemployed: percentage of people 16 and over, in the labor force, and unemployed (numeric - decimal)  -- PctEmploy: percentage of people 16 and over who are employed (numeric - decimal)  -- PctEmplManu: percentage of people 16 and over who are employed in manufacturing (numeric - decimal)  -- PctEmplProfServ: percentage of people 16 and over who are employed in professional services (numeric - decimal)  -- PctOccupManu: percentage of people 16 and over who are employed in manufacturing (numeric - decimal)   ########  -- PctOccupMgmtProf: percentage of people 16 and over who are employed in management or professional occupations (numeric - decimal)  -- MalePctDivorce: percentage of males who are divorced (numeric - decimal)  -- MalePctNevMarr: percentage of males who have never married (numeric - decimal)  -- FemalePctDiv: percentage of females who are divorced (numeric - decimal)  -- TotalPctDiv: percentage of population who are divorced (numeric - decimal)  -- PersPerFam: mean number of people per family (numeric - decimal)  -- PctFam2Par: percentage of families (with kids) that are headed by two parents (numeric - decimal)  -- PctKids2Par: percentage of kids in family housing with two parents (numeric - decimal)  -- PctYoungKids2Par: percent of kids 4 and under in two parent households (numeric - decimal)  -- PctTeen2Par: percent of kids age 12-17 in two parent households (numeric - decimal)  -- PctWorkMomYoungKids: percentage of moms of kids 6 and under in labor force (numeric - decimal)  -- PctWorkMom: percentage of moms of kids under 18 in labor force (numeric - decimal)  -- NumIlleg: number of kids born to never married (numeric - decimal)  -- PctIlleg: percentage of kids born to never married (numeric - decimal)  -- NumImmig: total number of people known to be foreign born (numeric - decimal)  -- PctImmigRecent: percentage of _immigrants_ who immigated within last 3 years (numeric - decimal)  -- PctImmigRec5: percentage of _immigrants_ who immigated within last 5 years (numeric - decimal)  -- PctImmigRec8: percentage of _immigrants_ who immigated within last 8 years (numeric - decimal)  -- PctImmigRec10: percentage of _immigrants_ who immigated within last 10 years (numeric - decimal)  -- PctRecentImmig: percent of _population_ who have immigrated within the last 3 years (numeric - decimal)  -- PctRecImmig5: percent of _population_ who have immigrated within the last 5 years (numeric - decimal)  -- PctRecImmig8: percent of _population_ who have immigrated within the last 8 years (numeric - decimal)  -- PctRecImmig10: percent of _population_ who have immigrated within the last 10 years (numeric - decimal)  -- PctSpeakEnglOnly: percent of people who speak only English (numeric - decimal)  -- PctNotSpeakEnglWell: percent of people who do not speak English well (numeric - decimal)  -- PctLargHouseFam: percent of family households that are large (6 or more) (numeric - decimal)  -- PctLargHouseOccup: percent of all occupied households that are large (6 or more people) (numeric - decimal)  -- PersPerOccupHous: mean persons per household (numeric - decimal)  -- PersPerOwnOccHous: mean persons per owner occupied household (numeric - decimal)  -- PersPerRentOccHous: mean persons per rental household (numeric - decimal)  -- PctPersOwnOccup: percent of people in owner occupied households (numeric - decimal)  -- PctPersDenseHous: percent of persons in dense housing (more than 1 person per room) (numeric - decimal)  -- PctHousLess3BR: percent of housing units with less than 3 bedrooms (numeric - decimal)  -- MedNumBR: median number of bedrooms (numeric - decimal)  -- HousVacant: number of vacant households (numeric - decimal)  -- PctHousOccup: percent of housing occupied (numeric - decimal)  -- PctHousOwnOcc: percent of households owner occupied (numeric - decimal)  -- PctVacantBoarded: percent of vacant housing that is boarded up (numeric - decimal)  -- PctVacMore6Mos: percent of vacant housing that has been vacant more than 6 months (numeric - decimal)  -- MedYrHousBuilt: median year housing units built (numeric - decimal)  -- PctHousNoPhone: percent of occupied housing units without phone (in 1990, this was rare!) (numeric - decimal)  -- PctWOFullPlumb: percent of housing without complete plumbing facilities (numeric - decimal)  -- OwnOccLowQuart: owner occupied housing - lower quartile value (numeric - decimal)  -- OwnOccMedVal: owner occupied housing - median value (numeric - decimal)  -- OwnOccHiQuart: owner occupied housing - upper quartile value (numeric - decimal)  -- RentLowQ: rental housing - lower quartile rent (numeric - decimal)  -- RentMedian: rental housing - median rent (Census variable H32B from file STF1A) (numeric - decimal)  -- RentHighQ: rental housing - upper quartile rent (numeric - decimal)  -- MedRent: median gross rent (Census variable H43A from file STF3A - includes utilities) (numeric - decimal)  -- MedRentPctHousInc: median gross rent as a percentage of household income (numeric - decimal)  -- MedOwnCostPctInc: median owners cost as a percentage of household income - for owners with a mortgage (numeric - decimal)  -- MedOwnCostPctIncNoMtg: median owners cost as a percentage of household income - for owners without a mortgage (numeric - decimal)  -- NumInShelters: number of people in homeless shelters (numeric - decimal)  -- NumStreet: number of homeless people counted in the street (numeric - decimal)  -- PctForeignBorn: percent of people foreign born (numeric - decimal)  -- PctBornSameState: percent of people born in the same state as currently living (numeric - decimal)  -- PctSameHouse85: percent of people living in the same house as in 1985 (5 years before) (numeric - decimal)  -- PctSameCity85: percent of people living in the same city as in 1985 (5 years before) (numeric - decimal)  -- PctSameState85: percent of people living in the same state as in 1985 (5 years before) (numeric - decimal)  -- LemasSwornFT: number of sworn full time police officers (numeric - decimal)  -- LemasSwFTPerPop: sworn full time police officers per 100K population (numeric - decimal)  -- LemasSwFTFieldOps: number of sworn full time police officers in field operations (on the street as opposed to administrative etc) (numeric - decimal)  -- LemasSwFTFieldPerPop: sworn full time police officers in field operations (on the street as opposed to administrative etc) per 100K population (numeric - decimal)  -- LemasTotalReq: total requests for police (numeric - decimal)  -- LemasTotReqPerPop: total requests for police per 100K popuation (numeric - decimal)  -- PolicReqPerOffic: total requests for police per police officer (numeric - decimal)  -- PolicPerPop: police officers per 100K population (numeric - decimal)  -- RacialMatchCommPol: a measure of the racial match between the community and the police force. High values indicate proportions in community and police force are similar (numeric - decimal)  -- PctPolicWhite: percent of police that are caucasian (numeric - decimal)  -- PctPolicBlack: percent of police that are african american (numeric - decimal)  -- PctPolicHisp: percent of police that are hispanic (numeric - decimal)  -- PctPolicAsian: percent of police that are asian (numeric - decimal)  -- PctPolicMinor: percent of police that are minority of any kind (numeric - decimal)  -- OfficAssgnDrugUnits: number of officers assigned to special drug units (numeric - decimal)  -- NumKindsDrugsSeiz: number of different kinds of drugs seized (numeric - decimal)  -- PolicAveOTWorked: police average overtime worked (numeric - decimal)  -- LandArea: land area in square miles (numeric - decimal)  -- PopDens: population density in persons per square mile (numeric - decimal)  -- PctUsePubTrans: percent of people using public transit for commuting (numeric - decimal)  -- PolicCars: number of police cars (numeric - decimal)  -- PolicOperBudg: police operating budget (numeric - decimal)  -- LemasPctPolicOnPatr: percent of sworn full time police officers on patrol (numeric - decimal)  -- LemasGangUnitDeploy: gang unit deployed (numeric - decimal - but really ordinal - 0 means NO, 1 means YES,  0.5 means Part Time)  -- LemasPctOfficDrugUn: percent of officers assigned to drug units (numeric - decimal)  -- PolicBudgPerPop: police operating budget per population (numeric - decimal)  -- ViolentCrimesPerPop: total number of violent crimes per 100K popuation (numeric - decimal) GOAL attribute (to be predicted)Summary Statistics:			Min	Max	 Mean	 SD	Correl	Median	 Mode	Missingpopulation		0	1	 0.06	 0.13	 0.37	 0.02	 0.01	0householdsize		0	1	 0.46	 0.16	-0.03	 0.44	 0.41	0racepctblack		0	1	 0.18	 0.25	 0.63	 0.06	 0.01	0racePctWhite		0	1	 0.75	 0.24	-0.68	 0.85	 0.98	0racePctAsian		0	1	 0.15	 0.21	 0.04	 0.07	 0.02	0racePctHisp		0	1	 0.14	 0.23	 0.29	 0.04	 0.01	0agePct12t21		0	1	 0.42	 0.16	 0.06	 0.4	 0.38	0agePct12t29		0	1	 0.49	 0.14	 0.15	 0.48	 0.49	0agePct16t24		0	1	 0.34	 0.17	 0.10	 0.29	 0.29	0agePct65up		0	1	 0.42	 0.18	 0.07	 0.42	 0.47	0numbUrban		0	1	 0.06	 0.13	 0.36	 0.03	 0	0pctUrban		0	1	 0.70	 0.44	 0.08	 1	 1	0medIncome		0	1	 0.36	 0.21	-0.42	 0.32	 0.23	0pctWWage		0	1	 0.56	 0.18	-0.31	 0.56	 0.58	0pctWFarmSelf		0	1	 0.29	 0.20	-0.15	 0.23	 0.16	0pctWInvInc		0	1	 0.50	 0.18	-0.58	 0.48	 0.41	0pctWSocSec		0	1	 0.47	 0.17	 0.12	 0.475	 0.56	0pctWPubAsst		0	1	 0.32	 0.22	 0.57	 0.26	 0.1	0pctWRetire		0	1	 0.48	 0.17	-0.10	 0.47	 0.44	0medFamInc		0	1	 0.38	 0.20	-0.44	 0.33	 0.25	0perCapInc		0	1	 0.35	 0.19	-0.35	 0.3	 0.23	0whitePerCap		0	1	 0.37	 0.19	-0.21	 0.32	 0.3	0blackPerCap		0	1	 0.29	 0.17	-0.28	 0.25	 0.18	0indianPerCap		0	1	 0.20	 0.16	-0.09	 0.17	 0	0AsianPerCap		0	1	 0.32	 0.20	-0.16	 0.28	 0.18	0OtherPerCap		0	1	 0.28	 0.19	-0.13	 0.25	 0	1HispPerCap		0	1	 0.39	 0.18	-0.24	 0.345	 0.3	0NumUnderPov		0	1	 0.06	 0.13	 0.45	 0.02	 0.01	0PctPopUnderPov		0	1	 0.30	 0.23	 0.52	 0.25	 0.08	0PctLess9thGrade		0	1	 0.32	 0.21	 0.41	 0.27	 0.19	0PctNotHSGrad		0	1	 0.38	 0.20	 0.48	 0.36	 0.39	0PctBSorMore		0	1	 0.36	 0.21	-0.31	 0.31	 0.18	0PctUnemployed		0	1	 0.36	 0.20	 0.50	 0.32	 0.24	0PctEmploy		0	1	 0.50	 0.17	-0.33	 0.51	 0.56	0PctEmplManu		0	1	 0.40	 0.20	-0.04	 0.37	 0.26	0PctEmplProfServ		0	1	 0.44	 0.18	-0.07	 0.41	 0.36	0PctOccupManu		0	1	 0.39	 0.20	 0.30	 0.37	 0.32	0PctOccupMgmtProf	0	1	 0.44	 0.19	-0.34	 0.4	 0.36	0MalePctDivorce		0	1	 0.46	 0.18	 0.53	 0.47	 0.56	0MalePctNevMarr		0	1	 0.43	 0.18	 0.30	 0.4	 0.38	0FemalePctDiv		0	1	 0.49	 0.18	 0.56	 0.5	 0.54	0TotalPctDiv		0	1	 0.49	 0.18	 0.55	 0.5	 0.57	0PersPerFam		0	1	 0.49	 0.15	 0.14	 0.47	 0.44	0PctFam2Par		0	1	 0.61	 0.20	-0.71	 0.63	 0.7	0PctKids2Par		0	1	 0.62	 0.21	-0.74	 0.64	 0.72	0PctYoungKids2Par	0	1	 0.66	 0.22	-0.67	 0.7	 0.91	0PctTeen2Par		0	1	 0.58	 0.19	-0.66	 0.61	 0.6	0PctWorkMomYoungKids	0	1	 0.50	 0.17	-0.02	 0.51	 0.51	0PctWorkMom		0	1	 0.53	 0.18	-0.15	 0.54	 0.57	0NumIlleg		0	1	 0.04	 0.11	 0.47	 0.01	 0	0PctIlleg		0	1	 0.25	 0.23	 0.74	 0.17	 0.09	0NumImmig		0	1	 0.03	 0.09	 0.29	 0.01	 0	0PctImmigRecent		0	1	 0.32	 0.22	 0.17	 0.29	 0	0PctImmigRec5		0	1	 0.36	 0.21	 0.22	 0.34	 0	0PctImmigRec8		0	1	 0.40	 0.20	 0.25	 0.39	 0.26	0PctImmigRec10		0	1	 0.43	 0.19	 0.29	 0.43	 0.43	0PctRecentImmig		0	1	 0.18	 0.24	 0.23	 0.09	 0.01	0PctRecImmig5		0	1	 0.18	 0.24	 0.25	 0.08	 0.02	0PctRecImmig8		0	1	 0.18	 0.24	 0.25	 0.09	 0.02	0PctRecImmig10		0	1	 0.18	 0.23	 0.26	 0.09	 0.02	0PctSpeakEnglOnly	0	1	 0.79	 0.23	-0.24	 0.87	 0.96	0PctNotSpeakEnglWell	0	1	 0.15	 0.22	 0.30	 0.06	 0.03	0PctLargHouseFam		0	1	 0.27	 0.20	 0.38	 0.2	 0.17	0PctLargHouseOccup	0	1	 0.25	 0.19	 0.29	 0.19	 0.19	0PersPerOccupHous	0	1	 0.46	 0.17	-0.04	 0.44	 0.37	0PersPerOwnOccHous	0	1	 0.49	 0.16	-0.12	 0.48	 0.45	0PersPerRentOccHous	0	1	 0.40	 0.19	 0.25	 0.36	 0.32	0PctPersOwnOccup		0	1	 0.56	 0.20	-0.53	 0.56	 0.54	0PctPersDenseHous	0	1	 0.19	 0.21	 0.45	 0.11	 0.06	0PctHousLess3BR		0	1	 0.50	 0.17	 0.47	 0.51	 0.53	0MedNumBR		0	1	 0.31	 0.26	-0.36	 0.5	 0.5	0HousVacant		0	1	 0.08	 0.15	 0.42	 0.03	 0.01	0PctHousOccup		0	1	 0.72	 0.19	-0.32	 0.77	 0.88	0PctHousOwnOcc		0	1	 0.55	 0.19	-0.47	 0.54	 0.52	0PctVacantBoarded	0	1	 0.20	 0.22	 0.48	 0.13	 0	0PctVacMore6Mos		0	1	 0.43	 0.19	 0.02	 0.42	 0.44	0MedYrHousBuilt		0	1	 0.49	 0.23	-0.11	 0.52	 0	0PctHousNoPhone		0	1	 0.26	 0.24	 0.49	 0.185	 0.01	0PctWOFullPlumb		0	1	 0.24	 0.21	 0.36	 0.19	 0	0OwnOccLowQuart		0	1	 0.26	 0.22	-0.21	 0.18	 0.09	0OwnOccMedVal		0	1	 0.26	 0.23	-0.19	 0.17	 0.08	0OwnOccHiQuart		0	1	 0.27	 0.24	-0.17	 0.18	 0.08	0RentLowQ		0	1	 0.35	 0.22	-0.25	 0.31	 0.13	0RentMedian		0	1	 0.37	 0.21	-0.24	 0.33	 0.19	0RentHighQ		0	1	 0.42	 0.25	-0.23	 0.37	 1	0MedRent			0	1	 0.38	 0.21	-0.24	 0.34	 0.17	0MedRentPctHousInc	0	1	 0.49	 0.17	 0.33	 0.48	 0.4	0MedOwnCostPctInc	0	1	 0.45	 0.19	 0.06	 0.45	 0.41	0MedOwnCostPctIncNoMtg	0	1	 0.40	 0.19	 0.05	 0.37	 0.24	0NumInShelters		0	1	 0.03	 0.10	 0.38	 0	 0	0NumStreet		0	1	 0.02	 0.10	 0.34	 0	 0	0PctForeignBorn		0	1	 0.22	 0.23	 0.19	 0.13	 0.03	0PctBornSameState	0	1	 0.61	 0.20	-0.08	 0.63	 0.78	0PctSameHouse85		0	1	 0.54	 0.18	-0.16	 0.54	 0.59	0PctSameCity85		0	1	 0.63	 0.20	 0.08	 0.67	 0.74	0PctSameState85		0	1	 0.65	 0.20	-0.02	 0.7	 0.79	0LemasSwornFT		0	1	 0.07	 0.14	 0.34	 0.02	 0.02	1675LemasSwFTPerPop		0	1	 0.22	 0.16	 0.15	 0.18	 0.2	1675LemasSwFTFieldOps	0	1	 0.92	 0.13	-0.33	 0.97	 0.98	1675LemasSwFTFieldPerPop	0	1	 0.25	 0.16	 0.16	 0.21	 0.19	1675LemasTotalReq		0	1	 0.10	 0.16	 0.35	 0.04	 0.02	1675LemasTotReqPerPop	0	1	 0.22	 0.16	 0.27	 0.17	 0.14	1675PolicReqPerOffic	0	1	 0.34	 0.20	 0.17	 0.29	 0.23	1675PolicPerPop		0	1	 0.22	 0.16	 0.15	 0.18	 0.2	1675RacialMatchCommPol	0	1	 0.69	 0.23	-0.46	 0.74	 0.78	1675PctPolicWhite		0	1	 0.73	 0.22	-0.44	 0.78	 0.72	1675PctPolicBlack		0	1	 0.22	 0.24	 0.54	 0.12	 0	1675PctPolicHisp		0	1	 0.13	 0.20	 0.12	 0.06	 0	1675PctPolicAsian		0	1	 0.11	 0.23	 0.10	 0	 0	1675PctPolicMinor		0	1	 0.26	 0.23	 0.49	 0.2	 0.07	1675OfficAssgnDrugUnits	0	1	 0.08	 0.12	 0.34	 0.04	 0.03	1675NumKindsDrugsSeiz	0	1	 0.56	 0.20	 0.13	 0.57	 0.57	1675PolicAveOTWorked	0	1	 0.31	 0.23	 0.03	 0.26	 0.19	1675LandArea		0	1	 0.07	 0.11	 0.20	 0.04	 0.01	0PopDens			0	1	 0.23	 0.20	 0.28	 0.17	 0.09	0PctUsePubTrans		0	1	 0.16	 0.23	 0.15	 0.07	 0.01	0PolicCars		0	1	 0.16	 0.21	 0.38	 0.08	 0.02	1675PolicOperBudg		0	1	 0.08	 0.14	 0.34	 0.03	 0.02	1675LemasPctPolicOnPatr	0	1	 0.70	 0.21	-0.08	 0.75	 0.74	1675LemasGangUnitDeploy	0	1	 0.44	 0.41	 0.12	 0.5	 0	1675LemasPctOfficDrugUn	0	1	 0.09	 0.24	 0.35	 0	 0	0PolicBudgPerPop		0	1	 0.20	 0.16	 0.10	 0.15	 0.12	1675ViolentCrimesPerPop	0	1	 0.24	 0.23	 1.00	 0.15	 0.03	0Distribution of the Goal Variable (Violent Crimes per Population):   Range	Frequency0.000-0.067	4840.067-0.133	4200.133-0.200	2840.200-0.267	1770.267-0.333	1420.333-0.400	1130.400-0.467	 590.467-0.533	 760.533-0.600	 570.600-0.667	 380.667-0.733	 370.733-0.800	 200.800-0.867	 230.867-0.933	 140.933-1.000	 50"
Twitter Data set for Arabic Sentiment Analysis,Twitter Data set for Arabic Sentiment Analysis,This problem of Sentiment Analysis (SA) has been studied well on the English language but not Arabic one. Two main approaches have been devised: corpus-based and lexicon-based. ,Twitter+Data+set+for+Arabic+Sentiment+Analysis,https://archive.ics.uci.edu/ml//machine-learning-databases/00293/,https://archive.ics.uci.edu/ml/datasets/Twitter+Data+set+for+Arabic+Sentiment+Analysis," --- By using a tweet crawler, we collect 2000 labelled tweets (1000 positive tweets and 1000 negative ones)       on various topics such as: politics and arts. These tweets include opinions written in both       Modern Standard Arabic (MSA) and the Jordanian dialect.   --- The selected tweets convey some kind of feelings (positive or negative) and the objective of our model is        to extract valuable information from such tweets in order to determine the sentiment orientation of the inputted text.       The months-long annotation process of the tweets is manually conducted mainly by two human experts       (native speakers of Arabic). If both experts agree on the label of a certain tweet, then the tweet is assigned this label.       Otherwise, a third expert is consulted to break the tie.    --- Predicted attribute: class of opinion polarity.",Social,1. Tweet as a string vector   2. class:       -- Positive polarity      -- Negative poalritySummary Statistics:	 			        Positive	Negative          	Total tweets		        1000	        1000	Total words		        7189	        9769	Avg. words in each tweet        7.19	        9.97	Avg. characters in each tweet	40.04	        59.02,"This problem of Sentiment Analysis (SA) has been studied well on the English language but not Arabic one. Two main approaches have been devised: corpus-based and lexicon-based.  --- By using a tweet crawler, we collect 2000 labelled tweets (1000 positive tweets and 1000 negative ones)       on various topics such as: politics and arts. These tweets include opinions written in both       Modern Standard Arabic (MSA) and the Jordanian dialect.   --- The selected tweets convey some kind of feelings (positive or negative) and the objective of our model is        to extract valuable information from such tweets in order to determine the sentiment orientation of the inputted text.       The months-long annotation process of the tweets is manually conducted mainly by two human experts       (native speakers of Arabic). If both experts agree on the label of a certain tweet, then the tweet is assigned this label.       Otherwise, a third expert is consulted to break the tie.    --- Predicted attribute: class of opinion polarity.1. Tweet as a string vector   2. class:       -- Positive polarity      -- Negative poalritySummary Statistics:	 			        Positive	Negative          	Total tweets		        1000	        1000	Total words		        7189	        9769	Avg. words in each tweet        7.19	        9.97	Avg. characters in each tweet	40.04	        59.02"
Communities and Crime Unnormalized,Communities and Crime Unnormalized,"Communities in the US. Data combines socio-economic data from the '90 Census, law enforcement data from the 1990 Law Enforcement Management and Admin Stats survey, and crime data from the 1995 FBI UCR",Communities+and+Crime+Unnormalized,https://archive.ics.uci.edu/ml//machine-learning-databases/00211/,https://archive.ics.uci.edu/ml/datasets/Communities+and+Crime+Unnormalized,"The source datasets needed to be combined via programming. Many variables are included so that algorithms that select or learn weights for attributes could be tested. However, clearly unrelated attributes were not included; attributes were picked if there was any plausible connection to crime (N=125), plus the crime variables which are potential dependent variables. The variables included in the dataset involve the community, such as the percent of the population considered urban, and the median family income, and involving law enforcement, such as per capita number of police officers, and percent of officers assigned to drug units. The crime attributes (N=18) that could be predicted are the 8 crimes considered 'Index Crimes' by the FBI)(Murders, Rape, Robbery, .... ), per capita (actually per 100,000 population) versions of each, and Per Capita Violent Crimes and Per Capita Nonviolent Crimes).   A limitation was that the LEMAS survey was of the police departments with at least 100 officers, plus a random sample of smaller departments. For our purposes, communities not found in both census and crime datasets were omitted. Many communities are missing LEMAS data.The per capita crimes variables were calculated using population values included in the 1995 FBI data (which differ from the 1990 Census values). The per capita violent crimes variable was calculated using population and the sum of crime variables considered violent crimes in the United States: murder, rape, robbery, and assault. There was apparently some controversy in some states concerning the counting of rapes. These resulted in missing values for rape, which resulted in missing values for per capita violent crime. Many of these omitted communities were from the midwestern USA (Minnesota, Illinois, and Michigan have many of these).    The per capita nonviolent crime variable was calculated using the sum of crime variables considered non-violent crimes in the United States: burglaries, larcenies, auto thefts and arsons. (There are many other types of crimes, these only include FBI 'Index Crimes')Some further pre-processing of the dataset must be done. Choose the desirable dependent variable from among the 18 possible. It would not be interesting or appropriate to predict total crime (e.g. violent crime) while including subtotals (e.g. murders) as independent variables. There are also identifying variables (community name, county code, community code) that are not predictive, and would get in the way of some algorithms. Weka's Unsupervised Attribute Remove Filter can be used to remove unwanted attributes.The FBI notes that use of this data to evaluate communities is over-simplistic, as many relevant factors are not included. For one example, communities with large numbers of visitors will have higher per capita crime (measured by residents) than communities with fewer visitors, other things being equal.  ",Social,"(125 predictive, 4 non-predictive, 18 potential goal)  -- communityname: Community name - not predictive - for information only (string)  -- state: US state (by 2 letter postal abbreviation)(nominal)   -- countyCode: numeric code for county - not predictive, and many missing values (numeric)  -- communityCode: numeric code for community - not predictive and many missing values (numeric)   -- fold: fold number for non-random 10 fold cross validation, potentially useful for debugging, paired tests - not predictive (numeric - integer)   -- population: population for community: (numeric - expected to be integer)  -- householdsize: mean people per household (numeric - decimal)  -- racepctblack: percentage of population that is african american (numeric - decimal)  -- racePctWhite: percentage of population that is caucasian (numeric - decimal)  -- racePctAsian: percentage of population that is of asian heritage (numeric - decimal)  -- racePctHisp: percentage of population that is of hispanic heritage (numeric - decimal)  -- agePct12t21: percentage of population that is 12-21 in age (numeric - decimal)  -- agePct12t29: percentage of population that is 12-29 in age (numeric - decimal)  -- agePct16t24: percentage of population that is 16-24 in age (numeric - decimal)  -- agePct65up: percentage of population that is 65 and over in age (numeric - decimal)  -- numbUrban: number of people living in areas classified as urban (numeric - expected to be integer)  -- pctUrban: percentage of people living in areas classified as urban (numeric - decimal)  -- medIncome: median household income (numeric - may be integer)  -- pctWWage: percentage of households with wage or salary income in 1989 (numeric - decimal)  -- pctWFarmSelf: percentage of households with farm or self employment income in 1989 (numeric - decimal)  -- pctWInvInc: percentage of households with investment / rent income in 1989 (numeric - decimal)  -- pctWSocSec: percentage of households with social security income in 1989 (numeric - decimal)  -- pctWPubAsst: percentage of households with public assistance income in 1989 (numeric - decimal)  -- pctWRetire: percentage of households with retirement income in 1989 (numeric - decimal)  -- medFamInc: median family income (differs from household income for non-family households) (numeric - may be integer)  -- perCapInc: per capita income (numeric - decimal)  -- whitePerCap: per capita income for caucasians (numeric - decimal)  -- blackPerCap: per capita income for african americans (numeric - decimal)  -- indianPerCap: per capita income for native americans (numeric - decimal)  -- AsianPerCap: per capita income for people with asian heritage (numeric - decimal)  -- OtherPerCap: per capita income for people with 'other' heritage (numeric - decimal)  -- HispPerCap: per capita income for people with hispanic heritage (numeric - decimal)  -- NumUnderPov: number of people under the poverty level (numeric - expected to be integer)  -- PctPopUnderPov: percentage of people under the poverty level (numeric - decimal)  -- PctLess9thGrade: percentage of people 25 and over with less than a 9th grade education (numeric - decimal)  -- PctNotHSGrad: percentage of people 25 and over that are not high school graduates (numeric - decimal)  -- PctBSorMore: percentage of people 25 and over with a bachelors degree or higher education (numeric - decimal)  -- PctUnemployed: percentage of people 16 and over, in the labor force, and unemployed (numeric - decimal)  -- PctEmploy: percentage of people 16 and over who are employed (numeric - decimal)  -- PctEmplManu: percentage of people 16 and over who are employed in manufacturing (numeric - decimal)  -- PctEmplProfServ: percentage of people 16 and over who are employed in professional services (numeric - decimal)  -- PctOccupManu: percentage of people 16 and over who are employed in manufacturing (numeric - decimal)   #### No longer sure of difference from PctEmplManu - may include unemployed manufacturing workers ####  -- PctOccupMgmtProf: percentage of people 16 and over who are employed in management or professional occupations (numeric - decimal)  -- MalePctDivorce: percentage of males who are divorced (numeric - decimal)  -- MalePctNevMarr: percentage of males who have never married (numeric - decimal)  -- FemalePctDiv: percentage of females who are divorced (numeric - decimal)  -- TotalPctDiv: percentage of population who are divorced (numeric - decimal)  -- PersPerFam: mean number of people per family (numeric - decimal)  -- PctFam2Par: percentage of families (with kids) that are headed by two parents (numeric - decimal)  -- PctKids2Par: percentage of kids in family housing with two parents (numeric - decimal)  -- PctYoungKids2Par: percent of kids 4 and under in two parent households (numeric - decimal)  -- PctTeen2Par: percent of kids age 12-17 in two parent households (numeric - decimal)  -- PctWorkMomYoungKids: percentage of moms of kids 6 and under in labor force (numeric - decimal)  -- PctWorkMom: percentage of moms of kids under 18 in labor force (numeric - decimal)  -- NumKidsBornNeverMar: number of kids born to never married (numeric - expected to be integer)  -- PctKidsBornNeverMar: percentage of kids born to never married (numeric - decimal)  -- NumImmig: total number of people known to be foreign born (numeric - expected to be integer)  -- PctImmigRecent: percentage of _immigrants_ who immigated within last 3 years (numeric - decimal)  -- PctImmigRec5: percentage of _immigrants_ who immigated within last 5 years (numeric - decimal)  -- PctImmigRec8: percentage of _immigrants_ who immigated within last 8 years (numeric - decimal)  -- PctImmigRec10: percentage of _immigrants_ who immigated within last 10 years (numeric - decimal)  -- PctRecentImmig: percent of _population_ who have immigrated within the last 3 years (numeric - decimal)  -- PctRecImmig5: percent of _population_ who have immigrated within the last 5 years (numeric - decimal)  -- PctRecImmig8: percent of _population_ who have immigrated within the last 8 years (numeric - decimal)  -- PctRecImmig10: percent of _population_ who have immigrated within the last 10 years (numeric - decimal)  -- PctSpeakEnglOnly: percent of people who speak only English (numeric - decimal)  -- PctNotSpeakEnglWell: percent of people who do not speak English well (numeric - decimal)  -- PctLargHouseFam: percent of family households that are large (6 or more) (numeric - decimal)  -- PctLargHouseOccup: percent of all occupied households that are large (6 or more people) (numeric - decimal)  -- PersPerOccupHous: mean persons per household (numeric - decimal)  -- PersPerOwnOccHous: mean persons per owner occupied household (numeric - decimal)  -- PersPerRentOccHous: mean persons per rental household (numeric - decimal)  -- PctPersOwnOccup: percent of people in owner occupied households (numeric - decimal)  -- PctPersDenseHous: percent of persons in dense housing (more than 1 person per room) (numeric - decimal)  -- PctHousLess3BR: percent of housing units with less than 3 bedrooms (numeric - decimal)  -- MedNumBR: median number of bedrooms (numeric - decimal)  -- HousVacant: number of vacant households (numeric - expected to be integer)  -- PctHousOccup: percent of housing occupied (numeric - decimal)  -- PctHousOwnOcc: percent of households owner occupied (numeric - decimal)  -- PctVacantBoarded: percent of vacant housing that is boarded up (numeric - decimal)  -- PctVacMore6Mos: percent of vacant housing that has been vacant more than 6 months (numeric - decimal)  -- MedYrHousBuilt: median year housing units built (numeric - may be integer)  -- PctHousNoPhone: percent of occupied housing units without phone (in 1990, this was rare!) (numeric - decimal)  -- PctWOFullPlumb: percent of housing without complete plumbing facilities (numeric - decimal)  -- OwnOccLowQuart: owner occupied housing - lower quartile value (numeric - decimal)  -- OwnOccMedVal: owner occupied housing - median value (numeric - decimal)  -- OwnOccHiQuart: owner occupied housing - upper quartile value (numeric - decimal)  -- OwnOccQrange: owner occupied housing - difference between upper quartile and lower quartile values (numeric - decimal)  -- RentLowQ: rental housing - lower quartile rent (numeric - decimal)  -- RentMedian: rental housing - median rent (Census variable H32B from file STF1A) (numeric - decimal)  -- RentHighQ: rental housing - upper quartile rent (numeric - decimal)  -- RentQrange: rental housing - difference between upper quartile and lower quartile rent (numeric - decimal)  -- MedRent: median gross rent (Census variable H43A from file STF3A - includes utilities) (numeric - decimal)  -- MedRentPctHousInc: median gross rent as a percentage of household income (numeric - decimal)  -- MedOwnCostPctInc: median owners cost as a percentage of household income - for owners with a mortgage (numeric - decimal)  -- MedOwnCostPctIncNoMtg: median owners cost as a percentage of household income - for owners without a mortgage (numeric - decimal)  -- NumInShelters: number of people in homeless shelters (numeric - expected to be integer)  -- NumStreet: number of homeless people counted in the street (numeric - expected to be integer)  -- PctForeignBorn: percent of people foreign born (numeric - decimal)  -- PctBornSameState: percent of people born in the same state as currently living (numeric - decimal)  -- PctSameHouse85: percent of people living in the same house as in 1985 (5 years before) (numeric - decimal)  -- PctSameCity85: percent of people living in the same city as in 1985 (5 years before) (numeric - decimal)  -- PctSameState85: percent of people living in the same state as in 1985 (5 years before) (numeric - decimal)  -- LemasSwornFT: number of sworn full time police officers (numeric - expected to be integer)  -- LemasSwFTPerPop: sworn full time police officers per 100K population (numeric - decimal)  -- LemasSwFTFieldOps: number of sworn full time police officers in field operations (on the street as opposed to administrative etc) (numeric - expected to be integer)  -- LemasSwFTFieldPerPop: sworn full time police officers in field operations (on the street as opposed to administrative etc) per 100K population (numeric - decimal)  -- LemasTotalReq: total requests for police (numeric - expected to be integer)  -- LemasTotReqPerPop: total requests for police per 100K popuation (numeric - decimal)  -- PolicReqPerOffic: total requests for police per police officer (numeric - decimal)  -- PolicPerPop: police officers per 100K population (numeric - decimal)  -- RacialMatchCommPol: a measure of the racial match between the community and the police force. High values indicate proportions in community and police force are similar (numeric - decimal)  -- PctPolicWhite: percent of police that are caucasian (numeric - decimal)  -- PctPolicBlack: percent of police that are african american (numeric - decimal)  -- PctPolicHisp: percent of police that are hispanic (numeric - decimal)  -- PctPolicAsian: percent of police that are asian (numeric - decimal)  -- PctPolicMinor: percent of police that are minority of any kind (numeric - decimal)  -- OfficAssgnDrugUnits: number of officers assigned to special drug units (numeric - expected to be integer)  -- NumKindsDrugsSeiz: number of different kinds of drugs seized (numeric - expected to be integer)  -- PolicAveOTWorked: police average overtime worked (numeric - decimal)  -- LandArea: land area in square miles (numeric - decimal)  -- PopDens: population density in persons per square mile (numeric - decimal)  -- PctUsePubTrans: percent of people using public transit for commuting (numeric - decimal)  -- PolicCars: number of police cars (numeric - expected to be integer)  -- PolicOperBudg: police operating budget (numeric - may be integer)  -- LemasPctPolicOnPatr: percent of sworn full time police officers on patrol (numeric - decimal)  -- LemasGangUnitDeploy: gang unit deployed (numeric - integer - but really nominal - 0 means NO, 10 means YES,  5 means Part Time)  -- LemasPctOfficDrugUn: percent of officers assigned to drug units (numeric - decimal)  -- PolicBudgPerPop: police operating budget per population (numeric - decimal)  -- murders: number of murders in 1995 (numeric - expected to be integer) potential GOAL attribute (to be predicted)  -- murdPerPop: number of murders per 100K population (numeric - decimal) potential GOAL attribute (to be predicted)  -- rapes: number of rapes in 1995 (numeric - expected to be integer) potential GOAL attribute (to be predicted)  -- rapesPerPop: number of rapes per 100K population  (numeric - decimal) potential GOAL attribute (to be predicted)  -- robberies: number of robberies in 1995  (numeric - expected to be integer) potential GOAL attribute (to be predicted)  -- robbbPerPop: number of robberies per 100K population  (numeric - decimal) potential GOAL attribute (to be predicted)  -- assaults: number of assaults in 1995  (numeric - expected to be integer) potential GOAL attribute (to be predicted)  -- assaultPerPop: number of assaults per 100K population  (numeric - decimal) potential GOAL attribute (to be predicted)  -- burglaries: number of burglaries in 1995  (numeric - expected to be integer) potential GOAL attribute (to be predicted)  -- burglPerPop: number of burglaries per 100K population  (numeric - decimal) potential GOAL attribute (to be predicted)  -- larcenies: number of larcenies in 1995  (numeric - expected to be integer) potential GOAL attribute (to be predicted)  -- larcPerPop: number of larcenies per 100K population  (numeric - decimal) potential GOAL attribute (to be predicted)  -- autoTheft: number of auto thefts in 1995  (numeric - expected to be integer) potential GOAL attribute (to be predicted)  -- autoTheftPerPop: number of auto thefts per 100K population  (numeric - decimal) potential GOAL attribute (to be predicted)  -- arsons: number of arsons in 1995  (numeric - expected to be integer) potential GOAL attribute (to be predicted)  -- arsonsPerPop: number of arsons per 100K population  (numeric - decimal) potential GOAL attribute (to be predicted)  -- ViolentCrimesPerPop: total number of violent crimes per 100K popuation (numeric - decimal) GOAL attribute (to be predicted)  -- nonViolPerPop: total number of non-violent crimes per 100K popuation (numeric - decimal) potential GOAL attribute (to be predicted)Summary Statistics:variable,Minimum,Maximum,Mean,Standard Deviation,Correlation w/ ViolPerPop,Median,Mode,Missingpop,10005,7322564,53117.9842,204620.2529,0.212353809,22792,12361,0perHoush,1.6,5.28,2.707327314,0.334119654,-0.020110177,2.66,2.6,0pctBlack,0,96.67,9.33510158,14.2471563,0.628367756,2.87,0.24,0pctWhite,2.68,99.63,83.97981941,16.41908022,-0.676848823,90.35,98.04,0pctAsian,0.03,57.46,2.67020316,4.473843444,0.031949477,1.23,0.41,0pctHisp,0.12,95.29,7.950176072,14.58983204,0.253596415,2.18,0.78,0pct12-21,4.58,54.4,14.44583747,4.518622844,0.023535103,13.62,13.62,0pct12-29,9.38,70.51,27.64483973,6.181517075,0.105908765,26.78,26.78,0pct16-24,4.64,63.62,13.97514221,5.970746729,0.045251915,12.54,11.61,0pct65up,1.66,52.77,11.83639278,4.777565216,0.055637064,11.73,11.06,0persUrban,0,7322564,47734.72009,205606.6933,0.21384036,18041,0,0pctUrban,0,100,70.46530926,44.08027532,0.086294263,100,100,0medIncome,8866,123625,33984.69616,13424.68001,-0.397407452,31441,27095,0pctWwage,31.68,96.76,78.31275847,7.950672435,-0.289829747,78.61,85.12,0pctWfarm,0,6.53,0.881841986,0.689005635,-0.148357317,0.69,0.54,0pctWdiv,5.81,89.04,43.75093454,12.78792465,-0.557786505,42.88,41.65,0pctWsocsec,4.81,76.39,26.40941761,8.295604161,0.107881101,26.59,21.51,0pctPubAsst,0.18,44.82,6.801444695,4.700334848,0.563107116,5.61,2.27,0pctRetire,3.46,45.51,15.96900226,4.622553011,-0.098964807,15.65,13.14,0medFamIncome,10447,139008,39857.05508,14251.20603,-0.411864109,36678,30546,0perCapInc,5237,63302,15603.5246,6281.558523,-0.315255977,14101,11252,0whitePerCap,5472,68850,16567.69842,6346.840251,-0.185898177,15073,12735,0blackPerCap,0,212120,11541.74944,9232.102062,-0.209243037,9777,0,0NAperCap,0,480000,12229.19142,14853.83618,-0.060250637,9895,0,0asianPerCap,0,106165,14227.98962,9881.266395,-0.128086386,12250,0,0otherPerCap,0,137000,9442.765131,7926.466713,-0.103288444,8186,0,1hispPerCap,0,54648,11018.99819,5884.063446,-0.219349786,9721,0,0persPoverty,78,1384994,7590.853273,39361.46001,0.240253072,2142,470,0pctPoverty,0.64,58,11.62053725,8.600352277,0.505349223,9.33,3.26,0pctLowEdu,0.2,49.89,9.186645598,6.66670296,0.371421768,7.74,5.78,0pctNotHSgrad,1.46,73.66,22.30511964,10.98951654,0.46759552,21.38,11.27,0pctCollGrad,1.63,79.18,23.05687585,12.68721342,-0.299897539,19.65,14.2,0pctUnemploy,1.32,31.23,6.045241535,2.89561824,0.483440771,5.45,4.36,0pctEmploy,24.82,84.67,62.02161174,8.31204498,-0.31764382,62.44,62.6,0pctEmployMfg,2.05,50.03,18.22890745,8.099280979,-0.04712343,17.3,25.38,0pctEmployProfServ,8.69,62.67,24.53229797,6.659470242,-0.064554813,23.39,21.52,0pctOccupManu,1.37,44.27,13.81916479,6.430263859,0.283898507,13.15,16.52,0pctOccupMgmt,6.48,64.97,28.2092009,9.326123364,-0.324430512,26.24,28.31,0pctMaleDivorc,2.13,20.08,9.12758465,2.802747328,0.510455756,9.15,10.82,0pctMaleNevMar,12.06,76.6,30.68351693,8.127990901,0.271229742,29,26.78,0pctFemDivorc,3.35,23.92,12.32530023,3.262612867,0.537302801,12.52,14.36,0pctAllDivorc,2.83,22.23,10.81251467,3.000883481,0.536548564,10.9,11.77,0persPerFam,2.29,4.64,3.129697517,0.240742507,0.149955382,3.1,3.13,0pct2Par,22.97,93.6,74.05912867,10.52595184,-0.698640874,75.03,72.16,0pctKids2Par,18.3,92.58,71.22725508,12.04504833,-0.728058986,72.53,63.25,0pctKids-4w2Par,8.7,100,81.86542212,12.26373565,-0.658436367,83.99,100,0pct12-17w2Par,20.2,97.34,75.52178781,10.36526212,-0.655627787,76.92,77.49,0pctWorkMom-6,24.42,87.97,60.54264108,8.008936744,-0.02162507,60.71,63.48,0pctWorkMom-18,41.95,89.37,68.85479458,6.679959744,-0.146173218,69.23,65.64,0kidsBornNevrMarr,0,527557,2141.418962,14692.58284,0.240337327,352,139,0pctKidsBornNevrMarr,0,27.35,3.115498871,3.127681493,0.738089083,2.04,0.97,0numForeignBorn,20,2082931,6277.273589,55419.65383,0.144585649,1024,147,0pctFgnImmig-3,0,64.29,13.525693,9.780097693,0.156688654,12.26,0,0pctFgnImmig-5,0,76.16,20.42128668,12.41035515,0.201445794,19.08,0,0pctFgnImmig-8,0,80.81,27.54418059,14.36881288,0.236607959,26.72,0,0pctFgnImmig-10,0,88,34.73392777,16.32732237,0.281536984,34.79,0,0pctImmig-3,0,13.71,1.099124153,1.595766262,0.215616823,0.5,0,0pctImmig-5,0,19.93,1.697462754,2.46105956,0.232900674,0.75,0,0pctImmig-8,0,25.34,2.307503386,3.286647928,0.23889175,1.04,0,0pctImmig-10,0,32.63,2.943760722,4.246468259,0.250865298,1.31,0,0pctSpeakOnlyEng,6.15,98.98,87.07499323,14.07608745,-0.219031839,92.18,93.57,0pctNotSpeakEng,0,38.33,2.405792325,4.210367661,0.27243614,0.92,0.44,0pctLargHousFam,0.96,34.87,5.38661851,3.794309411,0.341601121,4.28,3.71,0pctLargHous,0.44,30.87,3.91578781,3.175770454,0.257215583,3.05,2.98,0persPerOccupHous,1.58,4.52,2.615841986,0.315646341,-0.017700909,2.57,2.44,0persPerOwnOccup,1.61,4.48,2.74048307,0.297420849,-0.099169625,2.71,2.65,0persPerRenterOccup,1.55,4.73,2.367137698,0.391805778,0.240564095,2.29,2.17,0pctPersOwnOccup,13.93,97.24,66.36945372,14.18258845,-0.507329566,65.91,63.79,0pctPopDenseHous,0.05,59.49,4.132437923,5.599131346,0.395855647,2.34,1.31,0pctSmallHousUnits,3.06,95.34,45.40534086,13.77834736,0.454469731,46.39,53.15,0medNumBedrm,1,4,2.640632054,0.512686001,-0.347149961,3,3,0houseVacant,36,172768,1748.368849,6503.866478,0.289690649,558,246,0pctHousOccup,37.47,99,92.93397291,5.04073584,-0.256836226,94.21,95.38,0pctHousOwnerOccup,16.86,96.49,63.36829797,13.9700567,-0.45535904,62.83,56.17,0pctVacantBoarded,0,39.89,2.778523702,3.592396207,0.479910148,1.66,0,0pctVacant6up,3.12,82.13,34.77388713,13.91146771,0.030768767,34.1,37.5,0medYrHousBuilt,1939,1987,1962.623476,11.16655501,-0.111201128,1964,1939,0pctHousWOphone,0,23.88,4.289823928,4.088174777,0.473717673,2.85,0,0pctHousWOplumb,0,5.33,0.425273138,0.426188232,0.311226836,0.32,0,0ownHousLowQ,14999,500001,88695.80226,66670.78153,-0.194912005,65500,34000,0ownHousMed,19500,500001,113097.5233,81906.36228,-0.17822542,82800,500001,0ownHousUperQ,28200,500001,145318.2578,99030.91382,-0.166029142,106700,500001,0ownHousQrange,0,331000,56622.45553,39106.49804,-0.086578248,43400,28100,0rentLowQ,99,1001,329.9665914,144.1384609,-0.245708342,307,252,0rentMed,120,1001,428.537246,170.7066437,-0.232797807,397,316,0rentUpperQ,182,1001,527.2528217,199.29078,-0.223893683,486,1001,0rentQrange ,0,803,197.2862302,85.20568803,-0.110281171,171,139,0medGrossRent,192,1001,501.4663657,169.2717347,-0.231754244,467,1001,0medRentpctHousInc,14.9,35.1,26.29810384,2.979297132,0.315536838,26.1,24.7,0medOwnCostpct,14,32.7,20.99015801,2.987621666,0.061058949,21,22.6,0medOwnCostPctWO,10.1,23.4,13.01020316,1.419678674,0.063296009,12.8,11.8,0persEmergShelt,0,23383,66.95349887,564.253149,0.19494198,0,0,0persHomeless,0,10447,17.8234763,245.4525529,0.136446046,0,0,0pctForeignBorn,0.18,60.4,7.340302483,8.418475989,0.193229615,4.31,2.97,0pctBornStateResid,6.75,93.14,61.5396298,16.75006116,-0.070943862,64.49,74.45,0pctSameHouse-5,11.83,78.56,51.53859594,10.51792598,-0.14008735,52.17,54.85,0pctSameCounty-5,27.95,96.59,77.41107901,10.87818569,0.082634597,79.49,81.47,0pctSameState-5,32.83,99.9,88.11186456,7.287836465,-0.006663834,90.03,92.69,0numPolice,65,25655,499.1982507,1681.472251,0.194219827,173,100,1872policePerPop,29.4,3437.23,246.4909621,273.7991617,0.073197363,196.01,#N/A,1872policeField,14,22496,432.5597668,1493.708385,0.186477279,152,94,1872policeFieldPerPop,19.21,3290.62,210.8447813,235.4788145,0.065928304,170.27,183.22,1872policeCalls,2100,8328470,252404.9883,689449.7817,0.230023206,90000,50000,1872policCallPerPop,2704.8,1926281.5,120651.7189,148211.3422,0.14854896,91034.6,#N/A,1872policCallPerOffic,20.8,2162.5,523.658309,307.8390067,0.145798061,443.2,422.6,1872policePerPop2,29.4,3437.2,246.493586,273.7984086,0.073203166,196,171.5,1872racialMatch,42.15,100,85.4996793,10.94131216,-0.469374164,87.93,100,1872pctPolicWhite,1.6,100,82.5158309,15.33261214,-0.392584252,86.18,100,1872pctPolicBlack,0,67.31,9.263294461,11.02142376,0.513568853,5,0,1872pctPolicHisp,0,98.4,5.459766764,10.60453332,0.056080974,2.04,0,1872pctPolicAsian,0,18.57,0.681282799,1.706344058,0.072778715,0,0,1872pctPolicMinority,0,98.4,15.2422449,14.82675626,0.416418453,11.37,0,1872officDrugUnits,0,1773,26.28862974,100.8219209,0.166934688,12,6,1872numDiffDrugsSeiz,1,15,8.816326531,2.836390802,0.115940631,9,9,1872policAveOT,0,634.7,119.1142857,92.49518559,0.010162351,98.7,0,1872landArea,0.9,3569.8,27.41995485,109.8226001,0.075697852,13.7,4.9,0popDensity,10,44229.9,2783.835034,2828.993341,0.256966815,2027.3,3217.7,0pctUsePubTrans,0,54.33,3.041124153,4.91291686,0.190478991,1.22,0,0policCarsAvail,20,3187,185.4781341,318.5428335,0.313164478,86,55,1872policOperBudget,2380215,1617293056,32176019.34,110456627.5,0.195267289,11164110,8000000,1872pctPolicPatrol,10.85,99.94,87.13093294,10.34961235,-0.093114808,89.58,93.07,1872gangUnit,0,10,4.285714286,4.064537838,0.109156269,5,0,1872pctOfficDrugUnit,0,48.44,0.980162528,2.877127691,0.318474028,0,0,0policBudgetPerPop,15260.4,2422367,153577.8712,203040.8861,0.056100531,114582,#N/A,1872murders,0,1946,7.764785553,58.16646847,0.248259306,1,0,0murdPerPop,0,91.09,5.859295711,9.156828742,0.671541352,2.17,0,0rapes,0,2818,28.04633782,105.6161353,0.336087881,7,0,208rapesPerPop,0,401.35,36.25848032,34.23974957,0.581533276,26.92,0,208robberies,0,86001,237.9521229,2250.720788,0.208547391,19,1,1robbbPerPop,0,2264.13,162.6125971,234.4866243,0.828574083,74.8,0,1assaults,0,62778,326.5281562,1987.947941,0.301016534,56,12,13assaultPerPop,0,4932.5,378.0046049,438.2385994,0.945565838,226.525,0,13burglaries,2,99207,761.2368897,3111.702756,0.316504514,205,79,3burglPerPop,16.92,11881.02,1033.430203,763.3544416,0.698552626,822.715,728.93,3larcenies,10,235132,2137.629295,7600.573464,0.2950221,747,547,3larcPerPop,77.86,25910.55,3372.97915,1901.316145,0.509410495,3079.51,4631.1,3autoTheft,1,112464,516.6925859,3258.164244,0.244925811,75,16,3autoTheftPerPop,6.55,4968.59,473.9656284,504.6660256,0.636484339,302.355,213.62,3arsons,0,5119,30.90772128,180.1252481,0.232824758,5,0,91arsonsPerPop,0,436.37,32.15368173,39.24090028,0.416718515,21.08,0,91violentPerPop,0,4877.06,589.0789218,614.7845182,1,374.06,223.06,221nonViolPerPop,116.79,27119.76,4908.241804,2739.708901,0.675374243,4425.45,4295.96,97Statistics for nominal State variable:State,CountAK,3AL,43AR,25AZ,20CA,279CO,25CT,71DC,1DE,1FL,90GA,37IA,20ID,7IL,40IN,48KS,1KY,26LA,22MA,123MD,12ME,17MI,108MN,66MO,42MS,20NC,46ND,8NH,21NJ,211NM,10NV,5NY,46OH,111OK,36OR,31PA,101RI,26SC,28SD,9TN,35TX,162UT,24VA,33VT,4WA,40WI,60WV,14WY,7Distribution of the main Goal Variable (Violent Crimes per Population): Range	Frequency (On boundary goes in the lower bin; e.g. exactly 200 goes in 100-200) 0,11-100,285100-200,306200-300,265300-400,185400-500,151500-600,131600-700,100700-800,77800-900,72900-1000,611000-1100,381100-1200,331200-1300,501300-1400,351400-1500,301500-1600,281600-1700,281700-1800,141800-1900,121900-2000,14More,78.arff header for weka:@relation crimeunnormalized@attribute communityname string@attribute State {AK,AL,AR,AZ,CA,CO,CT,DC,DE,FL,GA,IA,ID,IL,IN,KS,KY,LA,MA,MD,ME,MI,MN,MO,MS,NC,ND,NH,NJ,NM,NV,NY,OH,OK,OR,PA,RI,SC,SD,TN,TX,UT,VA,VT,WA,WI,WV,WY}@attribute countyCode numeric@attribute communityCode numeric@attribute fold numeric@attribute pop numeric @attribute perHoush numeric @attribute pctBlack numeric @attribute pctWhite numeric @attribute pctAsian numeric @attribute pctHisp numeric @attribute pct12-21 numeric @attribute pct12-29 numeric @attribute pct16-24 numeric @attribute pct65up numeric @attribute persUrban numeric @attribute pctUrban numeric @attribute medIncome numeric @attribute pctWwage numeric @attribute pctWfarm numeric @attribute pctWdiv numeric @attribute pctWsocsec numeric @attribute pctPubAsst numeric @attribute pctRetire numeric @attribute medFamIncome numeric @attribute perCapInc numeric @attribute whitePerCap numeric @attribute blackPerCap numeric @attribute NAperCap numeric @attribute asianPerCap numeric @attribute otherPerCap numeric @attribute hispPerCap numeric @attribute persPoverty numeric @attribute pctPoverty numeric @attribute pctLowEdu numeric @attribute pctNotHSgrad numeric @attribute pctCollGrad numeric @attribute pctUnemploy numeric @attribute pctEmploy numeric @attribute pctEmployMfg numeric @attribute pctEmployProfServ numeric @attribute pctOccupManu numeric @attribute pctOccupMgmt numeric @attribute pctMaleDivorc numeric @attribute pctMaleNevMar numeric @attribute pctFemDivorc numeric @attribute pctAllDivorc numeric @attribute persPerFam numeric @attribute pct2Par numeric @attribute pctKids2Par numeric @attribute pctKids-4w2Par numeric @attribute pct12-17w2Par numeric @attribute pctWorkMom-6 numeric @attribute pctWorkMom-18 numeric @attribute kidsBornNevrMarr numeric @attribute pctKidsBornNevrMarr numeric @attribute numForeignBorn numeric @attribute pctFgnImmig-3 numeric @attribute pctFgnImmig-5 numeric @attribute pctFgnImmig-8 numeric @attribute pctFgnImmig-10 numeric @attribute pctImmig-3 numeric @attribute pctImmig-5 numeric @attribute pctImmig-8 numeric @attribute pctImmig-10 numeric @attribute pctSpeakOnlyEng numeric @attribute pctNotSpeakEng numeric @attribute pctLargHousFam numeric @attribute pctLargHous numeric @attribute persPerOccupHous numeric @attribute persPerOwnOccup numeric @attribute persPerRenterOccup numeric @attribute pctPersOwnOccup numeric @attribute pctPopDenseHous numeric @attribute pctSmallHousUnits numeric @attribute medNumBedrm numeric @attribute houseVacant numeric @attribute pctHousOccup numeric @attribute pctHousOwnerOccup numeric @attribute pctVacantBoarded numeric @attribute pctVacant6up numeric @attribute medYrHousBuilt numeric @attribute pctHousWOphone numeric @attribute pctHousWOplumb numeric @attribute ownHousLowQ numeric @attribute ownHousMed numeric @attribute ownHousUperQ numeric @attribute ownHousQrange numeric @attribute rentLowQ numeric @attribute rentMed numeric @attribute rentUpperQ numeric @attribute rentQrange numeric @attribute medGrossRent numeric @attribute medRentpctHousInc numeric @attribute medOwnCostpct numeric @attribute medOwnCostPctWO numeric @attribute persEmergShelt numeric @attribute persHomeless numeric @attribute pctForeignBorn numeric @attribute pctBornStateResid numeric @attribute pctSameHouse-5 numeric @attribute pctSameCounty-5 numeric @attribute pctSameState-5 numeric @attribute numPolice numeric @attribute policePerPop numeric @attribute policeField numeric @attribute policeFieldPerPop numeric @attribute policeCalls numeric @attribute policCallPerPop numeric @attribute policCallPerOffic numeric @attribute policePerPop2 numeric @attribute racialMatch numeric @attribute pctPolicWhite numeric @attribute pctPolicBlack numeric @attribute pctPolicHisp numeric @attribute pctPolicAsian numeric @attribute pctPolicMinority numeric @attribute officDrugUnits numeric @attribute numDiffDrugsSeiz numeric @attribute policAveOT numeric @attribute landArea numeric @attribute popDensity numeric @attribute pctUsePubTrans numeric @attribute policCarsAvail numeric @attribute policOperBudget numeric @attribute pctPolicPatrol numeric @attribute gangUnit numeric @attribute pctOfficDrugUnit numeric @attribute policBudgetPerPop numeric @attribute murders numeric @attribute murdPerPop numeric @attribute rapes numeric @attribute rapesPerPop numeric @attribute robberies numeric @attribute robbbPerPop numeric @attribute assaults numeric @attribute assaultPerPop numeric @attribute burglaries numeric @attribute burglPerPop numeric @attribute larcenies numeric @attribute larcPerPop numeric @attribute autoTheft numeric @attribute autoTheftPerPop numeric @attribute arsons numeric @attribute arsonsPerPop numeric @attribute violentPerPop numeric @attribute nonViolPerPop numeric @data","Communities in the US. Data combines socio-economic data from the '90 Census, law enforcement data from the 1990 Law Enforcement Management and Admin Stats survey, and crime data from the 1995 FBI UCRThe source datasets needed to be combined via programming. Many variables are included so that algorithms that select or learn weights for attributes could be tested. However, clearly unrelated attributes were not included; attributes were picked if there was any plausible connection to crime (N=125), plus the crime variables which are potential dependent variables. The variables included in the dataset involve the community, such as the percent of the population considered urban, and the median family income, and involving law enforcement, such as per capita number of police officers, and percent of officers assigned to drug units. The crime attributes (N=18) that could be predicted are the 8 crimes considered 'Index Crimes' by the FBI)(Murders, Rape, Robbery, .... ), per capita (actually per 100,000 population) versions of each, and Per Capita Violent Crimes and Per Capita Nonviolent Crimes).   A limitation was that the LEMAS survey was of the police departments with at least 100 officers, plus a random sample of smaller departments. For our purposes, communities not found in both census and crime datasets were omitted. Many communities are missing LEMAS data.The per capita crimes variables were calculated using population values included in the 1995 FBI data (which differ from the 1990 Census values). The per capita violent crimes variable was calculated using population and the sum of crime variables considered violent crimes in the United States: murder, rape, robbery, and assault. There was apparently some controversy in some states concerning the counting of rapes. These resulted in missing values for rape, which resulted in missing values for per capita violent crime. Many of these omitted communities were from the midwestern USA (Minnesota, Illinois, and Michigan have many of these).    The per capita nonviolent crime variable was calculated using the sum of crime variables considered non-violent crimes in the United States: burglaries, larcenies, auto thefts and arsons. (There are many other types of crimes, these only include FBI 'Index Crimes')Some further pre-processing of the dataset must be done. Choose the desirable dependent variable from among the 18 possible. It would not be interesting or appropriate to predict total crime (e.g. violent crime) while including subtotals (e.g. murders) as independent variables. There are also identifying variables (community name, county code, community code) that are not predictive, and would get in the way of some algorithms. Weka's Unsupervised Attribute Remove Filter can be used to remove unwanted attributes.The FBI notes that use of this data to evaluate communities is over-simplistic, as many relevant factors are not included. For one example, communities with large numbers of visitors will have higher per capita crime (measured by residents) than communities with fewer visitors, other things being equal.  (125 predictive, 4 non-predictive, 18 potential goal)  -- communityname: Community name - not predictive - for information only (string)  -- state: US state (by 2 letter postal abbreviation)(nominal)   -- countyCode: numeric code for county - not predictive, and many missing values (numeric)  -- communityCode: numeric code for community - not predictive and many missing values (numeric)   -- fold: fold number for non-random 10 fold cross validation, potentially useful for debugging, paired tests - not predictive (numeric - integer)   -- population: population for community: (numeric - expected to be integer)  -- householdsize: mean people per household (numeric - decimal)  -- racepctblack: percentage of population that is african american (numeric - decimal)  -- racePctWhite: percentage of population that is caucasian (numeric - decimal)  -- racePctAsian: percentage of population that is of asian heritage (numeric - decimal)  -- racePctHisp: percentage of population that is of hispanic heritage (numeric - decimal)  -- agePct12t21: percentage of population that is 12-21 in age (numeric - decimal)  -- agePct12t29: percentage of population that is 12-29 in age (numeric - decimal)  -- agePct16t24: percentage of population that is 16-24 in age (numeric - decimal)  -- agePct65up: percentage of population that is 65 and over in age (numeric - decimal)  -- numbUrban: number of people living in areas classified as urban (numeric - expected to be integer)  -- pctUrban: percentage of people living in areas classified as urban (numeric - decimal)  -- medIncome: median household income (numeric - may be integer)  -- pctWWage: percentage of households with wage or salary income in 1989 (numeric - decimal)  -- pctWFarmSelf: percentage of households with farm or self employment income in 1989 (numeric - decimal)  -- pctWInvInc: percentage of households with investment / rent income in 1989 (numeric - decimal)  -- pctWSocSec: percentage of households with social security income in 1989 (numeric - decimal)  -- pctWPubAsst: percentage of households with public assistance income in 1989 (numeric - decimal)  -- pctWRetire: percentage of households with retirement income in 1989 (numeric - decimal)  -- medFamInc: median family income (differs from household income for non-family households) (numeric - may be integer)  -- perCapInc: per capita income (numeric - decimal)  -- whitePerCap: per capita income for caucasians (numeric - decimal)  -- blackPerCap: per capita income for african americans (numeric - decimal)  -- indianPerCap: per capita income for native americans (numeric - decimal)  -- AsianPerCap: per capita income for people with asian heritage (numeric - decimal)  -- OtherPerCap: per capita income for people with 'other' heritage (numeric - decimal)  -- HispPerCap: per capita income for people with hispanic heritage (numeric - decimal)  -- NumUnderPov: number of people under the poverty level (numeric - expected to be integer)  -- PctPopUnderPov: percentage of people under the poverty level (numeric - decimal)  -- PctLess9thGrade: percentage of people 25 and over with less than a 9th grade education (numeric - decimal)  -- PctNotHSGrad: percentage of people 25 and over that are not high school graduates (numeric - decimal)  -- PctBSorMore: percentage of people 25 and over with a bachelors degree or higher education (numeric - decimal)  -- PctUnemployed: percentage of people 16 and over, in the labor force, and unemployed (numeric - decimal)  -- PctEmploy: percentage of people 16 and over who are employed (numeric - decimal)  -- PctEmplManu: percentage of people 16 and over who are employed in manufacturing (numeric - decimal)  -- PctEmplProfServ: percentage of people 16 and over who are employed in professional services (numeric - decimal)  -- PctOccupManu: percentage of people 16 and over who are employed in manufacturing (numeric - decimal)   #### No longer sure of difference from PctEmplManu - may include unemployed manufacturing workers ####  -- PctOccupMgmtProf: percentage of people 16 and over who are employed in management or professional occupations (numeric - decimal)  -- MalePctDivorce: percentage of males who are divorced (numeric - decimal)  -- MalePctNevMarr: percentage of males who have never married (numeric - decimal)  -- FemalePctDiv: percentage of females who are divorced (numeric - decimal)  -- TotalPctDiv: percentage of population who are divorced (numeric - decimal)  -- PersPerFam: mean number of people per family (numeric - decimal)  -- PctFam2Par: percentage of families (with kids) that are headed by two parents (numeric - decimal)  -- PctKids2Par: percentage of kids in family housing with two parents (numeric - decimal)  -- PctYoungKids2Par: percent of kids 4 and under in two parent households (numeric - decimal)  -- PctTeen2Par: percent of kids age 12-17 in two parent households (numeric - decimal)  -- PctWorkMomYoungKids: percentage of moms of kids 6 and under in labor force (numeric - decimal)  -- PctWorkMom: percentage of moms of kids under 18 in labor force (numeric - decimal)  -- NumKidsBornNeverMar: number of kids born to never married (numeric - expected to be integer)  -- PctKidsBornNeverMar: percentage of kids born to never married (numeric - decimal)  -- NumImmig: total number of people known to be foreign born (numeric - expected to be integer)  -- PctImmigRecent: percentage of _immigrants_ who immigated within last 3 years (numeric - decimal)  -- PctImmigRec5: percentage of _immigrants_ who immigated within last 5 years (numeric - decimal)  -- PctImmigRec8: percentage of _immigrants_ who immigated within last 8 years (numeric - decimal)  -- PctImmigRec10: percentage of _immigrants_ who immigated within last 10 years (numeric - decimal)  -- PctRecentImmig: percent of _population_ who have immigrated within the last 3 years (numeric - decimal)  -- PctRecImmig5: percent of _population_ who have immigrated within the last 5 years (numeric - decimal)  -- PctRecImmig8: percent of _population_ who have immigrated within the last 8 years (numeric - decimal)  -- PctRecImmig10: percent of _population_ who have immigrated within the last 10 years (numeric - decimal)  -- PctSpeakEnglOnly: percent of people who speak only English (numeric - decimal)  -- PctNotSpeakEnglWell: percent of people who do not speak English well (numeric - decimal)  -- PctLargHouseFam: percent of family households that are large (6 or more) (numeric - decimal)  -- PctLargHouseOccup: percent of all occupied households that are large (6 or more people) (numeric - decimal)  -- PersPerOccupHous: mean persons per household (numeric - decimal)  -- PersPerOwnOccHous: mean persons per owner occupied household (numeric - decimal)  -- PersPerRentOccHous: mean persons per rental household (numeric - decimal)  -- PctPersOwnOccup: percent of people in owner occupied households (numeric - decimal)  -- PctPersDenseHous: percent of persons in dense housing (more than 1 person per room) (numeric - decimal)  -- PctHousLess3BR: percent of housing units with less than 3 bedrooms (numeric - decimal)  -- MedNumBR: median number of bedrooms (numeric - decimal)  -- HousVacant: number of vacant households (numeric - expected to be integer)  -- PctHousOccup: percent of housing occupied (numeric - decimal)  -- PctHousOwnOcc: percent of households owner occupied (numeric - decimal)  -- PctVacantBoarded: percent of vacant housing that is boarded up (numeric - decimal)  -- PctVacMore6Mos: percent of vacant housing that has been vacant more than 6 months (numeric - decimal)  -- MedYrHousBuilt: median year housing units built (numeric - may be integer)  -- PctHousNoPhone: percent of occupied housing units without phone (in 1990, this was rare!) (numeric - decimal)  -- PctWOFullPlumb: percent of housing without complete plumbing facilities (numeric - decimal)  -- OwnOccLowQuart: owner occupied housing - lower quartile value (numeric - decimal)  -- OwnOccMedVal: owner occupied housing - median value (numeric - decimal)  -- OwnOccHiQuart: owner occupied housing - upper quartile value (numeric - decimal)  -- OwnOccQrange: owner occupied housing - difference between upper quartile and lower quartile values (numeric - decimal)  -- RentLowQ: rental housing - lower quartile rent (numeric - decimal)  -- RentMedian: rental housing - median rent (Census variable H32B from file STF1A) (numeric - decimal)  -- RentHighQ: rental housing - upper quartile rent (numeric - decimal)  -- RentQrange: rental housing - difference between upper quartile and lower quartile rent (numeric - decimal)  -- MedRent: median gross rent (Census variable H43A from file STF3A - includes utilities) (numeric - decimal)  -- MedRentPctHousInc: median gross rent as a percentage of household income (numeric - decimal)  -- MedOwnCostPctInc: median owners cost as a percentage of household income - for owners with a mortgage (numeric - decimal)  -- MedOwnCostPctIncNoMtg: median owners cost as a percentage of household income - for owners without a mortgage (numeric - decimal)  -- NumInShelters: number of people in homeless shelters (numeric - expected to be integer)  -- NumStreet: number of homeless people counted in the street (numeric - expected to be integer)  -- PctForeignBorn: percent of people foreign born (numeric - decimal)  -- PctBornSameState: percent of people born in the same state as currently living (numeric - decimal)  -- PctSameHouse85: percent of people living in the same house as in 1985 (5 years before) (numeric - decimal)  -- PctSameCity85: percent of people living in the same city as in 1985 (5 years before) (numeric - decimal)  -- PctSameState85: percent of people living in the same state as in 1985 (5 years before) (numeric - decimal)  -- LemasSwornFT: number of sworn full time police officers (numeric - expected to be integer)  -- LemasSwFTPerPop: sworn full time police officers per 100K population (numeric - decimal)  -- LemasSwFTFieldOps: number of sworn full time police officers in field operations (on the street as opposed to administrative etc) (numeric - expected to be integer)  -- LemasSwFTFieldPerPop: sworn full time police officers in field operations (on the street as opposed to administrative etc) per 100K population (numeric - decimal)  -- LemasTotalReq: total requests for police (numeric - expected to be integer)  -- LemasTotReqPerPop: total requests for police per 100K popuation (numeric - decimal)  -- PolicReqPerOffic: total requests for police per police officer (numeric - decimal)  -- PolicPerPop: police officers per 100K population (numeric - decimal)  -- RacialMatchCommPol: a measure of the racial match between the community and the police force. High values indicate proportions in community and police force are similar (numeric - decimal)  -- PctPolicWhite: percent of police that are caucasian (numeric - decimal)  -- PctPolicBlack: percent of police that are african american (numeric - decimal)  -- PctPolicHisp: percent of police that are hispanic (numeric - decimal)  -- PctPolicAsian: percent of police that are asian (numeric - decimal)  -- PctPolicMinor: percent of police that are minority of any kind (numeric - decimal)  -- OfficAssgnDrugUnits: number of officers assigned to special drug units (numeric - expected to be integer)  -- NumKindsDrugsSeiz: number of different kinds of drugs seized (numeric - expected to be integer)  -- PolicAveOTWorked: police average overtime worked (numeric - decimal)  -- LandArea: land area in square miles (numeric - decimal)  -- PopDens: population density in persons per square mile (numeric - decimal)  -- PctUsePubTrans: percent of people using public transit for commuting (numeric - decimal)  -- PolicCars: number of police cars (numeric - expected to be integer)  -- PolicOperBudg: police operating budget (numeric - may be integer)  -- LemasPctPolicOnPatr: percent of sworn full time police officers on patrol (numeric - decimal)  -- LemasGangUnitDeploy: gang unit deployed (numeric - integer - but really nominal - 0 means NO, 10 means YES,  5 means Part Time)  -- LemasPctOfficDrugUn: percent of officers assigned to drug units (numeric - decimal)  -- PolicBudgPerPop: police operating budget per population (numeric - decimal)  -- murders: number of murders in 1995 (numeric - expected to be integer) potential GOAL attribute (to be predicted)  -- murdPerPop: number of murders per 100K population (numeric - decimal) potential GOAL attribute (to be predicted)  -- rapes: number of rapes in 1995 (numeric - expected to be integer) potential GOAL attribute (to be predicted)  -- rapesPerPop: number of rapes per 100K population  (numeric - decimal) potential GOAL attribute (to be predicted)  -- robberies: number of robberies in 1995  (numeric - expected to be integer) potential GOAL attribute (to be predicted)  -- robbbPerPop: number of robberies per 100K population  (numeric - decimal) potential GOAL attribute (to be predicted)  -- assaults: number of assaults in 1995  (numeric - expected to be integer) potential GOAL attribute (to be predicted)  -- assaultPerPop: number of assaults per 100K population  (numeric - decimal) potential GOAL attribute (to be predicted)  -- burglaries: number of burglaries in 1995  (numeric - expected to be integer) potential GOAL attribute (to be predicted)  -- burglPerPop: number of burglaries per 100K population  (numeric - decimal) potential GOAL attribute (to be predicted)  -- larcenies: number of larcenies in 1995  (numeric - expected to be integer) potential GOAL attribute (to be predicted)  -- larcPerPop: number of larcenies per 100K population  (numeric - decimal) potential GOAL attribute (to be predicted)  -- autoTheft: number of auto thefts in 1995  (numeric - expected to be integer) potential GOAL attribute (to be predicted)  -- autoTheftPerPop: number of auto thefts per 100K population  (numeric - decimal) potential GOAL attribute (to be predicted)  -- arsons: number of arsons in 1995  (numeric - expected to be integer) potential GOAL attribute (to be predicted)  -- arsonsPerPop: number of arsons per 100K population  (numeric - decimal) potential GOAL attribute (to be predicted)  -- ViolentCrimesPerPop: total number of violent crimes per 100K popuation (numeric - decimal) GOAL attribute (to be predicted)  -- nonViolPerPop: total number of non-violent crimes per 100K popuation (numeric - decimal) potential GOAL attribute (to be predicted)Summary Statistics:variable,Minimum,Maximum,Mean,Standard Deviation,Correlation w/ ViolPerPop,Median,Mode,Missingpop,10005,7322564,53117.9842,204620.2529,0.212353809,22792,12361,0perHoush,1.6,5.28,2.707327314,0.334119654,-0.020110177,2.66,2.6,0pctBlack,0,96.67,9.33510158,14.2471563,0.628367756,2.87,0.24,0pctWhite,2.68,99.63,83.97981941,16.41908022,-0.676848823,90.35,98.04,0pctAsian,0.03,57.46,2.67020316,4.473843444,0.031949477,1.23,0.41,0pctHisp,0.12,95.29,7.950176072,14.58983204,0.253596415,2.18,0.78,0pct12-21,4.58,54.4,14.44583747,4.518622844,0.023535103,13.62,13.62,0pct12-29,9.38,70.51,27.64483973,6.181517075,0.105908765,26.78,26.78,0pct16-24,4.64,63.62,13.97514221,5.970746729,0.045251915,12.54,11.61,0pct65up,1.66,52.77,11.83639278,4.777565216,0.055637064,11.73,11.06,0persUrban,0,7322564,47734.72009,205606.6933,0.21384036,18041,0,0pctUrban,0,100,70.46530926,44.08027532,0.086294263,100,100,0medIncome,8866,123625,33984.69616,13424.68001,-0.397407452,31441,27095,0pctWwage,31.68,96.76,78.31275847,7.950672435,-0.289829747,78.61,85.12,0pctWfarm,0,6.53,0.881841986,0.689005635,-0.148357317,0.69,0.54,0pctWdiv,5.81,89.04,43.75093454,12.78792465,-0.557786505,42.88,41.65,0pctWsocsec,4.81,76.39,26.40941761,8.295604161,0.107881101,26.59,21.51,0pctPubAsst,0.18,44.82,6.801444695,4.700334848,0.563107116,5.61,2.27,0pctRetire,3.46,45.51,15.96900226,4.622553011,-0.098964807,15.65,13.14,0medFamIncome,10447,139008,39857.05508,14251.20603,-0.411864109,36678,30546,0perCapInc,5237,63302,15603.5246,6281.558523,-0.315255977,14101,11252,0whitePerCap,5472,68850,16567.69842,6346.840251,-0.185898177,15073,12735,0blackPerCap,0,212120,11541.74944,9232.102062,-0.209243037,9777,0,0NAperCap,0,480000,12229.19142,14853.83618,-0.060250637,9895,0,0asianPerCap,0,106165,14227.98962,9881.266395,-0.128086386,12250,0,0otherPerCap,0,137000,9442.765131,7926.466713,-0.103288444,8186,0,1hispPerCap,0,54648,11018.99819,5884.063446,-0.219349786,9721,0,0persPoverty,78,1384994,7590.853273,39361.46001,0.240253072,2142,470,0pctPoverty,0.64,58,11.62053725,8.600352277,0.505349223,9.33,3.26,0pctLowEdu,0.2,49.89,9.186645598,6.66670296,0.371421768,7.74,5.78,0pctNotHSgrad,1.46,73.66,22.30511964,10.98951654,0.46759552,21.38,11.27,0pctCollGrad,1.63,79.18,23.05687585,12.68721342,-0.299897539,19.65,14.2,0pctUnemploy,1.32,31.23,6.045241535,2.89561824,0.483440771,5.45,4.36,0pctEmploy,24.82,84.67,62.02161174,8.31204498,-0.31764382,62.44,62.6,0pctEmployMfg,2.05,50.03,18.22890745,8.099280979,-0.04712343,17.3,25.38,0pctEmployProfServ,8.69,62.67,24.53229797,6.659470242,-0.064554813,23.39,21.52,0pctOccupManu,1.37,44.27,13.81916479,6.430263859,0.283898507,13.15,16.52,0pctOccupMgmt,6.48,64.97,28.2092009,9.326123364,-0.324430512,26.24,28.31,0pctMaleDivorc,2.13,20.08,9.12758465,2.802747328,0.510455756,9.15,10.82,0pctMaleNevMar,12.06,76.6,30.68351693,8.127990901,0.271229742,29,26.78,0pctFemDivorc,3.35,23.92,12.32530023,3.262612867,0.537302801,12.52,14.36,0pctAllDivorc,2.83,22.23,10.81251467,3.000883481,0.536548564,10.9,11.77,0persPerFam,2.29,4.64,3.129697517,0.240742507,0.149955382,3.1,3.13,0pct2Par,22.97,93.6,74.05912867,10.52595184,-0.698640874,75.03,72.16,0pctKids2Par,18.3,92.58,71.22725508,12.04504833,-0.728058986,72.53,63.25,0pctKids-4w2Par,8.7,100,81.86542212,12.26373565,-0.658436367,83.99,100,0pct12-17w2Par,20.2,97.34,75.52178781,10.36526212,-0.655627787,76.92,77.49,0pctWorkMom-6,24.42,87.97,60.54264108,8.008936744,-0.02162507,60.71,63.48,0pctWorkMom-18,41.95,89.37,68.85479458,6.679959744,-0.146173218,69.23,65.64,0kidsBornNevrMarr,0,527557,2141.418962,14692.58284,0.240337327,352,139,0pctKidsBornNevrMarr,0,27.35,3.115498871,3.127681493,0.738089083,2.04,0.97,0numForeignBorn,20,2082931,6277.273589,55419.65383,0.144585649,1024,147,0pctFgnImmig-3,0,64.29,13.525693,9.780097693,0.156688654,12.26,0,0pctFgnImmig-5,0,76.16,20.42128668,12.41035515,0.201445794,19.08,0,0pctFgnImmig-8,0,80.81,27.54418059,14.36881288,0.236607959,26.72,0,0pctFgnImmig-10,0,88,34.73392777,16.32732237,0.281536984,34.79,0,0pctImmig-3,0,13.71,1.099124153,1.595766262,0.215616823,0.5,0,0pctImmig-5,0,19.93,1.697462754,2.46105956,0.232900674,0.75,0,0pctImmig-8,0,25.34,2.307503386,3.286647928,0.23889175,1.04,0,0pctImmig-10,0,32.63,2.943760722,4.246468259,0.250865298,1.31,0,0pctSpeakOnlyEng,6.15,98.98,87.07499323,14.07608745,-0.219031839,92.18,93.57,0pctNotSpeakEng,0,38.33,2.405792325,4.210367661,0.27243614,0.92,0.44,0pctLargHousFam,0.96,34.87,5.38661851,3.794309411,0.341601121,4.28,3.71,0pctLargHous,0.44,30.87,3.91578781,3.175770454,0.257215583,3.05,2.98,0persPerOccupHous,1.58,4.52,2.615841986,0.315646341,-0.017700909,2.57,2.44,0persPerOwnOccup,1.61,4.48,2.74048307,0.297420849,-0.099169625,2.71,2.65,0persPerRenterOccup,1.55,4.73,2.367137698,0.391805778,0.240564095,2.29,2.17,0pctPersOwnOccup,13.93,97.24,66.36945372,14.18258845,-0.507329566,65.91,63.79,0pctPopDenseHous,0.05,59.49,4.132437923,5.599131346,0.395855647,2.34,1.31,0pctSmallHousUnits,3.06,95.34,45.40534086,13.77834736,0.454469731,46.39,53.15,0medNumBedrm,1,4,2.640632054,0.512686001,-0.347149961,3,3,0houseVacant,36,172768,1748.368849,6503.866478,0.289690649,558,246,0pctHousOccup,37.47,99,92.93397291,5.04073584,-0.256836226,94.21,95.38,0pctHousOwnerOccup,16.86,96.49,63.36829797,13.9700567,-0.45535904,62.83,56.17,0pctVacantBoarded,0,39.89,2.778523702,3.592396207,0.479910148,1.66,0,0pctVacant6up,3.12,82.13,34.77388713,13.91146771,0.030768767,34.1,37.5,0medYrHousBuilt,1939,1987,1962.623476,11.16655501,-0.111201128,1964,1939,0pctHousWOphone,0,23.88,4.289823928,4.088174777,0.473717673,2.85,0,0pctHousWOplumb,0,5.33,0.425273138,0.426188232,0.311226836,0.32,0,0ownHousLowQ,14999,500001,88695.80226,66670.78153,-0.194912005,65500,34000,0ownHousMed,19500,500001,113097.5233,81906.36228,-0.17822542,82800,500001,0ownHousUperQ,28200,500001,145318.2578,99030.91382,-0.166029142,106700,500001,0ownHousQrange,0,331000,56622.45553,39106.49804,-0.086578248,43400,28100,0rentLowQ,99,1001,329.9665914,144.1384609,-0.245708342,307,252,0rentMed,120,1001,428.537246,170.7066437,-0.232797807,397,316,0rentUpperQ,182,1001,527.2528217,199.29078,-0.223893683,486,1001,0rentQrange ,0,803,197.2862302,85.20568803,-0.110281171,171,139,0medGrossRent,192,1001,501.4663657,169.2717347,-0.231754244,467,1001,0medRentpctHousInc,14.9,35.1,26.29810384,2.979297132,0.315536838,26.1,24.7,0medOwnCostpct,14,32.7,20.99015801,2.987621666,0.061058949,21,22.6,0medOwnCostPctWO,10.1,23.4,13.01020316,1.419678674,0.063296009,12.8,11.8,0persEmergShelt,0,23383,66.95349887,564.253149,0.19494198,0,0,0persHomeless,0,10447,17.8234763,245.4525529,0.136446046,0,0,0pctForeignBorn,0.18,60.4,7.340302483,8.418475989,0.193229615,4.31,2.97,0pctBornStateResid,6.75,93.14,61.5396298,16.75006116,-0.070943862,64.49,74.45,0pctSameHouse-5,11.83,78.56,51.53859594,10.51792598,-0.14008735,52.17,54.85,0pctSameCounty-5,27.95,96.59,77.41107901,10.87818569,0.082634597,79.49,81.47,0pctSameState-5,32.83,99.9,88.11186456,7.287836465,-0.006663834,90.03,92.69,0numPolice,65,25655,499.1982507,1681.472251,0.194219827,173,100,1872policePerPop,29.4,3437.23,246.4909621,273.7991617,0.073197363,196.01,#N/A,1872policeField,14,22496,432.5597668,1493.708385,0.186477279,152,94,1872policeFieldPerPop,19.21,3290.62,210.8447813,235.4788145,0.065928304,170.27,183.22,1872policeCalls,2100,8328470,252404.9883,689449.7817,0.230023206,90000,50000,1872policCallPerPop,2704.8,1926281.5,120651.7189,148211.3422,0.14854896,91034.6,#N/A,1872policCallPerOffic,20.8,2162.5,523.658309,307.8390067,0.145798061,443.2,422.6,1872policePerPop2,29.4,3437.2,246.493586,273.7984086,0.073203166,196,171.5,1872racialMatch,42.15,100,85.4996793,10.94131216,-0.469374164,87.93,100,1872pctPolicWhite,1.6,100,82.5158309,15.33261214,-0.392584252,86.18,100,1872pctPolicBlack,0,67.31,9.263294461,11.02142376,0.513568853,5,0,1872pctPolicHisp,0,98.4,5.459766764,10.60453332,0.056080974,2.04,0,1872pctPolicAsian,0,18.57,0.681282799,1.706344058,0.072778715,0,0,1872pctPolicMinority,0,98.4,15.2422449,14.82675626,0.416418453,11.37,0,1872officDrugUnits,0,1773,26.28862974,100.8219209,0.166934688,12,6,1872numDiffDrugsSeiz,1,15,8.816326531,2.836390802,0.115940631,9,9,1872policAveOT,0,634.7,119.1142857,92.49518559,0.010162351,98.7,0,1872landArea,0.9,3569.8,27.41995485,109.8226001,0.075697852,13.7,4.9,0popDensity,10,44229.9,2783.835034,2828.993341,0.256966815,2027.3,3217.7,0pctUsePubTrans,0,54.33,3.041124153,4.91291686,0.190478991,1.22,0,0policCarsAvail,20,3187,185.4781341,318.5428335,0.313164478,86,55,1872policOperBudget,2380215,1617293056,32176019.34,110456627.5,0.195267289,11164110,8000000,1872pctPolicPatrol,10.85,99.94,87.13093294,10.34961235,-0.093114808,89.58,93.07,1872gangUnit,0,10,4.285714286,4.064537838,0.109156269,5,0,1872pctOfficDrugUnit,0,48.44,0.980162528,2.877127691,0.318474028,0,0,0policBudgetPerPop,15260.4,2422367,153577.8712,203040.8861,0.056100531,114582,#N/A,1872murders,0,1946,7.764785553,58.16646847,0.248259306,1,0,0murdPerPop,0,91.09,5.859295711,9.156828742,0.671541352,2.17,0,0rapes,0,2818,28.04633782,105.6161353,0.336087881,7,0,208rapesPerPop,0,401.35,36.25848032,34.23974957,0.581533276,26.92,0,208robberies,0,86001,237.9521229,2250.720788,0.208547391,19,1,1robbbPerPop,0,2264.13,162.6125971,234.4866243,0.828574083,74.8,0,1assaults,0,62778,326.5281562,1987.947941,0.301016534,56,12,13assaultPerPop,0,4932.5,378.0046049,438.2385994,0.945565838,226.525,0,13burglaries,2,99207,761.2368897,3111.702756,0.316504514,205,79,3burglPerPop,16.92,11881.02,1033.430203,763.3544416,0.698552626,822.715,728.93,3larcenies,10,235132,2137.629295,7600.573464,0.2950221,747,547,3larcPerPop,77.86,25910.55,3372.97915,1901.316145,0.509410495,3079.51,4631.1,3autoTheft,1,112464,516.6925859,3258.164244,0.244925811,75,16,3autoTheftPerPop,6.55,4968.59,473.9656284,504.6660256,0.636484339,302.355,213.62,3arsons,0,5119,30.90772128,180.1252481,0.232824758,5,0,91arsonsPerPop,0,436.37,32.15368173,39.24090028,0.416718515,21.08,0,91violentPerPop,0,4877.06,589.0789218,614.7845182,1,374.06,223.06,221nonViolPerPop,116.79,27119.76,4908.241804,2739.708901,0.675374243,4425.45,4295.96,97Statistics for nominal State variable:State,CountAK,3AL,43AR,25AZ,20CA,279CO,25CT,71DC,1DE,1FL,90GA,37IA,20ID,7IL,40IN,48KS,1KY,26LA,22MA,123MD,12ME,17MI,108MN,66MO,42MS,20NC,46ND,8NH,21NJ,211NM,10NV,5NY,46OH,111OK,36OR,31PA,101RI,26SC,28SD,9TN,35TX,162UT,24VA,33VT,4WA,40WI,60WV,14WY,7Distribution of the main Goal Variable (Violent Crimes per Population): Range	Frequency (On boundary goes in the lower bin; e.g. exactly 200 goes in 100-200) 0,11-100,285100-200,306200-300,265300-400,185400-500,151500-600,131600-700,100700-800,77800-900,72900-1000,611000-1100,381100-1200,331200-1300,501300-1400,351400-1500,301500-1600,281600-1700,281700-1800,141800-1900,121900-2000,14More,78.arff header for weka:@relation crimeunnormalized@attribute communityname string@attribute State {AK,AL,AR,AZ,CA,CO,CT,DC,DE,FL,GA,IA,ID,IL,IN,KS,KY,LA,MA,MD,ME,MI,MN,MO,MS,NC,ND,NH,NJ,NM,NV,NY,OH,OK,OR,PA,RI,SC,SD,TN,TX,UT,VA,VT,WA,WI,WV,WY}@attribute countyCode numeric@attribute communityCode numeric@attribute fold numeric@attribute pop numeric @attribute perHoush numeric @attribute pctBlack numeric @attribute pctWhite numeric @attribute pctAsian numeric @attribute pctHisp numeric @attribute pct12-21 numeric @attribute pct12-29 numeric @attribute pct16-24 numeric @attribute pct65up numeric @attribute persUrban numeric @attribute pctUrban numeric @attribute medIncome numeric @attribute pctWwage numeric @attribute pctWfarm numeric @attribute pctWdiv numeric @attribute pctWsocsec numeric @attribute pctPubAsst numeric @attribute pctRetire numeric @attribute medFamIncome numeric @attribute perCapInc numeric @attribute whitePerCap numeric @attribute blackPerCap numeric @attribute NAperCap numeric @attribute asianPerCap numeric @attribute otherPerCap numeric @attribute hispPerCap numeric @attribute persPoverty numeric @attribute pctPoverty numeric @attribute pctLowEdu numeric @attribute pctNotHSgrad numeric @attribute pctCollGrad numeric @attribute pctUnemploy numeric @attribute pctEmploy numeric @attribute pctEmployMfg numeric @attribute pctEmployProfServ numeric @attribute pctOccupManu numeric @attribute pctOccupMgmt numeric @attribute pctMaleDivorc numeric @attribute pctMaleNevMar numeric @attribute pctFemDivorc numeric @attribute pctAllDivorc numeric @attribute persPerFam numeric @attribute pct2Par numeric @attribute pctKids2Par numeric @attribute pctKids-4w2Par numeric @attribute pct12-17w2Par numeric @attribute pctWorkMom-6 numeric @attribute pctWorkMom-18 numeric @attribute kidsBornNevrMarr numeric @attribute pctKidsBornNevrMarr numeric @attribute numForeignBorn numeric @attribute pctFgnImmig-3 numeric @attribute pctFgnImmig-5 numeric @attribute pctFgnImmig-8 numeric @attribute pctFgnImmig-10 numeric @attribute pctImmig-3 numeric @attribute pctImmig-5 numeric @attribute pctImmig-8 numeric @attribute pctImmig-10 numeric @attribute pctSpeakOnlyEng numeric @attribute pctNotSpeakEng numeric @attribute pctLargHousFam numeric @attribute pctLargHous numeric @attribute persPerOccupHous numeric @attribute persPerOwnOccup numeric @attribute persPerRenterOccup numeric @attribute pctPersOwnOccup numeric @attribute pctPopDenseHous numeric @attribute pctSmallHousUnits numeric @attribute medNumBedrm numeric @attribute houseVacant numeric @attribute pctHousOccup numeric @attribute pctHousOwnerOccup numeric @attribute pctVacantBoarded numeric @attribute pctVacant6up numeric @attribute medYrHousBuilt numeric @attribute pctHousWOphone numeric @attribute pctHousWOplumb numeric @attribute ownHousLowQ numeric @attribute ownHousMed numeric @attribute ownHousUperQ numeric @attribute ownHousQrange numeric @attribute rentLowQ numeric @attribute rentMed numeric @attribute rentUpperQ numeric @attribute rentQrange numeric @attribute medGrossRent numeric @attribute medRentpctHousInc numeric @attribute medOwnCostpct numeric @attribute medOwnCostPctWO numeric @attribute persEmergShelt numeric @attribute persHomeless numeric @attribute pctForeignBorn numeric @attribute pctBornStateResid numeric @attribute pctSameHouse-5 numeric @attribute pctSameCounty-5 numeric @attribute pctSameState-5 numeric @attribute numPolice numeric @attribute policePerPop numeric @attribute policeField numeric @attribute policeFieldPerPop numeric @attribute policeCalls numeric @attribute policCallPerPop numeric @attribute policCallPerOffic numeric @attribute policePerPop2 numeric @attribute racialMatch numeric @attribute pctPolicWhite numeric @attribute pctPolicBlack numeric @attribute pctPolicHisp numeric @attribute pctPolicAsian numeric @attribute pctPolicMinority numeric @attribute officDrugUnits numeric @attribute numDiffDrugsSeiz numeric @attribute policAveOT numeric @attribute landArea numeric @attribute popDensity numeric @attribute pctUsePubTrans numeric @attribute policCarsAvail numeric @attribute policOperBudget numeric @attribute pctPolicPatrol numeric @attribute gangUnit numeric @attribute pctOfficDrugUnit numeric @attribute policBudgetPerPop numeric @attribute murders numeric @attribute murdPerPop numeric @attribute rapes numeric @attribute rapesPerPop numeric @attribute robberies numeric @attribute robbbPerPop numeric @attribute assaults numeric @attribute assaultPerPop numeric @attribute burglaries numeric @attribute burglPerPop numeric @attribute larcenies numeric @attribute larcPerPop numeric @attribute autoTheft numeric @attribute autoTheftPerPop numeric @attribute arsons numeric @attribute arsonsPerPop numeric @attribute violentPerPop numeric @attribute nonViolPerPop numeric @data"
Student Performance,Student Performance,Predict student performance in secondary education (high school). ,Student+Performance,https://archive.ics.uci.edu/ml//machine-learning-databases/00320/,https://archive.ics.uci.edu/ml/datasets/Student+Performance,"This data approach student achievement in secondary education of two Portuguese schools. The data attributes include student grades, demographic, social and school related features) and it was collected by using school reports and questionnaires. Two datasets are provided regarding the performance in two distinct subjects: Mathematics (mat) and Portuguese language (por). In [Cortez and Silva, 2008], the two datasets were modeled under binary/five-level classification and regression tasks. Important note: the target attribute G3 has a strong correlation with attributes G2 and G1. This occurs because G3 is the final year grade (issued at the 3rd period), while G1 and G2 correspond to the 1st and 2nd period grades. It is more difficult to predict G3 without G2 and G1, but such prediction is much more useful (see paper source for more details).",Social,"# Attributes for both student-mat.csv (Math course) and student-por.csv (Portuguese language course) datasets:1 school - student's school (binary: 'GP' - Gabriel Pereira or 'MS' - Mousinho da Silveira)2 sex - student's sex (binary: 'F' - female or 'M' - male)3 age - student's age (numeric: from 15 to 22)4 address - student's home address type (binary: 'U' - urban or 'R' - rural)5 famsize - family size (binary: 'LE3' - less or equal to 3 or 'GT3' - greater than 3)6 Pstatus - parent's cohabitation status (binary: 'T' - living together or 'A' - apart)7 Medu - mother's education (numeric: 0 - none,  1 - primary education (4th grade), 2 Ã¢â‚¬â€œ 5th to 9th grade, 3 Ã¢â‚¬â€œ secondary education or 4 Ã¢â‚¬â€œ higher education)8 Fedu - father's education (numeric: 0 - none,  1 - primary education (4th grade), 2 Ã¢â‚¬â€œ 5th to 9th grade, 3 Ã¢â‚¬â€œ secondary education or 4 Ã¢â‚¬â€œ higher education)9 Mjob - mother's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other')10 Fjob - father's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other')11 reason - reason to choose this school (nominal: close to 'home', school 'reputation', 'course' preference or 'other')12 guardian - student's guardian (nominal: 'mother', 'father' or 'other')13 traveltime - home to school travel time (numeric: 1 - <15 min., 2 - 15 to 30 min., 3 - 30 min. to 1 hour, or 4 - >1 hour)14 studytime - weekly study time (numeric: 1 - <2 hours, 2 - 2 to 5 hours, 3 - 5 to 10 hours, or 4 - >10 hours)15 failures - number of past class failures (numeric: n if 1<=n<3, else 4)16 schoolsup - extra educational support (binary: yes or no)17 famsup - family educational support (binary: yes or no)18 paid - extra paid classes within the course subject (Math or Portuguese) (binary: yes or no)19 activities - extra-curricular activities (binary: yes or no)20 nursery - attended nursery school (binary: yes or no)21 higher - wants to take higher education (binary: yes or no)22 internet - Internet access at home (binary: yes or no)23 romantic - with a romantic relationship (binary: yes or no)24 famrel - quality of family relationships (numeric: from 1 - very bad to 5 - excellent)25 freetime - free time after school (numeric: from 1 - very low to 5 - very high)26 goout - going out with friends (numeric: from 1 - very low to 5 - very high)27 Dalc - workday alcohol consumption (numeric: from 1 - very low to 5 - very high)28 Walc - weekend alcohol consumption (numeric: from 1 - very low to 5 - very high)29 health - current health status (numeric: from 1 - very bad to 5 - very good)30 absences - number of school absences (numeric: from 0 to 93)# these grades are related with the course subject, Math or Portuguese:31 G1 - first period grade (numeric: from 0 to 20)31 G2 - second period grade (numeric: from 0 to 20)32 G3 - final grade (numeric: from 0 to 20, output target)","Predict student performance in secondary education (high school). This data approach student achievement in secondary education of two Portuguese schools. The data attributes include student grades, demographic, social and school related features) and it was collected by using school reports and questionnaires. Two datasets are provided regarding the performance in two distinct subjects: Mathematics (mat) and Portuguese language (por). In [Cortez and Silva, 2008], the two datasets were modeled under binary/five-level classification and regression tasks. Important note: the target attribute G3 has a strong correlation with attributes G2 and G1. This occurs because G3 is the final year grade (issued at the 3rd period), while G1 and G2 correspond to the 1st and 2nd period grades. It is more difficult to predict G3 without G2 and G1, but such prediction is much more useful (see paper source for more details).# Attributes for both student-mat.csv (Math course) and student-por.csv (Portuguese language course) datasets:1 school - student's school (binary: 'GP' - Gabriel Pereira or 'MS' - Mousinho da Silveira)2 sex - student's sex (binary: 'F' - female or 'M' - male)3 age - student's age (numeric: from 15 to 22)4 address - student's home address type (binary: 'U' - urban or 'R' - rural)5 famsize - family size (binary: 'LE3' - less or equal to 3 or 'GT3' - greater than 3)6 Pstatus - parent's cohabitation status (binary: 'T' - living together or 'A' - apart)7 Medu - mother's education (numeric: 0 - none,  1 - primary education (4th grade), 2 Ã¢â‚¬â€œ 5th to 9th grade, 3 Ã¢â‚¬â€œ secondary education or 4 Ã¢â‚¬â€œ higher education)8 Fedu - father's education (numeric: 0 - none,  1 - primary education (4th grade), 2 Ã¢â‚¬â€œ 5th to 9th grade, 3 Ã¢â‚¬â€œ secondary education or 4 Ã¢â‚¬â€œ higher education)9 Mjob - mother's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other')10 Fjob - father's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other')11 reason - reason to choose this school (nominal: close to 'home', school 'reputation', 'course' preference or 'other')12 guardian - student's guardian (nominal: 'mother', 'father' or 'other')13 traveltime - home to school travel time (numeric: 1 - <15 min., 2 - 15 to 30 min., 3 - 30 min. to 1 hour, or 4 - >1 hour)14 studytime - weekly study time (numeric: 1 - <2 hours, 2 - 2 to 5 hours, 3 - 5 to 10 hours, or 4 - >10 hours)15 failures - number of past class failures (numeric: n if 1<=n<3, else 4)16 schoolsup - extra educational support (binary: yes or no)17 famsup - family educational support (binary: yes or no)18 paid - extra paid classes within the course subject (Math or Portuguese) (binary: yes or no)19 activities - extra-curricular activities (binary: yes or no)20 nursery - attended nursery school (binary: yes or no)21 higher - wants to take higher education (binary: yes or no)22 internet - Internet access at home (binary: yes or no)23 romantic - with a romantic relationship (binary: yes or no)24 famrel - quality of family relationships (numeric: from 1 - very bad to 5 - excellent)25 freetime - free time after school (numeric: from 1 - very low to 5 - very high)26 goout - going out with friends (numeric: from 1 - very low to 5 - very high)27 Dalc - workday alcohol consumption (numeric: from 1 - very low to 5 - very high)28 Walc - weekend alcohol consumption (numeric: from 1 - very low to 5 - very high)29 health - current health status (numeric: from 1 - very bad to 5 - very good)30 absences - number of school absences (numeric: from 0 to 93)# these grades are related with the course subject, Math or Portuguese:31 G1 - first period grade (numeric: from 0 to 20)31 G2 - second period grade (numeric: from 0 to 20)32 G3 - final grade (numeric: from 0 to 20, output target)"
Wisesight Sentiment Corpus,Wisesight Sentiment Corpus,"Social media messages in Thai language with sentiment label (positive, neutral, negative, question).",Wisesight+Sentiment+Corpus,https://archive.ics.uci.edu/ml//machine-learning-databases/00600/,https://archive.ics.uci.edu/ml/datasets/Wisesight+Sentiment+Corpus,"For wisesight-160 and wisesight-1000, which are samples from this corpus in a tokenized form, see [Web Link]For data exploration and classification examples, see Thai Text Classification Benchmarks. [Web Link]Personal data- We trying to exclude any known personally identifiable information from this data set.- Usernames and non-public figure names are removed- Phone numbers are masked (e.g. 088-888-8888, 09-9999-9999, 0-2222-2222)- If you see any personal data still remain in the set, please tell us - so we can remove them.Sentiment value annotation methodology- Sentiment values are assigned by human annotators.- A human annotator put his/her best effort to assign just one label, out of three, to a message.- A message can be ambiguous. When possible, the judgement will be based solely on the text itself.- In some situation, like when the context is missing, the annotator may have to rely on his/her own world knowledge and just guess.- In some cases, the human annotator may have an access to the message's context, like an image. These additional information are not included as part of this corpus.- Agreement, enjoyment, and satisfaction are positive. Disagreement, sadness, and disappointment are negative.- Showing interest in a topic or in a product is counted as positive.- In this sense, a question about a particular product could has a positive sentiment value, if it shows the interest in the product.- Saying that other product or service is better is counted as negative.- General information or news title tend to be counted as neutral.",Social,"A message can has only one label: Question, Negative, Neutral, PositiveAll messages are kept in plaintext files. All files are UTF-8 encoded.One message per line. A newline character in the original message will be replaced with a space.One label per file.q.txt Questions (575 messages)neg.txt Message with negative sentiment (6,823)neu.txt Message with neutral sentiment (14,561)pos.txt Message with positive sentiment (4,778)","Social media messages in Thai language with sentiment label (positive, neutral, negative, question).For wisesight-160 and wisesight-1000, which are samples from this corpus in a tokenized form, see [Web Link]For data exploration and classification examples, see Thai Text Classification Benchmarks. [Web Link]Personal data- We trying to exclude any known personally identifiable information from this data set.- Usernames and non-public figure names are removed- Phone numbers are masked (e.g. 088-888-8888, 09-9999-9999, 0-2222-2222)- If you see any personal data still remain in the set, please tell us - so we can remove them.Sentiment value annotation methodology- Sentiment values are assigned by human annotators.- A human annotator put his/her best effort to assign just one label, out of three, to a message.- A message can be ambiguous. When possible, the judgement will be based solely on the text itself.- In some situation, like when the context is missing, the annotator may have to rely on his/her own world knowledge and just guess.- In some cases, the human annotator may have an access to the message's context, like an image. These additional information are not included as part of this corpus.- Agreement, enjoyment, and satisfaction are positive. Disagreement, sadness, and disappointment are negative.- Showing interest in a topic or in a product is counted as positive.- In this sense, a question about a particular product could has a positive sentiment value, if it shows the interest in the product.- Saying that other product or service is better is counted as negative.- General information or news title tend to be counted as neutral.A message can has only one label: Question, Negative, Neutral, PositiveAll messages are kept in plaintext files. All files are UTF-8 encoded.One message per line. A newline character in the original message will be replaced with a space.One label per file.q.txt Questions (575 messages)neg.txt Message with negative sentiment (6,823)neu.txt Message with neutral sentiment (14,561)pos.txt Message with positive sentiment (4,778)"
Student Loan Relational,Student Loan Relational,Student Loan Relational Domain,Student+Loan+Relational,https://archive.ics.uci.edu/ml//machine-learning-databases/student-loan/,https://archive.ics.uci.edu/ml/datasets/Student+Loan+Relational,The predicate no_payment_due/1 is true for those people who are not required to repay a student loan.  Auxiliary relations can be used to fully discriminate positive from negative instances of no_payment_due/1.  Closed world assumption applies to all auxiliary relations.,Social,,Student Loan Relational DomainThe predicate no_payment_due/1 is true for those people who are not required to repay a student loan.  Auxiliary relations can be used to fully discriminate positive from negative instances of no_payment_due/1.  Closed world assumption applies to all auxiliary relations.nan
NYSK,NYSK,NYSK (New York v. Strauss-Kahn) is a collection of English news articles about the case relating to allegations of sexual assault against the former IMF director Dominique Strauss-Kahn (May 2011).,NYSK,https://archive.ics.uci.edu/ml//machine-learning-databases/00260/,https://archive.ics.uci.edu/ml/datasets/NYSK,"Documents are first obtained via a Web search using AMIEI: an integrated platform for delivering enterprise intelligence, developed by AMI Software ([Web Link]) with the following query: ``dsk'' OR ``strauss-kahn'' OR ``strauss-khan''.NYSK dataset was used to extract topic-sentiment correlation and evolution over time but may be used for other text mining tasks like topic extraction, sentiment analysis, etc.",Social,Documents are then filtered and presented in XML format. All XML fields are self explanatory.,"NYSK (New York v. Strauss-Kahn) is a collection of English news articles about the case relating to allegations of sexual assault against the former IMF director Dominique Strauss-Kahn (May 2011).Documents are first obtained via a Web search using AMIEI: an integrated platform for delivering enterprise intelligence, developed by AMI Software ([Web Link]) with the following query: ``dsk'' OR ``strauss-kahn'' OR ``strauss-khan''.NYSK dataset was used to extract topic-sentiment correlation and evolution over time but may be used for other text mining tasks like topic extraction, sentiment analysis, etc.Documents are then filtered and presented in XML format. All XML fields are self explanatory."
Speaker Accent Recognition,Speaker Accent Recognition,Data set featuring single English words read by speakers from six different countries for accent detection and recognition,Speaker+Accent+Recognition,https://archive.ics.uci.edu/ml//machine-learning-databases/00518/,https://archive.ics.uci.edu/ml/datasets/Speaker+Accent+Recognition,,Social,"Response variable: language = {ES, FR, GE, IT, UK, US} The six possible accents consideredExplanatory variables:X1, X2, ..., X12 Obtained using MFCC on the original time domain soundtrack of the maximum 1s of reading of a word","Data set featuring single English words read by speakers from six different countries for accent detection and recognitionnanResponse variable: language = {ES, FR, GE, IT, UK, US} The six possible accents consideredExplanatory variables:X1, X2, ..., X12 Obtained using MFCC on the original time domain soundtrack of the maximum 1s of reading of a word"
Gender by Name,Gender by Name,"This dataset attributes first names to genders, giving counts and probabilities.  It combines open-source government data from the US, UK, Canada, and Australia.
",Gender+by+Name,https://archive.ics.uci.edu/ml//machine-learning-databases/00591/,https://archive.ics.uci.edu/ml/datasets/Gender+by+Name,"This dataset combines raw counts for first/given names of male and female babies in those time periods, and then calculates a probability for a name given the aggregate count.  Source datasets are from government authorities:-US: Baby Names from Social Security Card Applications - National Data, 1880 to 2019-UK:  Baby names in England and Wales Statistical bulletins, 2011 to 2018-Canada: British Columbia 100 Years of Popular Baby names, 1918 to 2018-Australia:  Popular Baby Names, Attorney-General's Department, 1944 to 2019",Social,Name:  String	Gender:  M/F (category/string)Count: IntegerProbability: Float,"This dataset attributes first names to genders, giving counts and probabilities.  It combines open-source government data from the US, UK, Canada, and Australia.
This dataset combines raw counts for first/given names of male and female babies in those time periods, and then calculates a probability for a name given the aggregate count.  Source datasets are from government authorities:-US: Baby Names from Social Security Card Applications - National Data, 1880 to 2019-UK:  Baby names in England and Wales Statistical bulletins, 2011 to 2018-Canada: British Columbia 100 Years of Popular Baby names, 1918 to 2018-Australia:  Popular Baby Names, Attorney-General's Department, 1944 to 2019Name:  String	Gender:  M/F (category/string)Count: IntegerProbability: Float"
A study of  Asian Religious and Biblical Texts,A study of  Asian Religious and Biblical Texts,"Mainly from Project Gutenberg, we combine Upanishads, Yoga Sutras, Buddha Sutras, Tao Te Ching and Book of Wisdom, Book of Proverbs, Book of Ecclesiastes and Book of Ecclesiasticus ",A+study+of++Asian+Religious+and+Biblical+Texts,https://archive.ics.uci.edu/ml//machine-learning-databases/00512/,https://archive.ics.uci.edu/ml/datasets/A+study+of++Asian+Religious+and+Biblical+Texts,"Most of the sacred texts in this dataset were collected from Project Gutenberg. We herein provide the raw texts along with our pre-processed Document Term Matrices (DTM). For more details, please contact the authors",Social,The attributes are just the words from the bag of words preprocessing of the  mini-corpus made up of the 8 religious books considered in this study. There are 8265 words used,"Mainly from Project Gutenberg, we combine Upanishads, Yoga Sutras, Buddha Sutras, Tao Te Ching and Book of Wisdom, Book of Proverbs, Book of Ecclesiastes and Book of Ecclesiasticus Most of the sacred texts in this dataset were collected from Project Gutenberg. We herein provide the raw texts along with our pre-processed Document Term Matrices (DTM). For more details, please contact the authorsThe attributes are just the words from the bag of words preprocessing of the  mini-corpus made up of the 8 religious books considered in this study. There are 8265 words used"
Adult,Adult,"Predict whether income exceeds $50K/yr based on census data.  Also known as ""Census Income"" dataset.",Adult,https://archive.ics.uci.edu/ml//machine-learning-databases/adult/,https://archive.ics.uci.edu/ml/datasets/Adult,Extraction was done by Barry Becker from the 1994 Census database.  A set of reasonably clean records was extracted using the following conditions: ((AAGE>16) && (AGI>100) && (AFNLWGT>1)&& (HRSWK>0))Prediction task is to determine whether a person makes over 50K a year.,Social,"Listing of attributes:>50K, <=50K.age: continuous.workclass: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.fnlwgt: continuous.education: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool.education-num: continuous.marital-status: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.occupation: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.relationship: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.race: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.sex: Female, Male.capital-gain: continuous.capital-loss: continuous.hours-per-week: continuous.native-country: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands.","Predict whether income exceeds $50K/yr based on census data.  Also known as ""Census Income"" dataset.Extraction was done by Barry Becker from the 1994 Census database.  A set of reasonably clean records was extracted using the following conditions: ((AAGE>16) && (AGI>100) && (AFNLWGT>1)&& (HRSWK>0))Prediction task is to determine whether a person makes over 50K a year.Listing of attributes:>50K, <=50K.age: continuous.workclass: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.fnlwgt: continuous.education: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool.education-num: continuous.marital-status: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.occupation: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.relationship: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.race: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.sex: Female, Male.capital-gain: continuous.capital-loss: continuous.hours-per-week: continuous.native-country: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands."
Real-time Election Results: Portugal 2019,Real-time Election Results: Portugal 2019,Data set of the real-time election results of the 2019 Portuguese Parliamentary Election.,Real-time+Election+Results%3A+Portugal+2019,https://archive.ics.uci.edu/ml//machine-learning-databases/00513/,https://archive.ics.uci.edu/ml/datasets/Real-time+Election+Results%3A+Portugal+2019,"A data set describing the evolution of results in the Portuguese Parliamentary Elections of October 6th 2019. The data spans a time interval of 4 hours and 25 minutes, in intervals of 5 minutes, concerning the results of the 27 parties involved in the electoral event. The data set is tailored for predictive modelling tasks, mostly focused on numerical forecasting tasks. Regardless, it allows for other tasks such as ordinal regression or learn-to-rankProvide a short description of your data set (less than 200 characters).Additional (and updated) information may be found in [Web Link] :- Raw data sets- R code to build the final data set- Basic operations to build predictive modelling tasks using this data set",Social,TimeElapsed (Numeric): Time (minutes) passed since the first data acquisitiontime (timestamp): Date and time of the data acquisitionterritoryName (string): Short name of the location (district or nation-wide)totalMandates (numeric): MP's elected at the momentavailableMandates (numeric): MP's left to elect at the momentnumParishes (numeric): Total number of parishes in this locationnumParishesApproved (numeric): Number of parishes approved in this locationblankVotes (numeric): Number of blank votesblankVotesPercentage (numeric): Percentage of blank votesnullVotes (numeric): Number of null votesnullVotesPercentage (numeric): Percentage of null votesvotersPercentage (numeric): Percentage of voterssubscribedVoters (numeric): Number of subscribed voters in the locationtotalVoters (numeric): Percentage of blank votespre.blankVotes (numeric): Number of blank votes (previous election)pre.blankVotesPercentage (numeric): Percentage of blank votes (previous election)pre.nullVotes (numeric): Number of null votes (previous election)pre.nullVotesPercentage (numeric): Percentage of null votes (previous election)pre.votersPercentage (numeric): Percentage of voters (previous election)pre.subscribedVoters (numeric): Number of subscribed voters in the location (previous election)pre.totalVoters (numeric): Percentage of blank votes (previous election)Party (string): Political PartyMandates (numeric): MP's elected at the moment for the party in a given districtPercentage (numeric): Percentage of votes in a partyvalidVotesPercentage (numeric): Percentage of valid votes in a partyVotes (numeric): Percentage of party votesHondt (numeric): Number of MP's according to the distribution of votes nowFinalMandates (numeric): Target: final number of elected MP's in a district/national-level,"Data set of the real-time election results of the 2019 Portuguese Parliamentary Election.A data set describing the evolution of results in the Portuguese Parliamentary Elections of October 6th 2019. The data spans a time interval of 4 hours and 25 minutes, in intervals of 5 minutes, concerning the results of the 27 parties involved in the electoral event. The data set is tailored for predictive modelling tasks, mostly focused on numerical forecasting tasks. Regardless, it allows for other tasks such as ordinal regression or learn-to-rankProvide a short description of your data set (less than 200 characters).Additional (and updated) information may be found in [Web Link] :- Raw data sets- R code to build the final data set- Basic operations to build predictive modelling tasks using this data setTimeElapsed (Numeric): Time (minutes) passed since the first data acquisitiontime (timestamp): Date and time of the data acquisitionterritoryName (string): Short name of the location (district or nation-wide)totalMandates (numeric): MP's elected at the momentavailableMandates (numeric): MP's left to elect at the momentnumParishes (numeric): Total number of parishes in this locationnumParishesApproved (numeric): Number of parishes approved in this locationblankVotes (numeric): Number of blank votesblankVotesPercentage (numeric): Percentage of blank votesnullVotes (numeric): Number of null votesnullVotesPercentage (numeric): Percentage of null votesvotersPercentage (numeric): Percentage of voterssubscribedVoters (numeric): Number of subscribed voters in the locationtotalVoters (numeric): Percentage of blank votespre.blankVotes (numeric): Number of blank votes (previous election)pre.blankVotesPercentage (numeric): Percentage of blank votes (previous election)pre.nullVotes (numeric): Number of null votes (previous election)pre.nullVotesPercentage (numeric): Percentage of null votes (previous election)pre.votersPercentage (numeric): Percentage of voters (previous election)pre.subscribedVoters (numeric): Number of subscribed voters in the location (previous election)pre.totalVoters (numeric): Percentage of blank votes (previous election)Party (string): Political PartyMandates (numeric): MP's elected at the moment for the party in a given districtPercentage (numeric): Percentage of votes in a partyvalidVotesPercentage (numeric): Percentage of valid votes in a partyVotes (numeric): Percentage of party votesHondt (numeric): Number of MP's according to the distribution of votes nowFinalMandates (numeric): Target: final number of elected MP's in a district/national-level"
US Census Data (1990),US Census Data (1990),The USCensus1990raw data set contains a one percent sample of the Public Use Microdata Samples (PUMS) person records drawn from the full 1990 census sample.,US+Census+Data+%281990%29,https://archive.ics.uci.edu/ml//machine-learning-databases/census1990-mld/,https://archive.ics.uci.edu/ml/datasets/US+Census+Data+%281990%29,"The data was collected as part of the 1990 census. There are 68 categorical attributes. This data set was derived from the USCensus1990raw data set. The attributes are listed in the file USCensus1990.attributes.txt (repeated below) and the coding for the values is described below. Many of the less useful attributes in the original data set have been dropped, the few continuous variables have been discretized and the few discrete variables that have a large number of possible values have been collapsed to have fewer possible values. More specifically the USCensus1990 data set was obtained from the USCensus1990raw data set by the following sequence of operations; - Randomization: The order of the cases in the original USCensus1990raw data set were randomly permuted. - Selection of attributes: The 68 attributes included in the data set are given below. In the USCensus1990 data set we have added a single letter prefix to the original name. We add the letter 'i' to indicate that the original attribute values are used and 'd' to indicate that original attribute values for each case have been mapped to new values (the precise mapping is described below). Hierarchies of values are provided in the file USCensus1990raw.coding.htm and the mapping functions used to transform the USCensus1990raw to the USCensus1990 data sets are giving in the file USCensus1990.mapping.sql. The data is contained in a file called USCensus1990.data.txt. The first row contains the list of attributes. The first attribute is a caseid and should be ignored during analysis. The data is comma delimited with one case per row. ",Social,"      --------------------------------------------------------------        Old Variable        New Variable      --------------------------------------------------------------        Age         dAge        Ancstry1        dAncstry1        Ancstry2        dAncstry2        Avail           iAvail        Citizen         iCitizen        Class           iClass        Depart          dDepart        Disabl1         iDisabl1        Disabl2         iDisabl2        English         iEnglish        Feb55           iFeb55        Fertil          iFertil        Hispanic        dHispanic        Hour89          dHour89        Hours           dHours        Immigr          iImmigr        Income1         dIncome1        Income2         dIncome2        Income3         dIncome3        Income4         dIncome4        Income5         dIncome5        Income6         dIncome6        Income7         dIncome7        Income8         dIncome8        Industry        dIndustry        Korean          iKorean        Lang1           iLang1        Looking         iLooking        Marital         iMarital        May75880        iMay75880        Means           iMeans        Military        iMilitary        Mobility        iMobility        Mobillim        iMobillim        Occup           dOccup        Othrserv        iOthrserv        Perscare        iPerscare        POB         dPOB        Poverty         dPoverty        Pwgt1           dPwgt1        Ragechld        iRagechld        Rearning        dRearning        Relat1          iRelat1        Relat2          iRelat2        Remplpar        iRemplpar        Riders          iRiders        Rlabor          iRlabor        Rownchld        iRownchld        Rpincome        dRpincome        RPOB            iRPOB        Rrelchld        iRrelchld        Rspouse         iRspouse        Rvetserv        iRvetserv        School          iSchool        Sept80          iSept80        Sex         iSex        Subfam1         iSubfam1        Subfam2         iSubfam2        Tmpabsnt        iTmpabsnt        Travtime        dTravtime        Vietnam         iVietnam        Week89          dWeek89        Work89          iWork89        Worklwk         iWorklwk        WWII            iWWII        Yearsch         iYearsch        Yearwrk         iYearwrk        Yrsserv         dYrsservMapping: In this step we map all of the old values for variables with prefix 'd' to new values. The mappings for the variables dAncstry1, dAncstry2, dHispanic, dIndustry, dOccup, dPOB were designed to correspond to a natural coarsening of the original values based on the information in the file coding.htm. The remaining variables are continuous valued variables and the mapping for these variables was chosen to make variables that were fairly uniformly distributed across the states (quantiles). The precise mappings are specified in the file USCensus1990.mapping.sql. This file contains all of T-SQL procedures used to map the variables. These procedures can be used directly in SQLServer to map the original values or translated to some other language.       --------------------------------------------------------------        Variable        Procedure      --------------------------------------------------------------        dAge            discAge        dAncstry1       discAncstry1        dAncstry2       discAncstry2        dHispanic       discHispanic        dHour89         discHour89        dHours          discHours        dIncome1        discIncome1        dIncome2        discIncome2to8        dIncome3        discIncome2to8        dIncome4        discIncome2to8        dIncome5        discIncome2to8        dIncome6        discIncome2to8        dIncome7        discIncome2to8        dIncome8        discIncome2to8        dIndustry       discIndustry        dOccup          discOccup        dPOB            discPOB        dPoverty        discPoverty        dPwgt1          discPwgt1        dRearning       discRearning        dRpincome       discRpincome        dTravtime       discTravtime        dWeek89         discWeek89        dYrsserv        discYrsserv","The USCensus1990raw data set contains a one percent sample of the Public Use Microdata Samples (PUMS) person records drawn from the full 1990 census sample.The data was collected as part of the 1990 census. There are 68 categorical attributes. This data set was derived from the USCensus1990raw data set. The attributes are listed in the file USCensus1990.attributes.txt (repeated below) and the coding for the values is described below. Many of the less useful attributes in the original data set have been dropped, the few continuous variables have been discretized and the few discrete variables that have a large number of possible values have been collapsed to have fewer possible values. More specifically the USCensus1990 data set was obtained from the USCensus1990raw data set by the following sequence of operations; - Randomization: The order of the cases in the original USCensus1990raw data set were randomly permuted. - Selection of attributes: The 68 attributes included in the data set are given below. In the USCensus1990 data set we have added a single letter prefix to the original name. We add the letter 'i' to indicate that the original attribute values are used and 'd' to indicate that original attribute values for each case have been mapped to new values (the precise mapping is described below). Hierarchies of values are provided in the file USCensus1990raw.coding.htm and the mapping functions used to transform the USCensus1990raw to the USCensus1990 data sets are giving in the file USCensus1990.mapping.sql. The data is contained in a file called USCensus1990.data.txt. The first row contains the list of attributes. The first attribute is a caseid and should be ignored during analysis. The data is comma delimited with one case per row.       --------------------------------------------------------------        Old Variable        New Variable      --------------------------------------------------------------        Age         dAge        Ancstry1        dAncstry1        Ancstry2        dAncstry2        Avail           iAvail        Citizen         iCitizen        Class           iClass        Depart          dDepart        Disabl1         iDisabl1        Disabl2         iDisabl2        English         iEnglish        Feb55           iFeb55        Fertil          iFertil        Hispanic        dHispanic        Hour89          dHour89        Hours           dHours        Immigr          iImmigr        Income1         dIncome1        Income2         dIncome2        Income3         dIncome3        Income4         dIncome4        Income5         dIncome5        Income6         dIncome6        Income7         dIncome7        Income8         dIncome8        Industry        dIndustry        Korean          iKorean        Lang1           iLang1        Looking         iLooking        Marital         iMarital        May75880        iMay75880        Means           iMeans        Military        iMilitary        Mobility        iMobility        Mobillim        iMobillim        Occup           dOccup        Othrserv        iOthrserv        Perscare        iPerscare        POB         dPOB        Poverty         dPoverty        Pwgt1           dPwgt1        Ragechld        iRagechld        Rearning        dRearning        Relat1          iRelat1        Relat2          iRelat2        Remplpar        iRemplpar        Riders          iRiders        Rlabor          iRlabor        Rownchld        iRownchld        Rpincome        dRpincome        RPOB            iRPOB        Rrelchld        iRrelchld        Rspouse         iRspouse        Rvetserv        iRvetserv        School          iSchool        Sept80          iSept80        Sex         iSex        Subfam1         iSubfam1        Subfam2         iSubfam2        Tmpabsnt        iTmpabsnt        Travtime        dTravtime        Vietnam         iVietnam        Week89          dWeek89        Work89          iWork89        Worklwk         iWorklwk        WWII            iWWII        Yearsch         iYearsch        Yearwrk         iYearwrk        Yrsserv         dYrsservMapping: In this step we map all of the old values for variables with prefix 'd' to new values. The mappings for the variables dAncstry1, dAncstry2, dHispanic, dIndustry, dOccup, dPOB were designed to correspond to a natural coarsening of the original values based on the information in the file coding.htm. The remaining variables are continuous valued variables and the mapping for these variables was chosen to make variables that were fairly uniformly distributed across the states (quantiles). The precise mappings are specified in the file USCensus1990.mapping.sql. This file contains all of T-SQL procedures used to map the variables. These procedures can be used directly in SQLServer to map the original values or translated to some other language.       --------------------------------------------------------------        Variable        Procedure      --------------------------------------------------------------        dAge            discAge        dAncstry1       discAncstry1        dAncstry2       discAncstry2        dHispanic       discHispanic        dHour89         discHour89        dHours          discHours        dIncome1        discIncome1        dIncome2        discIncome2to8        dIncome3        discIncome2to8        dIncome4        discIncome2to8        dIncome5        discIncome2to8        dIncome6        discIncome2to8        dIncome7        discIncome2to8        dIncome8        discIncome2to8        dIndustry       discIndustry        dOccup          discOccup        dPOB            discPOB        dPoverty        discPoverty        dPwgt1          discPwgt1        dRearning       discRearning        dRpincome       discRpincome        dTravtime       discTravtime        dWeek89         discWeek89        dYrsserv        discYrsserv"
Kinship,Kinship,Relational dataset,Kinship,https://archive.ics.uci.edu/ml//machine-learning-databases/kinship/,https://archive.ics.uci.edu/ml/datasets/Kinship,"This relational database consists of 24 unique names in two families (they have equivalent structures).  Hinton used one unique output unit for each person and was interested in predicting the following relations: wife, husband, mother, father, daughter, son, sister, brother, aunt, uncle, niece, and nephew.  Hinton used 104 input-output vector pairs (from a space of 12x24=288 possible pairs).  The prediction task is as follows: given a name and a relation, have the outputs be on for only those individuals (among the 24) that satisfy the relation.  The outputs for all other individuals should be off.Hinton's results: Using 100 vectors as input and 4 for testing, his results on two passes yielded 7 correct responses out of 8.  His network of 36 input units, 3 layers of hidden units, and 24 output units used 500 sweeps of the training set during training.Quinlan's results: Using FOIL, he repeated the experiment 20 times (rather than Hinton's 2 times).  FOIL was correct 78 out of 80 times on the test cases.  ",Social,   -- The relation names are:      wife      husband      mother      father      daughter      son      sister      brother      aunt      uncle      niece      nephew,"Relational datasetThis relational database consists of 24 unique names in two families (they have equivalent structures).  Hinton used one unique output unit for each person and was interested in predicting the following relations: wife, husband, mother, father, daughter, son, sister, brother, aunt, uncle, niece, and nephew.  Hinton used 104 input-output vector pairs (from a space of 12x24=288 possible pairs).  The prediction task is as follows: given a name and a relation, have the outputs be on for only those individuals (among the 24) that satisfy the relation.  The outputs for all other individuals should be off.Hinton's results: Using 100 vectors as input and 4 for testing, his results on two passes yielded 7 correct responses out of 8.  His network of 36 input units, 3 layers of hidden units, and 24 output units used 500 sweeps of the training set during training.Quinlan's results: Using FOIL, he repeated the experiment 20 times (rather than Hinton's 2 times).  FOIL was correct 78 out of 80 times on the test cases.     -- The relation names are:      wife      husband      mother      father      daughter      son      sister      brother      aunt      uncle      niece      nephew"
IPUMS Census Database,IPUMS Census Database,"This data set contains unweighted PUMS census data from the Los Angeles and Long Beach areas for the years 1970, 1980, and 1990.",IPUMS+Census+Database,https://archive.ics.uci.edu/ml//machine-learning-databases/ipums-mld/,https://archive.ics.uci.edu/ml/datasets/IPUMS+Census+Database,"The original source for this data set is the IPUMS project (RugglesSobek, 1997). The IPUMS project is a large collection of federal census data which has standardized coding schemes to make comparisons across time easy.The data is an unweighted 1 in 100 sample of responses from the Los Angeles -- Long Beach area for the years 1970, 1980, and 1990. The household and individual records were flattened into a single table and we used all variables that were available for all three years. When there was more than one version of a variable, such as for race, we used the most general. For occupation and industry we used the 1950 basis.Note that PUMS data is based on cluster samples, i.e. samples are made of households or dwellings from which there may be multiple individuals. Individuals from the same household are no longer independent. Ruggles (1995) considers this issue further and discusses its effect (along with the effects of stratification) on standard errors.The variable schltype appears to have different coding values across the years 1970, 1980, and 1990.There are two versions of this data set:1. The Small Data SetThe small data set contains a 1 in 1000 sample of the Los Angeles and Long Beach area. It was formed by sampling from the large data set.2. The Large Data SetThe large data set contains a 1 in 100 sample of the Los Angeles and Long Beach area.",Social,Please see ipums.la.names,"This data set contains unweighted PUMS census data from the Los Angeles and Long Beach areas for the years 1970, 1980, and 1990.The original source for this data set is the IPUMS project (RugglesSobek, 1997). The IPUMS project is a large collection of federal census data which has standardized coding schemes to make comparisons across time easy.The data is an unweighted 1 in 100 sample of responses from the Los Angeles -- Long Beach area for the years 1970, 1980, and 1990. The household and individual records were flattened into a single table and we used all variables that were available for all three years. When there was more than one version of a variable, such as for race, we used the most general. For occupation and industry we used the 1950 basis.Note that PUMS data is based on cluster samples, i.e. samples are made of households or dwellings from which there may be multiple individuals. Individuals from the same household are no longer independent. Ruggles (1995) considers this issue further and discusses its effect (along with the effects of stratification) on standard errors.The variable schltype appears to have different coding values across the years 1970, 1980, and 1990.There are two versions of this data set:1. The Small Data SetThe small data set contains a 1 in 1000 sample of the Los Angeles and Long Beach area. It was formed by sampling from the large data set.2. The Large Data SetThe large data set contains a 1 in 100 sample of the Los Angeles and Long Beach area.Please see ipums.la.names"
Bike Sharing Dataset,Bike Sharing Dataset,This dataset contains the hourly and daily count of rental bikes between years 2011 and 2012 in Capital bikeshare system with the corresponding weather and seasonal information.,Bike+Sharing+Dataset,https://archive.ics.uci.edu/ml//machine-learning-databases/00275/,https://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset,"Bike sharing systems are new generation of traditional bike rentals where whole process from membership, rental and return back has become automatic. Through these systems, user is able to easily rent a bike from a particular position and return back at another position. Currently, there are about over 500 bike-sharing programs around the world which is composed of over 500 thousands bicycles. Today, there exists great interest in these systems due to their important role in traffic, environmental and health issues. Apart from interesting real world applications of bike sharing systems, the characteristics of data being generated by these systems make them attractive for the research. Opposed to other transport services such as bus or subway, the duration of travel, departure and arrival position is explicitly recorded in these systems. This feature turns bike sharing system into a virtual sensor network that can be used for sensing mobility in the city. Hence, it is expected that most of important events in the city could be detected via monitoring these data.",Social,"Both hour.csv and day.csv have the following fields, except hr which is not available in day.csv		- instant: record index	- dteday : date	- season : season (1:winter, 2:spring, 3:summer, 4:fall)	- yr : year (0: 2011, 1:2012)	- mnth : month ( 1 to 12)	- hr : hour (0 to 23)	- holiday : weather day is holiday or not (extracted from [Web Link])	- weekday : day of the week	- workingday : if day is neither weekend nor holiday is 1, otherwise is 0.	+ weathersit : 		- 1: Clear, Few clouds, Partly cloudy, Partly cloudy		- 2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist		- 3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds		- 4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog	- temp : Normalized temperature in Celsius. The values are derived via (t-t_min)/(t_max-t_min), t_min=-8, t_max=+39 (only in hourly scale)	- atemp: Normalized feeling temperature in Celsius. The values are derived via (t-t_min)/(t_max-t_min), t_min=-16, t_max=+50 (only in hourly scale)	- hum: Normalized humidity. The values are divided to 100 (max)	- windspeed: Normalized wind speed. The values are divided to 67 (max)	- casual: count of casual users	- registered: count of registered users	- cnt: count of total rental bikes including both casual and registered","This dataset contains the hourly and daily count of rental bikes between years 2011 and 2012 in Capital bikeshare system with the corresponding weather and seasonal information.Bike sharing systems are new generation of traditional bike rentals where whole process from membership, rental and return back has become automatic. Through these systems, user is able to easily rent a bike from a particular position and return back at another position. Currently, there are about over 500 bike-sharing programs around the world which is composed of over 500 thousands bicycles. Today, there exists great interest in these systems due to their important role in traffic, environmental and health issues. Apart from interesting real world applications of bike sharing systems, the characteristics of data being generated by these systems make them attractive for the research. Opposed to other transport services such as bus or subway, the duration of travel, departure and arrival position is explicitly recorded in these systems. This feature turns bike sharing system into a virtual sensor network that can be used for sensing mobility in the city. Hence, it is expected that most of important events in the city could be detected via monitoring these data.Both hour.csv and day.csv have the following fields, except hr which is not available in day.csv		- instant: record index	- dteday : date	- season : season (1:winter, 2:spring, 3:summer, 4:fall)	- yr : year (0: 2011, 1:2012)	- mnth : month ( 1 to 12)	- hr : hour (0 to 23)	- holiday : weather day is holiday or not (extracted from [Web Link])	- weekday : day of the week	- workingday : if day is neither weekend nor holiday is 1, otherwise is 0.	+ weathersit : 		- 1: Clear, Few clouds, Partly cloudy, Partly cloudy		- 2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist		- 3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds		- 4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog	- temp : Normalized temperature in Celsius. The values are derived via (t-t_min)/(t_max-t_min), t_min=-8, t_max=+39 (only in hourly scale)	- atemp: Normalized feeling temperature in Celsius. The values are derived via (t-t_min)/(t_max-t_min), t_min=-16, t_max=+50 (only in hourly scale)	- hum: Normalized humidity. The values are divided to 100 (max)	- windspeed: Normalized wind speed. The values are divided to 67 (max)	- casual: count of casual users	- registered: count of registered users	- cnt: count of total rental bikes including both casual and registered"
Insurance Company Benchmark (COIL 2000),Insurance Company Benchmark (COIL 2000),This data set used in the CoIL 2000 Challenge contains information on customers of an insurance company. The data consists of 86 variables and includes product usage data and socio-demographic data,Insurance+Company+Benchmark+%28COIL+2000%29,https://archive.ics.uci.edu/ml//machine-learning-databases/tic-mld/,https://archive.ics.uci.edu/ml/datasets/Insurance+Company+Benchmark+%28COIL+2000%29,"Information about customers consists of 86 variables and includes product usage data and socio-demographic data derived from zip area codes. The data was supplied by the Dutch data mining company Sentient Machine Research and is based on a real world business problem. The training set contains over 5000 descriptions of customers, including the information of whether or not they have a caravan insurance policy. A test set contains 4000 customers of whom only the organisers know if they have a caravan insurance policy. The data dictionary ([Web Link]) describes the variables used and their values. Note: All the variables starting with M are zipcode variables. They give information on the distribution of that variable, e.g. Rented house, in the zipcode area of the customer. One instance per line with tab delimited fields. TICDATA2000.txt: Dataset to train and validate prediction models and build a description (5822 customer records). Each record consists of 86 attributes, containing sociodemographic data (attribute 1-43) and product ownership (attributes 44-86).The sociodemographic data is derived from zip codes. All customers living in areas with the same zip code have the same sociodemographic attributes. Attribute 86, ""CARAVAN:Number of mobile home policies"", is the target variable. TICEVAL2000.txt: Dataset for predictions (4000 customer records). It has the same format as TICDATA2000.txt, only the target is missing. Participants are supposed to return the list of predicted targets only. All datasets are in tab delimited format. The meaning of the attributes and attribute values is given below. TICTGTS2000.txt Targets for the evaluation set. ",Social,,"This data set used in the CoIL 2000 Challenge contains information on customers of an insurance company. The data consists of 86 variables and includes product usage data and socio-demographic dataInformation about customers consists of 86 variables and includes product usage data and socio-demographic data derived from zip area codes. The data was supplied by the Dutch data mining company Sentient Machine Research and is based on a real world business problem. The training set contains over 5000 descriptions of customers, including the information of whether or not they have a caravan insurance policy. A test set contains 4000 customers of whom only the organisers know if they have a caravan insurance policy. The data dictionary ([Web Link]) describes the variables used and their values. Note: All the variables starting with M are zipcode variables. They give information on the distribution of that variable, e.g. Rented house, in the zipcode area of the customer. One instance per line with tab delimited fields. TICDATA2000.txt: Dataset to train and validate prediction models and build a description (5822 customer records). Each record consists of 86 attributes, containing sociodemographic data (attribute 1-43) and product ownership (attributes 44-86).The sociodemographic data is derived from zip codes. All customers living in areas with the same zip code have the same sociodemographic attributes. Attribute 86, ""CARAVAN:Number of mobile home policies"", is the target variable. TICEVAL2000.txt: Dataset for predictions (4000 customer records). It has the same format as TICDATA2000.txt, only the target is missing. Participants are supposed to return the list of predicted targets only. All datasets are in tab delimited format. The meaning of the attributes and attribute values is given below. TICTGTS2000.txt Targets for the evaluation set. nan"
Census Income,Census Income,"Predict whether income exceeds $50K/yr based on census data.  Also known as ""Adult"" dataset.",Census+Income,https://archive.ics.uci.edu/ml//machine-learning-databases/adult/,https://archive.ics.uci.edu/ml/datasets/Census+Income,Extraction was done by Barry Becker from the 1994 Census database.  A set of reasonably clean records was extracted using the following conditions: ((AAGE>16) && (AGI>100) && (AFNLWGT>1)&& (HRSWK>0))Prediction task is to determine whether a person makes over 50K a year.,Social,"Listing of attributes:>50K, <=50K.age: continuous.workclass: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.fnlwgt: continuous.education: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool.education-num: continuous.marital-status: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.occupation: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.relationship: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.race: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.sex: Female, Male.capital-gain: continuous.capital-loss: continuous.hours-per-week: continuous.native-country: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands.","Predict whether income exceeds $50K/yr based on census data.  Also known as ""Adult"" dataset.Extraction was done by Barry Becker from the 1994 Census database.  A set of reasonably clean records was extracted using the following conditions: ((AAGE>16) && (AGI>100) && (AFNLWGT>1)&& (HRSWK>0))Prediction task is to determine whether a person makes over 50K a year.Listing of attributes:>50K, <=50K.age: continuous.workclass: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.fnlwgt: continuous.education: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool.education-num: continuous.marital-status: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.occupation: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.relationship: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.race: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.sex: Female, Male.capital-gain: continuous.capital-loss: continuous.hours-per-week: continuous.native-country: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands."
BlogFeedback,BlogFeedback,Instances in this dataset contain features extracted from blog posts. The task associated with the data is to predict how many comments the post will receive.,BlogFeedback,https://archive.ics.uci.edu/ml//machine-learning-databases/00304/,https://archive.ics.uci.edu/ml/datasets/BlogFeedback,"This data originates from blog posts. The raw HTML-documents of the blog posts were crawled and processed. The prediction task associated with the data is the prediction of the number of comments in the upcoming 24 hours. In order to simulate this situation, we choose a basetime (in the past) and select the blog posts that were published at most72 hours before the selected base date/time. Then, we calculateall the features of the selected blog posts from the information that was available at the basetime, therefore each instance corresponds to a blog post. The target is the number of comments that the blog post received in the next 24 hours relative to the basetime. In the train data, the basetimes were in the years 2010 and 2011. In the test data the basetimes were in February and March 2012. This simulates the real-world situtation in which training data from the past is available to predict events in the future.The train data was generated from different basetimes that may temporally overlap. Therefore, if you simply split the train into disjoint partitions, the underlying time intervals may overlap. Therefore, the you should use the provided, temporally disjoint train and test splits in order to ensure that theevaluation is fair. ",Social,"1...50:       Average, standard deviation, min, max and median of the       Attributes 51...60 for the source of the current blog post      With source we mean the blog on which the post appeared.       For example, myblog.blog.org would be the source of       the post myblog.blog.org/post_2010_09_10 51:   Total number of comments before basetime52:   Number of comments in the last 24 hours before the       basetime53:   Let T1 denote the datetime 48 hours before basetime,      Let T2 denote the datetime 24 hours before basetime.      This attribute is the number of comments in the time period       between T1 and T254:   Number of comments in the first 24 hours after the       publication of the blog post, but before basetime55:   The difference of Attribute 52 and Attribute 5356...60:       The same features as the attributes 51...55, but        features 56...60 refer to the number of links (trackbacks),       while features 51...55 refer to the number of comments.61:   The length of time between the publication of the blog post       and basetime62:   The length of the blog post63...262:       The 200 bag of words features for 200 frequent words of the       text of the blog post263...269: binary indicator features (0 or 1) for the weekday      (Monday...Sunday) of the basetime270...276: binary indicator features (0 or 1) for the weekday      (Monday...Sunday) of the date of publication of the blog      post277:  Number of parent pages: we consider a blog post P as a      parent of blog post B, if B is a reply (trackback) to       blog post P.278...280:        Minimum, maximum, average number of comments that the       parents received281:  The target: the number of comments in the next 24 hours      (relative to basetime)","Instances in this dataset contain features extracted from blog posts. The task associated with the data is to predict how many comments the post will receive.This data originates from blog posts. The raw HTML-documents of the blog posts were crawled and processed. The prediction task associated with the data is the prediction of the number of comments in the upcoming 24 hours. In order to simulate this situation, we choose a basetime (in the past) and select the blog posts that were published at most72 hours before the selected base date/time. Then, we calculateall the features of the selected blog posts from the information that was available at the basetime, therefore each instance corresponds to a blog post. The target is the number of comments that the blog post received in the next 24 hours relative to the basetime. In the train data, the basetimes were in the years 2010 and 2011. In the test data the basetimes were in February and March 2012. This simulates the real-world situtation in which training data from the past is available to predict events in the future.The train data was generated from different basetimes that may temporally overlap. Therefore, if you simply split the train into disjoint partitions, the underlying time intervals may overlap. Therefore, the you should use the provided, temporally disjoint train and test splits in order to ensure that theevaluation is fair. 1...50:       Average, standard deviation, min, max and median of the       Attributes 51...60 for the source of the current blog post      With source we mean the blog on which the post appeared.       For example, myblog.blog.org would be the source of       the post myblog.blog.org/post_2010_09_10 51:   Total number of comments before basetime52:   Number of comments in the last 24 hours before the       basetime53:   Let T1 denote the datetime 48 hours before basetime,      Let T2 denote the datetime 24 hours before basetime.      This attribute is the number of comments in the time period       between T1 and T254:   Number of comments in the first 24 hours after the       publication of the blog post, but before basetime55:   The difference of Attribute 52 and Attribute 5356...60:       The same features as the attributes 51...55, but        features 56...60 refer to the number of links (trackbacks),       while features 51...55 refer to the number of comments.61:   The length of time between the publication of the blog post       and basetime62:   The length of the blog post63...262:       The 200 bag of words features for 200 frequent words of the       text of the blog post263...269: binary indicator features (0 or 1) for the weekday      (Monday...Sunday) of the basetime270...276: binary indicator features (0 or 1) for the weekday      (Monday...Sunday) of the date of publication of the blog      post277:  Number of parent pages: we consider a blog post P as a      parent of blog post B, if B is a reply (trackback) to       blog post P.278...280:        Minimum, maximum, average number of comments that the       parents received281:  The target: the number of comments in the next 24 hours      (relative to basetime)"
Drug consumption (quantified),Drug consumption (quantified),Classify type of drug consumer by personality data,Drug+consumption+%28quantified%29,https://archive.ics.uci.edu/ml//machine-learning-databases/00373/,https://archive.ics.uci.edu/ml/datasets/Drug+consumption+%28quantified%29,"Database contains records for 1885 respondents. For each respondent 12 attributes are known: Personality measurements which include NEO-FFI-R (neuroticism, extraversion, openness to experience, agreeableness, and conscientiousness), BIS-11 (impulsivity), and ImpSS (sensation seeking), level of education, age, gender, country of residence and ethnicity. All input attributes are originally categorical and are quantified. After quantification values of all input features can be considered as real-valued. In addition, participants were questioned concerning their use of 18 legal and illegal drugs (alcohol, amphetamines, amyl nitrite, benzodiazepine, cannabis, chocolate, cocaine, caffeine, crack, ecstasy, heroin, ketamine, legal highs, LSD, methadone, mushrooms, nicotine and volatile substance abuse and one fictitious drug (Semeron) which was introduced to identify over-claimers. For each drug they have to select one of the answers: never used the drug, used it over a decade ago, or in the last decade, year, month, week, or day.Database contains 18 classification problems. Each of independent label variables contains seven classes: ""Never Used"", ""Used over a Decade Ago"", ""Used in Last Decade"", ""Used in Last Year"", ""Used in Last Month"", ""Used in Last Week"", and ""Used in Last Day"".Problem which can be solved:* Seven class classifications for each drug separately.* Problem can be transformed to binary classification by union of part of classes into one new class. For example, ""Never Used"", ""Used over a Decade Ago"" form class ""Non-user"" and all other classes form class ""User"".* The best binarization of classes for each attribute.* Evaluation of risk to be drug consumer for each drug.Detailed description of database and process of data quantification are presented in E. Fehrman, A. K. Muhammad, E. M. Mirkes, V. Egan and A. N. Gorban, ""The Five Factor Model of personality and evaluation of drug consumption risk.,"" arXiv [Web Link], 2015Paper above solve binary classification problem for all drugs. For most of drugs sensitivity and specificity are greater than 75%.",Social,"1. ID is number of record in original database. Cannot be related to participant. It can be used for reference only.2. Age (Real) is age of participant and has one of the values:     Value    Meaning Cases Fraction     -0.95197 18-24   643   34.11%     -0.07854 25-34   481   25.52%      0.49788 35-44   356   18.89%      1.09449 45-54   294   15.60%      1.82213 55-64    93    4.93%      2.59171 65+      18    0.95%     Descriptive statistics     Min      Max     Mean    Std.dev.     -0.95197 2.59171 0.03461 0.878133. Gender (Real) is gender of participant:     Value    Meaning Cases Fraction      0.48246 Female  942   49.97%     -0.48246 Male    943   50.03%     Descriptive statistics     Min      Max     Mean     Std.dev.     -0.48246 0.48246 -0.00026 0.482464. Education (Real) is level of education of participant and has one of the values:     Value    Meaning                                              Cases Fraction     -2.43591 Left school before 16 years                           28    1.49%     -1.73790 Left school at 16 years                               99    5.25%     -1.43719 Left school at 17 years                               30    1.59%     -1.22751 Left school at 18 years                              100    5.31%     -0.61113 Some college or university, no certificate or degree 506   26.84%     -0.05921 Professional certificate/ diploma                    270   14.32%      0.45468 University degree                                    480   25.46%      1.16365 Masters degree                                       283   15.01%      1.98437 Doctorate degree                                      89    4.72%     Descriptive statistics     Min      Max     Mean     Std.dev.     -2.43591 1.98437 -0.00379 0.950045. Country (Real) is country of current residence of participant and has one of the values:     Value    Meaning             Cases Fraction     -0.09765 Australia             54   2.86%      0.24923 Canada                87   4.62%     -0.46841 New Zealand            5   0.27%     -0.28519 Other                118   6.26%      0.21128 Republic of Ireland   20   1.06%      0.96082 UK                  1044  55.38%     -0.57009 USA                  557  29.55%     Descriptive statistics     Min      Max     Mean    Std.dev.     -0.57009 0.96082 0.35554 0.700156. Ethnicity (Real) is ethnicity of participant and has one of the values:     Value    Meaning           Cases Fraction     -0.50212 Asian               26   1.38%     -1.10702 Black               33   1.75%      1.90725 Mixed-Black/Asian    3   0.16%      0.12600 Mixed-White/Asian   20   1.06%     -0.22166 Mixed-White/Black   20   1.06%      0.11440 Other               63   3.34%     -0.31685 White             1720  91.25%     Descriptive statistics     Min      Max     Mean     Std.dev.     -1.10702 1.90725 -0.30958 0.166187. Nscore (Real) is NEO-FFI-R Neuroticism. Possible values are presented in table below:     Nscore Cases Value         Nscore Cases Value         Nscore Cases Value     12      1    -3.46436      29     60    -0.67825      46     67    1.02119     13      1    -3.15735      30     61    -0.58016      47     27    1.13281     14      7    -2.75696      31     87    -0.46725      48     49    1.23461     15      4    -2.52197      32     78    -0.34799      49     40    1.37297     16      3    -2.42317      33     68    -0.24649      50     24    1.49158     17      4    -2.34360      34     76    -0.14882      51     27    1.60383     18     10    -2.21844      35     69    -0.05188      52     17    1.72012     19     16    -2.05048      36     73     0.04257      53     20    1.83990     20     24    -1.86962      37     67     0.13606      54     15    1.98437     21     31    -1.69163      38     63     0.22393      55     11    2.12700     22     26    -1.55078      39     66     0.31287      56     10    2.28554     23     29    -1.43907      40     80     0.41667      57      6    2.46262     24     35    -1.32828      41     61     0.52135      58      3    2.61139     25     56    -1.19430      42     77     0.62967      59      5    2.82196     26     57    -1.05308      43     49     0.73545      60      2    3.27393     27     65    -0.92104      44     51     0.82562     28     70    -0.79151      45     37     0.91093     Descriptive statistics     Min      Max     Mean    Std.dev.     -3.46436 3.27393 0.00004 0.998088. Escore (Real) is NEO-FFI-R Extraversion. Possible values are presented in table below:     Escore Cases Value         Escore Cases Value         Escore Cases Value     16      2    -3.27393      31      55   -1.23177      45     91    0.80523     18      1    -3.00537      32      52   -1.09207      46     69    0.96248     19      6    -2.72827      33      77   -0.94779      47     64    1.11406     20      3    -2.53830      34      68   -0.80615      48     62    1.28610     21      3    -2.44904      35      58   -0.69509      49     37    1.45421     22      8    -2.32338      36      89   -0.57545      50     25    1.58487     23      5    -2.21069      37      90   -0.43999      51     34    1.74091     24      9    -2.11437      38     106   -0.30033      52     21    1.93886     25      4    -2.03972      39     107   -0.15487      53     15    2.12700     26     21    -1.92173      40     130    0.00332      54     10    2.32338     27     23    -1.76250      41     116    0.16767      55      9    2.57309     28     23    -1.63340      42     109    0.32197      56      2    2.85950     29     32    -1.50796      43     105    0.47617      58      1    3.00537     30     38    -1.37639      44     103    0.63779      59      2    3.27393     Descriptive statistics     Min      Max     Mean     Std.dev.     -3.27393 3.27393 -0.00016 0.997459. Oscore (Real) is NEO-FFI-R Openness to experience. Possible values are presented in table below:     Oscore Cases Value         Oscore Cases Value         Oscore Cases Value     24      2    -3.27393      38      64   -1.11902      50     83    0.58331     26      4    -2.85950      39      60   -0.97631      51     87    0.72330     28      4    -2.63199      40      68   -0.84732      52     87    0.88309     29     11    -2.39883      41      76   -0.71727      53     81    1.06238     30      9    -2.21069      42      87   -0.58331      54     57    1.24033     31      9    -2.09015      43      86   -0.45174      55     63    1.43533     32     13    -1.97495      44     101   -0.31776      56     38    1.65653     33     23    -1.82919      45     103   -0.17779      57     34    1.88511     34     25    -1.68062      46     134   -0.01928      58     19    2.15324     35     26    -1.55521      47     107    0.14143      59     13    2.44904     36     39    -1.42424      48     116    0.29338      60      7    2.90161     37     51    -1.27553      49      98    0.44585     Descriptive statistics     Min      Max     Mean     Std.dev.     -3.27393 2.90161 -0.00053 0.9962310. Ascore (Real) is NEO-FFI-R Agreeableness. Possible values are presented in table below:     Ascore Cases Value         Ascore Cases Value         Ascore Cases Value     12      1    -3.46436      34      42   -1.34289      48     104   0.76096     16      1    -3.15735      35      45   -1.21213      49      85   0.94156     18      1    -3.00537      36      62   -1.07533      50      68   1.11406     23      1    -2.90161      37      83   -0.91699      51      58   1.2861     24      2    -2.78793      38      82   -0.76096      52      39   1.45039     25      1    -2.70172      39     102   -0.60633      53      36   1.61108     26      7    -2.53830      40      98   -0.45321      54      36   1.81866     27      7    -2.35413      41     114   -0.30172      55      16   2.03972     28      8    -2.21844      42     101   -0.15487      56      14   2.23427     29     13    -2.07848      43     105   -0.01729      57       8   2.46262     30     18    -1.92595      44     118    0.13136      58       7   2.75696     31     24    -1.77200      45     112    0.28783      59       1   3.15735     32     30    -1.62090      46     100    0.43852      60       1   3.46436     33     34    -1.47955      47     100    0.59042                       Descriptive statistics     Min      Max     Mean     Std.dev.     -3.46436 3.46436 -0.00024 0.9974411. Cscore (Real) is NEO-FFI-R Conscientiousness. Possible values are presented in table below:     Cscore Cases Value         Cscore Cases Value         Cscore Cases Value     17      1    -3.46436      32       39  -1.25773      46     113   0.58489     19      1    -3.15735      33       49  -1.13788      47      95   0.7583     20      3    -2.90161      34       55  -1.01450      48      95   0.93949     21      2    -2.72827      35       55  -0.89891      49      76   1.13407     22      5    -2.57309      36       69  -0.78155      50      47   1.30612     23      5    -2.42317      37       81  -0.65253      51      43   1.46191     24      6    -2.30408      38       77  -0.52745      52      34   1.63088     25      9    -2.18109      39       87  -0.40581      53      28   1.81175     26     13    -2.04506      40       97  -0.27607      54      27   2.04506     27     13    -1.92173      41       99  -0.14277      55      13   2.33337     28     25    -1.78169      42      105  -0.00665      56       8   2.63199     29     24    -1.64101      43       90   0.12331      57       3   3.00537     30     29    -1.51840      44      111   0.25953      59       1   3.46436     31     41    -1.38502      45      111   0.41594                       Descriptive statistics     Min      Max     Mean     Std.dev.     -3.46436 3.46436 -0.00039 0.9975212. Impulsive (Real) is impulsiveness measured by BIS-11. Possible values are presented in table below:     Impulsiveness Cases Fraction     -2.55524       20    1.06%     -1.37983      276   14.64%     -0.71126      307   16.29%     -0.21712      355   18.83%      0.19268      257   13.63%      0.52975      216   11.46%      0.88113      195   10.34%      1.29221      148    7.85%      1.86203      104    5.52%      2.90161        7    0.37%     Descriptive statistics     Min      Max     Mean    Std.dev.     -2.55524 2.90161 0.00721 0.9544613. SS (Real) is sensation seeing measured by ImpSS. Possible values are presented in table below:     SS       Cases Fraction     -2.07848  71    3.77%     -1.54858  87    4.62%     -1.18084 132    7.00%     -0.84637 169    8.97%     -0.52593 211   11.19%     -0.21575 223   11.83%      0.07987 219   11.62%      0.40148 249   13.21%      0.76540 211   11.19%      1.22470 210   11.14%      1.92173 103    5.46%     Descriptive statistics     Min      Max     Mean     Std.dev.     -2.07848 1.92173 -0.00329 0.9637014. Alcohol is class of alcohol consumption. It is output attribute with following distribution of classes.15. Amphet is class of amphetamines consumption. It is output attribute with following distribution of classes.16. Amyl is class of amyl nitrite consumption. It is output attribute with following distribution of classes.17. Benzos is class of benzodiazepine consumption. It is output attribute with following distribution of classes:     Value Class                     Alcohol        Amphet          Amyl          Benzos                                  Cases Fraction Cases Fraction Cases Fraction Cases Fraction     CL0   Never Used              34    1.80%   976   51.78%   1305  69.23%   1000  53.05%     CL1   Used over a Decade Ago  34    1.80%   230   12.20%    210  11.14%    116   6.15%     CL2   Used in Last Decade     68    3.61%   243   12.89%    237  12.57%    234  12.41%     CL3   Used in Last Year      198   10.50%   198   10.50%     92   4.88%    236  12.52%     CL4   Used in Last Month     287   15.23%    75    3.98%     24   1.27%    120   6.37%     CL5   Used in Last Week      759   40.27%    61    3.24%     14   0.74%     84   4.46%     CL6   Used in Last Day       505   26.79%   102    5.41%      3   0.16%     95   5.04%18. Caff is class of caffeine consumption. It is output attribute with following distribution of classes.19. Cannabis is class of cannabis consumption. It is output attribute with following distribution of classes.20. Choc is class of chocolate consumption. It is output attribute with following distribution of classes.21. Coke is class of cocaine consumption. It is output attribute with following distribution of classes:     Value Class                      Caff         Cannabis         Choc           Coke                                  Cases Fraction Cases Fraction Cases Fraction Cases Fraction     CL0   Never Used               27   1.43%   413   21.91%    32    1.70%   1038  55.07%     CL1   Used over a Decade Ago   10   0.53%   207   10.98%     3    0.16%    160   8.49%     CL2   Used in Last Decade      24   1.27%   266   14.11%    10    0.53%    270  14.32%     CL3   Used in Last Year        60   3.18%   211   11.19%    54    2.86%    258  13.69%     CL4   Used in Last Month      106   5.62%   140    7.43%   296   15.70%     99   5.25%     CL5   Used in Last Week       273  14.48%   185    9.81%   683   36.23%     41   2.18%     CL6   Used in Last Day       1385  73.47%   463   24.56%   807   42.81%     19   1.01%22. Crack is class of crack consumption. It is output attribute with following distribution of classes.23. Ecstasy is class of ecstasy consumption. It is output attribute with following distribution of classes.24. Heroin is class of heroin consumption. It is output attribute with following distribution of classes.25. Ketamine is class of ketamine consumption. It is output attribute with following distribution of classes:     Value Class                     Crack         Ecstasy         Heroin        Ketamine                                  Cases Fraction Cases Fraction Cases Fraction Cases Fraction     CL0   Never Used             1627  86.31%   1021  54.16%   1605  85.15%   1490  79.05%     CL1   Used over a Decade Ago   67   3.55%    113   5.99%     68   3.61%     45   2.39%     CL2   Used in Last Decade     112   5.94%    234  12.41%     94   4.99%    142   7.53%     CL3   Used in Last Year        59   3.13%    277  14.69%     65   3.45%    129   6.84%     CL4   Used in Last Month        9   0.48%    156   8.28%     24   1.27%     42   2.23%     CL5   Used in Last Week         9   0.48%     63   3.34%     16   0.85%     33   1.75%     CL6   Used in Last Day          2   0.11%     21   1.11%     13   0.69%      4   0.21%26. Legalh is class of legal highs consumption. It is output attribute with following distribution of classes27. LSD is class of alcohol consumption. It is output attribute with following distribution of classes28. Meth is class of methadone consumption. It is output attribute with following distribution of classes.29. Mushrooms is class of magic mushrooms consumption. It is output attribute with following distribution of classes:     Value Class                     Legalh          LSD            Meth         Mushrooms                                  Cases Fraction Cases Fraction Cases Fraction Cases Fraction     CL0   Never Used             1094  58.04%   1069  56.71%   1429  75.81%   982   52.10%     CL1   Used over a Decade Ago   29   1.54%    259  13.74%     39   2.07%   209   11.09%     CL2   Used in Last Decade     198  10.50%    177   9.39%     97   5.15%   260   13.79%     CL3   Used in Last Year       323  17.14%    214  11.35%    149   7.90%   275   14.59%     CL4   Used in Last Month      110   5.84%     97   5.15%     50   2.65%   115    6.10%     CL5   Used in Last Week        64   3.40%     56   2.97%     48   2.55%    40    2.12%     CL6   Used in Last Day         67   3.55%     13   0.69%     73   3.87%     4    0.21%30. Nicotine is class of nicotine consumption. It is output attribute with following distribution of classes.31. Semer is class of fictitious drug Semeron consumption. It is output attribute with following distribution of classes.32. VSA is class of volatile substance abuse consumption. It is output attribute with following distribution of classes:     Value Class                    Nicotine        Semer           VSA                                  Cases Fraction Cases Fraction Cases Fraction     CL0   Never Used             428   22.71%   1877  99.58%   1455  77.19%     CL1   Used over a Decade Ago 193   10.24%      2   0.11%    200  10.61%     CL2   Used in Last Decade    204   10.82%      3   0.16%    135   7.16%     CL3   Used in Last Year      185    9.81%      2   0.11%     61   3.24%     CL4   Used in Last Month     108    5.73%      1   0.05%     13   0.69%     CL5   Used in Last Week      157    8.33%      0   0.00%     14   0.74%     CL6   Used in Last Day       610   32.36%      0   0.00%      7   0.37%","Classify type of drug consumer by personality dataDatabase contains records for 1885 respondents. For each respondent 12 attributes are known: Personality measurements which include NEO-FFI-R (neuroticism, extraversion, openness to experience, agreeableness, and conscientiousness), BIS-11 (impulsivity), and ImpSS (sensation seeking), level of education, age, gender, country of residence and ethnicity. All input attributes are originally categorical and are quantified. After quantification values of all input features can be considered as real-valued. In addition, participants were questioned concerning their use of 18 legal and illegal drugs (alcohol, amphetamines, amyl nitrite, benzodiazepine, cannabis, chocolate, cocaine, caffeine, crack, ecstasy, heroin, ketamine, legal highs, LSD, methadone, mushrooms, nicotine and volatile substance abuse and one fictitious drug (Semeron) which was introduced to identify over-claimers. For each drug they have to select one of the answers: never used the drug, used it over a decade ago, or in the last decade, year, month, week, or day.Database contains 18 classification problems. Each of independent label variables contains seven classes: ""Never Used"", ""Used over a Decade Ago"", ""Used in Last Decade"", ""Used in Last Year"", ""Used in Last Month"", ""Used in Last Week"", and ""Used in Last Day"".Problem which can be solved:* Seven class classifications for each drug separately.* Problem can be transformed to binary classification by union of part of classes into one new class. For example, ""Never Used"", ""Used over a Decade Ago"" form class ""Non-user"" and all other classes form class ""User"".* The best binarization of classes for each attribute.* Evaluation of risk to be drug consumer for each drug.Detailed description of database and process of data quantification are presented in E. Fehrman, A. K. Muhammad, E. M. Mirkes, V. Egan and A. N. Gorban, ""The Five Factor Model of personality and evaluation of drug consumption risk.,"" arXiv [Web Link], 2015Paper above solve binary classification problem for all drugs. For most of drugs sensitivity and specificity are greater than 75%.1. ID is number of record in original database. Cannot be related to participant. It can be used for reference only.2. Age (Real) is age of participant and has one of the values:     Value    Meaning Cases Fraction     -0.95197 18-24   643   34.11%     -0.07854 25-34   481   25.52%      0.49788 35-44   356   18.89%      1.09449 45-54   294   15.60%      1.82213 55-64    93    4.93%      2.59171 65+      18    0.95%     Descriptive statistics     Min      Max     Mean    Std.dev.     -0.95197 2.59171 0.03461 0.878133. Gender (Real) is gender of participant:     Value    Meaning Cases Fraction      0.48246 Female  942   49.97%     -0.48246 Male    943   50.03%     Descriptive statistics     Min      Max     Mean     Std.dev.     -0.48246 0.48246 -0.00026 0.482464. Education (Real) is level of education of participant and has one of the values:     Value    Meaning                                              Cases Fraction     -2.43591 Left school before 16 years                           28    1.49%     -1.73790 Left school at 16 years                               99    5.25%     -1.43719 Left school at 17 years                               30    1.59%     -1.22751 Left school at 18 years                              100    5.31%     -0.61113 Some college or university, no certificate or degree 506   26.84%     -0.05921 Professional certificate/ diploma                    270   14.32%      0.45468 University degree                                    480   25.46%      1.16365 Masters degree                                       283   15.01%      1.98437 Doctorate degree                                      89    4.72%     Descriptive statistics     Min      Max     Mean     Std.dev.     -2.43591 1.98437 -0.00379 0.950045. Country (Real) is country of current residence of participant and has one of the values:     Value    Meaning             Cases Fraction     -0.09765 Australia             54   2.86%      0.24923 Canada                87   4.62%     -0.46841 New Zealand            5   0.27%     -0.28519 Other                118   6.26%      0.21128 Republic of Ireland   20   1.06%      0.96082 UK                  1044  55.38%     -0.57009 USA                  557  29.55%     Descriptive statistics     Min      Max     Mean    Std.dev.     -0.57009 0.96082 0.35554 0.700156. Ethnicity (Real) is ethnicity of participant and has one of the values:     Value    Meaning           Cases Fraction     -0.50212 Asian               26   1.38%     -1.10702 Black               33   1.75%      1.90725 Mixed-Black/Asian    3   0.16%      0.12600 Mixed-White/Asian   20   1.06%     -0.22166 Mixed-White/Black   20   1.06%      0.11440 Other               63   3.34%     -0.31685 White             1720  91.25%     Descriptive statistics     Min      Max     Mean     Std.dev.     -1.10702 1.90725 -0.30958 0.166187. Nscore (Real) is NEO-FFI-R Neuroticism. Possible values are presented in table below:     Nscore Cases Value         Nscore Cases Value         Nscore Cases Value     12      1    -3.46436      29     60    -0.67825      46     67    1.02119     13      1    -3.15735      30     61    -0.58016      47     27    1.13281     14      7    -2.75696      31     87    -0.46725      48     49    1.23461     15      4    -2.52197      32     78    -0.34799      49     40    1.37297     16      3    -2.42317      33     68    -0.24649      50     24    1.49158     17      4    -2.34360      34     76    -0.14882      51     27    1.60383     18     10    -2.21844      35     69    -0.05188      52     17    1.72012     19     16    -2.05048      36     73     0.04257      53     20    1.83990     20     24    -1.86962      37     67     0.13606      54     15    1.98437     21     31    -1.69163      38     63     0.22393      55     11    2.12700     22     26    -1.55078      39     66     0.31287      56     10    2.28554     23     29    -1.43907      40     80     0.41667      57      6    2.46262     24     35    -1.32828      41     61     0.52135      58      3    2.61139     25     56    -1.19430      42     77     0.62967      59      5    2.82196     26     57    -1.05308      43     49     0.73545      60      2    3.27393     27     65    -0.92104      44     51     0.82562     28     70    -0.79151      45     37     0.91093     Descriptive statistics     Min      Max     Mean    Std.dev.     -3.46436 3.27393 0.00004 0.998088. Escore (Real) is NEO-FFI-R Extraversion. Possible values are presented in table below:     Escore Cases Value         Escore Cases Value         Escore Cases Value     16      2    -3.27393      31      55   -1.23177      45     91    0.80523     18      1    -3.00537      32      52   -1.09207      46     69    0.96248     19      6    -2.72827      33      77   -0.94779      47     64    1.11406     20      3    -2.53830      34      68   -0.80615      48     62    1.28610     21      3    -2.44904      35      58   -0.69509      49     37    1.45421     22      8    -2.32338      36      89   -0.57545      50     25    1.58487     23      5    -2.21069      37      90   -0.43999      51     34    1.74091     24      9    -2.11437      38     106   -0.30033      52     21    1.93886     25      4    -2.03972      39     107   -0.15487      53     15    2.12700     26     21    -1.92173      40     130    0.00332      54     10    2.32338     27     23    -1.76250      41     116    0.16767      55      9    2.57309     28     23    -1.63340      42     109    0.32197      56      2    2.85950     29     32    -1.50796      43     105    0.47617      58      1    3.00537     30     38    -1.37639      44     103    0.63779      59      2    3.27393     Descriptive statistics     Min      Max     Mean     Std.dev.     -3.27393 3.27393 -0.00016 0.997459. Oscore (Real) is NEO-FFI-R Openness to experience. Possible values are presented in table below:     Oscore Cases Value         Oscore Cases Value         Oscore Cases Value     24      2    -3.27393      38      64   -1.11902      50     83    0.58331     26      4    -2.85950      39      60   -0.97631      51     87    0.72330     28      4    -2.63199      40      68   -0.84732      52     87    0.88309     29     11    -2.39883      41      76   -0.71727      53     81    1.06238     30      9    -2.21069      42      87   -0.58331      54     57    1.24033     31      9    -2.09015      43      86   -0.45174      55     63    1.43533     32     13    -1.97495      44     101   -0.31776      56     38    1.65653     33     23    -1.82919      45     103   -0.17779      57     34    1.88511     34     25    -1.68062      46     134   -0.01928      58     19    2.15324     35     26    -1.55521      47     107    0.14143      59     13    2.44904     36     39    -1.42424      48     116    0.29338      60      7    2.90161     37     51    -1.27553      49      98    0.44585     Descriptive statistics     Min      Max     Mean     Std.dev.     -3.27393 2.90161 -0.00053 0.9962310. Ascore (Real) is NEO-FFI-R Agreeableness. Possible values are presented in table below:     Ascore Cases Value         Ascore Cases Value         Ascore Cases Value     12      1    -3.46436      34      42   -1.34289      48     104   0.76096     16      1    -3.15735      35      45   -1.21213      49      85   0.94156     18      1    -3.00537      36      62   -1.07533      50      68   1.11406     23      1    -2.90161      37      83   -0.91699      51      58   1.2861     24      2    -2.78793      38      82   -0.76096      52      39   1.45039     25      1    -2.70172      39     102   -0.60633      53      36   1.61108     26      7    -2.53830      40      98   -0.45321      54      36   1.81866     27      7    -2.35413      41     114   -0.30172      55      16   2.03972     28      8    -2.21844      42     101   -0.15487      56      14   2.23427     29     13    -2.07848      43     105   -0.01729      57       8   2.46262     30     18    -1.92595      44     118    0.13136      58       7   2.75696     31     24    -1.77200      45     112    0.28783      59       1   3.15735     32     30    -1.62090      46     100    0.43852      60       1   3.46436     33     34    -1.47955      47     100    0.59042                       Descriptive statistics     Min      Max     Mean     Std.dev.     -3.46436 3.46436 -0.00024 0.9974411. Cscore (Real) is NEO-FFI-R Conscientiousness. Possible values are presented in table below:     Cscore Cases Value         Cscore Cases Value         Cscore Cases Value     17      1    -3.46436      32       39  -1.25773      46     113   0.58489     19      1    -3.15735      33       49  -1.13788      47      95   0.7583     20      3    -2.90161      34       55  -1.01450      48      95   0.93949     21      2    -2.72827      35       55  -0.89891      49      76   1.13407     22      5    -2.57309      36       69  -0.78155      50      47   1.30612     23      5    -2.42317      37       81  -0.65253      51      43   1.46191     24      6    -2.30408      38       77  -0.52745      52      34   1.63088     25      9    -2.18109      39       87  -0.40581      53      28   1.81175     26     13    -2.04506      40       97  -0.27607      54      27   2.04506     27     13    -1.92173      41       99  -0.14277      55      13   2.33337     28     25    -1.78169      42      105  -0.00665      56       8   2.63199     29     24    -1.64101      43       90   0.12331      57       3   3.00537     30     29    -1.51840      44      111   0.25953      59       1   3.46436     31     41    -1.38502      45      111   0.41594                       Descriptive statistics     Min      Max     Mean     Std.dev.     -3.46436 3.46436 -0.00039 0.9975212. Impulsive (Real) is impulsiveness measured by BIS-11. Possible values are presented in table below:     Impulsiveness Cases Fraction     -2.55524       20    1.06%     -1.37983      276   14.64%     -0.71126      307   16.29%     -0.21712      355   18.83%      0.19268      257   13.63%      0.52975      216   11.46%      0.88113      195   10.34%      1.29221      148    7.85%      1.86203      104    5.52%      2.90161        7    0.37%     Descriptive statistics     Min      Max     Mean    Std.dev.     -2.55524 2.90161 0.00721 0.9544613. SS (Real) is sensation seeing measured by ImpSS. Possible values are presented in table below:     SS       Cases Fraction     -2.07848  71    3.77%     -1.54858  87    4.62%     -1.18084 132    7.00%     -0.84637 169    8.97%     -0.52593 211   11.19%     -0.21575 223   11.83%      0.07987 219   11.62%      0.40148 249   13.21%      0.76540 211   11.19%      1.22470 210   11.14%      1.92173 103    5.46%     Descriptive statistics     Min      Max     Mean     Std.dev.     -2.07848 1.92173 -0.00329 0.9637014. Alcohol is class of alcohol consumption. It is output attribute with following distribution of classes.15. Amphet is class of amphetamines consumption. It is output attribute with following distribution of classes.16. Amyl is class of amyl nitrite consumption. It is output attribute with following distribution of classes.17. Benzos is class of benzodiazepine consumption. It is output attribute with following distribution of classes:     Value Class                     Alcohol        Amphet          Amyl          Benzos                                  Cases Fraction Cases Fraction Cases Fraction Cases Fraction     CL0   Never Used              34    1.80%   976   51.78%   1305  69.23%   1000  53.05%     CL1   Used over a Decade Ago  34    1.80%   230   12.20%    210  11.14%    116   6.15%     CL2   Used in Last Decade     68    3.61%   243   12.89%    237  12.57%    234  12.41%     CL3   Used in Last Year      198   10.50%   198   10.50%     92   4.88%    236  12.52%     CL4   Used in Last Month     287   15.23%    75    3.98%     24   1.27%    120   6.37%     CL5   Used in Last Week      759   40.27%    61    3.24%     14   0.74%     84   4.46%     CL6   Used in Last Day       505   26.79%   102    5.41%      3   0.16%     95   5.04%18. Caff is class of caffeine consumption. It is output attribute with following distribution of classes.19. Cannabis is class of cannabis consumption. It is output attribute with following distribution of classes.20. Choc is class of chocolate consumption. It is output attribute with following distribution of classes.21. Coke is class of cocaine consumption. It is output attribute with following distribution of classes:     Value Class                      Caff         Cannabis         Choc           Coke                                  Cases Fraction Cases Fraction Cases Fraction Cases Fraction     CL0   Never Used               27   1.43%   413   21.91%    32    1.70%   1038  55.07%     CL1   Used over a Decade Ago   10   0.53%   207   10.98%     3    0.16%    160   8.49%     CL2   Used in Last Decade      24   1.27%   266   14.11%    10    0.53%    270  14.32%     CL3   Used in Last Year        60   3.18%   211   11.19%    54    2.86%    258  13.69%     CL4   Used in Last Month      106   5.62%   140    7.43%   296   15.70%     99   5.25%     CL5   Used in Last Week       273  14.48%   185    9.81%   683   36.23%     41   2.18%     CL6   Used in Last Day       1385  73.47%   463   24.56%   807   42.81%     19   1.01%22. Crack is class of crack consumption. It is output attribute with following distribution of classes.23. Ecstasy is class of ecstasy consumption. It is output attribute with following distribution of classes.24. Heroin is class of heroin consumption. It is output attribute with following distribution of classes.25. Ketamine is class of ketamine consumption. It is output attribute with following distribution of classes:     Value Class                     Crack         Ecstasy         Heroin        Ketamine                                  Cases Fraction Cases Fraction Cases Fraction Cases Fraction     CL0   Never Used             1627  86.31%   1021  54.16%   1605  85.15%   1490  79.05%     CL1   Used over a Decade Ago   67   3.55%    113   5.99%     68   3.61%     45   2.39%     CL2   Used in Last Decade     112   5.94%    234  12.41%     94   4.99%    142   7.53%     CL3   Used in Last Year        59   3.13%    277  14.69%     65   3.45%    129   6.84%     CL4   Used in Last Month        9   0.48%    156   8.28%     24   1.27%     42   2.23%     CL5   Used in Last Week         9   0.48%     63   3.34%     16   0.85%     33   1.75%     CL6   Used in Last Day          2   0.11%     21   1.11%     13   0.69%      4   0.21%26. Legalh is class of legal highs consumption. It is output attribute with following distribution of classes27. LSD is class of alcohol consumption. It is output attribute with following distribution of classes28. Meth is class of methadone consumption. It is output attribute with following distribution of classes.29. Mushrooms is class of magic mushrooms consumption. It is output attribute with following distribution of classes:     Value Class                     Legalh          LSD            Meth         Mushrooms                                  Cases Fraction Cases Fraction Cases Fraction Cases Fraction     CL0   Never Used             1094  58.04%   1069  56.71%   1429  75.81%   982   52.10%     CL1   Used over a Decade Ago   29   1.54%    259  13.74%     39   2.07%   209   11.09%     CL2   Used in Last Decade     198  10.50%    177   9.39%     97   5.15%   260   13.79%     CL3   Used in Last Year       323  17.14%    214  11.35%    149   7.90%   275   14.59%     CL4   Used in Last Month      110   5.84%     97   5.15%     50   2.65%   115    6.10%     CL5   Used in Last Week        64   3.40%     56   2.97%     48   2.55%    40    2.12%     CL6   Used in Last Day         67   3.55%     13   0.69%     73   3.87%     4    0.21%30. Nicotine is class of nicotine consumption. It is output attribute with following distribution of classes.31. Semer is class of fictitious drug Semeron consumption. It is output attribute with following distribution of classes.32. VSA is class of volatile substance abuse consumption. It is output attribute with following distribution of classes:     Value Class                    Nicotine        Semer           VSA                                  Cases Fraction Cases Fraction Cases Fraction     CL0   Never Used             428   22.71%   1877  99.58%   1455  77.19%     CL1   Used over a Decade Ago 193   10.24%      2   0.11%    200  10.61%     CL2   Used in Last Decade    204   10.82%      3   0.16%    135   7.16%     CL3   Used in Last Year      185    9.81%      2   0.11%     61   3.24%     CL4   Used in Last Month     108    5.73%      1   0.05%     13   0.69%     CL5   Used in Last Week      157    8.33%      0   0.00%     14   0.74%     CL6   Used in Last Day       610   32.36%      0   0.00%      7   0.37%"
Census-Income (KDD),Census-Income (KDD),This data set contains weighted census data extracted from the 1994 and 1995 current population surveys conducted by the U.S. Census Bureau.,Census-Income+%28KDD%29,https://archive.ics.uci.edu/ml//machine-learning-databases/census-income-mld/,https://archive.ics.uci.edu/ml/datasets/Census-Income+%28KDD%29,"This data set contains weighted census data extracted from the 1994 and 1995 Current Population Surveys conducted by the U.S. Census Bureau. The data contains 41 demographic and employment related variables. The instance weight indicates the number of people in the population that each record represents due to stratified sampling. To do real analysis and derive conclusions, this field must be used. This attribute should *not* be used in the classifiers. One instance per line with comma delimited fields. There are 199523 instances in the data file and 99762 in the test file. The data was split into train/test in approximately 2/3, 1/3 proportions using MineSet's MIndUtil mineset-to-mlc. ",Social,"More information detailing the meaning of the attributes can be found in the Census Bureau's documentation To make use of the data descriptions at this site, the following mappings to the Census Bureau's internal database column names will be needed: age						AAGEclass of worker					ACLSWKRindustry code					ADTINDoccupation code					ADTOCCadjusted gross income				AGIeducation					AHGAwage per hour					AHRSPAYenrolled in edu inst last wk			AHSCOLmarital status					AMARITLmajor industry code				AMJINDmajor occupation code				AMJOCCmace						ARACEhispanic Origin					AREORGNsex						ASEXmember of a labor union				AUNMEMreason for unemployment				AUNTYPEfull or part time employment stat		AWKSTATcapital gains					CAPGAINcapital losses					CAPLOSSdivdends from stocks				DIVVALfederal income tax liability			FEDTAXtax filer status				FILESTATregion of previous residence			GRINREGstate of previous residence			GRINSTdetailed household and family stat		HHDFMXdetailed household summary in household		HHDRELinstance weight					MARSUPWTmigration code-change in msa			MIGMTR1migration code-change in reg			MIGMTR3migration code-move within reg			MIGMTR4live in this house 1 year ago			MIGSAMEmigration prev res in sunbelt			MIGSUNnum persons worked for employer			NOEMPfamily members under 18				PARENTtotal person earnings				PEARNVALcountry of birth father				PEFNTVTYcountry of birth mother				PEMNTVTYcountry of birth self				PENATVTYcitizenship					PRCITSHPtotal person income				PTOTVALown business or self employed			SEOTRtaxable income amount				TAXINCfill inc questionnaire for veteran's admin	VETQVAveterans benefits				VETYNweeks worked in year				WKSWORKNote that Incomes have been binned at the $50K level to present a binary classification problem, much like the original UCI/ADULT database. The goal field of this data, however, was drawn from the ""total person income"" field rather than the ""adjusted gross income"" and may, therefore, behave differently than the orginal ADULT goal field. ","This data set contains weighted census data extracted from the 1994 and 1995 current population surveys conducted by the U.S. Census Bureau.This data set contains weighted census data extracted from the 1994 and 1995 Current Population Surveys conducted by the U.S. Census Bureau. The data contains 41 demographic and employment related variables. The instance weight indicates the number of people in the population that each record represents due to stratified sampling. To do real analysis and derive conclusions, this field must be used. This attribute should *not* be used in the classifiers. One instance per line with comma delimited fields. There are 199523 instances in the data file and 99762 in the test file. The data was split into train/test in approximately 2/3, 1/3 proportions using MineSet's MIndUtil mineset-to-mlc. More information detailing the meaning of the attributes can be found in the Census Bureau's documentation To make use of the data descriptions at this site, the following mappings to the Census Bureau's internal database column names will be needed: age						AAGEclass of worker					ACLSWKRindustry code					ADTINDoccupation code					ADTOCCadjusted gross income				AGIeducation					AHGAwage per hour					AHRSPAYenrolled in edu inst last wk			AHSCOLmarital status					AMARITLmajor industry code				AMJINDmajor occupation code				AMJOCCmace						ARACEhispanic Origin					AREORGNsex						ASEXmember of a labor union				AUNMEMreason for unemployment				AUNTYPEfull or part time employment stat		AWKSTATcapital gains					CAPGAINcapital losses					CAPLOSSdivdends from stocks				DIVVALfederal income tax liability			FEDTAXtax filer status				FILESTATregion of previous residence			GRINREGstate of previous residence			GRINSTdetailed household and family stat		HHDFMXdetailed household summary in household		HHDRELinstance weight					MARSUPWTmigration code-change in msa			MIGMTR1migration code-change in reg			MIGMTR3migration code-move within reg			MIGMTR4live in this house 1 year ago			MIGSAMEmigration prev res in sunbelt			MIGSUNnum persons worked for employer			NOEMPfamily members under 18				PARENTtotal person earnings				PEARNVALcountry of birth father				PEFNTVTYcountry of birth mother				PEMNTVTYcountry of birth self				PENATVTYcitizenship					PRCITSHPtotal person income				PTOTVALown business or self employed			SEOTRtaxable income amount				TAXINCfill inc questionnaire for veteran's admin	VETQVAveterans benefits				VETYNweeks worked in year				WKSWORKNote that Incomes have been binned at the $50K level to present a binary classification problem, much like the original UCI/ADULT database. The goal field of this data, however, was drawn from the ""total person income"" field rather than the ""adjusted gross income"" and may, therefore, behave differently than the orginal ADULT goal field. "
Wikipedia Math Essentials,Wikipedia Math Essentials,Contains Wikipedia pages about popular mathematics topics and the edges describe the links from one page to another. Features describe the number of daily visits between 2019 and 2021 March.,Wikipedia+Math+Essentials,https://archive.ics.uci.edu/ml//machine-learning-databases/00605/,https://archive.ics.uci.edu/ml/datasets/Wikipedia+Math+Essentials,Contains Wikipedia pages about popular mathematics topics and edges describe the links from one page to another. Features describe the number of daily visits between 2019 and 2021 March.,Social,Attributes are the daily number of visits on a page.,Contains Wikipedia pages about popular mathematics topics and the edges describe the links from one page to another. Features describe the number of daily visits between 2019 and 2021 March.Contains Wikipedia pages about popular mathematics topics and edges describe the links from one page to another. Features describe the number of daily visits between 2019 and 2021 March.Attributes are the daily number of visits on a page.
Balloons,Balloons,Data previously used in cognitive psychology experiment; 4 data sets represent different conditions of an experiment,Balloons,https://archive.ics.uci.edu/ml//machine-learning-databases/balloons/,https://archive.ics.uci.edu/ml/datasets/Balloons,There are four data sets representing different conditions of an experiment. All have the same attributes.a. adult-stretch.data  Inflated is true if age=adult or act=stretchb. adult+stretch.data  Inflated is true if age=adult and act=stretchc. small-yellow.data   Inflated is true if (color=yellow and size = small) ord. small-yellow+adult-stretch.data  Inflated is true if (color=yellow and size = small) or (age=adult and act=stretch),Social,"(Classes Inflated T or F)Color:             yellow, purplesize:              large, smallact:               stretch, dipage:               adult, childinflated:          T, F","Data previously used in cognitive psychology experiment; 4 data sets represent different conditions of an experimentThere are four data sets representing different conditions of an experiment. All have the same attributes.a. adult-stretch.data  Inflated is true if age=adult or act=stretchb. adult+stretch.data  Inflated is true if age=adult and act=stretchc. small-yellow.data   Inflated is true if (color=yellow and size = small) ord. small-yellow+adult-stretch.data  Inflated is true if (color=yellow and size = small) or (age=adult and act=stretch)(Classes Inflated T or F)Color:             yellow, purplesize:              large, smallact:               stretch, dipage:               adult, childinflated:          T, F"
Pedal Me Bicycle Deliveries,Pedal Me Bicycle Deliveries,A dataset of weekly bicycle package deliveries by Pedal Me in London during 2020 and 2021. Nodes in the graph represent geographical units and edges are proximity based mutual adjacency relationships.,Pedal+Me+Bicycle+Deliveries,https://archive.ics.uci.edu/ml//machine-learning-databases/00613/,https://archive.ics.uci.edu/ml/datasets/Pedal+Me+Bicycle+Deliveries,A dataset about the number of weekly bicycle package deliveries by Pedal Me in London during 2020 and 2021. Nodes in the graph represent geographical units and edges are proximity based mutual adjacency relationships.,Social,Attributes are the weekly deliveries done by Pedal Me in certain regions of London.,A dataset of weekly bicycle package deliveries by Pedal Me in London during 2020 and 2021. Nodes in the graph represent geographical units and edges are proximity based mutual adjacency relationships.A dataset about the number of weekly bicycle package deliveries by Pedal Me in London during 2020 and 2021. Nodes in the graph represent geographical units and edges are proximity based mutual adjacency relationships.Attributes are the weekly deliveries done by Pedal Me in certain regions of London.
Labor Relations,Labor Relations,From Collective Bargaining Review,Labor+Relations,https://archive.ics.uci.edu/ml//machine-learning-databases/labor-negotiations/,https://archive.ics.uci.edu/ml/datasets/Labor+Relations,Data was used to test 2 tier approach with learning from positive and negative examples,Social,"   1.  dur: duration of agreement        [1..7]   2   wage1.wage : wage increase in first year of contract        [2.0 .. 7.0]   3   wage2.wage : wage increase in second year of contract       [2.0 .. 7.0]   4   wage3.wage : wage increase in third year of contract       [2.0 .. 7.0]   5   cola : cost of living allowance        [none, tcf, tc]   6   hours.hrs : number of working hours during week       [35 .. 40]   7   pension : employer contributions to pension plan       [none, ret_allw, empl_contr]   8   stby_pay : standby pay       [2 .. 25]   9   shift_diff : shift differencial : supplement for work on II and III shift       [1 .. 25]  10   educ_allw.boolean : education allowance        [true false]  11   holidays : number of statutory holidays        [9 .. 15]  12   vacation : number of paid vacation days       [ba, avg, gnr]  13   lngtrm_disabil.boolean : employer's help during employee longterm disability         [true , false]  14   dntl_ins : employers contribution towards the dental plan       [none, half, full]  15   bereavement.boolean : employer's financial contribution towards the covering the costs of bereavement       [true , false]  16   empl_hplan : employer's contribution towards the health plan       [none, half, full]","From Collective Bargaining ReviewData was used to test 2 tier approach with learning from positive and negative examples   1.  dur: duration of agreement        [1..7]   2   wage1.wage : wage increase in first year of contract        [2.0 .. 7.0]   3   wage2.wage : wage increase in second year of contract       [2.0 .. 7.0]   4   wage3.wage : wage increase in third year of contract       [2.0 .. 7.0]   5   cola : cost of living allowance        [none, tcf, tc]   6   hours.hrs : number of working hours during week       [35 .. 40]   7   pension : employer contributions to pension plan       [none, ret_allw, empl_contr]   8   stby_pay : standby pay       [2 .. 25]   9   shift_diff : shift differencial : supplement for work on II and III shift       [1 .. 25]  10   educ_allw.boolean : education allowance        [true false]  11   holidays : number of statutory holidays        [9 .. 15]  12   vacation : number of paid vacation days       [ba, avg, gnr]  13   lngtrm_disabil.boolean : employer's help during employee longterm disability         [true , false]  14   dntl_ins : employers contribution towards the dental plan       [none, half, full]  15   bereavement.boolean : employer's financial contribution towards the covering the costs of bereavement       [true , false]  16   empl_hplan : employer's contribution towards the health plan       [none, half, full]"
Balance Scale,Balance Scale,Balance scale weight & distance database,Balance+Scale,https://archive.ics.uci.edu/ml//machine-learning-databases/balance-scale/,https://archive.ics.uci.edu/ml/datasets/Balance+Scale,"This data set was generated to model psychological experimental results.  Each example is classified as having the balance scale tip to the right, tip to the left, or be balanced.  The attributes are the left weight, the left distance, the right weight, and the right distance.  The correct way to find the class is the greater of  (left-distance * left-weight) and (right-distance * right-weight).  If they are equal, it is balanced.",Social,"	1. Class Name: 3 (L, B, R)	2. Left-Weight: 5 (1, 2, 3, 4, 5)	3. Left-Distance: 5 (1, 2, 3, 4, 5)	4. Right-Weight: 5 (1, 2, 3, 4, 5)	5. Right-Distance: 5 (1, 2, 3, 4, 5)","Balance scale weight & distance databaseThis data set was generated to model psychological experimental results.  Each example is classified as having the balance scale tip to the right, tip to the left, or be balanced.  The attributes are the left weight, the left distance, the right weight, and the right distance.  The correct way to find the class is the greater of  (left-distance * left-weight) and (right-distance * right-weight).  If they are equal, it is balanced.	1. Class Name: 3 (L, B, R)	2. Left-Weight: 5 (1, 2, 3, 4, 5)	3. Left-Distance: 5 (1, 2, 3, 4, 5)	4. Right-Weight: 5 (1, 2, 3, 4, 5)	5. Right-Distance: 5 (1, 2, 3, 4, 5)"
LastFM Asia Social Network,LastFM Asia Social Network,A social network of LastFM users which was collected from the public API in March 2020.,LastFM+Asia+Social+Network,https://archive.ics.uci.edu/ml//machine-learning-databases/00595/,https://archive.ics.uci.edu/ml/datasets/LastFM+Asia+Social+Network,A social network of LastFM users which was collected from the public API in March 2020. Nodes are LastFM users from Asian countries and edges are mutual follower relationships between them. The vertex features are extracted based on the artists liked by the users. The task related to the graph is multinomial node classification - one has to predict the location of users. This target feature was derived from the country field for each user. ,Social,Attributes are artists liked by the LASTFM Users. ,A social network of LastFM users which was collected from the public API in March 2020.A social network of LastFM users which was collected from the public API in March 2020. Nodes are LastFM users from Asian countries and edges are mutual follower relationships between them. The vertex features are extracted based on the artists liked by the users. The task related to the graph is multinomial node classification - one has to predict the location of users. This target feature was derived from the country field for each user. Attributes are artists liked by the LASTFM Users. 
wiki4HE,wiki4HE,Survey of faculty members from two Spanish universities on teaching uses of Wikipedia,wiki4HE,https://archive.ics.uci.edu/ml//machine-learning-databases/00334/,https://archive.ics.uci.edu/ml/datasets/wiki4HE,"Ongoing research on university faculty perceptions and practices of using Wikipedia as a teaching resource. Based on a Technology Acceptance Model, the relationships within the internal and external constructs of the model are analyzed. Both the perception of colleaguesÃ¢â‚¬â„¢ opinion about Wikipedia and the perceived quality of the information in Wikipedia play a central role in the obtained model. ",Social,"AGE: numericGENDER: 0=Male; 1=FemaleDOMAIN: 1=Arts & Humanities; 2=Sciences; 3=Health Sciences; 4=Engineering & Architecture; 5=Law & PoliticsPhD: 0=No; 1=YesYEARSEXP (years of university teaching experience): numericUNIVERSITY: 1=UOC; 2=UPFUOC_POSITION (academic position of UOC members): 1=Professor; 2=Associate; 3=Assistant; 4=Lecturer; 5=Instructor; 6=AdjunctOTHER (main job in another university for part-time members): 1=Yes; 2=NoOTHER_POSITION (work as part-time in another university and UPF members): 1=Professor; 2=Associate; 3=Assistant; 4=Lecturer; 5=Instructor; 6=AdjunctUSERWIKI (Wikipedia registered user): 0=No; 1=YesThe following survey items are Likert scale (1-5) ranging from strongly disagree / never (1) to strongly agree / always (5)Perceived UsefulnessPU1: The use of Wikipedia makes it easier for students to develop new skillsPU2: The use of Wikipedia improves students' learningPU3: Wikipedia is useful for teachingPerceived Ease of UsePEU1: Wikipedia is user-friendlyPEU2: It is easy to find in Wikipedia the information you seekPEU3: It is easy to add or edit information in WikipediaPerceived EnjoymentENJ1: The use of Wikipedia stimulates curiosityENJ2: The use of Wikipedia is entertainingQualityQU1: Articles in Wikipedia are reliableQU2: Articles in Wikipedia are updatedQU3: Articles in Wikipedia are comprehensiveQU4: In my area of expertise, Wikipedia has a lower quality than other educational resourcesQU5: I trust in the editing system of WikipediaVisibilityVIS1: Wikipedia improves visibility of students' workVIS2: It is easy to have a record of the contributions made in WikipediaVIS3: I cite Wikipedia in my academic papersSocial ImageIM1: The use of Wikipedia is well considered among colleaguesIM2: In academia, sharing open educational resources is appreciatedIM3: My colleagues use WikipediaSharing attitudeSA1: It is important to share academic content in open platformsSA2: It is important to publish research results in other media than academic journals or booksSA3: It is important that students become familiar with online collaborative environmentsUse behaviourUSE1: I use Wikipedia to develop my teaching materialsUSE2: I use Wikipedia as a platform to develop educational activities with studentsUSE3: I recommend my students to use WikipediaUSE4: I recommend my colleagues to use WikipediaUSE5: I agree my students use Wikipedia in my coursesProfile 2.0PF1: I contribute to blogsPF2: I actively participate in social networksPF3: I publish academic content in open platformsJob relevanceJR1: My university promotes the use of open collaborative environments in the InternetJR2: My university considers the use of open collaborative environments in the Internet as a teaching meritBehavioral intentionBI1: In the future I will recommend the use of Wikipedia to my colleagues and studentsBI2: In the future I will use Wikipedia in my teaching activityIncentivesINC1: To design educational activities using Wikipedia, it would be helpful: a best practices guideINC2: To design educational activities using Wikipedia, it would be helpful: getting instruction from a colleagueINC3: To design educational activities using Wikipedia, it would be helpful: getting specific trainingINC4: To design educational activities using Wikipedia, it would be helpfull: greater institutional recognitionExperienceEXP1: I consult Wikipedia for issues related to my field of expertiseEXP2: I consult Wikipedia for other academic related issuesEXP3: I consult Wikipedia for personal issuesEXP4: I contribute to Wikipedia (editions, revisions, articles improvement...)EXP5: I use wikis to work with my students","Survey of faculty members from two Spanish universities on teaching uses of WikipediaOngoing research on university faculty perceptions and practices of using Wikipedia as a teaching resource. Based on a Technology Acceptance Model, the relationships within the internal and external constructs of the model are analyzed. Both the perception of colleaguesÃ¢â‚¬â„¢ opinion about Wikipedia and the perceived quality of the information in Wikipedia play a central role in the obtained model. AGE: numericGENDER: 0=Male; 1=FemaleDOMAIN: 1=Arts & Humanities; 2=Sciences; 3=Health Sciences; 4=Engineering & Architecture; 5=Law & PoliticsPhD: 0=No; 1=YesYEARSEXP (years of university teaching experience): numericUNIVERSITY: 1=UOC; 2=UPFUOC_POSITION (academic position of UOC members): 1=Professor; 2=Associate; 3=Assistant; 4=Lecturer; 5=Instructor; 6=AdjunctOTHER (main job in another university for part-time members): 1=Yes; 2=NoOTHER_POSITION (work as part-time in another university and UPF members): 1=Professor; 2=Associate; 3=Assistant; 4=Lecturer; 5=Instructor; 6=AdjunctUSERWIKI (Wikipedia registered user): 0=No; 1=YesThe following survey items are Likert scale (1-5) ranging from strongly disagree / never (1) to strongly agree / always (5)Perceived UsefulnessPU1: The use of Wikipedia makes it easier for students to develop new skillsPU2: The use of Wikipedia improves students' learningPU3: Wikipedia is useful for teachingPerceived Ease of UsePEU1: Wikipedia is user-friendlyPEU2: It is easy to find in Wikipedia the information you seekPEU3: It is easy to add or edit information in WikipediaPerceived EnjoymentENJ1: The use of Wikipedia stimulates curiosityENJ2: The use of Wikipedia is entertainingQualityQU1: Articles in Wikipedia are reliableQU2: Articles in Wikipedia are updatedQU3: Articles in Wikipedia are comprehensiveQU4: In my area of expertise, Wikipedia has a lower quality than other educational resourcesQU5: I trust in the editing system of WikipediaVisibilityVIS1: Wikipedia improves visibility of students' workVIS2: It is easy to have a record of the contributions made in WikipediaVIS3: I cite Wikipedia in my academic papersSocial ImageIM1: The use of Wikipedia is well considered among colleaguesIM2: In academia, sharing open educational resources is appreciatedIM3: My colleagues use WikipediaSharing attitudeSA1: It is important to share academic content in open platformsSA2: It is important to publish research results in other media than academic journals or booksSA3: It is important that students become familiar with online collaborative environmentsUse behaviourUSE1: I use Wikipedia to develop my teaching materialsUSE2: I use Wikipedia as a platform to develop educational activities with studentsUSE3: I recommend my students to use WikipediaUSE4: I recommend my colleagues to use WikipediaUSE5: I agree my students use Wikipedia in my coursesProfile 2.0PF1: I contribute to blogsPF2: I actively participate in social networksPF3: I publish academic content in open platformsJob relevanceJR1: My university promotes the use of open collaborative environments in the InternetJR2: My university considers the use of open collaborative environments in the Internet as a teaching meritBehavioral intentionBI1: In the future I will recommend the use of Wikipedia to my colleagues and studentsBI2: In the future I will use Wikipedia in my teaching activityIncentivesINC1: To design educational activities using Wikipedia, it would be helpful: a best practices guideINC2: To design educational activities using Wikipedia, it would be helpful: getting instruction from a colleagueINC3: To design educational activities using Wikipedia, it would be helpful: getting specific trainingINC4: To design educational activities using Wikipedia, it would be helpfull: greater institutional recognitionExperienceEXP1: I consult Wikipedia for issues related to my field of expertiseEXP2: I consult Wikipedia for other academic related issuesEXP3: I consult Wikipedia for personal issuesEXP4: I contribute to Wikipedia (editions, revisions, articles improvement...)EXP5: I use wikis to work with my students"
Gender Gap in Spanish WP,Gender Gap in Spanish WP,Data set used to estimate the number of women editors and their editing practices in the Spanish Wikipedia,Gender+Gap+in+Spanish+WP,https://archive.ics.uci.edu/ml//machine-learning-databases/00619/,https://archive.ics.uci.edu/ml/datasets/Gender+Gap+in+Spanish+WP,Data set used to estimate the number of women editors and their editing practices in the Spanish Wikipedia,Social,"gender: 0 (unknown), 1 (male), 2 (female)C_api: gender extracted from WikiMedia API, codes as female / male / unknownC_man: gender extracted from content coding, coded as 1 (male) / 2 (female) / 3 (unknown)E_NEds: I index of stratum IJ (0,1,2,3)E_Bpag: J index of stratum IJ (0,1,2,3)firstDay: first edition in the Spanish Wikipedia (YYYYMMDDHHMMSS)lastDay: last edition in the Spanish Wikipedia (YYYYMMDDHHMMSS)NEds: total number of editionsNDays: number of days (lastDay-firstDay+1)NActDays: number of days with editionsNPages: number of different pages editedNPcreated: number of pages createdpagesWomen: number of edits in pages related to womenwikiprojWomen: number of edits in WikiProjects related to womenns_user: number of edits in namespace userns_wikipedia: number of edits in namespace wikipedians_talk: number of edits in namespace talkns_userTalk: number of edits in namespace user talkns_content: number of edits in content pagesweightIJ: correcting weight for stratum IJ NIJ: number of elements in stratum IJ","Data set used to estimate the number of women editors and their editing practices in the Spanish WikipediaData set used to estimate the number of women editors and their editing practices in the Spanish Wikipediagender: 0 (unknown), 1 (male), 2 (female)C_api: gender extracted from WikiMedia API, codes as female / male / unknownC_man: gender extracted from content coding, coded as 1 (male) / 2 (female) / 3 (unknown)E_NEds: I index of stratum IJ (0,1,2,3)E_Bpag: J index of stratum IJ (0,1,2,3)firstDay: first edition in the Spanish Wikipedia (YYYYMMDDHHMMSS)lastDay: last edition in the Spanish Wikipedia (YYYYMMDDHHMMSS)NEds: total number of editionsNDays: number of days (lastDay-firstDay+1)NActDays: number of days with editionsNPages: number of different pages editedNPcreated: number of pages createdpagesWomen: number of edits in pages related to womenwikiprojWomen: number of edits in WikiProjects related to womenns_user: number of edits in namespace userns_wikipedia: number of edits in namespace wikipedians_talk: number of edits in namespace talkns_userTalk: number of edits in namespace user talkns_content: number of edits in content pagesweightIJ: correcting weight for stratum IJ NIJ: number of elements in stratum IJ"
Travel Reviews,Travel Reviews,"Reviews on destinations in 10 categories mentioned across East Asia. Each traveler rating is mapped as Excellent(4), Very Good(3), Average(2), Poor(1), and Terrible(0) and average rating is used.",Travel+Reviews,https://archive.ics.uci.edu/ml//machine-learning-databases/00484/,https://archive.ics.uci.edu/ml/datasets/Travel+Reviews,"This data set is populated by crawling TripAdvisor.com. Reviews on destinations in 10 categories mentioned across East Asia are considered. Each traveler rating is mapped as Excellent (4), Very Good (3), Average (2), Poor (1), and Terrible (0) and average rating is used against each category per user.",Unknown,Attribute 1 : Unique user idAttribute 2 : Average user feedback on art galleriesAttribute 3 : Average user feedback on dance clubsAttribute 4 : Average user feedback on juice barsAttribute 5 : Average user feedback on restaurantsAttribute 6 : Average user feedback on museumsAttribute 7 : Average user feedback on resortsAttribute 8 : Average user feedback on parks/picnic spotsAttribute 9 : Average user feedback on beachesAttribute 10 : Average user feedback on theatersAttribute 11 : Average user feedback on religious institutions,"Reviews on destinations in 10 categories mentioned across East Asia. Each traveler rating is mapped as Excellent(4), Very Good(3), Average(2), Poor(1), and Terrible(0) and average rating is used.This data set is populated by crawling TripAdvisor.com. Reviews on destinations in 10 categories mentioned across East Asia are considered. Each traveler rating is mapped as Excellent (4), Very Good (3), Average (2), Poor (1), and Terrible (0) and average rating is used against each category per user.Attribute 1 : Unique user idAttribute 2 : Average user feedback on art galleriesAttribute 3 : Average user feedback on dance clubsAttribute 4 : Average user feedback on juice barsAttribute 5 : Average user feedback on restaurantsAttribute 6 : Average user feedback on museumsAttribute 7 : Average user feedback on resortsAttribute 8 : Average user feedback on parks/picnic spotsAttribute 9 : Average user feedback on beachesAttribute 10 : Average user feedback on theatersAttribute 11 : Average user feedback on religious institutions"
Trains,Trains,"2 data formats (structured, one-instance-per-line)",Trains,https://archive.ics.uci.edu/ml//machine-learning-databases/trains/,https://archive.ics.uci.edu/ml/datasets/Trains,"Notes:- Additional ""background"" knowledge is supplied that provides a partial ordering on some of the attribute values.- We are providing this dataset both in its original form and in a form similar to the more typical propositional datasets in our repository. Since the trains dataset records relations between attributes, this transformation was somewhat challenging.  However, it may shed some insight on this problem for people who are more familiar with the simple one-instance-per-line dataset format.Hierarchy of values:     if (cshape is one of {openrect,opentrap,ushaped,dblopnrect}then cshape is opentop    if (cshape is one of {hexagon,ellipse,closedrect,jaggedtop,slopetop, engine}then cshape closedtopPrediction task: Determine concise decision rules distinguishing trains traveling east from those traveling west.",Unknown," The following format was used for the ""transformed"" dataset representation as found in trains.transformed.data (one instance per line):  1. Number_of_cars (integer in [3-5])  2. Number_of_different_loads (integer in [1-4])  3-22: 5 attributes for each of cars 2 through 5: (20 attributes total)    - num_wheels (integer in [2-3])    - length (short or long)        - shape (closedrect, dblopnrect, ellipse, engine, hexagon, jaggedtop, openrect, opentrap, slopetop, ushaped)    - num_loads (integer in [0-3])    - load_shape (circlelod, hexagonlod, rectanglod, trianglod)  23-32: 10 Boolean attributes describing whether 2 types of loads are on adjacent cars of the train    - Rectangle_next_to_rectangle (0 if false, 1 if true)    - Rectangle_next_to_triangle (0 if false, 1 if true)    - Rectangle_next_to_hexagon (0 if false, 1 if true)    - Rectangle_next_to_circle (0 if false, 1 if true)    - Triangle_next_to_triangle (0 if false, 1 if true)    - Triangle_next_to_hexagon (0 if false, 1 if true)    - Triangle_next_to_circle (0 if false, 1 if true)    - Hexagon_next_to_hexagon (0 if false, 1 if true)    - Hexagon_next_to_circle (0 if false, 1 if true)    - Circle_next_to_circle (0 if false, 1 if true)  33. Class attribute (east or west)    The number of cars vary between 3 and 5.  Therefore, attributes referring to properties of cars that do not exist (such as the 5 attriubutes for the ""5th"" car when the train has fewer than 5 cars) are assigned a value of ""-"".","2 data formats (structured, one-instance-per-line)Notes:- Additional ""background"" knowledge is supplied that provides a partial ordering on some of the attribute values.- We are providing this dataset both in its original form and in a form similar to the more typical propositional datasets in our repository. Since the trains dataset records relations between attributes, this transformation was somewhat challenging.  However, it may shed some insight on this problem for people who are more familiar with the simple one-instance-per-line dataset format.Hierarchy of values:     if (cshape is one of {openrect,opentrap,ushaped,dblopnrect}then cshape is opentop    if (cshape is one of {hexagon,ellipse,closedrect,jaggedtop,slopetop, engine}then cshape closedtopPrediction task: Determine concise decision rules distinguishing trains traveling east from those traveling west. The following format was used for the ""transformed"" dataset representation as found in trains.transformed.data (one instance per line):  1. Number_of_cars (integer in [3-5])  2. Number_of_different_loads (integer in [1-4])  3-22: 5 attributes for each of cars 2 through 5: (20 attributes total)    - num_wheels (integer in [2-3])    - length (short or long)        - shape (closedrect, dblopnrect, ellipse, engine, hexagon, jaggedtop, openrect, opentrap, slopetop, ushaped)    - num_loads (integer in [0-3])    - load_shape (circlelod, hexagonlod, rectanglod, trianglod)  23-32: 10 Boolean attributes describing whether 2 types of loads are on adjacent cars of the train    - Rectangle_next_to_rectangle (0 if false, 1 if true)    - Rectangle_next_to_triangle (0 if false, 1 if true)    - Rectangle_next_to_hexagon (0 if false, 1 if true)    - Rectangle_next_to_circle (0 if false, 1 if true)    - Triangle_next_to_triangle (0 if false, 1 if true)    - Triangle_next_to_hexagon (0 if false, 1 if true)    - Triangle_next_to_circle (0 if false, 1 if true)    - Hexagon_next_to_hexagon (0 if false, 1 if true)    - Hexagon_next_to_circle (0 if false, 1 if true)    - Circle_next_to_circle (0 if false, 1 if true)  33. Class attribute (east or west)    The number of cars vary between 3 and 5.  Therefore, attributes referring to properties of cars that do not exist (such as the 5 attriubutes for the ""5th"" car when the train has fewer than 5 cars) are assigned a value of ""-""."
Flags,Flags,"From Collins Gem Guide to Flags, 1986",Flags,https://archive.ics.uci.edu/ml//machine-learning-databases/flags/,https://archive.ics.uci.edu/ml/datasets/Flags,This data file contains details of various nations and their flags. In this file the fields are separated by spaces (not commas).  With this data you can try things like predicting the religion of a country from its size and the colours in its flag.  10 attributes are numeric-valued.  The remainder are either Boolean- or nominal-valued.,Unknown,"   1. name:	Name of the country concerned   2. landmass:	1=N.America, 2=S.America, 3=Europe, 4=Africa, 4=Asia, 6=Oceania   3. zone:	Geographic quadrant, based on Greenwich and the Equator; 1=NE, 2=SE, 3=SW, 4=NW   4. area:	in thousands of square km   5. population:	in round millions   6. language: 1=English, 2=Spanish, 3=French, 4=German, 5=Slavic, 6=Other Indo-European, 7=Chinese, 8=Arabic, 9=Japanese/Turkish/Finnish/Magyar, 10=Others   7. religion: 0=Catholic, 1=Other Christian, 2=Muslim, 3=Buddhist, 4=Hindu, 5=Ethnic, 6=Marxist, 7=Others   8. bars:     Number of vertical bars in the flag   9. stripes:  Number of horizontal stripes in the flag  10. colours:  Number of different colours in the flag  11. red:      0 if red absent, 1 if red present in the flag  12. green:    same for green  13. blue:     same for blue  14. gold:     same for gold (also yellow)  15. white:    same for white  16. black:    same for black  17. orange:   same for orange (also brown)  18. mainhue:  predominant colour in the flag (tie-breaks decided by taking the topmost hue, if that fails then the most central hue, and if that fails the leftmost hue)  19. circles:  Number of circles in the flag  20. crosses:  Number of (upright) crosses  21. saltires: Number of diagonal crosses  22. quarters: Number of quartered sections  23. sunstars: Number of sun or star symbols  24. crescent: 1 if a crescent moon symbol present, else 0  25. triangle: 1 if any triangles present, 0 otherwise  26. icon:     1 if an inanimate image present (e.g., a boat), otherwise 0  27. animate:  1 if an animate image (e.g., an eagle, a tree, a human hand) present, 0 otherwise  28. text:     1 if any letters or writing on the flag (e.g., a motto or slogan), 0 otherwise  29. topleft:  colour in the top-left corner (moving right to decide tie-breaks)  30. botright: Colour in the bottom-left corner (moving left to decide tie-breaks)","From Collins Gem Guide to Flags, 1986This data file contains details of various nations and their flags. In this file the fields are separated by spaces (not commas).  With this data you can try things like predicting the religion of a country from its size and the colours in its flag.  10 attributes are numeric-valued.  The remainder are either Boolean- or nominal-valued.   1. name:	Name of the country concerned   2. landmass:	1=N.America, 2=S.America, 3=Europe, 4=Africa, 4=Asia, 6=Oceania   3. zone:	Geographic quadrant, based on Greenwich and the Equator; 1=NE, 2=SE, 3=SW, 4=NW   4. area:	in thousands of square km   5. population:	in round millions   6. language: 1=English, 2=Spanish, 3=French, 4=German, 5=Slavic, 6=Other Indo-European, 7=Chinese, 8=Arabic, 9=Japanese/Turkish/Finnish/Magyar, 10=Others   7. religion: 0=Catholic, 1=Other Christian, 2=Muslim, 3=Buddhist, 4=Hindu, 5=Ethnic, 6=Marxist, 7=Others   8. bars:     Number of vertical bars in the flag   9. stripes:  Number of horizontal stripes in the flag  10. colours:  Number of different colours in the flag  11. red:      0 if red absent, 1 if red present in the flag  12. green:    same for green  13. blue:     same for blue  14. gold:     same for gold (also yellow)  15. white:    same for white  16. black:    same for black  17. orange:   same for orange (also brown)  18. mainhue:  predominant colour in the flag (tie-breaks decided by taking the topmost hue, if that fails then the most central hue, and if that fails the leftmost hue)  19. circles:  Number of circles in the flag  20. crosses:  Number of (upright) crosses  21. saltires: Number of diagonal crosses  22. quarters: Number of quartered sections  23. sunstars: Number of sun or star symbols  24. crescent: 1 if a crescent moon symbol present, else 0  25. triangle: 1 if any triangles present, 0 otherwise  26. icon:     1 if an inanimate image present (e.g., a boat), otherwise 0  27. animate:  1 if an animate image (e.g., an eagle, a tree, a human hand) present, 0 otherwise  28. text:     1 if any letters or writing on the flag (e.g., a motto or slogan), 0 otherwise  29. topleft:  colour in the top-left corner (moving right to decide tie-breaks)  30. botright: Colour in the bottom-left corner (moving left to decide tie-breaks)"
Guitar Chords finger positions,Guitar Chords finger positions,Position of the fingers for 2633 guitar chords in standard tuning (double checked with software),Guitar+Chords+finger+positions,https://archive.ics.uci.edu/ml//machine-learning-databases/00575/,https://archive.ics.uci.edu/ml/datasets/Guitar+Chords+finger+positions,"For each row, the dataset provides: the root of the chord, the type of chord, the intervals that compose the chord, and the finger positions.",Unknown,"The finger positions are denoted for each guitar string (from the lowest E to the highest).x: string muted, 0: open string, 1: index finger, 2: middle finger, 3: ring finger, 4: pinkie","Position of the fingers for 2633 guitar chords in standard tuning (double checked with software)For each row, the dataset provides: the root of the chord, the type of chord, the intervals that compose the chord, and the finger positions.The finger positions are denoted for each guitar string (from the lowest E to the highest).x: string muted, 0: open string, 1: index finger, 2: middle finger, 3: ring finger, 4: pinkie"
Vertebral Column,Vertebral Column,"Data set containing values for six biomechanical features used to classify orthopaedic patients into 3 classes (normal, disk hernia or spondilolysthesis) or 2 classes (normal or abnormal).",Vertebral+Column,https://archive.ics.uci.edu/ml//machine-learning-databases/00212/,https://archive.ics.uci.edu/ml/datasets/Vertebral+Column,"Biomedical data set built by Dr. Henrique da Mota during a medical residence period in the Group of Applied Research in Orthopaedics (GARO) of the Centre MÃƒÂ©dico-Chirurgical de RÃƒÂ©adaptation des Massues, Lyon, France. The data have been organized in two different but related classification tasks. The first task consists in classifying patients as belonging to one out of three categories: Normal (100 patients), Disk Hernia (60 patients) or Spondylolisthesis  (150 patients). For the second task, the categories Disk Hernia and Spondylolisthesis were merged into a single category labelled as 'abnormal'. Thus, the second task consists in classifying patients as belonging to one out of two categories: Normal (100 patients) or Abnormal (210 patients). We provide files also for use within the WEKA environment.",Unknown,"Each patient is represented in the data set by six biomechanical attributes derived from the shape and orientation of the pelvis and lumbar spine (in this order): pelvic incidence, pelvic tilt, lumbar lordosis angle, sacral slope, pelvic radius and grade of spondylolisthesis. The following convention is used for the class labels: DH (Disk Hernia), Spondylolisthesis (SL), Normal (NO) and Abnormal (AB).","Data set containing values for six biomechanical features used to classify orthopaedic patients into 3 classes (normal, disk hernia or spondilolysthesis) or 2 classes (normal or abnormal).Biomedical data set built by Dr. Henrique da Mota during a medical residence period in the Group of Applied Research in Orthopaedics (GARO) of the Centre MÃƒÂ©dico-Chirurgical de RÃƒÂ©adaptation des Massues, Lyon, France. The data have been organized in two different but related classification tasks. The first task consists in classifying patients as belonging to one out of three categories: Normal (100 patients), Disk Hernia (60 patients) or Spondylolisthesis  (150 patients). For the second task, the categories Disk Hernia and Spondylolisthesis were merged into a single category labelled as 'abnormal'. Thus, the second task consists in classifying patients as belonging to one out of two categories: Normal (100 patients) or Abnormal (210 patients). We provide files also for use within the WEKA environment.Each patient is represented in the data set by six biomechanical attributes derived from the shape and orientation of the pelvis and lumbar spine (in this order): pelvic incidence, pelvic tilt, lumbar lordosis angle, sacral slope, pelvic radius and grade of spondylolisthesis. The following convention is used for the class labels: DH (Disk Hernia), Spondylolisthesis (SL), Normal (NO) and Abnormal (AB)."
"USPTO Algorithm Challenge, run by NASA-Harvard Tournament Lab and TopCoder    Problem: Pat","USPTO Algorithm Challenge, run by NASA-Harvard Tournament Lab and TopCoder    Problem: Pat",Data used for USPTO Algorithm Competition. Contains drawing pages from US patents with manually labeled figure and part labels.,USPTO+Algorithm+Challenge%2C+run+by+NASA-Harvard+Tournament+Lab+and+TopCoder++++Problem%3A+Pat,https://archive.ics.uci.edu/ml//machine-learning-databases/00268/,https://archive.ics.uci.edu/ml/datasets/USPTO+Algorithm+Challenge%2C+run+by+NASA-Harvard+Tournament+Lab+and+TopCoder++++Problem%3A+Pat,"USPTO Algorithm Challenge, run by NASA-Harvard Tournament Lab and TopCoder   Problem: Patent Labeling",Unknown,"Dataset Information:    -- This folder contains 4 groups of USPTO patent images including ground truth information. 	-- The 4 groups are 'train1', 'train2', 'test', 'evaluation'. 	-- 'train1', 'test', 'evaluation' contains data in the original 'USPTO Algorithm Challenge' for training, testing and final evaluation, respectively.	-- 'train2' contains additional data which was used in the 'USPTO Algorithm Followup Challenge.'  	   Notice that 'train2' includes some cover page images of patent document which is not included in other groups.    -- In each group, there are two folders contain original images and corresponding ground truth informations. 	-- The original images are in 'jpeg' format.	-- There are two types of ground truth: figure label ground truth and part label ground truth.	-- The ground truth files are text files with '.ans' extension.     -- The structure of the ground truth files are described as below:	-- The first line is one number indicating how many instances exist in corresponding image	-- The following lines are polygon coordinates and corresponding label contents, each line corresponds to a figure label or part label, in the form 'N x1 y1 x2 y2 Ã¢â‚¬Â¦ xN yN x1 y1 content'. 	-- In each of those lines, the first number N indicates how many polygon vertices are recorded in current instance. 	-- The following numbers are x, y coordinates of those vertices.	-- The final word in each line is the content of figure label or part label. 	-- Each number or word is separated by a white space.	-- For group 'train2', there are only part label ground truth available.	-- We also release the source code of the top 5 winning solution. See additional archive file.","Data used for USPTO Algorithm Competition. Contains drawing pages from US patents with manually labeled figure and part labels.USPTO Algorithm Challenge, run by NASA-Harvard Tournament Lab and TopCoder   Problem: Patent LabelingDataset Information:    -- This folder contains 4 groups of USPTO patent images including ground truth information. 	-- The 4 groups are 'train1', 'train2', 'test', 'evaluation'. 	-- 'train1', 'test', 'evaluation' contains data in the original 'USPTO Algorithm Challenge' for training, testing and final evaluation, respectively.	-- 'train2' contains additional data which was used in the 'USPTO Algorithm Followup Challenge.'  	   Notice that 'train2' includes some cover page images of patent document which is not included in other groups.    -- In each group, there are two folders contain original images and corresponding ground truth informations. 	-- The original images are in 'jpeg' format.	-- There are two types of ground truth: figure label ground truth and part label ground truth.	-- The ground truth files are text files with '.ans' extension.     -- The structure of the ground truth files are described as below:	-- The first line is one number indicating how many instances exist in corresponding image	-- The following lines are polygon coordinates and corresponding label contents, each line corresponds to a figure label or part label, in the form 'N x1 y1 x2 y2 Ã¢â‚¬Â¦ xN yN x1 y1 content'. 	-- In each of those lines, the first number N indicates how many polygon vertices are recorded in current instance. 	-- The following numbers are x, y coordinates of those vertices.	-- The final word in each line is the content of figure label or part label. 	-- Each number or word is separated by a white space.	-- For group 'train2', there are only part label ground truth available.	-- We also release the source code of the top 5 winning solution. See additional archive file."
Entree Chicago Recommendation Data,Entree Chicago Recommendation Data,This data contains a record of user interactions with the Entree Chicago restaurant recommendation system.,Entree+Chicago+Recommendation+Data,https://archive.ics.uci.edu/ml//machine-learning-databases/entree-mld/,https://archive.ics.uci.edu/ml/datasets/Entree+Chicago+Recommendation+Data,"This data records interactions with Entree Chicago restaurant recommendation system (originally [Web Link]) from September, 1996 to April, 1999. The data is organized into files roughly spanning a quarter year -- with Q3 1996 and Q2 1999 each only containing one month. Each line in a session file represents a session of user interaction with the system. The (tab-separated) fields are as follows:      Date, IP, Entry point, Rated restaurant1, ..., Rated restaurantN, End point1. Entry point:Users can use a restaurant from any city as a entry point, but they always get recommendations for Chicago restaurants. The entry point therefore draws from a larger universe of restaurants than the rest of the data. Entry points have the form nnnX, where nnn is a numeric restaurant ID and X is a character A-H that encodes the city.      A = Atlanta     B = Boston     C = Chicago     D = Los Angeles     E = New Orleans     F = New York     G = San Francisco     H = Washington DC2. Rated Restaurant:These are all Chicago restaurants. These entries have the form nnnX, where nnn is a numeric restaurant ID and X is a character L-T that encodes the navigation operation.      L = browse (move from one restaurant in a list of recommendations to another)     M = cheaper (search for a restaurant like this one, but cheaper)     N = nicer   (         ""               ""           , but nicer)     O = closer  (unused in the production version of the system)     P = more traditional (search for a restaurant like this, but serving more traditional cuisine)     Q = more creative (search for a restaurant serving more creative cuisine)     R = more lively (search for a restaurant with a livelier atmosphere)     S = quieter (search for a restaurant with a quieter atmosphere)     T = change cuisine (search for a restaurant like this, but serving a different kind of food) Note that with this tweak, we would ideally like to know what cuisine the user wanted to change to, but this information was not recorded.3. End point:Just the numeric id for the (Chicago) restaurant that the user saw last. In our experiments, we are assuming that this was a good suggestion, but it is also possible that user just gives up. Some potentially useful data is missing. In many cases, we don't know the starting point because the user input a set of selection criteria (such as ""inexpensive traditional Mexican"") using a form submission, rather than starting from a known restaurant. These queries were not recorded. This is denoted by a 0 in the entry point field. Some sessions do not have a known end point. This is marked by -1 in the end point field. In addition to the user's interactions, there is also data linking the restaurant ID with its name and features such as ""fabulous wine lists"", ""good for younger kids"", and ""Ethopian"" cuisine. This data is stored by city (e.g. Atlanta, Boston, etc.) and is in the following format:     restaurant id [tab] restaurant name [tab] restaurant features (3 digits ids separated by spaces)",Unknown,,"This data contains a record of user interactions with the Entree Chicago restaurant recommendation system.This data records interactions with Entree Chicago restaurant recommendation system (originally [Web Link]) from September, 1996 to April, 1999. The data is organized into files roughly spanning a quarter year -- with Q3 1996 and Q2 1999 each only containing one month. Each line in a session file represents a session of user interaction with the system. The (tab-separated) fields are as follows:      Date, IP, Entry point, Rated restaurant1, ..., Rated restaurantN, End point1. Entry point:Users can use a restaurant from any city as a entry point, but they always get recommendations for Chicago restaurants. The entry point therefore draws from a larger universe of restaurants than the rest of the data. Entry points have the form nnnX, where nnn is a numeric restaurant ID and X is a character A-H that encodes the city.      A = Atlanta     B = Boston     C = Chicago     D = Los Angeles     E = New Orleans     F = New York     G = San Francisco     H = Washington DC2. Rated Restaurant:These are all Chicago restaurants. These entries have the form nnnX, where nnn is a numeric restaurant ID and X is a character L-T that encodes the navigation operation.      L = browse (move from one restaurant in a list of recommendations to another)     M = cheaper (search for a restaurant like this one, but cheaper)     N = nicer   (         ""               ""           , but nicer)     O = closer  (unused in the production version of the system)     P = more traditional (search for a restaurant like this, but serving more traditional cuisine)     Q = more creative (search for a restaurant serving more creative cuisine)     R = more lively (search for a restaurant with a livelier atmosphere)     S = quieter (search for a restaurant with a quieter atmosphere)     T = change cuisine (search for a restaurant like this, but serving a different kind of food) Note that with this tweak, we would ideally like to know what cuisine the user wanted to change to, but this information was not recorded.3. End point:Just the numeric id for the (Chicago) restaurant that the user saw last. In our experiments, we are assuming that this was a good suggestion, but it is also possible that user just gives up. Some potentially useful data is missing. In many cases, we don't know the starting point because the user input a set of selection criteria (such as ""inexpensive traditional Mexican"") using a form submission, rather than starting from a known restaurant. These queries were not recorded. This is denoted by a 0 in the entry point field. Some sessions do not have a known end point. This is marked by -1 in the end point field. In addition to the user's interactions, there is also data linking the restaurant ID with its name and features such as ""fabulous wine lists"", ""good for younger kids"", and ""Ethopian"" cuisine. This data is stored by city (e.g. Atlanta, Boston, etc.) and is in the following format:     restaurant id [tab] restaurant name [tab] restaurant features (3 digits ids separated by spaces)nan"
Folio,Folio,20 photos of leaves for each of 32 different species.,Folio,https://archive.ics.uci.edu/ml//machine-learning-databases/00338/,https://archive.ics.uci.edu/ml/datasets/Folio,- The leaves were placed on a white background and then photographed. - The pictures were taken in broad daylight to ensure optimum light intensity.,Unknown,List of plant species:1. Beaumier du perou2. Eggplant3. Fruitcitere4. Guava5. Hibiscus6. Betel7. Rose8. Chrysanthemum9. Ficus10. Duranta gold11. Ashanti blood12. Bitter Orange13. Coeur Demoiselle14. Jackfruit15. Mulberry Leaf16. Pimento17. Pomme Jacquot18. Star Apple19. Barbados Cherry20. Sweet Olive21. Croton22. Thevetia23. Vieux Garcon24. Chocolate tree25. Carricature plant26. Coffee27. Ketembilla28. Chinese guava29. Lychee30. Geranium31. Sweet potato32. Papaya,20 photos of leaves for each of 32 different species.- The leaves were placed on a white background and then photographed. - The pictures were taken in broad daylight to ensure optimum light intensity.List of plant species:1. Beaumier du perou2. Eggplant3. Fruitcitere4. Guava5. Hibiscus6. Betel7. Rose8. Chrysanthemum9. Ficus10. Duranta gold11. Ashanti blood12. Bitter Orange13. Coeur Demoiselle14. Jackfruit15. Mulberry Leaf16. Pimento17. Pomme Jacquot18. Star Apple19. Barbados Cherry20. Sweet Olive21. Croton22. Thevetia23. Vieux Garcon24. Chocolate tree25. Carricature plant26. Coffee27. Ketembilla28. Chinese guava29. Lychee30. Geranium31. Sweet potato32. Papaya
Activity Recognition from Single Chest-Mounted Accelerometer,Activity Recognition from Single Chest-Mounted Accelerometer,The dataset collects data from a wearable accelerometer mounted on the chest. The dataset is intended for Activity Recognition research purposes.,Activity+Recognition+from+Single+Chest-Mounted+Accelerometer,https://archive.ics.uci.edu/ml//machine-learning-databases/00287/,https://archive.ics.uci.edu/ml/datasets/Activity+Recognition+from+Single+Chest-Mounted+Accelerometer,   --- The dataset collects data from a wearable accelerometer mounted on the chest   --- Sampling frequency of the accelerometer: 52 Hz   --- Accelerometer Data are Uncalibrated   --- Number of Participants: 15   --- Number of Activities: 7   --- Data Format: CSV,Unknown,"   --- Data are separated by participant   --- Each file contains the following information       ---- sequential number, x acceleration, y acceleration, z acceleration, label    --- Labels are codified by numbers       --- 1: Working at Computer       --- 2: Standing Up, Walking and Going updown stairs       --- 3: Standing       --- 4: Walking       --- 5: Going UpDown Stairs       --- 6: Walking and Talking with Someone       --- 7: Talking while Standing","The dataset collects data from a wearable accelerometer mounted on the chest. The dataset is intended for Activity Recognition research purposes.   --- The dataset collects data from a wearable accelerometer mounted on the chest   --- Sampling frequency of the accelerometer: 52 Hz   --- Accelerometer Data are Uncalibrated   --- Number of Participants: 15   --- Number of Activities: 7   --- Data Format: CSV   --- Data are separated by participant   --- Each file contains the following information       ---- sequential number, x acceleration, y acceleration, z acceleration, label    --- Labels are codified by numbers       --- 1: Working at Computer       --- 2: Standing Up, Walking and Going updown stairs       --- 3: Standing       --- 4: Walking       --- 5: Going UpDown Stairs       --- 6: Walking and Talking with Someone       --- 7: Talking while Standing"
Turkiye Student Evaluation,Turkiye Student Evaluation,This data set contains a total 5820 evaluation scores provided by students from Gazi University in Ankara (Turkey). There is a total of 28 course specific questions and additional 5 attributes.,Turkiye+Student+Evaluation,https://archive.ics.uci.edu/ml//machine-learning-databases/00262/,https://archive.ics.uci.edu/ml/datasets/Turkiye+Student+Evaluation,,Unknown,"   instr: Instructor's identifier; values taken from {1,2,3}   class: Course code (descriptor); values taken from {1-13}   repeat: Number of times the student is taking this course; values taken from {0,1,2,3,...}   attendance: Code of the level of attendance; values from {0, 1, 2, 3, 4}   difficulty: Level of difficulty of the course as perceived by the student; values taken from {1,2,3,4,5}   Q1:  The semester course content, teaching method and evaluation system were provided at the start.   Q2:  The course aims and objectives were clearly stated at the beginning of the period.   Q3:  The course was worth the amount of credit assigned to it.   Q4:  The course was taught according to the syllabus announced on the first day of class.   Q5:	The class discussions, homework assignments, applications and studies were satisfactory.   Q6:  The textbook and other courses resources were sufficient and up to date.				   Q7:  The course allowed field work, applications, laboratory, discussion and other studies.   Q8:  The quizzes, assignments, projects and exams contributed to helping the learning.	   Q9:  I greatly enjoyed the class and was eager to actively participate during the lectures.   Q10: My initial expectations about the course were met at the end of the period or year.   Q11: The course was relevant and beneficial to my professional development.   Q12: The course helped me look at life and the world with a new perspective.   Q13: The Instructor's knowledge was relevant and up to date.   Q14: The Instructor came prepared for classes.   Q15: The Instructor taught in accordance with the announced lesson plan.   Q16: The Instructor was committed to the course and was understandable.   Q17: The Instructor arrived on time for classes.   Q18: The Instructor has a smooth and easy to follow delivery/speech.   Q19: The Instructor made effective use of class hours.   Q20: The Instructor explained the course and was eager to be helpful to students.   Q21: The Instructor demonstrated a positive approach to students.   Q22: The Instructor was open and respectful of the views of students about the course.   Q23: The Instructor encouraged participation in the course.   Q24: The Instructor gave relevant homework assignments/projects, and helped/guided students.   Q25: The Instructor responded to questions about the course inside and outside of the course.   Q26: The Instructor's evaluation system (midterm and final questions, projects, assignments, etc.) effectively measured the course objectives.   Q27: The Instructor provided solutions to exams and discussed them with students.   Q28: The Instructor treated all students in a right and objective manner.      Q1-Q28 are all Likert-type, meaning that the values are taken from {1,2,3,4,5}","This data set contains a total 5820 evaluation scores provided by students from Gazi University in Ankara (Turkey). There is a total of 28 course specific questions and additional 5 attributes.nan   instr: Instructor's identifier; values taken from {1,2,3}   class: Course code (descriptor); values taken from {1-13}   repeat: Number of times the student is taking this course; values taken from {0,1,2,3,...}   attendance: Code of the level of attendance; values from {0, 1, 2, 3, 4}   difficulty: Level of difficulty of the course as perceived by the student; values taken from {1,2,3,4,5}   Q1:  The semester course content, teaching method and evaluation system were provided at the start.   Q2:  The course aims and objectives were clearly stated at the beginning of the period.   Q3:  The course was worth the amount of credit assigned to it.   Q4:  The course was taught according to the syllabus announced on the first day of class.   Q5:	The class discussions, homework assignments, applications and studies were satisfactory.   Q6:  The textbook and other courses resources were sufficient and up to date.				   Q7:  The course allowed field work, applications, laboratory, discussion and other studies.   Q8:  The quizzes, assignments, projects and exams contributed to helping the learning.	   Q9:  I greatly enjoyed the class and was eager to actively participate during the lectures.   Q10: My initial expectations about the course were met at the end of the period or year.   Q11: The course was relevant and beneficial to my professional development.   Q12: The course helped me look at life and the world with a new perspective.   Q13: The Instructor's knowledge was relevant and up to date.   Q14: The Instructor came prepared for classes.   Q15: The Instructor taught in accordance with the announced lesson plan.   Q16: The Instructor was committed to the course and was understandable.   Q17: The Instructor arrived on time for classes.   Q18: The Instructor has a smooth and easy to follow delivery/speech.   Q19: The Instructor made effective use of class hours.   Q20: The Instructor explained the course and was eager to be helpful to students.   Q21: The Instructor demonstrated a positive approach to students.   Q22: The Instructor was open and respectful of the views of students about the course.   Q23: The Instructor encouraged participation in the course.   Q24: The Instructor gave relevant homework assignments/projects, and helped/guided students.   Q25: The Instructor responded to questions about the course inside and outside of the course.   Q26: The Instructor's evaluation system (midterm and final questions, projects, assignments, etc.) effectively measured the course objectives.   Q27: The Instructor provided solutions to exams and discussed them with students.   Q28: The Instructor treated all students in a right and objective manner.      Q1-Q28 are all Likert-type, meaning that the values are taken from {1,2,3,4,5}"
User Identification From Walking Activity,User Identification From Walking Activity,"The dataset collects data from an Android smartphone positioned in the chest pocket from 22 participants walking in the wild over a predefined path. 
",User+Identification+From+Walking+Activity,https://archive.ics.uci.edu/ml//machine-learning-databases/00286/,https://archive.ics.uci.edu/ml/datasets/User+Identification+From+Walking+Activity,The dataset collects data from an Android smartphone positioned in the chest pocket. Accelerometer Data are collected from 22 participants walking in the wild over a predefined path. The dataset is intended for Activity Recognition research purposes. It provides challenges for identification and authentication of people using motion patterns.   --- Sampling frequency of the accelerometer: DELAY_FASTEST with network connections disabled   --- Number of Participants: 22   --- Data Format: CSV,Unknown,"   --- Data are separated by participant   --- Each file contains the following information       ---- time-step, x acceleration, y acceleration, z acceleration","The dataset collects data from an Android smartphone positioned in the chest pocket from 22 participants walking in the wild over a predefined path. 
The dataset collects data from an Android smartphone positioned in the chest pocket. Accelerometer Data are collected from 22 participants walking in the wild over a predefined path. The dataset is intended for Activity Recognition research purposes. It provides challenges for identification and authentication of people using motion patterns.   --- Sampling frequency of the accelerometer: DELAY_FASTEST with network connections disabled   --- Number of Participants: 22   --- Data Format: CSV   --- Data are separated by participant   --- Each file contains the following information       ---- time-step, x acceleration, y acceleration, z acceleration"
Undocumented,Undocumented,Various datasets without documentation (feel free to explore!),Undocumented,https://archive.ics.uci.edu/ml//machine-learning-databases/undocumented/,https://archive.ics.uci.edu/ml/datasets/Undocumented,,Unknown,,Various datasets without documentation (feel free to explore!)nannan
Twenty Newsgroups,Twenty Newsgroups,This data set consists of 20000 messages taken from 20 newsgroups.,Twenty+Newsgroups,https://archive.ics.uci.edu/ml//machine-learning-databases/20newsgroups-mld/,https://archive.ics.uci.edu/ml/datasets/Twenty+Newsgroups,,Unknown,,This data set consists of 20000 messages taken from 20 newsgroups.nannan
Geographical Original of Music,Geographical Original of Music,"Instances in this dataset contain audio features extracted from 1059 wave files. The task associated with the data is to predict the geographical origin of music.
",Geographical+Original+of+Music,https://archive.ics.uci.edu/ml//machine-learning-databases/00315/,https://archive.ics.uci.edu/ml/datasets/Geographical+Original+of+Music," The dataset was built from a personal collection of 1059 tracks covering 33 countries/area. The music used is traditional, ethnic or `world' only, as classified by the publishers of the product on which it appears. Any Western music is not included because its influence is global - what we seek are the aspects of music that most influence location. Thus, being able to specify a location with strong influence on the music is central. The geographical location of origin was manually collected the information from the CD sleeve notes, and when this information was inadequate we searched other information sources. The location data is limited in precision to the country of origin.  The country of origin was determined by the artist's or artists' main country/area of residence.  Any track that had ambiguous origin is not included.  We have taken the position of each country's capital city (or the province of the area) by latitude and longitude as the absolute point of origin.The program MARSYAS[1] was used to extract audio features from the wave files. We used the default MARSYAS settings in single vector format (68 features) to estimate the performance with basic timbal information covering the entire length of each track. No feature weighting or pre-filtering was applied. All features were transformed to have a mean of 0, and a standard deviation of 1. We also investigated the utility of adding chromatic attributes. These describe the notes of the scale being used. This is especially important as a distinguishing feature in geographical ethnomusicology. The chromatic features provided by MARSYAS are 12 per octave - Western tuning, but it may be possible to tell something from how similar to or different from Western tuning the music is.[1] G. Tzanetakis and P. Cook, Ã¢â‚¬Å“MARSYAS: a framework for audio analysis,Ã¢â‚¬Â� Organised Sound, vol. 4, pp. 169Ã¢â‚¬â€œ175, 2000. ",Unknown,"The dataset is present in two files, where each file corresponds to a different feature sets.Both files contain the audio features of 1059 tracks.In the 'default_features_1059_tracks.txt' file, the first 68 columns are audio features of the track, and the last two columns are the origin of the music, represented by latitude and longitude.In the 'default_plus_chromatic_features_1059_tracks.txt' file, the first 116 columns are audio features of the track, and the last two columns are the origin of the music.","Instances in this dataset contain audio features extracted from 1059 wave files. The task associated with the data is to predict the geographical origin of music.
 The dataset was built from a personal collection of 1059 tracks covering 33 countries/area. The music used is traditional, ethnic or `world' only, as classified by the publishers of the product on which it appears. Any Western music is not included because its influence is global - what we seek are the aspects of music that most influence location. Thus, being able to specify a location with strong influence on the music is central. The geographical location of origin was manually collected the information from the CD sleeve notes, and when this information was inadequate we searched other information sources. The location data is limited in precision to the country of origin.  The country of origin was determined by the artist's or artists' main country/area of residence.  Any track that had ambiguous origin is not included.  We have taken the position of each country's capital city (or the province of the area) by latitude and longitude as the absolute point of origin.The program MARSYAS[1] was used to extract audio features from the wave files. We used the default MARSYAS settings in single vector format (68 features) to estimate the performance with basic timbal information covering the entire length of each track. No feature weighting or pre-filtering was applied. All features were transformed to have a mean of 0, and a standard deviation of 1. We also investigated the utility of adding chromatic attributes. These describe the notes of the scale being used. This is especially important as a distinguishing feature in geographical ethnomusicology. The chromatic features provided by MARSYAS are 12 per octave - Western tuning, but it may be possible to tell something from how similar to or different from Western tuning the music is.[1] G. Tzanetakis and P. Cook, Ã¢â‚¬Å“MARSYAS: a framework for audio analysis,Ã¢â‚¬Â� Organised Sound, vol. 4, pp. 169Ã¢â‚¬â€œ175, 2000. The dataset is present in two files, where each file corresponds to a different feature sets.Both files contain the audio features of 1059 tracks.In the 'default_features_1059_tracks.txt' file, the first 68 columns are audio features of the track, and the last two columns are the origin of the music, represented by latitude and longitude.In the 'default_plus_chromatic_features_1059_tracks.txt' file, the first 116 columns are audio features of the track, and the last two columns are the origin of the music."
Gesture Phase Segmentation,Gesture Phase Segmentation,"The dataset is composed by features extracted from 7 videos with people gesticulating, aiming at studying Gesture Phase Segmentation. It contains 50 attributes divided into two files for each video.",Gesture+Phase+Segmentation,https://archive.ics.uci.edu/ml//machine-learning-databases/00302/,https://archive.ics.uci.edu/ml/datasets/Gesture+Phase+Segmentation,"The dataset is composed by features extracted from 7 videos with people gesticulating, aiming at studying Gesture Phase Segmentation.Each video is represented by two files: a raw file, which contains the position of hands, wrists, head and spine of the user in each frame; and a processed file, which contains velocity and acceleration of hands and wrists. See the data set description for more information on the dataset.",Unknown,"Raw files: 18 numeric attributes (double), a timestamp and a class attribute (nominal).Processed files: 32 numeric attributes (double) and a class attribute (nominal).A feature vector with up to 50 numeric attributes can be generated with the two files mentioned above.","The dataset is composed by features extracted from 7 videos with people gesticulating, aiming at studying Gesture Phase Segmentation. It contains 50 attributes divided into two files for each video.The dataset is composed by features extracted from 7 videos with people gesticulating, aiming at studying Gesture Phase Segmentation.Each video is represented by two files: a raw file, which contains the position of hands, wrists, head and spine of the user in each frame; and a processed file, which contains velocity and acceleration of hands and wrists. See the data set description for more information on the dataset.Raw files: 18 numeric attributes (double), a timestamp and a class attribute (nominal).Processed files: 32 numeric attributes (double) and a class attribute (nominal).A feature vector with up to 50 numeric attributes can be generated with the two files mentioned above."
YearPredictionMSD,YearPredictionMSD,"Prediction of the release year of a song from audio features. Songs are mostly western, commercial tracks ranging from 1922 to 2011, with a peak in the year 2000s.",YearPredictionMSD,https://archive.ics.uci.edu/ml//machine-learning-databases/00203/,https://archive.ics.uci.edu/ml/datasets/YearPredictionMSD,"You should respect the following train / test split:train: first 463,715 examplestest: last 51,630 examplesIt avoids the 'producer effect' by making sure no songfrom a given artist ends up in both the train and test set.",Unknown,"90 attributes, 12 = timbre average, 78 = timbre covarianceThe first value is the year (target), ranging from 1922 to 2011.Features extracted from the 'timbre' features from The Echo Nest API.We take the average and covariance over all 'segments', each segmentbeing described by a 12-dimensional timbre vector.","Prediction of the release year of a song from audio features. Songs are mostly western, commercial tracks ranging from 1922 to 2011, with a peak in the year 2000s.You should respect the following train / test split:train: first 463,715 examplestest: last 51,630 examplesIt avoids the 'producer effect' by making sure no songfrom a given artist ends up in both the train and test set.90 attributes, 12 = timbre average, 78 = timbre covarianceThe first value is the year (target), ranging from 1922 to 2011.Features extracted from the 'timbre' features from The Echo Nest API.We take the average and covariance over all 'segments', each segmentbeing described by a 12-dimensional timbre vector."
University,University,Data in original (LISP-readable) form,University,https://archive.ics.uci.edu/ml//machine-learning-databases/university/,https://archive.ics.uci.edu/ml/datasets/University,"Format: Each observation concerns one university. In some cases, more information is provided about the attribute (e.g., units or domain). Some duplicates may exist and a single observation may have more than one value for a given attribute (esp. academic emphasis).It appears that several attributes could serve as a distinguished class attribute for this database.  The data file remains in the state as given to us by Steve Souders.  It is a LISP readable file with a few relevant functions at the end of the data file.  The info on missing data values have not been calculated.  We hope to get to this in the future.",Unknown,     1. University-name     2. State     3. location     4. Control     5. number-of-students     6. male:female (ratio)     7. student:faculty (ratio)     8. sat-verbal     9. sat-math    10. expenses    11. percent-financial-aid    12. number-of-applicants    13. percent-admittance    14. percent-enrolled    15. academics     16. social    17. quality-of-life    18. academic-emphasis,"Data in original (LISP-readable) formFormat: Each observation concerns one university. In some cases, more information is provided about the attribute (e.g., units or domain). Some duplicates may exist and a single observation may have more than one value for a given attribute (esp. academic emphasis).It appears that several attributes could serve as a distinguished class attribute for this database.  The data file remains in the state as given to us by Steve Souders.  It is a LISP readable file with a few relevant functions at the end of the data file.  The info on missing data values have not been calculated.  We hope to get to this in the future.     1. University-name     2. State     3. location     4. Control     5. number-of-students     6. male:female (ratio)     7. student:faculty (ratio)     8. sat-verbal     9. sat-math    10. expenses    11. percent-financial-aid    12. number-of-applicants    13. percent-admittance    14. percent-enrolled    15. academics     16. social    17. quality-of-life    18. academic-emphasis"
Facebook Comment Volume Dataset,Facebook Comment Volume Dataset,Instances in this dataset contain features extracted from facebook posts. The task associated with the data is to predict how many comments the post will receive.,Facebook+Comment+Volume+Dataset,https://archive.ics.uci.edu/ml//machine-learning-databases/00363/,https://archive.ics.uci.edu/ml/datasets/Facebook+Comment+Volume+Dataset,"The Dataset is uploaded in ZIP format. The dataset contains 5 variants of the dataset, for the details about the variants and detailed analysis read and cite the research paper @INPROCEEDINGS{Sing1503:Comment,AUTHOR='Kamaljot Singh and Ranjeet Kaur Sandhu and Dinesh Kumar',TITLE='Comment Volume Prediction Using Neural Networks and Decision Trees',BOOKTITLE='IEEE UKSim-AMSS 17th International Conference on Computer Modelling andSimulation, UKSim2015 (UKSim2015)',ADDRESS='Cambridge, United Kingdom',DAYS=25,MONTH=mar,YEAR=2015,KEYWORDS='Neural Networks; RBF Network; Prediction; Facebook; Comments; Data Mining;REP Tree; M5P Trees.',ABSTRACT='The leading treads towards social networking services had drawn massivepublic attention from last one and half decade. The amount of data that isuploaded to these social networking services is increasing day by day. So,there is massive requirement to study the highly dynamic behavior of userstowards these services. This is a preliminary work to model the userpatterns and to study the effectiveness of machine learning predictivemodeling approaches on leading social networking service Facebook. Wemodeled the user comment patters, over the posts on Facebook Pages andpredicted that how many comments a post is expected to receive in next Hhrs. In order to automate the process, we developed a software prototypeconsisting of the crawler, Information extractor, information processor andknowledge discovery module. We used Neural Networks and Decision Trees,predictive modeling techniques on different dataset variants and evaluatedthem under Hits(at)10 (custom measure), Area Under Curve, Evaluation Timeand Mean Absolute error evaluation metrics. We concluded that the Decisiontrees performed better than the Neural Networks under light of allevaluation metrics.'}The research paper is also available at conference website:uksim.info/uksim2015/[Web Link]another extended paper is that is to be published soon is :@ARTICLE{Sing1601:Facebook,AUTHOR='Kamaljot Singh',TITLE='Facebook Comment Volume Prediction',JOURNAL='International Journal of Simulation- Systems, Science and Technology-IJSSST V16',ADDRESS='Cambridge, United Kingdom',DAYS=30,MONTH=jan,YEAR=2016,KEYWORDS='Neural Networks; RBF Network; Prediction; Facebook; Comments; Data Mining;REP Tree; M5P Trees.',ABSTRACT='The amount of data that is uploaded to social networking services isincreasing day by day. So, their is massive requirement to study the highlydynamic behavior of users towards these services. This work is to model theuser patterns and to study the effectiveness of machine learning predictivemodeling approaches on leading social networking service Facebook. Wemodeled the user comment patters, over the posts on Facebook Pages andpredicted that how many comments a post is expected to receive in next Hhrs. To automate the process, we developed a software prototype consistingof the crawler, Information extractor, information processor and knowledgediscovery module. We used Neural Networks and Decision Trees, predictivemodeling techniques on different data-set variants and evaluated them underHits(at)10, Area Under Curve, Evaluation Time and M.A.E metrics. Weconcluded that the Decision trees performed better than the Neural Networksunder light of all metrics.'}this above paper will be freely available after publication at www.ijssst.info",Unknown,"1Page Popularity/likesDecimal EncodingPage featureDefines the popularity or support for the source of the document.2Page CheckinsÃ¢â‚¬â„¢sDecimal EncodingPage  featureDescribes how many individuals so far visited this place. This feature is only associated with the places eg:some institution, place, theater etc.3Page talking aboutDecimal EncodingPage featureDefines the daily interest of individuals towards source of the document/ Post. The people who actually come back to the page, after liking the page. This include activities such as comments, likes to a post, shares, etc by visitors to the page.4Page CategoryValue  EncodingPage featureDefines the category of the source of the document eg: place, institution, brand etc.5 - 29DerivedDecimal  EncodingDerived featureThese features are aggregated by page, by calculating min, max, average, median and standard deviation of essential features.30CC1Decimal EncodingEssential featureThe total number of comments before selected base date/time.31CC2Decimal EncodingEssential featureThe number of comments in last 24 hours, relative to base date/time.32CC3Decimal EncodingEssential featureThe number of comments in last 48 to last 24 hours relative to base date/time.33CC4Decimal EncodingEssential featureThe number of comments in the first 24 hours after the publication of post but before base date/time.34CC5Decimal EncodingEssential featureThe difference between CC2 and CC3.35Base timeDecimal(0-71) EncodingOther featureSelected time in order to simulate the scenario.36Post lengthDecimal EncodingOther featureCharacter count in the post.37Post Share CountÃ¯Â¿Â¼Ã¯Â¿Â¼Decimal EncodingOther featureThis features counts the no of shares of the post, that how many peoples had shared this post on to their timeline.38Post Promotion StatusÃ¯Â¿Â¼Ã¯Â¿Â¼Binary EncodingOther featureTo reach more people with posts in News Feed, individual promote their post and this features tells that whether the post is promoted(1) or not(0).39H LocalÃ¯Â¿Â¼Decimal(0-23) EncodingOther featureThis describes the H hrs, for which we have the target variable/ comments received.40-46Post published weekdayBinary EncodingWeekdays featureThis represents the day(Sunday...Saturday) on which the post was published.47-53Base DateTime weekdayBinary EncodingWeekdays featureThis represents the day(Sunday...Saturday) on selected base Date/Time.54Target VariableDecimalTargetThe no of comments in next H hrs(H is given in Feature no 39).","Instances in this dataset contain features extracted from facebook posts. The task associated with the data is to predict how many comments the post will receive.The Dataset is uploaded in ZIP format. The dataset contains 5 variants of the dataset, for the details about the variants and detailed analysis read and cite the research paper @INPROCEEDINGS{Sing1503:Comment,AUTHOR='Kamaljot Singh and Ranjeet Kaur Sandhu and Dinesh Kumar',TITLE='Comment Volume Prediction Using Neural Networks and Decision Trees',BOOKTITLE='IEEE UKSim-AMSS 17th International Conference on Computer Modelling andSimulation, UKSim2015 (UKSim2015)',ADDRESS='Cambridge, United Kingdom',DAYS=25,MONTH=mar,YEAR=2015,KEYWORDS='Neural Networks; RBF Network; Prediction; Facebook; Comments; Data Mining;REP Tree; M5P Trees.',ABSTRACT='The leading treads towards social networking services had drawn massivepublic attention from last one and half decade. The amount of data that isuploaded to these social networking services is increasing day by day. So,there is massive requirement to study the highly dynamic behavior of userstowards these services. This is a preliminary work to model the userpatterns and to study the effectiveness of machine learning predictivemodeling approaches on leading social networking service Facebook. Wemodeled the user comment patters, over the posts on Facebook Pages andpredicted that how many comments a post is expected to receive in next Hhrs. In order to automate the process, we developed a software prototypeconsisting of the crawler, Information extractor, information processor andknowledge discovery module. We used Neural Networks and Decision Trees,predictive modeling techniques on different dataset variants and evaluatedthem under Hits(at)10 (custom measure), Area Under Curve, Evaluation Timeand Mean Absolute error evaluation metrics. We concluded that the Decisiontrees performed better than the Neural Networks under light of allevaluation metrics.'}The research paper is also available at conference website:uksim.info/uksim2015/[Web Link]another extended paper is that is to be published soon is :@ARTICLE{Sing1601:Facebook,AUTHOR='Kamaljot Singh',TITLE='Facebook Comment Volume Prediction',JOURNAL='International Journal of Simulation- Systems, Science and Technology-IJSSST V16',ADDRESS='Cambridge, United Kingdom',DAYS=30,MONTH=jan,YEAR=2016,KEYWORDS='Neural Networks; RBF Network; Prediction; Facebook; Comments; Data Mining;REP Tree; M5P Trees.',ABSTRACT='The amount of data that is uploaded to social networking services isincreasing day by day. So, their is massive requirement to study the highlydynamic behavior of users towards these services. This work is to model theuser patterns and to study the effectiveness of machine learning predictivemodeling approaches on leading social networking service Facebook. Wemodeled the user comment patters, over the posts on Facebook Pages andpredicted that how many comments a post is expected to receive in next Hhrs. To automate the process, we developed a software prototype consistingof the crawler, Information extractor, information processor and knowledgediscovery module. We used Neural Networks and Decision Trees, predictivemodeling techniques on different data-set variants and evaluated them underHits(at)10, Area Under Curve, Evaluation Time and M.A.E metrics. Weconcluded that the Decision trees performed better than the Neural Networksunder light of all metrics.'}this above paper will be freely available after publication at www.ijssst.info1Page Popularity/likesDecimal EncodingPage featureDefines the popularity or support for the source of the document.2Page CheckinsÃ¢â‚¬â„¢sDecimal EncodingPage  featureDescribes how many individuals so far visited this place. This feature is only associated with the places eg:some institution, place, theater etc.3Page talking aboutDecimal EncodingPage featureDefines the daily interest of individuals towards source of the document/ Post. The people who actually come back to the page, after liking the page. This include activities such as comments, likes to a post, shares, etc by visitors to the page.4Page CategoryValue  EncodingPage featureDefines the category of the source of the document eg: place, institution, brand etc.5 - 29DerivedDecimal  EncodingDerived featureThese features are aggregated by page, by calculating min, max, average, median and standard deviation of essential features.30CC1Decimal EncodingEssential featureThe total number of comments before selected base date/time.31CC2Decimal EncodingEssential featureThe number of comments in last 24 hours, relative to base date/time.32CC3Decimal EncodingEssential featureThe number of comments in last 48 to last 24 hours relative to base date/time.33CC4Decimal EncodingEssential featureThe number of comments in the first 24 hours after the publication of post but before base date/time.34CC5Decimal EncodingEssential featureThe difference between CC2 and CC3.35Base timeDecimal(0-71) EncodingOther featureSelected time in order to simulate the scenario.36Post lengthDecimal EncodingOther featureCharacter count in the post.37Post Share CountÃ¯Â¿Â¼Ã¯Â¿Â¼Decimal EncodingOther featureThis features counts the no of shares of the post, that how many peoples had shared this post on to their timeline.38Post Promotion StatusÃ¯Â¿Â¼Ã¯Â¿Â¼Binary EncodingOther featureTo reach more people with posts in News Feed, individual promote their post and this features tells that whether the post is promoted(1) or not(0).39H LocalÃ¯Â¿Â¼Decimal(0-23) EncodingOther featureThis describes the H hrs, for which we have the target variable/ comments received.40-46Post published weekdayBinary EncodingWeekdays featureThis represents the day(Sunday...Saturday) on which the post was published.47-53Base DateTime weekdayBinary EncodingWeekdays featureThis represents the day(Sunday...Saturday) on selected base Date/Time.54Target VariableDecimalTargetThe no of comments in next H hrs(H is given in Feature no 39)."
University of Tehran Question Dataset 2016 (UTQD.2016),University of Tehran Question Dataset 2016 (UTQD.2016),Persian questions gathered from a jeopardy game broadcasted on Iranian national television. ,University+of+Tehran+Question+Dataset+2016+%28UTQD.2016%29,https://archive.ics.uci.edu/ml//machine-learning-databases/00425/,https://archive.ics.uci.edu/ml/datasets/University+of+Tehran+Question+Dataset+2016+%28UTQD.2016%29,The format of each record: Coarse-grained:Fine-grained|Question,Unknown,,Persian questions gathered from a jeopardy game broadcasted on Iranian national television. The format of each record: Coarse-grained:Fine-grained|Questionnan
Corel Image Features,Corel Image Features,"This dataset contains image features extracted from a Corel image collection. Four sets of features are available based on the color histogram, color histogram layout, color moments, and co-occurence",Corel+Image+Features,https://archive.ics.uci.edu/ml//machine-learning-databases/CorelFeatures-mld/,https://archive.ics.uci.edu/ml/datasets/Corel+Image+Features,"The original image collection was obtained from Corel at [Web Link]. There are 68,040 photo images from various categories.Each set of features is stored in a separate file. For each file, a line corresponds to a single image. The first value in a line is is the image ID and the subsequent values are the feature vector (e.g. color histogram, etc.) of the image. The same image has the same ID in all files but the image ID is not the same as the image filename. ",Unknown,"From each image four sets of features were extracted: - Color Histogram - Color Histogram Layout - Color Moments - Co-occurrence Texture Color Histogram: 32 dimensions (8 x 4 = H x S)- HSV color space is divided into 32 subspaces (32 colors : 8 ranges of H and 4 ranges of S). - the value in each dimension in a ColorHistogram of an image is the density of each color in the entire image. - Histogram intersection (overlap area between ColorHistograms of two images) can be used to measure the similarity between two images. Color Histogram Layout: 32 dimensions (4 x 2 x 4 = H x S x sub-images)- each image is divided into 4 sub-images (one horizontal split and one vertical split). - 4x2 Color Histogram for each sub-image is computed. - Histogram Intersection can be used to measure the similarity between two images. Color Moments: 9 dimensions (3 x 3)- the 9 values are: (one for each of H,S, and V in HSV color space)   -- mean,   -- standard deviation, and   -- skewness. - Euclidean distance between Color Moments of two images can be used to represent the dis-similarity (distance) between two images. Co-occurrence Texture: 16 dimensions (4 x 4)- images are converted to 16 gray-scale images. - co-ocurrence in 4 directions is computed (horizontal, vertical, and two diagonal directions). the 16 values are: (one for each direction).   -- Second Angular Moment,   -- Contrast, I  -- nverse Difference Moment, and   -- Entropy. -Euclidean distance between ColorMoments of two images can be used to measure the dis-similarity (distance) between two images. ","This dataset contains image features extracted from a Corel image collection. Four sets of features are available based on the color histogram, color histogram layout, color moments, and co-occurenceThe original image collection was obtained from Corel at [Web Link]. There are 68,040 photo images from various categories.Each set of features is stored in a separate file. For each file, a line corresponds to a single image. The first value in a line is is the image ID and the subsequent values are the feature vector (e.g. color histogram, etc.) of the image. The same image has the same ID in all files but the image ID is not the same as the image filename. From each image four sets of features were extracted: - Color Histogram - Color Histogram Layout - Color Moments - Co-occurrence Texture Color Histogram: 32 dimensions (8 x 4 = H x S)- HSV color space is divided into 32 subspaces (32 colors : 8 ranges of H and 4 ranges of S). - the value in each dimension in a ColorHistogram of an image is the density of each color in the entire image. - Histogram intersection (overlap area between ColorHistograms of two images) can be used to measure the similarity between two images. Color Histogram Layout: 32 dimensions (4 x 2 x 4 = H x S x sub-images)- each image is divided into 4 sub-images (one horizontal split and one vertical split). - 4x2 Color Histogram for each sub-image is computed. - Histogram Intersection can be used to measure the similarity between two images. Color Moments: 9 dimensions (3 x 3)- the 9 values are: (one for each of H,S, and V in HSV color space)   -- mean,   -- standard deviation, and   -- skewness. - Euclidean distance between Color Moments of two images can be used to represent the dis-similarity (distance) between two images. Co-occurrence Texture: 16 dimensions (4 x 4)- images are converted to 16 gray-scale images. - co-ocurrence in 4 directions is computed (horizontal, vertical, and two diagonal directions). the 16 values are: (one for each direction).   -- Second Angular Moment,   -- Contrast, I  -- nverse Difference Moment, and   -- Entropy. -Euclidean distance between ColorMoments of two images can be used to measure the dis-similarity (distance) between two images. "
Teaching Assistant Evaluation,Teaching Assistant Evaluation,"The data consist of evaluations of teaching performance; scores are ""low"", ""medium"", or ""high""",Teaching+Assistant+Evaluation,https://archive.ics.uci.edu/ml//machine-learning-databases/tae/,https://archive.ics.uci.edu/ml/datasets/Teaching+Assistant+Evaluation,"The data consist of evaluations of teaching performance over three regular semesters and two summer semesters of 151 teaching assistant (TA) assignments at the Statistics Department of the University of Wisconsin-Madison. The scores were divided into 3 roughly equal-sized categories (""low"", ""medium"", and ""high"") to form the class variable.",Unknown,"   1. Whether of not the TA is a native English speaker (binary); 1=English speaker, 2=non-English speaker   2. Course instructor (categorical, 25 categories)   3. Course (categorical, 26 categories)   4. Summer or regular semester (binary) 1=Summer, 2=Regular   5. Class size (numerical)   6. Class attribute (categorical) 1=Low, 2=Medium, 3=High","The data consist of evaluations of teaching performance; scores are ""low"", ""medium"", or ""high""The data consist of evaluations of teaching performance over three regular semesters and two summer semesters of 151 teaching assistant (TA) assignments at the Statistics Department of the University of Wisconsin-Madison. The scores were divided into 3 roughly equal-sized categories (""low"", ""medium"", and ""high"") to form the class variable.   1. Whether of not the TA is a native English speaker (binary); 1=English speaker, 2=non-English speaker   2. Course instructor (categorical, 25 categories)   3. Course (categorical, 26 categories)   4. Summer or regular semester (binary) 1=Summer, 2=Regular   5. Class size (numerical)   6. Class attribute (categorical) 1=Low, 2=Medium, 3=High"
DGP2 - The Second Data Generation Program,DGP2 - The Second Data Generation Program,"Generates application domains based on specific parameters, number of features, and proportion of positive to negative examples",DGP2+-+The+Second+Data+Generation+Program,https://archive.ics.uci.edu/ml//machine-learning-databases/dgp-2/,https://archive.ics.uci.edu/ml/datasets/DGP2+-+The+Second+Data+Generation+Program,"DGP/2 is an improvement of DGP.  It allows for additional parameters and automates the setting of the standard deviation parameter, which is not easily done by the user.  In particular, DGP/2 allows for variation in the number of instances, the number of features, the range of feature values, the number of peaks, the percent of positive instances desired and a radius around the peaks that these instances will fall within (this controls instance density, and determines the standard deviation value for the normal distribution function).",Unknown,,"Generates application domains based on specific parameters, number of features, and proportion of positive to negative examplesDGP/2 is an improvement of DGP.  It allows for additional parameters and automates the setting of the standard deviation parameter, which is not easily done by the user.  In particular, DGP/2 allows for variation in the number of instances, the number of features, the range of feature values, the number of peaks, the percent of positive instances desired and a radius around the peaks that these instances will fall within (this controls instance density, and determines the standard deviation value for the normal distribution function).nan"
Dexter,Dexter,"DEXTER is a text classification problem in a bag-of-word representation. This is a two-class classification problem with sparse continuous input variables. This dataset is one of five datasets of the NIPS 2003 feature selection challenge.
",Dexter,https://archive.ics.uci.edu/ml//machine-learning-databases/dexter/,https://archive.ics.uci.edu/ml/datasets/Dexter,"The original data were formatted by Thorsten Joachims in the â€œbag-of-wordsâ€� representation. There were 9947 features (of which 2562 are always zeros for all the examples) representing frequencies of occurrence of word stems in text. The task is to learn which Reuters articles are about 'corporate acquisitions'. We added a number of distractor feature called 'probes' having no predictive power. The order of the features and patterns were randomized. DEXTER -- Positive ex. -- Negative ex. -- Total		   Training set --150 -- 150 -- 300		   Validation set -- 150 -- 150 -- 300		   Test set -- 1000 -- 1000 -- 2000		   All -- 1300 -- 1300 -- 2600		 Number of variables/features/attributes:Real: 9947Probes: 10053Total: 20000This dataset is one of five datasets used in the NIPS 2003 feature selection challenge. Our website [Web Link] is still open for post-challenge submissions. Information about other related challenges are found at: [Web Link]. The CLOP package includes sample code to process these data: [Web Link].All details about the preparation of the data are found in our technical report: Design of experiments for the NIPS 2003 variable selection benchmark, Isabelle Guyon, July 2003, [Web Link] (also included in the dataset archive). Such information was made available only after the end of the challenge.The data are split into training, validation, and test set. Target values are provided only for the 2 first sets. Test set performance results are obtained by submitting prediction results to: [Web Link].The data are in the following format:dataname.param: Parameters and statistics about the datadataname.feat: Identities of the features (withheld, to avoid biasing feature selection).dataname_train.data: Training set (a sparse matrix, patterns in lines, features in columns: feature number followed by value).  dataname_valid.data: Validation set.    dataname_test.data: Test set. dataname_train.labels: Labels (truth values of the classes) for training examples.   dataname_valid.labels: Validation set labels (withheld during the benchmark, but provided now).dataname_test.labels: Test set labels  (withheld, so the data can still be use as a benchmark).",Unknown,We do not provide feature information to avoid biasing feature selection.,"DEXTER is a text classification problem in a bag-of-word representation. This is a two-class classification problem with sparse continuous input variables. This dataset is one of five datasets of the NIPS 2003 feature selection challenge.
The original data were formatted by Thorsten Joachims in the â€œbag-of-wordsâ€� representation. There were 9947 features (of which 2562 are always zeros for all the examples) representing frequencies of occurrence of word stems in text. The task is to learn which Reuters articles are about 'corporate acquisitions'. We added a number of distractor feature called 'probes' having no predictive power. The order of the features and patterns were randomized. DEXTER -- Positive ex. -- Negative ex. -- Total		   Training set --150 -- 150 -- 300		   Validation set -- 150 -- 150 -- 300		   Test set -- 1000 -- 1000 -- 2000		   All -- 1300 -- 1300 -- 2600		 Number of variables/features/attributes:Real: 9947Probes: 10053Total: 20000This dataset is one of five datasets used in the NIPS 2003 feature selection challenge. Our website [Web Link] is still open for post-challenge submissions. Information about other related challenges are found at: [Web Link]. The CLOP package includes sample code to process these data: [Web Link].All details about the preparation of the data are found in our technical report: Design of experiments for the NIPS 2003 variable selection benchmark, Isabelle Guyon, July 2003, [Web Link] (also included in the dataset archive). Such information was made available only after the end of the challenge.The data are split into training, validation, and test set. Target values are provided only for the 2 first sets. Test set performance results are obtained by submitting prediction results to: [Web Link].The data are in the following format:dataname.param: Parameters and statistics about the datadataname.feat: Identities of the features (withheld, to avoid biasing feature selection).dataname_train.data: Training set (a sparse matrix, patterns in lines, features in columns: feature number followed by value).  dataname_valid.data: Validation set.    dataname_test.data: Test set. dataname_train.labels: Labels (truth values of the classes) for training examples.   dataname_valid.labels: Validation set labels (withheld during the benchmark, but provided now).dataname_test.labels: Test set labels  (withheld, so the data can still be use as a benchmark).We do not provide feature information to avoid biasing feature selection."
Record Linkage Comparison Patterns,Record Linkage Comparison Patterns,Element-wise comparison of records with personal data from a record linkage setting. The task is to decide from a comparison pattern whether the underlying records belong to one person.,Record+Linkage+Comparison+Patterns,https://archive.ics.uci.edu/ml//machine-learning-databases/00210/,https://archive.ics.uci.edu/ml/datasets/Record+Linkage+Comparison+Patterns,"The records represent individual data including first and family name, sex, date of birth and postal code, which were collected through iterative insertions in the course of several years. The comparison patterns in this data set are based on a sample of 100.000 records dating from 2005 to 2008. Data pairs were classified as 'match' or 'non-match' during an extensive manual review where several documentarists were involved. The resulting classification formed the basis for assessing the quality of the registryÃ¢â‚¬â„¢s own record linkage procedure.In order to limit the amount of patterns, a blocking procedure was applied,which selects only record pairs that meet specific agreement conditions. Theresults of the following six blocking iterations were merged together:  1. Phonetic equality of first name and family name, equality of date of birth.  2. Phonetic equality of first name, equality of day of birth.  3. Phonetic equality of first name, equality of month of birth.  4. Phonetic equality of first name, equality of year of birth.  5. Equality of complete date of birth.  6. Phonetic equality of family name, equality of sex.  This procedure resulted in 5.749.132 record pairs, of which 20.931 are matches.The data set is split into 10 blocks of (approximately) equal size and ratioof matches to non-matches.The separate file frequencies.csv contains for every predictive attribute the average number of values in the underlying records. These values can, for example,be used as u-probabilities in weight-based record linkage following theframework of Fellegi and Sunter.",Unknown,"1. id_1: internal identifier of first record.2. id_2: internal identifier of second record.3. cmp_fname_c1: agreement of first name, first component4. cmp_fname_c2: agreement of first name, second component5. cmp_lname_c1: agreement of family name, first component6. cmp_lname_c2: agreement of family name, second component7. cmp_sex: agreement sex8. cmp_bd: agreement of date of birth, day component9. cmp_bm: agreement of date of birth, month component10. cmp_by: agreement of date of birth, year component11. cmp_plz: agreement of postal code12. is_match: matching status (TRUE for matches, FALSE for non-matches)  The agreement of name components is measured as a real number in the interval [0,1], where 0 denotes maximal disagreement and 1 equality of the underlying values. For the other comparisons, only the values 0 (not equal) and 1 (equal) are used.is_match is the outcome variable. id_1 and id_2 are not used for prediction but could be used to construct connected components from the found matches.","Element-wise comparison of records with personal data from a record linkage setting. The task is to decide from a comparison pattern whether the underlying records belong to one person.The records represent individual data including first and family name, sex, date of birth and postal code, which were collected through iterative insertions in the course of several years. The comparison patterns in this data set are based on a sample of 100.000 records dating from 2005 to 2008. Data pairs were classified as 'match' or 'non-match' during an extensive manual review where several documentarists were involved. The resulting classification formed the basis for assessing the quality of the registryÃ¢â‚¬â„¢s own record linkage procedure.In order to limit the amount of patterns, a blocking procedure was applied,which selects only record pairs that meet specific agreement conditions. Theresults of the following six blocking iterations were merged together:  1. Phonetic equality of first name and family name, equality of date of birth.  2. Phonetic equality of first name, equality of day of birth.  3. Phonetic equality of first name, equality of month of birth.  4. Phonetic equality of first name, equality of year of birth.  5. Equality of complete date of birth.  6. Phonetic equality of family name, equality of sex.  This procedure resulted in 5.749.132 record pairs, of which 20.931 are matches.The data set is split into 10 blocks of (approximately) equal size and ratioof matches to non-matches.The separate file frequencies.csv contains for every predictive attribute the average number of values in the underlying records. These values can, for example,be used as u-probabilities in weight-based record linkage following theframework of Fellegi and Sunter.1. id_1: internal identifier of first record.2. id_2: internal identifier of second record.3. cmp_fname_c1: agreement of first name, first component4. cmp_fname_c2: agreement of first name, second component5. cmp_lname_c1: agreement of family name, first component6. cmp_lname_c2: agreement of family name, second component7. cmp_sex: agreement sex8. cmp_bd: agreement of date of birth, day component9. cmp_bm: agreement of date of birth, month component10. cmp_by: agreement of date of birth, year component11. cmp_plz: agreement of postal code12. is_match: matching status (TRUE for matches, FALSE for non-matches)  The agreement of name components is measured as a real number in the interval [0,1], where 0 denotes maximal disagreement and 1 equality of the underlying values. For the other comparisons, only the values 0 (not equal) and 1 (equal) are used.is_match is the outcome variable. id_1 and id_2 are not used for prediction but could be used to construct connected components from the found matches."
CalIt2 Building People Counts,CalIt2 Building People Counts,This data comes from the main door of the CalIt2 building at UCI.,CalIt2+Building+People+Counts,https://archive.ics.uci.edu/ml//machine-learning-databases/event-detection/,https://archive.ics.uci.edu/ml/datasets/CalIt2+Building+People+Counts,"Observations come from 2 data streams (people flow in and out of the building),  over 15 weeks, 48 time slices per day (half hour count aggregates). The purpose is to predict the presence of an event such as a conference in the building that is reflected by unusually high people counts for that day/time period.  ",Unknown,"1.  Flow ID: 7 is out flow, 9 is in flow2.  Date: MM/DD/YY3.  Time: HH:MM:SS4.  Count: Number of counts reported for the previous half hour  Rows: Each half hour time slice is represented by 2 rows: one row for the out flow during that time period (ID=7) and one row for the in flow during that time period (ID=9)Attributes in .events file (""ground truth"")1.  Date: MM/DD/YY2.  Begin event time: HH:MM:SS (military) 3.  End event time: HH:MM:SS (military)4.  Event name (anonymized)","This data comes from the main door of the CalIt2 building at UCI.Observations come from 2 data streams (people flow in and out of the building),  over 15 weeks, 48 time slices per day (half hour count aggregates). The purpose is to predict the presence of an event such as a conference in the building that is reflected by unusually high people counts for that day/time period.  1.  Flow ID: 7 is out flow, 9 is in flow2.  Date: MM/DD/YY3.  Time: HH:MM:SS4.  Count: Number of counts reported for the previous half hour  Rows: Each half hour time slice is represented by 2 rows: one row for the out flow during that time period (ID=7) and one row for the in flow during that time period (ID=9)Attributes in .events file (""ground truth"")1.  Date: MM/DD/YY2.  Begin event time: HH:MM:SS (military) 3.  End event time: HH:MM:SS (military)4.  Event name (anonymized)"
Car Evaluation,Car Evaluation,"Derived from simple hierarchical decision model, this database may be useful for testing constructive induction and structure discovery methods.",Car+Evaluation,https://archive.ics.uci.edu/ml//machine-learning-databases/car/,https://archive.ics.uci.edu/ml/datasets/Car+Evaluation,"Car Evaluation Database was derived from a simple hierarchical decision model originally developed for the demonstration of DEX, M. Bohanec, V. Rajkovic: Expert system for decision making. Sistemica 1(1), pp. 145-157, 1990.). The model evaluates cars according to the following concept structure:CAR                      car acceptability. PRICE                  overall price. . buying               buying price. . maint                price of the maintenance. TECH                   technical characteristics. . COMFORT              comfort. . . doors              number of doors. . . persons            capacity in terms of persons to carry. . . lug_boot           the size of luggage boot. . safety               estimated safety of the carInput attributes are printed in lowercase. Besides the target concept (CAR), the model includes three intermediate concepts: PRICE, TECH, COMFORT. Every concept is in the original model related to its lower level descendants by a set of examples (for these examples sets see [Web Link]).The Car Evaluation Database contains examples with the structural information removed, i.e., directly relates CAR to the six input attributes: buying, maint, doors, persons, lug_boot, safety.Because of known underlying concept structure, this database may be particularly useful for testing constructive induction and structure discovery methods.",Unknown,"Class Values:unacc, acc, good, vgoodAttributes:buying:   vhigh, high, med, low.maint:    vhigh, high, med, low.doors:    2, 3, 4, 5more.persons:  2, 4, more.lug_boot: small, med, big.safety:   low, med, high.","Derived from simple hierarchical decision model, this database may be useful for testing constructive induction and structure discovery methods.Car Evaluation Database was derived from a simple hierarchical decision model originally developed for the demonstration of DEX, M. Bohanec, V. Rajkovic: Expert system for decision making. Sistemica 1(1), pp. 145-157, 1990.). The model evaluates cars according to the following concept structure:CAR                      car acceptability. PRICE                  overall price. . buying               buying price. . maint                price of the maintenance. TECH                   technical characteristics. . COMFORT              comfort. . . doors              number of doors. . . persons            capacity in terms of persons to carry. . . lug_boot           the size of luggage boot. . safety               estimated safety of the carInput attributes are printed in lowercase. Besides the target concept (CAR), the model includes three intermediate concepts: PRICE, TECH, COMFORT. Every concept is in the original model related to its lower level descendants by a set of examples (for these examples sets see [Web Link]).The Car Evaluation Database contains examples with the structural information removed, i.e., directly relates CAR to the six input attributes: buying, maint, doors, persons, lug_boot, safety.Because of known underlying concept structure, this database may be particularly useful for testing constructive induction and structure discovery methods.Class Values:unacc, acc, good, vgoodAttributes:buying:   vhigh, high, med, low.maint:    vhigh, high, med, low.doors:    2, 3, 4, 5more.persons:  2, 4, more.lug_boot: small, med, big.safety:   low, med, high."
Legal Case Reports,Legal Case Reports,"A textual corpus of 4000 legal cases for automatic summarization and citation analysis. For each document we collect catchphrases, citations sentences, citation catchphrases and citation classes.",Legal+Case+Reports,https://archive.ics.uci.edu/ml//machine-learning-databases/00239/,https://archive.ics.uci.edu/ml/datasets/Legal+Case+Reports,"This dataset contains Australian legal cases from the Federal Court of Australia (FCA). The cases were downloaded from AustLII ([Web Link]). We included all cases from the year 2006,2007,2008 and 2009. We built it to experiment with automatic summarization and citation analysis. For each document we collected catchphrases, citations sentences, citation catchphrases, and citation classes. Catchphrases are found in the document, we used the catchphrases are gold standard for our summarization experiments. Citation sentences are found in later cases that cite the present case, we use citation sentences for summarization. Citation catchphrases are the catchphrases (where available) of both later cases that cite the present case, and older cases cited by the present case. Citation classes are indicated in the document, and indicate the type of treatment given to the cases cited by the present case.",Unknown,Provide information about each attribute in your data set.,"A textual corpus of 4000 legal cases for automatic summarization and citation analysis. For each document we collect catchphrases, citations sentences, citation catchphrases and citation classes.This dataset contains Australian legal cases from the Federal Court of Australia (FCA). The cases were downloaded from AustLII ([Web Link]). We included all cases from the year 2006,2007,2008 and 2009. We built it to experiment with automatic summarization and citation analysis. For each document we collected catchphrases, citations sentences, citation catchphrases, and citation classes. Catchphrases are found in the document, we used the catchphrases are gold standard for our summarization experiments. Citation sentences are found in later cases that cite the present case, we use citation sentences for summarization. Citation catchphrases are the catchphrases (where available) of both later cases that cite the present case, and older cases cited by the present case. Citation classes are indicated in the document, and indicate the type of treatment given to the cases cited by the present case.Provide information about each attribute in your data set."
Lenses,Lenses,Database for fitting contact lenses,Lenses,https://archive.ics.uci.edu/ml//machine-learning-databases/lenses/,https://archive.ics.uci.edu/ml/datasets/Lenses,"The examples are complete and noise free. The examples highly simplified the problem. The attributes do not fully describe all the factors affecting the decision as to which type, if any, to fit. Notes:  --This database is complete (all possible combinations of attribute-value pairs are represented).--Each instance is complete and correct.--9 rules cover the training set.",Unknown,"    -- 3 Classes     1 : the patient should be fitted with hard contact lenses,     2 : the patient should be fitted with soft contact lenses,     3 : the patient should not be fitted with contact lenses.    1. age of the patient: (1) young, (2) pre-presbyopic, (3) presbyopic    2. spectacle prescription:  (1) myope, (2) hypermetrope    3. astigmatic:     (1) no, (2) yes    4. tear production rate:  (1) reduced, (2) normal","Database for fitting contact lensesThe examples are complete and noise free. The examples highly simplified the problem. The attributes do not fully describe all the factors affecting the decision as to which type, if any, to fit. Notes:  --This database is complete (all possible combinations of attribute-value pairs are represented).--Each instance is complete and correct.--9 rules cover the training set.    -- 3 Classes     1 : the patient should be fitted with hard contact lenses,     2 : the patient should be fitted with soft contact lenses,     3 : the patient should not be fitted with contact lenses.    1. age of the patient: (1) young, (2) pre-presbyopic, (3) presbyopic    2. spectacle prescription:  (1) myope, (2) hypermetrope    3. astigmatic:     (1) no, (2) yes    4. tear production rate:  (1) reduced, (2) normal"
Libras Movement,Libras Movement,"The data set contains 15 classes of 24 instances each. Each class references to a hand movement type in LIBRAS (Portuguese
name 'LÍngua BRAsileira de Sinais', oficial brazilian signal language).",Libras+Movement,https://archive.ics.uci.edu/ml//machine-learning-databases/libras/,https://archive.ics.uci.edu/ml/datasets/Libras+Movement,"The dataset (movement_libras) contains 15 classes of 24 instances each, where each class references to a hand movement type in LIBRAS.In the video pre-processing, a time normalization is carried out selecting 45 frames from each video, in according to an uniform distribution. In each frame, the centroid pixels of the segmented objects (the hand) are found, which compose the discrete version of the curve F with 45 points. All curves are normalized in the unitary space.In order to prepare these movements to be analysed by algorithms, we have carried out a mapping operation, that is, eachcurve F is mapped in a representation with 90 features, with representing the coordinates of movement. Some sub-datasets are offered in order to support comparisons of results.",Unknown,90 numeric (double) and 1 for the class (integer),"The data set contains 15 classes of 24 instances each. Each class references to a hand movement type in LIBRAS (Portuguese
name 'LÍngua BRAsileira de Sinais', oficial brazilian signal language).The dataset (movement_libras) contains 15 classes of 24 instances each, where each class references to a hand movement type in LIBRAS.In the video pre-processing, a time normalization is carried out selecting 45 frames from each video, in according to an uniform distribution. In each frame, the centroid pixels of the segmented objects (the hand) are found, which compose the discrete version of the curve F with 45 points. All curves are normalized in the unitary space.In order to prepare these movements to be analysed by algorithms, we have carried out a mapping operation, that is, eachcurve F is mapped in a representation with 90 features, with representing the coordinates of movement. Some sub-datasets are offered in order to support comparisons of results.90 numeric (double) and 1 for the class (integer)"
QtyT40I10D100K,QtyT40I10D100K,"Since there is no numerical sequential data stream available in standard data sets, this data set is generated from the original T40I10D100K data set",QtyT40I10D100K,https://archive.ics.uci.edu/ml//machine-learning-databases/00238/,https://archive.ics.uci.edu/ml/datasets/QtyT40I10D100K,"This data set is generated from the original T40I10D100K data set, to mine fuzzy sequential patterns over quantitative streams. While the original T40I10D100K is generated from the synthetic data generator described in Ã¢â‚¬Å“R. Agrawal, R. Srikant, Fast algorithms for mining association rules, 20th Intl. Conf. on Very Large Databases (VLDBÃ¢â‚¬â„¢94), pp. 487-499. 1994Ã¢â‚¬Â�.The data set is a SQL Server 2008 database, which can be attached to a SQL Server Instance to use",Unknown,CustomerID: the ID of the customer who has performed the transaction (randomly generated [1 100])Time: the time that the transaction has been performedTransaction: the transaction which has been performedQuantity: the quantity value of each transaction (randomly generated [1 10]),"Since there is no numerical sequential data stream available in standard data sets, this data set is generated from the original T40I10D100K data setThis data set is generated from the original T40I10D100K data set, to mine fuzzy sequential patterns over quantitative streams. While the original T40I10D100K is generated from the synthetic data generator described in Ã¢â‚¬Å“R. Agrawal, R. Srikant, Fast algorithms for mining association rules, 20th Intl. Conf. on Very Large Databases (VLDBÃ¢â‚¬â„¢94), pp. 487-499. 1994Ã¢â‚¬Â�.The data set is a SQL Server 2008 database, which can be attached to a SQL Server Instance to useCustomerID: the ID of the customer who has performed the transaction (randomly generated [1 100])Time: the time that the transaction has been performedTransaction: the transaction which has been performedQuantity: the quantity value of each transaction (randomly generated [1 10])"
QSAR biodegradation,QSAR biodegradation,Data set containing values for 41 attributes (molecular descriptors) used to classify 1055 chemicals into 2 classes (ready and not ready biodegradable).,QSAR+biodegradation,https://archive.ics.uci.edu/ml//machine-learning-databases/00254/,https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation,"The QSAR biodegradation dataset was built in the Milano Chemometrics and QSAR Research Group (UniversitÃƒÂ  degli Studi Milano Ã¢â‚¬â€œ Bicocca, Milano, Italy). The research leading to these results has received funding from the European CommunityÃ¢â‚¬â„¢s Seventh Framework Programme [FP7/2007-2013] under Grant Agreement n. 238701 of Marie Curie ITN Environmental Chemoinformatics (ECO) project.The data have been used to develop QSAR (Quantitative Structure Activity Relationships) models for the study of the relationships between chemical structure and biodegradation of molecules. Biodegradation experimental values of 1055 chemicals were collected from the webpage of the National Institute of Technology and Evaluation of Japan (NITE). Classification models were developed in order to discriminate ready (356) and not ready (699) biodegradable molecules by means of three different modelling methods: k Nearest Neighbours, Partial Least Squares Discriminant Analysis and Support Vector Machines. Details on attributes (molecular descriptors) selected in each model can be found in the quoted reference: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878.",Unknown,41 molecular descriptors and 1 experimental class:1) SpMax_L: Leading eigenvalue from Laplace matrix2) J_Dz(e): Balaban-like index from Barysz matrix weighted by Sanderson electronegativity3) nHM: Number of heavy atoms4) F01[N-N]: Frequency of N-N at topological distance 15) F04[C-N]: Frequency of C-N at topological distance 46) NssssC: Number of atoms of type ssssC7) nCb-: Number of substituted benzene C(sp2)8) C%: Percentage of C atoms9) nCp: Number of terminal primary C(sp3)10) nO: Number of oxygen atoms11) F03[C-N]: Frequency of C-N at topological distance 312) SdssC: Sum of dssC E-states13) HyWi_B(m): Hyper-Wiener-like index (log function) from Burden matrix weighted by mass14) LOC: Lopping centric index15) SM6_L: Spectral moment of order 6 from Laplace matrix16) F03[C-O]: Frequency of C - O at topological distance 317) Me: Mean atomic Sanderson electronegativity (scaled on Carbon atom)18) Mi: Mean first ionization potential (scaled on Carbon atom)19) nN-N: Number of N hydrazines20) nArNO2: Number of nitro groups (aromatic)21) nCRX3: Number of CRX322) SpPosA_B(p): Normalized spectral positive sum from Burden matrix weighted by polarizability23) nCIR: Number of circuits24) B01[C-Br]: Presence/absence of C - Br at topological distance 125) B03[C-Cl]: Presence/absence of C - Cl at topological distance 326) N-073: Ar2NH / Ar3N / Ar2N-Al / R..N..R27) SpMax_A: Leading eigenvalue from adjacency matrix (Lovasz-Pelikan index)28) Psi_i_1d: Intrinsic state pseudoconnectivity index - type 1d29) B04[C-Br]: Presence/absence of C - Br at topological distance 430) SdO: Sum of dO E-states31) TI2_L: Second Mohar index from Laplace matrix32) nCrt: Number of ring tertiary C(sp3)33) C-026: R--CX--R34) F02[C-N]: Frequency of C - N at topological distance 235) nHDon: Number of donor atoms for H-bonds (N and O)36) SpMax_B(m): Leading eigenvalue from Burden matrix weighted by mass37) Psi_i_A: Intrinsic state pseudoconnectivity index - type S average38) nN: Number of Nitrogen atoms39) SM6_B(m): Spectral moment of order 6 from Burden matrix weighted by mass40) nArCOOR: Number of esters (aromatic)41) nX: Number of halogen atoms42) experimental class: ready biodegradable (RB) and not ready biodegradable (NRB),"Data set containing values for 41 attributes (molecular descriptors) used to classify 1055 chemicals into 2 classes (ready and not ready biodegradable).The QSAR biodegradation dataset was built in the Milano Chemometrics and QSAR Research Group (UniversitÃƒÂ  degli Studi Milano Ã¢â‚¬â€œ Bicocca, Milano, Italy). The research leading to these results has received funding from the European CommunityÃ¢â‚¬â„¢s Seventh Framework Programme [FP7/2007-2013] under Grant Agreement n. 238701 of Marie Curie ITN Environmental Chemoinformatics (ECO) project.The data have been used to develop QSAR (Quantitative Structure Activity Relationships) models for the study of the relationships between chemical structure and biodegradation of molecules. Biodegradation experimental values of 1055 chemicals were collected from the webpage of the National Institute of Technology and Evaluation of Japan (NITE). Classification models were developed in order to discriminate ready (356) and not ready (699) biodegradable molecules by means of three different modelling methods: k Nearest Neighbours, Partial Least Squares Discriminant Analysis and Support Vector Machines. Details on attributes (molecular descriptors) selected in each model can be found in the quoted reference: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878.41 molecular descriptors and 1 experimental class:1) SpMax_L: Leading eigenvalue from Laplace matrix2) J_Dz(e): Balaban-like index from Barysz matrix weighted by Sanderson electronegativity3) nHM: Number of heavy atoms4) F01[N-N]: Frequency of N-N at topological distance 15) F04[C-N]: Frequency of C-N at topological distance 46) NssssC: Number of atoms of type ssssC7) nCb-: Number of substituted benzene C(sp2)8) C%: Percentage of C atoms9) nCp: Number of terminal primary C(sp3)10) nO: Number of oxygen atoms11) F03[C-N]: Frequency of C-N at topological distance 312) SdssC: Sum of dssC E-states13) HyWi_B(m): Hyper-Wiener-like index (log function) from Burden matrix weighted by mass14) LOC: Lopping centric index15) SM6_L: Spectral moment of order 6 from Laplace matrix16) F03[C-O]: Frequency of C - O at topological distance 317) Me: Mean atomic Sanderson electronegativity (scaled on Carbon atom)18) Mi: Mean first ionization potential (scaled on Carbon atom)19) nN-N: Number of N hydrazines20) nArNO2: Number of nitro groups (aromatic)21) nCRX3: Number of CRX322) SpPosA_B(p): Normalized spectral positive sum from Burden matrix weighted by polarizability23) nCIR: Number of circuits24) B01[C-Br]: Presence/absence of C - Br at topological distance 125) B03[C-Cl]: Presence/absence of C - Cl at topological distance 326) N-073: Ar2NH / Ar3N / Ar2N-Al / R..N..R27) SpMax_A: Leading eigenvalue from adjacency matrix (Lovasz-Pelikan index)28) Psi_i_1d: Intrinsic state pseudoconnectivity index - type 1d29) B04[C-Br]: Presence/absence of C - Br at topological distance 430) SdO: Sum of dO E-states31) TI2_L: Second Mohar index from Laplace matrix32) nCrt: Number of ring tertiary C(sp3)33) C-026: R--CX--R34) F02[C-N]: Frequency of C - N at topological distance 235) nHDon: Number of donor atoms for H-bonds (N and O)36) SpMax_B(m): Leading eigenvalue from Burden matrix weighted by mass37) Psi_i_A: Intrinsic state pseudoconnectivity index - type S average38) nN: Number of Nitrogen atoms39) SM6_B(m): Spectral moment of order 6 from Burden matrix weighted by mass40) nArCOOR: Number of esters (aromatic)41) nX: Number of halogen atoms42) experimental class: ready biodegradable (RB) and not ready biodegradable (NRB)"
Pseudo Periodic Synthetic Time Series,Pseudo Periodic Synthetic Time Series,"This data set is designed for testing indexing schemes in time series databases. The data appears highly periodic, but never exactly repeats itself.",Pseudo+Periodic+Synthetic+Time+Series,https://archive.ics.uci.edu/ml//machine-learning-databases/synthetic-mld/,https://archive.ics.uci.edu/ml/datasets/Pseudo+Periodic+Synthetic+Time+Series,"This data set is designed for testing indexing schemes in time series databases. It is a much larger dataset than has been used in any published study (That we are currently aware of). It contains one million data points. The data has been split into 10 sections to facilitate testing (see below). We recommend building the index with 9 of the 100,000-datapoint sections, and randomly extracting a query shape from the 10th section. (Some previously published work seems to have used queries that were also used to build the indexing structure. This will produce optimistic results) The data are interesting because they have structure at different resolutions. Each of the 10 sections where generated by independent invocations of the function: (see equation.gif)Where rand(x) produces a random integer between zero and x.The data appears highly periodic, but never exactly repeats itself. This feature is designed to challenge the indexing structure. The time series are ploted here: (ts1-5.gif), (ts6-10.gif)",Unknown,"The data is stored in one ASCII file. There are 10 columns, 100,000 rows. All data points are in the range -0.5 to +0.5.Rows are separated by carriage returns, columns by spaces. ","This data set is designed for testing indexing schemes in time series databases. The data appears highly periodic, but never exactly repeats itself.This data set is designed for testing indexing schemes in time series databases. It is a much larger dataset than has been used in any published study (That we are currently aware of). It contains one million data points. The data has been split into 10 sections to facilitate testing (see below). We recommend building the index with 9 of the 100,000-datapoint sections, and randomly extracting a query shape from the 10th section. (Some previously published work seems to have used queries that were also used to build the indexing structure. This will produce optimistic results) The data are interesting because they have structure at different resolutions. Each of the 10 sections where generated by independent invocations of the function: (see equation.gif)Where rand(x) produces a random integer between zero and x.The data appears highly periodic, but never exactly repeats itself. This feature is designed to challenge the indexing structure. The time series are ploted here: (ts1-5.gif), (ts6-10.gif)The data is stored in one ASCII file. There are 10 columns, 100,000 rows. All data points are in the range -0.5 to +0.5.Rows are separated by carriage returns, columns by spaces. "
Prodigy,Prodigy,"Assorted domains like blocksworld, eightpuzzle, and schedworld.",Prodigy,URL not available,https://archive.ics.uci.edu/ml/datasets/Prodigy,"Here is a summary of the domains that can be used currently with Prodigy.  Each one is described briefly. For more information in any of them, read the README file in the directory corresponding to the domain.  * stripsworld: There are several directories related to this domain:       -- stripsworld: the domain for STRIPS.       -- extended-strips: an extension to the STRIPS domain where doors can be locked and there are keys for the locks.       -- multirobot: the STRIPS domain with two or more robots.  * blocksworld: There are several directories related to this domain:       -- blocksworld: the domain as was built initially.       -- frozenblocksworld: a stable version. Used for the manual.       -- extended-bw: an extension to blocksworld that deals with  the weight and location of the blocks.     (See also gridworld)  * eightpuzzle: a domain for solving the eight puzzle.  * grammar: a simple grammar.  * gridworld: a 3-D version of blocksworld.  * jupiter: Prodigy interacts with an external world, via the World Modelers.  * logic: a simple logic domain.  * matrix-algebra: gaussian elimination in matrices.  * r1: VAX configuration domain (a simplification of R1).  * rocket: chinese rocket domain.  * schedworld:  a machine shop scheduling domain.  * telescope: a domain for building telescope mirrors.",Unknown,,"Assorted domains like blocksworld, eightpuzzle, and schedworld.Here is a summary of the domains that can be used currently with Prodigy.  Each one is described briefly. For more information in any of them, read the README file in the directory corresponding to the domain.  * stripsworld: There are several directories related to this domain:       -- stripsworld: the domain for STRIPS.       -- extended-strips: an extension to the STRIPS domain where doors can be locked and there are keys for the locks.       -- multirobot: the STRIPS domain with two or more robots.  * blocksworld: There are several directories related to this domain:       -- blocksworld: the domain as was built initially.       -- frozenblocksworld: a stable version. Used for the manual.       -- extended-bw: an extension to blocksworld that deals with  the weight and location of the blocks.     (See also gridworld)  * eightpuzzle: a domain for solving the eight puzzle.  * grammar: a simple grammar.  * gridworld: a 3-D version of blocksworld.  * jupiter: Prodigy interacts with an external world, via the World Modelers.  * logic: a simple logic domain.  * matrix-algebra: gaussian elimination in matrices.  * r1: VAX configuration domain (a simplification of R1).  * rocket: chinese rocket domain.  * schedworld:  a machine shop scheduling domain.  * telescope: a domain for building telescope mirrors.nan"
Madelon,Madelon,"MADELON is an artificial dataset, which was part of the NIPS 2003 feature selection challenge. This is a two-class classification problem with continuous input variables. The difficulty is that the problem is multivariate and highly non-linear. ",Madelon,https://archive.ics.uci.edu/ml//machine-learning-databases/madelon/,https://archive.ics.uci.edu/ml/datasets/Madelon,"MADELON is an artificial dataset containing data points grouped in 32 clusters placed on the vertices of a five dimensional hypercube and randomly labeled +1 or -1. The five dimensions constitute 5 informative features. 15 linear combinations of those features were added to form a set of 20 (redundant) informative features. Based on those 20 features one must separate the examples into the 2 classes (corresponding to the +-1 labels). We added a number of distractor feature called 'probes' having no predictive power. The order of the features and patterns were randomized.MADELON -- Positive ex. -- Negative ex. -- Total		   Training set -- 1000 -- 1000 -- 2000		   Validation set -- 300 -- 300 -- 600		   Test set -- 900 -- 900 -- 1800		   All -- 2200 -- 2200 -- 4400		 Number of variables/features/attributes:Real: 20Probes: 480Total: 500This dataset is one of five datasets used in the NIPS 2003 feature selection challenge. Our website [Web Link] is still open for post-challenge submissions. Information about other related challenges are found at: [Web Link]. The CLOP package includes sample code to process these data: [Web Link].All details about the preparation of the data are found in our technical report: Design of experiments for the NIPS 2003 variable selection benchmark, Isabelle Guyon, July 2003, [Web Link] (also included in the dataset archive). Such information was made available only after the end of the challenge.The data are split into training, validation, and test set. Target values are provided only for the 2 first sets. Test set performance results are obtained by submitting prediction results to: [Web Link].The data are in the following format:dataname.param: Parameters and statistics about the datadataname.feat: Identities of the features (in the order the features are found in the data).dataname_train.data: Training set (a space-delimited regular matrix, patterns in lines, features in columns).  dataname_valid.data: Validation set.    dataname_test.data: Test set. dataname_train.labels: Labels (truth values of the classes) for training examples.   dataname_valid.labels: Validation set labels (withheld during the benchmark, but provided now).dataname_test.labels: Test set labels  (withheld, so the data can still be use as a benchmark).",Unknown,"We do not provide attribute information, to avoid biasing the feature selection process.","MADELON is an artificial dataset, which was part of the NIPS 2003 feature selection challenge. This is a two-class classification problem with continuous input variables. The difficulty is that the problem is multivariate and highly non-linear. MADELON is an artificial dataset containing data points grouped in 32 clusters placed on the vertices of a five dimensional hypercube and randomly labeled +1 or -1. The five dimensions constitute 5 informative features. 15 linear combinations of those features were added to form a set of 20 (redundant) informative features. Based on those 20 features one must separate the examples into the 2 classes (corresponding to the +-1 labels). We added a number of distractor feature called 'probes' having no predictive power. The order of the features and patterns were randomized.MADELON -- Positive ex. -- Negative ex. -- Total		   Training set -- 1000 -- 1000 -- 2000		   Validation set -- 300 -- 300 -- 600		   Test set -- 900 -- 900 -- 1800		   All -- 2200 -- 2200 -- 4400		 Number of variables/features/attributes:Real: 20Probes: 480Total: 500This dataset is one of five datasets used in the NIPS 2003 feature selection challenge. Our website [Web Link] is still open for post-challenge submissions. Information about other related challenges are found at: [Web Link]. The CLOP package includes sample code to process these data: [Web Link].All details about the preparation of the data are found in our technical report: Design of experiments for the NIPS 2003 variable selection benchmark, Isabelle Guyon, July 2003, [Web Link] (also included in the dataset archive). Such information was made available only after the end of the challenge.The data are split into training, validation, and test set. Target values are provided only for the 2 first sets. Test set performance results are obtained by submitting prediction results to: [Web Link].The data are in the following format:dataname.param: Parameters and statistics about the datadataname.feat: Identities of the features (in the order the features are found in the data).dataname_train.data: Training set (a space-delimited regular matrix, patterns in lines, features in columns).  dataname_valid.data: Validation set.    dataname_test.data: Test set. dataname_train.labels: Labels (truth values of the classes) for training examples.   dataname_valid.labels: Validation set labels (withheld during the benchmark, but provided now).dataname_test.labels: Test set labels  (withheld, so the data can still be use as a benchmark).We do not provide attribute information, to avoid biasing the feature selection process."
BuddyMove Data Set,BuddyMove Data Set,User interest information extracted from user reviews published in holidayiq.com about various types of point of interests in South India,BuddyMove+Data+Set,https://archive.ics.uci.edu/ml//machine-learning-databases/00476/,https://archive.ics.uci.edu/ml/datasets/BuddyMove+Data+Set,This dataset was populated from destination reviews published by 249 reviewers of holidayiq.com till October 2014. Reviews falling in 6 categories among destinations across South India were considered and the count of reviews in each category for every reviewer (traveler) is captured. ,Unknown,"Attribute 1 : Unique user idAttribute 2 : Number of reviews on stadiums, sports complex, etc.Attribute 3 : Number of reviews on religious institutionsAttribute 4 : Number of reviews on beach, lake, river, etc.Attribute 5 : Number of reviews on theatres, exhibitions, etc.Attribute 6 : Number of reviews on malls, shopping places, etc.Attribute 7 : Number of reviews on parks, picnic spots, etc. ","User interest information extracted from user reviews published in holidayiq.com about various types of point of interests in South IndiaThis dataset was populated from destination reviews published by 249 reviewers of holidayiq.com till October 2014. Reviews falling in 6 categories among destinations across South India were considered and the count of reviews in each category for every reviewer (traveler) is captured. Attribute 1 : Unique user idAttribute 2 : Number of reviews on stadiums, sports complex, etc.Attribute 3 : Number of reviews on religious institutionsAttribute 4 : Number of reviews on beach, lake, river, etc.Attribute 5 : Number of reviews on theatres, exhibitions, etc.Attribute 6 : Number of reviews on malls, shopping places, etc.Attribute 7 : Number of reviews on parks, picnic spots, etc. "
Power consumption of Tetouan city,Power consumption of Tetouan city,This dataset is related to  power consumption of three different distribution networks of Tetouan city which is located in north Morocco.,Power+consumption+of+Tetouan+city,https://archive.ics.uci.edu/ml//machine-learning-databases/00616/,https://archive.ics.uci.edu/ml/datasets/Power+consumption+of+Tetouan+city,Provide all relevant information about your data set.,Unknown,Date Time: Each ten minutes.Temperature: Weather Temperature of Tetouan city.Humidity: Weather Humidity of Tetouan city.Wind Speed of Tetouan city.general diffuse flowsdiffuse flowspower consumption of zone 1 of Tetouan city.power consumption of zone 2 of Tetouan city.power consumption of zone 3 of Tetouan city.,This dataset is related to  power consumption of three different distribution networks of Tetouan city which is located in north Morocco.Provide all relevant information about your data set.Date Time: Each ten minutes.Temperature: Weather Temperature of Tetouan city.Humidity: Weather Humidity of Tetouan city.Wind Speed of Tetouan city.general diffuse flowsdiffuse flowspower consumption of zone 1 of Tetouan city.power consumption of zone 2 of Tetouan city.power consumption of zone 3 of Tetouan city.
Pittsburgh Bridges,Pittsburgh Bridges,Bridges database that has original and numeric-discretized datasets,Pittsburgh+Bridges,https://archive.ics.uci.edu/ml//machine-learning-databases/bridges/,https://archive.ics.uci.edu/ml/datasets/Pittsburgh+Bridges,There are two versions to the database:     -  V1 contains the original examples and      - V2 contains descriptions after discretizing numeric properties.There are no ``classes'' in the domain. Rather this is a DESIGN domain where 5 properties (design description) need to be predicted based on 7 specification properties.,Unknown,"The type field state whether a property is continuous/integer (c) or nominal (n).For properties with c,n type, the range of continuous numbers is given first and the possible values of the nominal follow the semi-colon.Name / Type / Possible values / Comments   1.  IDENTIF / -- /	-- / identifier of the examples   2.  RIVER / n / A, M, O / --   3.  LOCATION / n / 1 to 52 / --   4.  ERECTED / c,n / 1818-1986 ; CRAFTS, EMERGING, MATURE, MODERN / --   5.  PURPOSE / n / WALK, AQUEDUCT, RR, HIGHWAY / --   6.  LENGTH / c,n / 804-4558 ; SHORT, MEDIUM, LONG / --   7.  LANES / c,n / 1, 2, 4, 6 ; 1, 2, 4, 6 / --   8.  CLEAR-G / n / N, G / --   9.  T-OR-D / n / THROUGH, DECK / --   10. MATERIAL / n / WOOD, IRON, STEEL / --   11. SPAN / n / SHORT, MEDUIM, LONG / --   12. REL-L / n / S, S-F, F / --   13. TYPE / n / WOOD, SUSPEN, SIMPLE-T, ARCH, CANTILEV, CONT-T / --","Bridges database that has original and numeric-discretized datasetsThere are two versions to the database:     -  V1 contains the original examples and      - V2 contains descriptions after discretizing numeric properties.There are no ``classes'' in the domain. Rather this is a DESIGN domain where 5 properties (design description) need to be predicted based on 7 specification properties.The type field state whether a property is continuous/integer (c) or nominal (n).For properties with c,n type, the range of continuous numbers is given first and the possible values of the nominal follow the semi-colon.Name / Type / Possible values / Comments   1.  IDENTIF / -- /	-- / identifier of the examples   2.  RIVER / n / A, M, O / --   3.  LOCATION / n / 1 to 52 / --   4.  ERECTED / c,n / 1818-1986 ; CRAFTS, EMERGING, MATURE, MODERN / --   5.  PURPOSE / n / WALK, AQUEDUCT, RR, HIGHWAY / --   6.  LENGTH / c,n / 804-4558 ; SHORT, MEDIUM, LONG / --   7.  LANES / c,n / 1, 2, 4, 6 ; 1, 2, 4, 6 / --   8.  CLEAR-G / n / N, G / --   9.  T-OR-D / n / THROUGH, DECK / --   10. MATERIAL / n / WOOD, IRON, STEEL / --   11. SPAN / n / SHORT, MEDUIM, LONG / --   12. REL-L / n / S, S-F, F / --   13. TYPE / n / WOOD, SUSPEN, SIMPLE-T, ARCH, CANTILEV, CONT-T / --"
Metro Interstate Traffic Volume,Metro Interstate Traffic Volume,"Hourly Minneapolis-St Paul, MN traffic volume for westbound I-94. Includes weather and holiday features from 2012-2018.",Metro+Interstate+Traffic+Volume,https://archive.ics.uci.edu/ml//machine-learning-databases/00492/,https://archive.ics.uci.edu/ml/datasets/Metro+Interstate+Traffic+Volume,"Hourly Interstate 94 Westbound traffic volume for MN DoT ATR station 301, roughly midway between Minneapolis and St Paul, MN. Hourly weather features and holidays included for impacts on traffic volume.",Unknown,"holiday                Categorical    US National holidays plus regional holiday, Minnesota State Fairtemp                   Numeric        Average temp in kelvinrain_1h                Numeric        Amount in mm of rain that occurred in the hoursnow_1h                Numeric        Amount in mm of snow that occurred in the hourclouds_all             Numeric        Percentage of cloud coverweather_main           Categorical    Short textual description of the current weatherweather_description    Categorical    Longer textual description of the current weatherdate_time              DateTime       Hour of the data collected in local CST timetraffic_volume         Numeric        Hourly I-94 ATR 301 reported westbound traffic volume","Hourly Minneapolis-St Paul, MN traffic volume for westbound I-94. Includes weather and holiday features from 2012-2018.Hourly Interstate 94 Westbound traffic volume for MN DoT ATR station 301, roughly midway between Minneapolis and St Paul, MN. Hourly weather features and holidays included for impacts on traffic volume.holiday                Categorical    US National holidays plus regional holiday, Minnesota State Fairtemp                   Numeric        Average temp in kelvinrain_1h                Numeric        Amount in mm of rain that occurred in the hoursnow_1h                Numeric        Amount in mm of snow that occurred in the hourclouds_all             Numeric        Percentage of cloud coverweather_main           Categorical    Short textual description of the current weatherweather_description    Categorical    Longer textual description of the current weatherdate_time              DateTime       Hour of the data collected in local CST timetraffic_volume         Numeric        Hourly I-94 ATR 301 reported westbound traffic volume"
Demand Forecasting for a store,Demand Forecasting for a store,Contains data for a store from week 1 to week 146.,Demand+Forecasting+for+a+store,https://archive.ics.uci.edu/ml//machine-learning-databases/00532/,https://archive.ics.uci.edu/ml/datasets/Demand+Forecasting+for+a+store,"Your client is a meal delivery company which operates in multiple cities. They have various fulfillment centers in these cities for dispatching meal orders to their customers. The client wants you to help these centers with demand forecasting for upcoming weeks so that these centers will plan the stock of raw materials accordingly.The replenishment of majority of raw materials is done on weekly basis and since the raw material is perishable, the procurement planning is of utmost importance. Secondly, staffing of the centers is also one area wherein accurate demand forecasts are really helpful. Given the following information, the task is to predict the demand for the next 10 weeks (Weeks: 146-155) for the center-meal combinations in the test set:  Historical data of demand for a product-center combination (Weeks: 1 to 145)Product(Meal) features such as category, sub-category, current price and discountInformation for fulfillment center like center area, city information etc.",Unknown,"Weekly Demand data (train.csv): Contains the historical demand data for all centers, test.csv contains all the following features except the target variable Variable	Definitionid	Unique IDweek	Week Nocenter_id	Unique ID for fulfillment centermeal_id	Unique ID for Mealcheckout_price	Final price including discount, taxes & delivery chargesbase_price	Base price of the mealemailer_for_promotion	Emailer sent for promotion of mealhomepage_featured	Meal featured at homepagenum_orders	(Target) Orders Count   fulfilment_center_info.csv: Contains information for each fulfilment center Variable	Definitioncenter_id	Unique ID for fulfillment centercity_code	Unique code for cityregion_code	Unique code for regioncenter_type	Anonymized center typeop_area	Area of operation (in km^2) meal_info.csv: Contains information for each meal being served Variable	Definitionmeal_id	Unique ID for the mealcategory	Type of meal (beverages/snacks/soupsÃ¢â‚¬Â¦.)cuisine	Meal cuisine (Indian/Italian/Ã¢â‚¬Â¦)","Contains data for a store from week 1 to week 146.Your client is a meal delivery company which operates in multiple cities. They have various fulfillment centers in these cities for dispatching meal orders to their customers. The client wants you to help these centers with demand forecasting for upcoming weeks so that these centers will plan the stock of raw materials accordingly.The replenishment of majority of raw materials is done on weekly basis and since the raw material is perishable, the procurement planning is of utmost importance. Secondly, staffing of the centers is also one area wherein accurate demand forecasts are really helpful. Given the following information, the task is to predict the demand for the next 10 weeks (Weeks: 146-155) for the center-meal combinations in the test set:  Historical data of demand for a product-center combination (Weeks: 1 to 145)Product(Meal) features such as category, sub-category, current price and discountInformation for fulfillment center like center area, city information etc.Weekly Demand data (train.csv): Contains the historical demand data for all centers, test.csv contains all the following features except the target variable Variable	Definitionid	Unique IDweek	Week Nocenter_id	Unique ID for fulfillment centermeal_id	Unique ID for Mealcheckout_price	Final price including discount, taxes & delivery chargesbase_price	Base price of the mealemailer_for_promotion	Emailer sent for promotion of mealhomepage_featured	Meal featured at homepagenum_orders	(Target) Orders Count   fulfilment_center_info.csv: Contains information for each fulfilment center Variable	Definitioncenter_id	Unique ID for fulfillment centercity_code	Unique code for cityregion_code	Unique code for regioncenter_type	Anonymized center typeop_area	Area of operation (in km^2) meal_info.csv: Contains information for each meal being served Variable	Definitionmeal_id	Unique ID for the mealcategory	Type of meal (beverages/snacks/soupsÃ¢â‚¬Â¦.)cuisine	Meal cuisine (Indian/Italian/Ã¢â‚¬Â¦)"
Chronic_Kidney_Disease,Chronic_Kidney_Disease,This dataset can be used to predict the chronic kidney disease and it can be collected from the hospital nearly 2 months of period.,Chronic_Kidney_Disease,https://archive.ics.uci.edu/ml//machine-learning-databases/00336/,https://archive.ics.uci.edu/ml/datasets/Chronic_Kidney_Disease,We use the following representation to collect the dataset                        age		-	age				bp		-	blood pressure			sg		-	specific gravity			al		-   	albumin			su		-	sugar			rbc		-	red blood cells			pc		-	pus cell			pcc		-	pus cell clumps			ba		-	bacteria			bgr		-	blood glucose random			bu		-	blood urea			sc		-	serum creatinine			sod		-	sodium			pot		-	potassium			hemo		-	hemoglobin			pcv		-	packed cell volume			wc		-	white blood cell count			rc		-	red blood cell count			htn		-	hypertension			dm		-	diabetes mellitus			cad		-	coronary artery disease			appet		-	appetite			pe		-	pedal edema			ane		-	anemia			class		-	class	,Unknown,"We use 24 + class = 25 ( 11  numeric ,14  nominal)1.Age(numerical)  	  	age in years 	2.Blood Pressure(numerical)	       	bp in mm/Hg 	3.Specific Gravity(nominal)	  	sg - (1.005,1.010,1.015,1.020,1.025) 	4.Albumin(nominal)		al - (0,1,2,3,4,5) 	5.Sugar(nominal)		su - (0,1,2,3,4,5) 	6.Red Blood Cells(nominal)		rbc - (normal,abnormal) 	7.Pus Cell (nominal)		pc - (normal,abnormal) 	8.Pus Cell clumps(nominal)		pcc - (present,notpresent) 	9.Bacteria(nominal)		ba  - (present,notpresent) 	10.Blood Glucose Random(numerical)				bgr in mgs/dl 	11.Blood Urea(numerical)			bu in mgs/dl 	12.Serum Creatinine(numerical)			sc in mgs/dl 	13.Sodium(numerical)		sod in mEq/L 	14.Potassium(numerical)			pot in mEq/L 	15.Hemoglobin(numerical)		hemo in gms 	16.Packed  Cell Volume(numerical) 	17.White Blood Cell Count(numerical)		wc in cells/cumm 	18.Red Blood Cell Count(numerical)			rc in millions/cmm 	19.Hypertension(nominal)			htn - (yes,no) 	20.Diabetes Mellitus(nominal)			dm - (yes,no) 	21.Coronary Artery Disease(nominal)		cad - (yes,no) 	22.Appetite(nominal)			appet - (good,poor) 	23.Pedal Edema(nominal)		pe - (yes,no)	 	24.Anemia(nominal)		ane - (yes,no) 	25.Class (nominal)				class - (ckd,notckd)","This dataset can be used to predict the chronic kidney disease and it can be collected from the hospital nearly 2 months of period.We use the following representation to collect the dataset                        age		-	age				bp		-	blood pressure			sg		-	specific gravity			al		-   	albumin			su		-	sugar			rbc		-	red blood cells			pc		-	pus cell			pcc		-	pus cell clumps			ba		-	bacteria			bgr		-	blood glucose random			bu		-	blood urea			sc		-	serum creatinine			sod		-	sodium			pot		-	potassium			hemo		-	hemoglobin			pcv		-	packed cell volume			wc		-	white blood cell count			rc		-	red blood cell count			htn		-	hypertension			dm		-	diabetes mellitus			cad		-	coronary artery disease			appet		-	appetite			pe		-	pedal edema			ane		-	anemia			class		-	class	We use 24 + class = 25 ( 11  numeric ,14  nominal)1.Age(numerical)  	  	age in years 	2.Blood Pressure(numerical)	       	bp in mm/Hg 	3.Specific Gravity(nominal)	  	sg - (1.005,1.010,1.015,1.020,1.025) 	4.Albumin(nominal)		al - (0,1,2,3,4,5) 	5.Sugar(nominal)		su - (0,1,2,3,4,5) 	6.Red Blood Cells(nominal)		rbc - (normal,abnormal) 	7.Pus Cell (nominal)		pc - (normal,abnormal) 	8.Pus Cell clumps(nominal)		pcc - (present,notpresent) 	9.Bacteria(nominal)		ba  - (present,notpresent) 	10.Blood Glucose Random(numerical)				bgr in mgs/dl 	11.Blood Urea(numerical)			bu in mgs/dl 	12.Serum Creatinine(numerical)			sc in mgs/dl 	13.Sodium(numerical)		sod in mEq/L 	14.Potassium(numerical)			pot in mEq/L 	15.Hemoglobin(numerical)		hemo in gms 	16.Packed  Cell Volume(numerical) 	17.White Blood Cell Count(numerical)		wc in cells/cumm 	18.Red Blood Cell Count(numerical)			rc in millions/cmm 	19.Hypertension(nominal)			htn - (yes,no) 	20.Diabetes Mellitus(nominal)			dm - (yes,no) 	21.Coronary Artery Disease(nominal)		cad - (yes,no) 	22.Appetite(nominal)			appet - (good,poor) 	23.Pedal Edema(nominal)		pe - (yes,no)	 	24.Anemia(nominal)		ane - (yes,no) 	25.Class (nominal)				class - (ckd,notckd)"
MONK's Problems,MONK's Problems,A set of three artificial domains over the same attribute space; Used to test a wide range of induction algorithms,MONK%27s+Problems,https://archive.ics.uci.edu/ml//machine-learning-databases/monks-problems/,https://archive.ics.uci.edu/ml/datasets/MONK%27s+Problems,"The MONK's problem were the basis of a first international comparison of learning algorithms. The result of this comparison is summarized in ""The MONK's Problems - A Performance Comparison of Different Learning algorithms"" by S.B. Thrun, J. Bala, E. Bloedorn, I.  Bratko, B. Cestnik, J. Cheng, K. De Jong, S.  Dzeroski, S.E. Fahlman, D. Fisher, R. Hamann, K. Kaufman, S. Keller, I. Kononenko, J.  Kreuziger, R.S. Michalski, T. Mitchell, P.  Pachowicz, Y. Reich H.  Vafaie, W. Van de Welde, W. Wenzel, J. Wnek, and J. Zhang has been published as Technical Report CS-CMU-91-197, Carnegie Mellon University in Dec. 1991.One significant characteristic of this comparison is that it was performed by a collection of researchers, each of whom was an advocate of the technique they tested (often they were the creators of the various methods). In this sense, the results are less biased than in comparisons performed by a single person advocating a specific learning method, and more accurately reflect the generalization behavior of the learning techniques as applied by knowledgeable users.There are three MONK's problems.  The domains for all MONK's problems are the same (described below).  One of the MONK's problems has noise added. For each problem, the domain has been partitioned into a train and test set.",Unknown,"    1. class: 0, 1     2. a1:    1, 2, 3    3. a2:    1, 2, 3    4. a3:    1, 2    5. a4:    1, 2, 3    6. a5:    1, 2, 3, 4    7. a6:    1, 2    8. Id:    (A unique symbol for each instance)","A set of three artificial domains over the same attribute space; Used to test a wide range of induction algorithmsThe MONK's problem were the basis of a first international comparison of learning algorithms. The result of this comparison is summarized in ""The MONK's Problems - A Performance Comparison of Different Learning algorithms"" by S.B. Thrun, J. Bala, E. Bloedorn, I.  Bratko, B. Cestnik, J. Cheng, K. De Jong, S.  Dzeroski, S.E. Fahlman, D. Fisher, R. Hamann, K. Kaufman, S. Keller, I. Kononenko, J.  Kreuziger, R.S. Michalski, T. Mitchell, P.  Pachowicz, Y. Reich H.  Vafaie, W. Van de Welde, W. Wenzel, J. Wnek, and J. Zhang has been published as Technical Report CS-CMU-91-197, Carnegie Mellon University in Dec. 1991.One significant characteristic of this comparison is that it was performed by a collection of researchers, each of whom was an advocate of the technique they tested (often they were the creators of the various methods). In this sense, the results are less biased than in comparisons performed by a single person advocating a specific learning method, and more accurately reflect the generalization behavior of the learning techniques as applied by knowledgeable users.There are three MONK's problems.  The domains for all MONK's problems are the same (described below).  One of the MONK's problems has noise added. For each problem, the domain has been partitioned into a train and test set.    1. class: 0, 1     2. a1:    1, 2, 3    3. a2:    1, 2, 3    4. a3:    1, 2    5. a4:    1, 2, 3    6. a5:    1, 2, 3, 4    7. a6:    1, 2    8. Id:    (A unique symbol for each instance)"
CLINC150,CLINC150,This is a intent classification (text classification) dataset with 150 in-domain intent classes. The main purpose of this dataset is to evaluate various classifiers on out-of-domain performance. ,CLINC150,https://archive.ics.uci.edu/ml//machine-learning-databases/00570/,https://archive.ics.uci.edu/ml/datasets/CLINC150,"There are 4 versions of the dataset:- data_full.json: each of the 150 in-domain intent classes have 100 train, 20 val, and 30 test samples. The out-of-domain class has 100 train, 100 val, and 1,000 test samples. Note that the out-of-domain class does not necessarily need to be used at training time. This is the main version of the dataset.- data_small.json: each of the 150 in-domain intent classes have 50 train, 20 val, and 30 test samples. The out-of-domain class has 100 train, 100 val, and 1,000 test samples. Note that the out-of-domain class does not necessarily need to be used at training time.- data_imbalanced.json: each of the 150 in-domain intent classes have either 25, 50, 75, or 100 train, 20 val, and 30 samples. The out-of-domain class has 100 train, 100 val, and 1,000 test samples. Note that the out-of-domain class does not necessarily need to be used at training time.- data_oos_plus.json: same as data_full.json except there are 250 out-of-domain training samples.",Unknown,"All samples are in text format. No tokenization has been applied. Users of this dataset are free to use whatever sentence representation (e.g. bag-of-words, sentence embeddings) they choose. ","This is a intent classification (text classification) dataset with 150 in-domain intent classes. The main purpose of this dataset is to evaluate various classifiers on out-of-domain performance. There are 4 versions of the dataset:- data_full.json: each of the 150 in-domain intent classes have 100 train, 20 val, and 30 test samples. The out-of-domain class has 100 train, 100 val, and 1,000 test samples. Note that the out-of-domain class does not necessarily need to be used at training time. This is the main version of the dataset.- data_small.json: each of the 150 in-domain intent classes have 50 train, 20 val, and 30 test samples. The out-of-domain class has 100 train, 100 val, and 1,000 test samples. Note that the out-of-domain class does not necessarily need to be used at training time.- data_imbalanced.json: each of the 150 in-domain intent classes have either 25, 50, 75, or 100 train, 20 val, and 30 samples. The out-of-domain class has 100 train, 100 val, and 1,000 test samples. Note that the out-of-domain class does not necessarily need to be used at training time.- data_oos_plus.json: same as data_full.json except there are 250 out-of-domain training samples.All samples are in text format. No tokenization has been applied. Users of this dataset are free to use whatever sentence representation (e.g. bag-of-words, sentence embeddings) they choose. "
CMU Face Images,CMU Face Images,"This data consists of 640 black and white face images of people taken with varying pose (straight, left, right, up), expression (neutral, happy, sad, angry), eyes (wearing sunglasses or not), and size",CMU+Face+Images,https://archive.ics.uci.edu/ml//machine-learning-databases/faces-mld/,https://archive.ics.uci.edu/ml/datasets/CMU+Face+Images,"Each image can be characterized by the pose, expression, eyes, and size. There are 32 images for each person capturing every combination of features. To view the images, you can use the program xv. The image data can be found in /faces. This directory contains 20 subdirectories, one for each person, named by userid. Each of these directories contains several different face images of the same person. You will be interested in the images with the following naming convention:     .pgm  is the user id of the person in the image, and this field has 20 values: an2i, at33, boland, bpm, ch4f, cheyer, choon, danieln, glickman, karyadi, kawamura, kk49, megak, mitchell, night, phoebe, saavik, steffi, sz24, and tammo.  is the head position of the person, and this field has 4 values: straight, left, right, up.  is the facial expression of the person, and this field has 4 values: neutral, happy, sad, angry.  is the eye state of the person, and this field has 2 values: open, sunglasses.  is the scale of the image, and this field has 3 values: 1, 2, and 4. 1 indicates a full-resolution image (128 columns by 120 rows); 2 indicates a half-resolution image (64 by 60); 4 indicates a quarter-resolution image (32 by 30). If you've been looking closely in the image directories, you may notice that some images have a .bad suffix rather than the .pgm suffix. As it turns out, 16 of the 640 images taken have glitches due to problems with the camera setup; these are the .bad images. Some people had more glitches than others, but everyone who got ``faced'' should have at least 28 good face images (out of the 32 variations possible, discounting scale). More information and C code for loading the images is available here: [Web Link]. ",Unknown,,"This data consists of 640 black and white face images of people taken with varying pose (straight, left, right, up), expression (neutral, happy, sad, angry), eyes (wearing sunglasses or not), and sizeEach image can be characterized by the pose, expression, eyes, and size. There are 32 images for each person capturing every combination of features. To view the images, you can use the program xv. The image data can be found in /faces. This directory contains 20 subdirectories, one for each person, named by userid. Each of these directories contains several different face images of the same person. You will be interested in the images with the following naming convention:     .pgm  is the user id of the person in the image, and this field has 20 values: an2i, at33, boland, bpm, ch4f, cheyer, choon, danieln, glickman, karyadi, kawamura, kk49, megak, mitchell, night, phoebe, saavik, steffi, sz24, and tammo.  is the head position of the person, and this field has 4 values: straight, left, right, up.  is the facial expression of the person, and this field has 4 values: neutral, happy, sad, angry.  is the eye state of the person, and this field has 2 values: open, sunglasses.  is the scale of the image, and this field has 3 values: 1, 2, and 4. 1 indicates a full-resolution image (128 columns by 120 rows); 2 indicates a half-resolution image (64 by 60); 4 indicates a quarter-resolution image (32 by 30). If you've been looking closely in the image directories, you may notice that some images have a .bad suffix rather than the .pgm suffix. As it turns out, 16 of the 640 images taken have glitches due to problems with the camera setup; these are the .bad images. Some people had more glitches than others, but everyone who got ``faced'' should have at least 28 good face images (out of the 32 variations possible, discounting scale). More information and C code for loading the images is available here: [Web Link]. nan"
Movie,Movie,"This data set contains a list of over 10000 films including many older, odd, and cult films. There is information on actors, casts, directors, producers, studios, etc.",Movie,https://archive.ics.uci.edu/ml//machine-learning-databases/movies-mld/,https://archive.ics.uci.edu/ml/datasets/Movie,"The data is stored in relational form across several files. The central file (MAIN) is a list of movies, each with a unique identifier. These identifiers may change in successive versions. The actors (CAST) for those movies are listed with their roles in a distinct file. More information about individual actors (ACTORS) is in a third file. All directors in MAIN are listed in a fourth file (PEOPLE), with a number of important producers, writers, and cinematographers. A fifth file (REMAKES) links movies that were copied to a substantial extent from each other. The sixth file (STUDIOS) provides some information about studios shown in MAIN.The original motivation was for database class exercises, to replace the boring `manager of the toy-department' queries. Note that the CASTS, refering MAIN and ACTORS is logically identical to the inventory file refering to suppliers and assemblies in the the standard bill-of-materials problems. Personal interests caused the database to be made complete for all Hitchcock movies and TV episodes. Related films by type and actor were added gradually.Subsequent research on temporal databases caused date fields (years only) to be added. It allows testing, say, if the dates-of-work of an ACTOR match the dates of the MAIN films that the CAST relation shows. Object-oriented database features could be tested with fields having multiple and two-level values, as documented in DOC.The entries were gradually collected during course work starting about 1975 and are still being updated. Most of the entries were manual. The DOC file lists some of the reference works used. Corrections and additions continue to be appreciated.Detailed descriptions of the fields and their formats is provided in doc.html. Missing Values:Outside of key fields, missing values are common. Their encoding is described in DOC. Sometimes the data seems to be unavailable, sometimes it hasn't been entered. Some information, as `lived-with' is inherently incomplete.Censored Data:Minor actors are ignored.Dependencies:Every MAIN film must have a director in PEOPLE. About 50 pseudo director names ahve been listed in PEOPLE to allow interesting films to with (yet) unknown directors to be entered. Every CASTS entry must relate to a MAIN film entry. Every ACTOR should appear in some CASTS entry, but not vice versa. See DOC for more type information.Other Relevant Information:Films are listed, if known, with their original language title. An Alt(T: ) field provides English translations, where known.Data Format:The current files are in HTML, to allow easy parsing to other formats. An XML version is being considered.The approximate file sizes are:DOC .......    50K MAIN ...... 1 145K   11 400 entriesPEOPLE ....   355K    3 290 entriesCASTS ..... 4 340K   46 000 entriesACTORS ....   811K    6 800 entriesREMAKES ...   135K    1 278 entriesSTUDIOS ...    26K      200 entries",Unknown,,"This data set contains a list of over 10000 films including many older, odd, and cult films. There is information on actors, casts, directors, producers, studios, etc.The data is stored in relational form across several files. The central file (MAIN) is a list of movies, each with a unique identifier. These identifiers may change in successive versions. The actors (CAST) for those movies are listed with their roles in a distinct file. More information about individual actors (ACTORS) is in a third file. All directors in MAIN are listed in a fourth file (PEOPLE), with a number of important producers, writers, and cinematographers. A fifth file (REMAKES) links movies that were copied to a substantial extent from each other. The sixth file (STUDIOS) provides some information about studios shown in MAIN.The original motivation was for database class exercises, to replace the boring `manager of the toy-department' queries. Note that the CASTS, refering MAIN and ACTORS is logically identical to the inventory file refering to suppliers and assemblies in the the standard bill-of-materials problems. Personal interests caused the database to be made complete for all Hitchcock movies and TV episodes. Related films by type and actor were added gradually.Subsequent research on temporal databases caused date fields (years only) to be added. It allows testing, say, if the dates-of-work of an ACTOR match the dates of the MAIN films that the CAST relation shows. Object-oriented database features could be tested with fields having multiple and two-level values, as documented in DOC.The entries were gradually collected during course work starting about 1975 and are still being updated. Most of the entries were manual. The DOC file lists some of the reference works used. Corrections and additions continue to be appreciated.Detailed descriptions of the fields and their formats is provided in doc.html. Missing Values:Outside of key fields, missing values are common. Their encoding is described in DOC. Sometimes the data seems to be unavailable, sometimes it hasn't been entered. Some information, as `lived-with' is inherently incomplete.Censored Data:Minor actors are ignored.Dependencies:Every MAIN film must have a director in PEOPLE. About 50 pseudo director names ahve been listed in PEOPLE to allow interesting films to with (yet) unknown directors to be entered. Every CASTS entry must relate to a MAIN film entry. Every ACTOR should appear in some CASTS entry, but not vice versa. See DOC for more type information.Other Relevant Information:Films are listed, if known, with their original language title. An Alt(T: ) field provides English translations, where known.Data Format:The current files are in HTML, to allow easy parsing to other formats. An XML version is being considered.The approximate file sizes are:DOC .......    50K MAIN ...... 1 145K   11 400 entriesPEOPLE ....   355K    3 290 entriesCASTS ..... 4 340K   46 000 entriesACTORS ....   811K    6 800 entriesREMAKES ...   135K    1 278 entriesSTUDIOS ...    26K      200 entriesnan"
News Aggregator,News Aggregator,References to news pages collected from an web aggregator in the period from 10-March-2014 to 10-August-2014. The resources are grouped into clusters that represent pages discussing the same story.,News+Aggregator,https://archive.ics.uci.edu/ml//machine-learning-databases/00359/,https://archive.ics.uci.edu/ml/datasets/News+Aggregator,"News are grouped into clusters that represent pages discussing the same news story. The dataset includes also references to web pages that, at the access time, pointed (has a link to) one of the news page in the collection.422937 news pages and divided up into:152746 	news of business category108465 	news of science and technology category115920 	news of business category 45615 	news of health category2076 clusters of similar news for entertainment category1789 clusters of similar news for science and technology category2019 clusters of similar news for business category1347 clusters of similar news for health categoryReferences to web pages containing a link to one news included in the collection are also included. They are represented as pairs of urls corresponding to 2-page browsing sessions. The collection includes 15516 2-page browsing sessions covering 946 distinct clusters divided up into:6091 2-page sessions for business category9425 2-page sessions for entertainment category",Unknown,"FILENAME #1: newsCorpora.csv (102.297.000 bytes)DESCRIPTION: News pagesFORMAT: ID 	 TITLE 	 URL 	 PUBLISHER 	 CATEGORY 	 STORY 	 HOSTNAME 	 TIMESTAMPwhere:ID		Numeric IDTITLE		News title URL		UrlPUBLISHER	Publisher nameCATEGORY	News category (b = business, t = science and technology, e = entertainment, m = health)STORY		Alphanumeric ID of the cluster that includes news about the same storyHOSTNAME	Url hostnameTIMESTAMP 	Approximate time the news was published, as the number of milliseconds since the epoch 00:00:00 GMT, January 1, 1970FILENAME #2: 2pageSessions.csv (3.049.986 bytes)DESCRIPTION: 2-page sessionsFORMAT: STORY 	 HOSTNAME 	 CATEGORY 	 URLwhere:STORY		Alphanumeric ID of the cluster that includes news about the same storyHOSTNAME	Url hostnameCATEGORY	News category (b = business, t = science and technology, e = entertainment, m = health)URL		Two space-delimited urls representing a browsing session","References to news pages collected from an web aggregator in the period from 10-March-2014 to 10-August-2014. The resources are grouped into clusters that represent pages discussing the same story.News are grouped into clusters that represent pages discussing the same news story. The dataset includes also references to web pages that, at the access time, pointed (has a link to) one of the news page in the collection.422937 news pages and divided up into:152746 	news of business category108465 	news of science and technology category115920 	news of business category 45615 	news of health category2076 clusters of similar news for entertainment category1789 clusters of similar news for science and technology category2019 clusters of similar news for business category1347 clusters of similar news for health categoryReferences to web pages containing a link to one news included in the collection are also included. They are represented as pairs of urls corresponding to 2-page browsing sessions. The collection includes 15516 2-page browsing sessions covering 946 distinct clusters divided up into:6091 2-page sessions for business category9425 2-page sessions for entertainment categoryFILENAME #1: newsCorpora.csv (102.297.000 bytes)DESCRIPTION: News pagesFORMAT: ID 	 TITLE 	 URL 	 PUBLISHER 	 CATEGORY 	 STORY 	 HOSTNAME 	 TIMESTAMPwhere:ID		Numeric IDTITLE		News title URL		UrlPUBLISHER	Publisher nameCATEGORY	News category (b = business, t = science and technology, e = entertainment, m = health)STORY		Alphanumeric ID of the cluster that includes news about the same storyHOSTNAME	Url hostnameTIMESTAMP 	Approximate time the news was published, as the number of milliseconds since the epoch 00:00:00 GMT, January 1, 1970FILENAME #2: 2pageSessions.csv (3.049.986 bytes)DESCRIPTION: 2-page sessionsFORMAT: STORY 	 HOSTNAME 	 CATEGORY 	 URLwhere:STORY		Alphanumeric ID of the cluster that includes news about the same storyHOSTNAME	Url hostnameCATEGORY	News category (b = business, t = science and technology, e = entertainment, m = health)URL		Two space-delimited urls representing a browsing session"
Connectionist Bench (Nettalk Corpus),Connectionist Bench (Nettalk Corpus),"The file ""nettalk.data"" contains a list of 20,008 English words, along with a phonetic transcription for each word. The task is to train a network to produce the proper phonemes",Connectionist+Bench+%28Nettalk+Corpus%29,https://archive.ics.uci.edu/ml//machine-learning-databases/undocumented/connectionist-bench/nettalk/,https://archive.ics.uci.edu/ml/datasets/Connectionist+Bench+%28Nettalk+Corpus%29,"This is an updated and corrected version of the data set used by Sejnowski and Rosenberg in their influential study of speech generation using a neural network [1].  The file ""nettalk.data"" contains a list of 20,008 English words, along with a phonetic transcription for each word. The task is to train a network to produce the proper phonemes, given a string of letters as input.  This is an example of an input/output mapping task that exhibits strong global regularities, but also a large number of more specialized rules and exceptional cases.Please see original readme file for more information.",Unknown,"The pronouncing dictionary was created to study the translation process between written English, using graphemes or letters as units, and spoken English, using phonemes as units. The dictionary includes 20008 aligned letter and phonetic representations with stresses.The dictionary contains four tab separated fields of information for each word.  The fields are:	1) a letter representation	2) a phonemic representation	3) stress and syllabic structure	4) an integer indicating foreign and irregular wordsPlease see original readme file for more information.","The file ""nettalk.data"" contains a list of 20,008 English words, along with a phonetic transcription for each word. The task is to train a network to produce the proper phonemesThis is an updated and corrected version of the data set used by Sejnowski and Rosenberg in their influential study of speech generation using a neural network [1].  The file ""nettalk.data"" contains a list of 20,008 English words, along with a phonetic transcription for each word. The task is to train a network to produce the proper phonemes, given a string of letters as input.  This is an example of an input/output mapping task that exhibits strong global regularities, but also a large number of more specialized rules and exceptional cases.Please see original readme file for more information.The pronouncing dictionary was created to study the translation process between written English, using graphemes or letters as units, and spoken English, using phonemes as units. The dictionary includes 20008 aligned letter and phonetic representations with stresses.The dictionary contains four tab separated fields of information for each word.  The fields are:	1) a letter representation	2) a phonemic representation	3) stress and syllabic structure	4) an integer indicating foreign and irregular wordsPlease see original readme file for more information."
Connectionist Bench (Vowel Recognition - Deterding Data),Connectionist Bench (Vowel Recognition - Deterding Data),Speaker independent recognition of the eleven steady state vowels of British English using a specified training set of lpc derived log area ratios.,Connectionist+Bench+%28Vowel+Recognition+-+Deterding+Data%29,https://archive.ics.uci.edu/ml//machine-learning-databases/undocumented/connectionist-bench/vowel/,https://archive.ics.uci.edu/ml/datasets/Connectionist+Bench+%28Vowel+Recognition+-+Deterding+Data%29,"The problem is specified by the accompanying data file, ""vowel.data"".  This consists of a three dimensional array: voweldata [speaker, vowel, input]. The speakers are indexed by integers 0-89.  (Actually, there are fifteen individual speakers, each saying each vowel six times.)  The vowels are indexed by integers 0-10.  For each utterance, there are ten floating-point input values, with array indices 0-9.The problem is to train the network as well as possible using only on data from ""speakers"" 0-47, and then to test the network on speakers 48-89, reporting the number of correct classifications in the test set.For a more detailed explanation of the problem, see the excerpt from Tony Robinson's Ph.D. thesis in the COMMENTS section.  In Robinson's opinion, connectionist problems fall into two classes, the possible and the impossible.  He is interested in the latter, by which he means problems that have no exact solution.  Thus the problem here is not to see how fast a network can be trained (although this is important), but to maximise a less than perfect performance.",Unknown,,"Speaker independent recognition of the eleven steady state vowels of British English using a specified training set of lpc derived log area ratios.The problem is specified by the accompanying data file, ""vowel.data"".  This consists of a three dimensional array: voweldata [speaker, vowel, input]. The speakers are indexed by integers 0-89.  (Actually, there are fifteen individual speakers, each saying each vowel six times.)  The vowels are indexed by integers 0-10.  For each utterance, there are ten floating-point input values, with array indices 0-9.The problem is to train the network as well as possible using only on data from ""speakers"" 0-47, and then to test the network on speakers 48-89, reporting the number of correct classifications in the test set.For a more detailed explanation of the problem, see the excerpt from Tony Robinson's Ph.D. thesis in the COMMENTS section.  In Robinson's opinion, connectionist problems fall into two classes, the possible and the impossible.  He is interested in the latter, by which he means problems that have no exact solution.  Thus the problem here is not to see how fast a network can be trained (although this is important), but to maximise a less than perfect performance.nan"
NSF Research Award Abstracts 1990-2003,NSF Research Award Abstracts 1990-2003,"This data set consists of (a) 129,000 abstracts describing NSF awards for basic research, (b) bag-of-word data files extracted from the abstracts, (c) a list of words used for indexing the bag-of-word",NSF+Research+Award+Abstracts+1990-2003,https://archive.ics.uci.edu/ml//machine-learning-databases/nsfabs-mld/,https://archive.ics.uci.edu/ml/datasets/NSF+Research+Award+Abstracts+1990-2003,"The abstracts, one per file, were furnished by the NSF (National Science Foundation). A sample abstract is shown in the next section.The bag-of-word data was produced by automatically processing the abstracts with a text analyzer called NSFAbst, built using VisualText. While most fields of the output are very accurate, the authors were not extracted from the Investigator: field with 100% accuracy, due to wide variability in that field.The word list came from a separate process, and may not include all the words of interest in the abstracts. ",Unknown,,"This data set consists of (a) 129,000 abstracts describing NSF awards for basic research, (b) bag-of-word data files extracted from the abstracts, (c) a list of words used for indexing the bag-of-wordThe abstracts, one per file, were furnished by the NSF (National Science Foundation). A sample abstract is shown in the next section.The bag-of-word data was produced by automatically processing the abstracts with a text analyzer called NSFAbst, built using VisualText. While most fields of the output are very accurate, the authors were not extracted from the Investigator: field with 100% accuracy, due to wide variability in that field.The word list came from a separate process, and may not include all the words of interest in the abstracts. nan"
Crop mapping using fused optical-radar data set,Crop mapping using fused optical-radar data set,"Combining optical and PolSAR remote sensing images offers a complementary data set with a significant number of temporal, spectral, textural, and polarimetric features for cropland classification.",Crop+mapping+using+fused+optical-radar+data+set,https://archive.ics.uci.edu/ml//machine-learning-databases/00525/,https://archive.ics.uci.edu/ml/datasets/Crop+mapping+using+fused+optical-radar+data+set,"This big data set is a fused bi-temporal optical-radar data for cropland classification. The images were collected by RapidEye satellites (optical) and the Unmanned Aerial Vehicle Synthetic Aperture Radar (UAVSAR) system (Radar) over an agricultural region near Winnipeg, Manitoba, Canada on 2012.There are 2 * 49 radar features and 2 * 38 optical features for two dates: 05 and 14 July 2012.Seven crop type classes exist for this data set as follows: 1-Corn; 2-Peas; 3- Canola; 4-Soybeans; 5- Oats; 6- Wheat; and 7-Broadleaf.",Unknown,"175 attributes including:      1- class;      2- f1 to f49:Polarimetric features on 05 July 2012;      3- f50 to f98:Polarimetric features on 14 July 2012;      4- f99 to f136:Optical features on 05 July 2012;      5- f137 to f174:Optical features on 14 July 2012;Details:label:crop type classf1:sigHH_Rad05Julyf2:sigHV_Rad05Julyf3:sigVV_Rad05Julyf4:sigRR_Rad05Julyf5:sigRL_Rad05Julyf6:sigLL_Rad05Julyf7:Rhhvv_Rad05Julyf8:Rhvhh_Rad05Julyf9:Rhvvv_Rad05Julyf10:Rrrll_Rad05Julyf11:Rrlrr_Rad05Julyf12:Rrlll_Rad05Julyf13:Rhh_Rad05Julyf14:Rhv_Rad05Julyf15:Rvv_Rad05Julyf16:Rrr_Rad05Julyf17:Rrl_Rad05Julyf18:Rll_Rad05Julyf19:Ro12_Rad05Julyf20:Ro13_Rad05Julyf21:Ro23_Rad05Julyf22:Ro12cir_Rad05Julyf23:Ro13cir_Rad05Julyf24:Ro23cir_Rad05Julyf25:l1_Rad05Julyf26:l2_Rad05Julyf27:l3_Rad05Julyf28:H_Rad05Julyf29:A_Rad05Julyf30:a_Rad05Julyf31:HA_Rad05Julyf32:H1mA_Rad05Julyf33:1mHA_Rad05Julyf34:1mH1mA_Rad05Julyf35:PH_Rad05Julyf36:rvi_Rad05Julyf37:paulalpha_Rad05Julyf38:paulbeta_Rad05Julyf39:paulgamma_Rad05Julyf40:krogks_Rad05Julyf41:krogkd_Rad05Julyf42:krogkh_Rad05Julyf43:freeodd_Rad05Julyf44:freedbl_Rad05Julyf45:freevol_Rad05Julyf46:yamodd_Rad05Julyf47:yamdbl_Rad05Julyf48:yamhlx_Rad05Julyf49:yamvol_Rad05Julyf50:sigHH_Rad14Julyf51:sigHV_Rad14Julyf52:sigVV_Rad14Julyf53:sigRR_Rad14Julyf54:sigRL_Rad14Julyf55:sigLL_Rad14Julyf56:Rhhvv_Rad14Julyf57:Rhvhh_Rad14Julyf58:Rhvvv_Rad14Julyf59:Rrrll_Rad14Julyf60:Rrlrr_Rad14Julyf61:Rrlll_Rad14Julyf62:Rhh_Rad14Julyf63:Rhv_Rad14Julyf64:Rvv_Rad14Julyf65:Rrr_Rad14Julyf66:Rrl_Rad14Julyf67:Rll_Rad14Julyf68:Ro12_Rad14Julyf69:Ro13_Rad14Julyf70:Ro23_Rad14Julyf71:Ro12cir_Rad14Julyf72:Ro13cir_Rad14Julyf73:Ro23cir_Rad14Julyf74:l1_Rad14Julyf75:l2_Rad14Julyf76:l3_Rad14Julyf77:H_Rad14Julyf78:A_Rad14Julyf79:a_Rad14Julyf80:HA_Rad14Julyf81:H1mA_Rad14Julyf82:1mHA_Rad14Julyf83:1mH1mA_Rad14Julyf84:PH_Rad14Julyf85:rvi_Rad14Julyf86:paulalpha_Rad14Julyf87:paulbeta_Rad14Julyf88:paulgamma_Rad14Julyf89:krogks_Rad14Julyf90:krogkd_Rad14Julyf91:krogkh_Rad14Julyf92:freeodd_Rad14Julyf93:freedbl_Rad14Julyf94:freevol_Rad14Julyf95:yamodd_Rad14Julyf96:yamdbl_Rad14Julyf97:yamhlx_Rad14Julyf98:yamvol_Rad14Julyf99:B_Opt05Julyf100:G_Opt05Julyf101:R_Opt05Julyf102:Redge_Opt05Julyf103:NIR_Opt05Julyf104:NDVI_Opt05Julyf105:SR_Opt05Julyf106:RGRI_Opt05Julyf107:EVI_Opt05Julyf108:ARVI_Opt05Julyf109:SAVI_Opt05Julyf110:NDGI_Opt05Julyf111:gNDVI_Opt05Julyf112:MTVI2_Opt05Julyf113:NDVIre_Opt05Julyf114:SRre_Opt05Julyf115:NDGIre_Opt05Julyf116:RTVIcore_Opt05Julyf117:RNDVI_Opt05Julyf118:TCARI_Opt05Julyf119:TVI_Opt05Julyf120:PRI2_Opt05Julyf121:MeanPC1_Opt05Julyf122:VarPC1_Opt05Julyf123:HomPC1_Opt05Julyf124:ConPC1_Opt05Julyf125:DisPC1_Opt05Julyf126:EntPC1_Opt05Julyf127:SecMomPC1_Opt05Julyf128:CorPC1_Opt05Julyf129:MeanPC2_Opt05Julyf130:VarPC2_Opt05Julyf131:HomPC2_Opt05Julyf132:ConPC2_Opt05Julyf133:DisPC2_Opt05Julyf134:EntPC2_Opt05Julyf135:SecMomPC2_Opt05Julyf136:CorPC2_Opt05Julyf137:B_Opt14Julyf138:G_Opt14Julyf139:R_Opt14Julyf140:Redge_Opt14Julyf141:NIR_Opt14Julyf142:NDVI_Opt14Julyf143:SR_Opt14Julyf144:RGRI_Opt14Julyf145:EVI_Opt14Julyf146:ARVI_Opt14Julyf147:SAVI_Opt14Julyf148:NDGI_Opt14Julyf149:gNDVI_Opt14Julyf150:MTVI2_Opt14Julyf151:NDVIre_Opt14Julyf152:SRre_Opt14Julyf153:NDGIre_Opt14Julyf154:RTVIcore_Opt14Julyf155:RNDVI_Opt14Julyf156:TCARI_Opt14Julyf157:TVI_Opt14Julyf158:PRI2_Opt14Julyf159:MeanPC1_Opt14Julyf160:VarPC1_Opt14Julyf161:HomPC1_Opt14Julyf162:ConPC1_Opt14Julyf163:DisPC1_Opt14Julyf164:EntPC1_Opt14Julyf165:SecMomPC1_Opt14Julyf166:CorPC1_Opt14Julyf167:MeanPC2_Opt14Julyf168:VarPC2_Opt14Julyf169:HomPC2_Opt14Julyf170:ConPC2_Opt14Julyf171:DisPC2_Opt14Julyf172:EntPC2_Opt14Julyf173:SecMomPC2_Opt14Julyf174:CorPC2_Opt14JulyFor more information about these attributes, please refer to relevant papers.","Combining optical and PolSAR remote sensing images offers a complementary data set with a significant number of temporal, spectral, textural, and polarimetric features for cropland classification.This big data set is a fused bi-temporal optical-radar data for cropland classification. The images were collected by RapidEye satellites (optical) and the Unmanned Aerial Vehicle Synthetic Aperture Radar (UAVSAR) system (Radar) over an agricultural region near Winnipeg, Manitoba, Canada on 2012.There are 2 * 49 radar features and 2 * 38 optical features for two dates: 05 and 14 July 2012.Seven crop type classes exist for this data set as follows: 1-Corn; 2-Peas; 3- Canola; 4-Soybeans; 5- Oats; 6- Wheat; and 7-Broadleaf.175 attributes including:      1- class;      2- f1 to f49:Polarimetric features on 05 July 2012;      3- f50 to f98:Polarimetric features on 14 July 2012;      4- f99 to f136:Optical features on 05 July 2012;      5- f137 to f174:Optical features on 14 July 2012;Details:label:crop type classf1:sigHH_Rad05Julyf2:sigHV_Rad05Julyf3:sigVV_Rad05Julyf4:sigRR_Rad05Julyf5:sigRL_Rad05Julyf6:sigLL_Rad05Julyf7:Rhhvv_Rad05Julyf8:Rhvhh_Rad05Julyf9:Rhvvv_Rad05Julyf10:Rrrll_Rad05Julyf11:Rrlrr_Rad05Julyf12:Rrlll_Rad05Julyf13:Rhh_Rad05Julyf14:Rhv_Rad05Julyf15:Rvv_Rad05Julyf16:Rrr_Rad05Julyf17:Rrl_Rad05Julyf18:Rll_Rad05Julyf19:Ro12_Rad05Julyf20:Ro13_Rad05Julyf21:Ro23_Rad05Julyf22:Ro12cir_Rad05Julyf23:Ro13cir_Rad05Julyf24:Ro23cir_Rad05Julyf25:l1_Rad05Julyf26:l2_Rad05Julyf27:l3_Rad05Julyf28:H_Rad05Julyf29:A_Rad05Julyf30:a_Rad05Julyf31:HA_Rad05Julyf32:H1mA_Rad05Julyf33:1mHA_Rad05Julyf34:1mH1mA_Rad05Julyf35:PH_Rad05Julyf36:rvi_Rad05Julyf37:paulalpha_Rad05Julyf38:paulbeta_Rad05Julyf39:paulgamma_Rad05Julyf40:krogks_Rad05Julyf41:krogkd_Rad05Julyf42:krogkh_Rad05Julyf43:freeodd_Rad05Julyf44:freedbl_Rad05Julyf45:freevol_Rad05Julyf46:yamodd_Rad05Julyf47:yamdbl_Rad05Julyf48:yamhlx_Rad05Julyf49:yamvol_Rad05Julyf50:sigHH_Rad14Julyf51:sigHV_Rad14Julyf52:sigVV_Rad14Julyf53:sigRR_Rad14Julyf54:sigRL_Rad14Julyf55:sigLL_Rad14Julyf56:Rhhvv_Rad14Julyf57:Rhvhh_Rad14Julyf58:Rhvvv_Rad14Julyf59:Rrrll_Rad14Julyf60:Rrlrr_Rad14Julyf61:Rrlll_Rad14Julyf62:Rhh_Rad14Julyf63:Rhv_Rad14Julyf64:Rvv_Rad14Julyf65:Rrr_Rad14Julyf66:Rrl_Rad14Julyf67:Rll_Rad14Julyf68:Ro12_Rad14Julyf69:Ro13_Rad14Julyf70:Ro23_Rad14Julyf71:Ro12cir_Rad14Julyf72:Ro13cir_Rad14Julyf73:Ro23cir_Rad14Julyf74:l1_Rad14Julyf75:l2_Rad14Julyf76:l3_Rad14Julyf77:H_Rad14Julyf78:A_Rad14Julyf79:a_Rad14Julyf80:HA_Rad14Julyf81:H1mA_Rad14Julyf82:1mHA_Rad14Julyf83:1mH1mA_Rad14Julyf84:PH_Rad14Julyf85:rvi_Rad14Julyf86:paulalpha_Rad14Julyf87:paulbeta_Rad14Julyf88:paulgamma_Rad14Julyf89:krogks_Rad14Julyf90:krogkd_Rad14Julyf91:krogkh_Rad14Julyf92:freeodd_Rad14Julyf93:freedbl_Rad14Julyf94:freevol_Rad14Julyf95:yamodd_Rad14Julyf96:yamdbl_Rad14Julyf97:yamhlx_Rad14Julyf98:yamvol_Rad14Julyf99:B_Opt05Julyf100:G_Opt05Julyf101:R_Opt05Julyf102:Redge_Opt05Julyf103:NIR_Opt05Julyf104:NDVI_Opt05Julyf105:SR_Opt05Julyf106:RGRI_Opt05Julyf107:EVI_Opt05Julyf108:ARVI_Opt05Julyf109:SAVI_Opt05Julyf110:NDGI_Opt05Julyf111:gNDVI_Opt05Julyf112:MTVI2_Opt05Julyf113:NDVIre_Opt05Julyf114:SRre_Opt05Julyf115:NDGIre_Opt05Julyf116:RTVIcore_Opt05Julyf117:RNDVI_Opt05Julyf118:TCARI_Opt05Julyf119:TVI_Opt05Julyf120:PRI2_Opt05Julyf121:MeanPC1_Opt05Julyf122:VarPC1_Opt05Julyf123:HomPC1_Opt05Julyf124:ConPC1_Opt05Julyf125:DisPC1_Opt05Julyf126:EntPC1_Opt05Julyf127:SecMomPC1_Opt05Julyf128:CorPC1_Opt05Julyf129:MeanPC2_Opt05Julyf130:VarPC2_Opt05Julyf131:HomPC2_Opt05Julyf132:ConPC2_Opt05Julyf133:DisPC2_Opt05Julyf134:EntPC2_Opt05Julyf135:SecMomPC2_Opt05Julyf136:CorPC2_Opt05Julyf137:B_Opt14Julyf138:G_Opt14Julyf139:R_Opt14Julyf140:Redge_Opt14Julyf141:NIR_Opt14Julyf142:NDVI_Opt14Julyf143:SR_Opt14Julyf144:RGRI_Opt14Julyf145:EVI_Opt14Julyf146:ARVI_Opt14Julyf147:SAVI_Opt14Julyf148:NDGI_Opt14Julyf149:gNDVI_Opt14Julyf150:MTVI2_Opt14Julyf151:NDVIre_Opt14Julyf152:SRre_Opt14Julyf153:NDGIre_Opt14Julyf154:RTVIcore_Opt14Julyf155:RNDVI_Opt14Julyf156:TCARI_Opt14Julyf157:TVI_Opt14Julyf158:PRI2_Opt14Julyf159:MeanPC1_Opt14Julyf160:VarPC1_Opt14Julyf161:HomPC1_Opt14Julyf162:ConPC1_Opt14Julyf163:DisPC1_Opt14Julyf164:EntPC1_Opt14Julyf165:SecMomPC1_Opt14Julyf166:CorPC1_Opt14Julyf167:MeanPC2_Opt14Julyf168:VarPC2_Opt14Julyf169:HomPC2_Opt14Julyf170:ConPC2_Opt14Julyf171:DisPC2_Opt14Julyf172:EntPC2_Opt14Julyf173:SecMomPC2_Opt14Julyf174:CorPC2_Opt14JulyFor more information about these attributes, please refer to relevant papers."
Meta-data,Meta-data,Meta-Data was used in order to give advice about which classification method is appropriate for a particular dataset (taken from results of Statlog project).,Meta-data,https://archive.ics.uci.edu/ml//machine-learning-databases/meta-data/,https://archive.ics.uci.edu/ml/datasets/Meta-data,"This DataSet is about the results of Statlog project. The project performed a comparative study between Statistical, Neural and Symbolic learning algorithms.Project StatLog (Esprit Project 5170) was concerned with comparative studies of different machine learning, neural and statistical classification algorithms. About 20 different algorithms were evaluated on more than 20 different datasets. The tests carried out under project produced many interesting results.The results of these tests are comprehensively described in a book  (D.Michie et.al, 1994). ",Unknown,"   1.	DS_Name		categorical	Name of DataSet    2.	T		continuous	Number of examples in test set   3.	N		continuous	Number of examples   4.	p		continuous	Number of attributes   5.	k		continuous	Number of classes    6.	Bin		continuous	Number of binary Attributes    7.	Cost		continuous	Cost (1=yes,0=no)    8.	SDratio		continuous	Standard deviation ratio    9.	correl		continuous	Mean correlation between attributes  10.	cancor1		continuous	First canonical correlation  11.	cancor2		continuous	Second canonical correlation  12.	fract1		continuous	First eigenvalue   13.	fract2		continuous	Second eigenvalue   14.	skewness	continuous	Mean of |E(X-Mean)|^3/STD^3  15.	kurtosis	continuous	Mean of |E(X-Mean)|^4/STD^4  16.	Hc		continuous	Mean entropy of attributes  17.	Hx		continuous	Entropy of classes  18.	MCx		continuous	Mean mutual entropy of class and attributes  19.	EnAtr		continuous	Equivalent number of attributes   20.	NSRatio		continuous	Noise-signal ratio   21.	Alg_Name	categorical	Name of Algorithm   22.	Norm_error	continuous	Normalized Error (continuous class) ","Meta-Data was used in order to give advice about which classification method is appropriate for a particular dataset (taken from results of Statlog project).This DataSet is about the results of Statlog project. The project performed a comparative study between Statistical, Neural and Symbolic learning algorithms.Project StatLog (Esprit Project 5170) was concerned with comparative studies of different machine learning, neural and statistical classification algorithms. About 20 different algorithms were evaluated on more than 20 different datasets. The tests carried out under project produced many interesting results.The results of these tests are comprehensively described in a book  (D.Michie et.al, 1994).    1.	DS_Name		categorical	Name of DataSet    2.	T		continuous	Number of examples in test set   3.	N		continuous	Number of examples   4.	p		continuous	Number of attributes   5.	k		continuous	Number of classes    6.	Bin		continuous	Number of binary Attributes    7.	Cost		continuous	Cost (1=yes,0=no)    8.	SDratio		continuous	Standard deviation ratio    9.	correl		continuous	Mean correlation between attributes  10.	cancor1		continuous	First canonical correlation  11.	cancor2		continuous	Second canonical correlation  12.	fract1		continuous	First eigenvalue   13.	fract2		continuous	Second eigenvalue   14.	skewness	continuous	Mean of |E(X-Mean)|^3/STD^3  15.	kurtosis	continuous	Mean of |E(X-Mean)|^4/STD^4  16.	Hc		continuous	Mean entropy of attributes  17.	Hx		continuous	Entropy of classes  18.	MCx		continuous	Mean mutual entropy of class and attributes  19.	EnAtr		continuous	Equivalent number of attributes   20.	NSRatio		continuous	Noise-signal ratio   21.	Alg_Name	categorical	Name of Algorithm   22.	Norm_error	continuous	Normalized Error (continuous class) "
Reuters-21578 Text Categorization Collection,Reuters-21578 Text Categorization Collection,This is a collection of documents that appeared on Reuters newswire in 1987. The documents were assembled and indexed with categories.,Reuters-21578+Text+Categorization+Collection,https://archive.ics.uci.edu/ml//machine-learning-databases/reuters21578-mld/,https://archive.ics.uci.edu/ml/datasets/Reuters-21578+Text+Categorization+Collection,"From the original readme file (please consult it for more information):-------------------------The documents in the Reuters-21578 collection appeared on the Reuters newswire in 1987.  The documents were assembled and indexed with categories by personnel from Reuters Ltd. (Sam Dobbins, Mike Topliss, Steve Weinstein) and Carnegie Group, Inc. (Peggy Andersen, Monica Cellio, Phil Hayes, Laura Knecht, Irene Nirenburg) in 1987.  In 1990, the documents were made available by Reuters and CGI for research purposes to the Information Retrieval Laboratory (W.  Bruce Croft, Director) of the Computer and Information Science Department at the University of Massachusetts at Amherst.  Formatting of the documents and production of associated data files was done in 1990 by David D.  Lewis and Stephen Harding at the Information Retrieval Laboratory.Further formatting and data file production was done in 1991 and 1992 by David D. Lewis and Peter Shoemaker at the Center for Information and Language Studies, University of Chicago.  This version of the data was made available for anonymous FTP as ""Reuters-22173, Distribution 1.0"" in January 1993. From 1993 through 1996, Distribution 1.0 was hosted at a succession of FTP sites maintained by the Center for Intelligent Information Retrieval (W. Bruce Croft, Director) of the Computer Science Department at the University of Massachusetts at Amherst.At the ACM SIGIR '96 conference in August, 1996 a group of text categorization researchers discussed how published results on Reuters-22173 could be made more comparable across studies.  It was decided that a new version of collection should be produced with less ambiguous formatting, and including documentation carefully spelling out standard methods of using the collection.  The opportunity would also be used to correct a variety of typographical and other errors in the categorization and formatting of the collection.Steve Finch and David D. Lewis did this cleanup of the collection September through November of 1996, relying heavily on Finch's SGML-tagged version of the collection from an earlier study.  One result of the re-examination of the collection was the removal of 595 documents which were exact duplicates (based on identity of timestamps down to the second) of other documents in the collection. The new collection therefore has only 21,578 documents, and thus is called the Reuters-21578 collection.  This README describes version 1.0 of this new collection, which we refer to as ""Reuters-21578, Distribution 1.0"".In preparing the collection and documentation we have benefited from discussions with Eric Brown, William Cohen, Fred Damerau, Yoram Singer, Amit Singhal, and Yiming Yang, among many others.We thank all the people and organizations listed above for their efforts and support, without which this collection would not exist.",Unknown,"Reuters-21578, Distribution 1.0 includes five files (all-exchanges-strings.lc.txt, all-orgs-strings.lc.txt, all-people-strings.lc.txt, all-places-strings.lc.txt, and all-topics-strings.lc.txt) which list the names of *all* legal categories in each set.  A sixth file, cat-descriptions_120396.txt gives some additional information on the category sets.","This is a collection of documents that appeared on Reuters newswire in 1987. The documents were assembled and indexed with categories.From the original readme file (please consult it for more information):-------------------------The documents in the Reuters-21578 collection appeared on the Reuters newswire in 1987.  The documents were assembled and indexed with categories by personnel from Reuters Ltd. (Sam Dobbins, Mike Topliss, Steve Weinstein) and Carnegie Group, Inc. (Peggy Andersen, Monica Cellio, Phil Hayes, Laura Knecht, Irene Nirenburg) in 1987.  In 1990, the documents were made available by Reuters and CGI for research purposes to the Information Retrieval Laboratory (W.  Bruce Croft, Director) of the Computer and Information Science Department at the University of Massachusetts at Amherst.  Formatting of the documents and production of associated data files was done in 1990 by David D.  Lewis and Stephen Harding at the Information Retrieval Laboratory.Further formatting and data file production was done in 1991 and 1992 by David D. Lewis and Peter Shoemaker at the Center for Information and Language Studies, University of Chicago.  This version of the data was made available for anonymous FTP as ""Reuters-22173, Distribution 1.0"" in January 1993. From 1993 through 1996, Distribution 1.0 was hosted at a succession of FTP sites maintained by the Center for Intelligent Information Retrieval (W. Bruce Croft, Director) of the Computer Science Department at the University of Massachusetts at Amherst.At the ACM SIGIR '96 conference in August, 1996 a group of text categorization researchers discussed how published results on Reuters-22173 could be made more comparable across studies.  It was decided that a new version of collection should be produced with less ambiguous formatting, and including documentation carefully spelling out standard methods of using the collection.  The opportunity would also be used to correct a variety of typographical and other errors in the categorization and formatting of the collection.Steve Finch and David D. Lewis did this cleanup of the collection September through November of 1996, relying heavily on Finch's SGML-tagged version of the collection from an earlier study.  One result of the re-examination of the collection was the removal of 595 documents which were exact duplicates (based on identity of timestamps down to the second) of other documents in the collection. The new collection therefore has only 21,578 documents, and thus is called the Reuters-21578 collection.  This README describes version 1.0 of this new collection, which we refer to as ""Reuters-21578, Distribution 1.0"".In preparing the collection and documentation we have benefited from discussions with Eric Brown, William Cohen, Fred Damerau, Yoram Singer, Amit Singhal, and Yiming Yang, among many others.We thank all the people and organizations listed above for their efforts and support, without which this collection would not exist.Reuters-21578, Distribution 1.0 includes five files (all-exchanges-strings.lc.txt, all-orgs-strings.lc.txt, all-people-strings.lc.txt, all-places-strings.lc.txt, and all-topics-strings.lc.txt) which list the names of *all* legal categories in each set.  A sixth file, cat-descriptions_120396.txt gives some additional information on the category sets."
KDD Cup 1998 Data,KDD Cup 1998 Data,"This is the data set used for The Second International Knowledge Discovery and Data Mining Tools Competition, which was held in conjunction with KDD-98",KDD+Cup+1998+Data,https://archive.ics.uci.edu/ml//machine-learning-databases/kddcup98-mld/,https://archive.ics.uci.edu/ml/datasets/KDD+Cup+1998+Data,Please see associated text files in the download folder.,Unknown,,"This is the data set used for The Second International Knowledge Discovery and Data Mining Tools Competition, which was held in conjunction with KDD-98Please see associated text files in the download folder.nan"
Japanese Vowels,Japanese Vowels,This dataset records 640 time series of 12 LPC cepstrum coefficients taken from nine male speakers.,Japanese+Vowels,https://archive.ics.uci.edu/ml//machine-learning-databases/JapaneseVowels-mld/,https://archive.ics.uci.edu/ml/datasets/Japanese+Vowels,"The data was collected for examining our newly developed classifier for multidimensional curves (multidimensional time series). Nine male speakers uttered two Japanese vowels /ae/ successively. For each utterance, with the analysis parameters described below, we applied 12-degree linear prediction analysis to it to obtain a discrete-time series with 12 LPC cepstrum coefficients. This means that one utterance by a speaker forms a time series whose length is in the range 7-29 and each point of a time series is of 12 features (12 coefficients).The number of the time series is 640 in total. We used one set of 270 time series for training and the other set of 370 time series for testing.Number of Instances (Utterances):    * Training: 270 (30 utterances by 9 speakers. See file 'size_ae.train'.)    * Testing: 370 (24-88 utterances by the same 9 speakers in different opportunities. See file 'size_ae.test'.) Length of Time Series:    * 7 - 29 depending on utterances Analysis parameters:    * Sampling rate : 10kHz    * Frame length : 25.6 ms    * Shift length : 6.4ms    * Degree of LPC coefficients : 12 Files:    * Training file: ae.train    * Testing file: ae.test Format:Each line in ae.train or ae.test represents 12 LPC coefficients in the increasing order separated by spaces. This corresponds to one analysis frame.Lines are organized into blocks, which are a set of 7-29 lines separated by blank lines and corresponds to a single speech utterance of /ae/ with 7-29 frames.Each speaker is a set of consecutive blocks. In ae.train there are 30 blocks for each speaker. Blocks 1-30 represent speaker 1, blocks 31-60 represent speaker 2, and so on up to speaker 9. In ae.test, speakers 1 to 9 have the corresponding number of blocks: 31 35 88 44 29 24 40 50 29. Thus, blocks 1-31 represent speaker 1 (31 utterances of /ae/), blocks 32-66 represent speaker 2 (35 utterances of /ae/), and so on.",Unknown,12 Real Attributes,"This dataset records 640 time series of 12 LPC cepstrum coefficients taken from nine male speakers.The data was collected for examining our newly developed classifier for multidimensional curves (multidimensional time series). Nine male speakers uttered two Japanese vowels /ae/ successively. For each utterance, with the analysis parameters described below, we applied 12-degree linear prediction analysis to it to obtain a discrete-time series with 12 LPC cepstrum coefficients. This means that one utterance by a speaker forms a time series whose length is in the range 7-29 and each point of a time series is of 12 features (12 coefficients).The number of the time series is 640 in total. We used one set of 270 time series for training and the other set of 370 time series for testing.Number of Instances (Utterances):    * Training: 270 (30 utterances by 9 speakers. See file 'size_ae.train'.)    * Testing: 370 (24-88 utterances by the same 9 speakers in different opportunities. See file 'size_ae.test'.) Length of Time Series:    * 7 - 29 depending on utterances Analysis parameters:    * Sampling rate : 10kHz    * Frame length : 25.6 ms    * Shift length : 6.4ms    * Degree of LPC coefficients : 12 Files:    * Training file: ae.train    * Testing file: ae.test Format:Each line in ae.train or ae.test represents 12 LPC coefficients in the increasing order separated by spaces. This corresponds to one analysis frame.Lines are organized into blocks, which are a set of 7-29 lines separated by blank lines and corresponds to a single speech utterance of /ae/ with 7-29 frames.Each speaker is a set of consecutive blocks. In ae.train there are 30 blocks for each speaker. Blocks 1-30 represent speaker 1, blocks 31-60 represent speaker 2, and so on up to speaker 9. In ae.test, speakers 1 to 9 have the corresponding number of blocks: 31 35 88 44 29 24 40 50 29. Thus, blocks 1-31 represent speaker 1 (31 utterances of /ae/), blocks 32-66 represent speaker 2 (35 utterances of /ae/), and so on.12 Real Attributes"
Audit Data,Audit Data,Exhaustive one year non-confidential data in the year 2015 to 2016 of firms is collected from the Auditor Office of India to build a predictor for classifying suspicious firms.,Audit+Data,https://archive.ics.uci.edu/ml//machine-learning-databases/00475/,https://archive.ics.uci.edu/ml/datasets/Audit+Data,"The goal of the research is to help the auditors by building a classification model that can predict the fraudulent firm on the basis the present and historical risk factors. The information about the sectors and the counts of firms are listed respectively as Irrigation (114), Public Health (77), Buildings and Roads (82), Forest (70), Corporate (47), Animal Husbandry (95), Communication (1), Electrical (4), Land (5), Science and Technology (3), Tourism (1), Fisheries (41), Industries (37), Agriculture (200).",Unknown,"Many risk factors are examined from various areas like past records of audit office, audit-paras, environmental conditions reports, firm reputation summary, on-going issues report, profit-value records, loss-value records, follow-up reports etc. After in-depth interview with the auditors, important risk factors are evaluated and their probability of existence is calculated from the present and past records.","Exhaustive one year non-confidential data in the year 2015 to 2016 of firms is collected from the Auditor Office of India to build a predictor for classifying suspicious firms.The goal of the research is to help the auditors by building a classification model that can predict the fraudulent firm on the basis the present and historical risk factors. The information about the sectors and the counts of firms are listed respectively as Irrigation (114), Public Health (77), Buildings and Roads (82), Forest (70), Corporate (47), Animal Husbandry (95), Communication (1), Electrical (4), Land (5), Science and Technology (3), Tourism (1), Fisheries (41), Industries (37), Agriculture (200).Many risk factors are examined from various areas like past records of audit office, audit-paras, environmental conditions reports, firm reputation summary, on-going issues report, profit-value records, loss-value records, follow-up reports etc. After in-depth interview with the auditors, important risk factors are evaluated and their probability of existence is calculated from the present and past records."
Tarvel Review Ratings,Tarvel Review Ratings,Google reviews on attractions from 24 categories across Europe are considered. Google user rating ranges from 1 to 5 and average user rating per category is calculated.,Tarvel+Review+Ratings,https://archive.ics.uci.edu/ml//machine-learning-databases/00485/,https://archive.ics.uci.edu/ml/datasets/Tarvel+Review+Ratings,This data set is populated by capturing user ratings from Google reviews. Reviews on attractions from 24 categories across Europe are considered. Google user rating ranges from 1 to 5 and average user rating per category is calculated. ,Unknown,Attribute 1 : Unique user idAttribute 2 : Average ratings on churchesAttribute 3 : Average ratings on resortsAttribute 4 : Average ratings on beachesAttribute 5 : Average ratings on parksAttribute 6 : Average ratings on theatresAttribute 7 : Average ratings on museumsAttribute 8 : Average ratings on mallsAttribute 9 : Average ratings on zooAttribute 10 : Average ratings on restaurantsAttribute 11 : Average ratings on pubs/barsAttribute 12 : Average ratings on local servicesAttribute 13 : Average ratings on burger/pizza shopsAttribute 14 : Average ratings on hotels/other lodgingsAttribute 15 : Average ratings on juice barsAttribute 16 : Average ratings on art galleriesAttribute 17 : Average ratings on dance clubsAttribute 18 : Average ratings on swimming poolsAttribute 19 : Average ratings on gymsAttribute 20 : Average ratings on bakeriesAttribute 21 : Average ratings on beauty & spasAttribute 22 : Average ratings on cafesAttribute 23 : Average ratings on view pointsAttribute 24 : Average ratings on monumentsAttribute 25 : Average ratings on gardens,Google reviews on attractions from 24 categories across Europe are considered. Google user rating ranges from 1 to 5 and average user rating per category is calculated.This data set is populated by capturing user ratings from Google reviews. Reviews on attractions from 24 categories across Europe are considered. Google user rating ranges from 1 to 5 and average user rating per category is calculated. Attribute 1 : Unique user idAttribute 2 : Average ratings on churchesAttribute 3 : Average ratings on resortsAttribute 4 : Average ratings on beachesAttribute 5 : Average ratings on parksAttribute 6 : Average ratings on theatresAttribute 7 : Average ratings on museumsAttribute 8 : Average ratings on mallsAttribute 9 : Average ratings on zooAttribute 10 : Average ratings on restaurantsAttribute 11 : Average ratings on pubs/barsAttribute 12 : Average ratings on local servicesAttribute 13 : Average ratings on burger/pizza shopsAttribute 14 : Average ratings on hotels/other lodgingsAttribute 15 : Average ratings on juice barsAttribute 16 : Average ratings on art galleriesAttribute 17 : Average ratings on dance clubsAttribute 18 : Average ratings on swimming poolsAttribute 19 : Average ratings on gymsAttribute 20 : Average ratings on bakeriesAttribute 21 : Average ratings on beauty & spasAttribute 22 : Average ratings on cafesAttribute 23 : Average ratings on view pointsAttribute 24 : Average ratings on monumentsAttribute 25 : Average ratings on gardens
Australian Sign Language signs,Australian Sign Language signs,This data consists of sample of Auslan (Australian Sign Language) signs. Examples of 95 signs were collected from five signers with a total of 6650 sign samples.,Australian+Sign+Language+signs,https://archive.ics.uci.edu/ml//machine-learning-databases/auslan-mld/,https://archive.ics.uci.edu/ml/datasets/Australian+Sign+Language+signs,"The source of the data is the raw measurements from a Nintendo PowerGlove. It was interfaced through a PowerGlove Serial Interface to a Silicon Graphics 4D/35G workstation. This glove definitely falls into the category of ""cheap and nasty"". Position information is calculated on the basis of ultrasound emissions from emitters the glove to a 3-microphone ""L-Bar"" that sits atop a monitor. There are two emitters on the glove; and three receivers. This allows the calculation of 4 pieces of information: x (left/right), y (up/down), z (backward/forward), and roll (is the palm pointing up or down?). x, y and z are measured with 8 bit accuracy. ""x, y, z"" should not be taken to be the normal 3-dimensional orthogonal basis. In particular, 1 unit in the z direction is not of similar distance to 1 unit in the x or y directions. These x, y, z positions are relative to a calibration point which is when the palm is resting on the seated signer's thigh. Roll is 4 bits. The data is susceptible to occasional ""spikes"" caused by random ultrasound noise. Median filters have been found to be beneficial in solving this problem. Finger bend is generated by conductive bend sensors on the first four fingers. Values vary between 0 (straight) and 3 (fully bent). Accuracy is 2 bits. The gloves automatically apply a hysteresis filter on these bend sensors. At best, these measurements should be treated sceptically. See past usage for a more detailed discussion on the data collection methodology. The data was collected from five signers:  Signer -- Description -- Sessions -- Total samples/sign Adam -- Sign linguist - PhD completed in area. -- 2 -- 8 Andrew -- Natural signer - signing since youth -- 3 -- 8 John -- Professional Auslan interpreter -- 5 -- 18 Stephen -- Professional Auslan interpreter -- 4  -- 16 Waleed -- The researcher. Novice signer -- 4 -- 20Each session was taken at a different time, after a break, etc. The ""adam"" dataset were sampled in a fixed order -- this means that they are subject to fatigue effects, etc. All other datasets were sampled in random order. The ""waleed"" and ""stephen"" datasets contain signs that begin with ""cal-"". These were considered as a means of calibration, but didn't work out too well. The data presented is the raw data with no filtering. Occasional dropouts in x, y, z values. These can be easily fixed using a median filter. Average number of frames per instance is 51, but varies from 30 to 102. The data is in a comma separated file containing all of the attributes mentioned above. Each sign sample is stored in a single file. The directory hierarchy is as follows: -Each signer is in a separate directory. -Each session from signer is in a subdirectory. Each session is denoted by a number. -Each sample is in a file named by the sample appended with the number of the sample of that sign. The filenames indicate the class. ",Unknown,"x:  - Continuous.   - Description: x position between -1 and 1. Units are *approximately* metres. y:   - Continuous.   - Description: y position between -1 and 1. Units are approximately metres. z:   - Continuous.   - Description: z position between -1 and 1. Units are not metres.      This space should not really be treated as linear, although it is safe to     treat it as monotonically increasing. roll:        - Continuous.  - Description:  roll with 0 meaning ""palm down"", rotating clcokwise through to a maximum of 1 (not included), which is also ""palm down"".pitch:    - Has a value of -1, indicating that it is not available for this data.    Should be ignored. yaw:    - Has a value of -1, indicating that it is not available for this data.     Should be ignored. thumb:    - Continuous.    - Description: Thumb bend. has a value of 0 (straight) to 1 (fully bent). fore:   - Continuous.    - Description: Forefinger bend. has a value of 0 (straight) to 1 (fully bent). index:   - Continuous.    - Description: Index finger bend. has a value of 0 (straight) to 1 (fully bent). ring:    - Continuous.    - Description: Ring finger bend. has a value of 0 (straight) to 1 (fully bent). little:         - In this case, it is a copy of ring bend. Should be ignored. keycode:    - Indicates which key was pressed on the glove. Should be ignored. gs1:         - glove state 1 Should be ignored. gs2:         - glove state 2 should be ignored. Receiver values:   - Determines if all receivers received values from all transmitters. A value of 0x3F indicates all receivers received information from all transmitters. Other values indicate this is not the case.","This data consists of sample of Auslan (Australian Sign Language) signs. Examples of 95 signs were collected from five signers with a total of 6650 sign samples.The source of the data is the raw measurements from a Nintendo PowerGlove. It was interfaced through a PowerGlove Serial Interface to a Silicon Graphics 4D/35G workstation. This glove definitely falls into the category of ""cheap and nasty"". Position information is calculated on the basis of ultrasound emissions from emitters the glove to a 3-microphone ""L-Bar"" that sits atop a monitor. There are two emitters on the glove; and three receivers. This allows the calculation of 4 pieces of information: x (left/right), y (up/down), z (backward/forward), and roll (is the palm pointing up or down?). x, y and z are measured with 8 bit accuracy. ""x, y, z"" should not be taken to be the normal 3-dimensional orthogonal basis. In particular, 1 unit in the z direction is not of similar distance to 1 unit in the x or y directions. These x, y, z positions are relative to a calibration point which is when the palm is resting on the seated signer's thigh. Roll is 4 bits. The data is susceptible to occasional ""spikes"" caused by random ultrasound noise. Median filters have been found to be beneficial in solving this problem. Finger bend is generated by conductive bend sensors on the first four fingers. Values vary between 0 (straight) and 3 (fully bent). Accuracy is 2 bits. The gloves automatically apply a hysteresis filter on these bend sensors. At best, these measurements should be treated sceptically. See past usage for a more detailed discussion on the data collection methodology. The data was collected from five signers:  Signer -- Description -- Sessions -- Total samples/sign Adam -- Sign linguist - PhD completed in area. -- 2 -- 8 Andrew -- Natural signer - signing since youth -- 3 -- 8 John -- Professional Auslan interpreter -- 5 -- 18 Stephen -- Professional Auslan interpreter -- 4  -- 16 Waleed -- The researcher. Novice signer -- 4 -- 20Each session was taken at a different time, after a break, etc. The ""adam"" dataset were sampled in a fixed order -- this means that they are subject to fatigue effects, etc. All other datasets were sampled in random order. The ""waleed"" and ""stephen"" datasets contain signs that begin with ""cal-"". These were considered as a means of calibration, but didn't work out too well. The data presented is the raw data with no filtering. Occasional dropouts in x, y, z values. These can be easily fixed using a median filter. Average number of frames per instance is 51, but varies from 30 to 102. The data is in a comma separated file containing all of the attributes mentioned above. Each sign sample is stored in a single file. The directory hierarchy is as follows: -Each signer is in a separate directory. -Each session from signer is in a subdirectory. Each session is denoted by a number. -Each sample is in a file named by the sample appended with the number of the sample of that sign. The filenames indicate the class. x:  - Continuous.   - Description: x position between -1 and 1. Units are *approximately* metres. y:   - Continuous.   - Description: y position between -1 and 1. Units are approximately metres. z:   - Continuous.   - Description: z position between -1 and 1. Units are not metres.      This space should not really be treated as linear, although it is safe to     treat it as monotonically increasing. roll:        - Continuous.  - Description:  roll with 0 meaning ""palm down"", rotating clcokwise through to a maximum of 1 (not included), which is also ""palm down"".pitch:    - Has a value of -1, indicating that it is not available for this data.    Should be ignored. yaw:    - Has a value of -1, indicating that it is not available for this data.     Should be ignored. thumb:    - Continuous.    - Description: Thumb bend. has a value of 0 (straight) to 1 (fully bent). fore:   - Continuous.    - Description: Forefinger bend. has a value of 0 (straight) to 1 (fully bent). index:   - Continuous.    - Description: Index finger bend. has a value of 0 (straight) to 1 (fully bent). ring:    - Continuous.    - Description: Ring finger bend. has a value of 0 (straight) to 1 (fully bent). little:         - In this case, it is a copy of ring bend. Should be ignored. keycode:    - Indicates which key was pressed on the glove. Should be ignored. gs1:         - glove state 1 Should be ignored. gs2:         - glove state 2 should be ignored. Receiver values:   - Determines if all receivers received values from all transmitters. A value of 0x3F indicates all receivers received information from all transmitters. Other values indicate this is not the case."
Australian Sign Language signs (High Quality),Australian Sign Language signs (High Quality),This data consists of sample of Auslan (Australian Sign Language) signs. 27 examples of each of 95 Auslan signs were captured from a native signer using high-quality position trackers,Australian+Sign+Language+signs+%28High+Quality%29,https://archive.ics.uci.edu/ml//machine-learning-databases/auslan2-mld/,https://archive.ics.uci.edu/ml/datasets/Australian+Sign+Language+signs+%28High+Quality%29,"Data was captured using a setup that consisted of: - Two Fifth Dimension Technologies (5DT) gloves, one right and one left - Two Ascension Flock-of-Birds magnetic position trackers, one attached to each hand - A four-port serial card to cope with four data sources - A PC (128MB RAM, Intel Pentium II 266MHz) was used In terms of the quality of the data, the Flock system was far superior to the Nintendo system also available from the same donor. Firstly, this was a two-hand system. Secondly, each position tracker provided 6 degrees of freedom - i.e. roll, pitch and yaw as well as x, y and z. The gloves also provided a full five fingers of data. But the big improvements were in resolution - both accuracy and temporal. Position and orientation were defined to 14-bit accuracy, giving position information with a typical positional error less than one centimetre and angle error less than one half of a degree. Finger bend was measured with 8 bits per finger, of which probably 6 bits were usable once the glove was calibrated. The refresh rate of the complete system was close to 100 frames per second; and all signals had significantly less noise than the Nintendo data. Samples from a single signer (a native Auslan signer) were collected over a period of nine weeks. In total, 27 samples per sign, and a total of 2565 signs were collected. The average length of each sign was approximately 57 frames. The data was collected from a volunteer native Auslan signer The data presented is the raw data with no filtering. The file consists of 9 subdirectories tctodd1-9. Each directory consists of 3 samples of each sign, captured on a different day. In total there are 95 different signs, with 27 samples per sign. Signs were provided by a native signer volunteer. Each file consists of a sequence of lines. Each line consists of 22 whitespace-separated numbers representing the 22 channels of information. The list of channels can be found in the domain description file. It also lists the classes. More information can be found here: [Web Link]. ",Unknown,"The following data were recorded for each hand:* x position expressed relative to a zero point set slightly below the chin. Expressed in meters.* y position expressed relative to a zero point set slightly below the chin. Expressed in meters.* z position expressed relative to a zero point set slightly below the chin. Expressed in meters.* roll expressed as a value between -0.5 and 0.5 with 0 being palm down. Positive means the palm is rolled clockwise from the perspective of the signer. To get degrees, multiply by 180.* pitch expressed as a value between -0.5 and 0.5 with 0 being palm flat (horizontal). Positive means the palm is pointing up. To get degrees, multiply by 180.* yaw expressed a value between -1.0 and 1.0 with 0 being palm straight ahead from the perspective of the signer. Positive means clockwise from the perspective above the signer. To get degrees, multiply by 180.* Thumb bend measure between 0 and 1. 0 means totally flat, 1 means totally bent. However, the finger bend measurements are not very exact.* Forefinger bend measure between 0 and 1. 0 means totally flat, 1 means totally bent. However, the finger bend measurements are not very exact.* Middle finger bend measure between 0 and 1. 0 means totally flat, 1 means totally bent. However, the finger bend measurements are not very exact.* Ring finger bend measure between 0 and 1. 0 means totally flat, 1 means totally bent. However, the finger bend measurements are not very exact.* Little finger bend measure between 0 and 1. 0 means totally flat, 1 means totally bent. However, the finger bend measurements are not very exact.","This data consists of sample of Auslan (Australian Sign Language) signs. 27 examples of each of 95 Auslan signs were captured from a native signer using high-quality position trackersData was captured using a setup that consisted of: - Two Fifth Dimension Technologies (5DT) gloves, one right and one left - Two Ascension Flock-of-Birds magnetic position trackers, one attached to each hand - A four-port serial card to cope with four data sources - A PC (128MB RAM, Intel Pentium II 266MHz) was used In terms of the quality of the data, the Flock system was far superior to the Nintendo system also available from the same donor. Firstly, this was a two-hand system. Secondly, each position tracker provided 6 degrees of freedom - i.e. roll, pitch and yaw as well as x, y and z. The gloves also provided a full five fingers of data. But the big improvements were in resolution - both accuracy and temporal. Position and orientation were defined to 14-bit accuracy, giving position information with a typical positional error less than one centimetre and angle error less than one half of a degree. Finger bend was measured with 8 bits per finger, of which probably 6 bits were usable once the glove was calibrated. The refresh rate of the complete system was close to 100 frames per second; and all signals had significantly less noise than the Nintendo data. Samples from a single signer (a native Auslan signer) were collected over a period of nine weeks. In total, 27 samples per sign, and a total of 2565 signs were collected. The average length of each sign was approximately 57 frames. The data was collected from a volunteer native Auslan signer The data presented is the raw data with no filtering. The file consists of 9 subdirectories tctodd1-9. Each directory consists of 3 samples of each sign, captured on a different day. In total there are 95 different signs, with 27 samples per sign. Signs were provided by a native signer volunteer. Each file consists of a sequence of lines. Each line consists of 22 whitespace-separated numbers representing the 22 channels of information. The list of channels can be found in the domain description file. It also lists the classes. More information can be found here: [Web Link]. The following data were recorded for each hand:* x position expressed relative to a zero point set slightly below the chin. Expressed in meters.* y position expressed relative to a zero point set slightly below the chin. Expressed in meters.* z position expressed relative to a zero point set slightly below the chin. Expressed in meters.* roll expressed as a value between -0.5 and 0.5 with 0 being palm down. Positive means the palm is rolled clockwise from the perspective of the signer. To get degrees, multiply by 180.* pitch expressed as a value between -0.5 and 0.5 with 0 being palm flat (horizontal). Positive means the palm is pointing up. To get degrees, multiply by 180.* yaw expressed a value between -1.0 and 1.0 with 0 being palm straight ahead from the perspective of the signer. Positive means clockwise from the perspective above the signer. To get degrees, multiply by 180.* Thumb bend measure between 0 and 1. 0 means totally flat, 1 means totally bent. However, the finger bend measurements are not very exact.* Forefinger bend measure between 0 and 1. 0 means totally flat, 1 means totally bent. However, the finger bend measurements are not very exact.* Middle finger bend measure between 0 and 1. 0 means totally flat, 1 means totally bent. However, the finger bend measurements are not very exact.* Ring finger bend measure between 0 and 1. 0 means totally flat, 1 means totally bent. However, the finger bend measurements are not very exact.* Little finger bend measure between 0 and 1. 0 means totally flat, 1 means totally bent. However, the finger bend measurements are not very exact."
Synthetic Control Chart Time Series,Synthetic Control Chart Time Series,This data consists of synthetically generated control charts.,Synthetic+Control+Chart+Time+Series,https://archive.ics.uci.edu/ml//machine-learning-databases/synthetic_control-mld/,https://archive.ics.uci.edu/ml/datasets/Synthetic+Control+Chart+Time+Series,"This dataset contains 600 examples of control charts synthetically generated by the process in Alcock and Manolopoulos (1999). There are six different classes of control charts:   1. Normal   2. Cyclic   3. Increasing trend   4. Decreasing trend   5. Upward shift   6. Downward shiftThe following image shows ten examples from each class: data.jpeg, where (A) Downward Trend. (B) Cyclic. (C) Normal. (D) Upward Shift. (E) Upward Trend. (F) Downward Shift.",Unknown,"The data is stored in an ASCII file, 600 rows, 60 columns, with a single chart per line. The classes are organized as follows:1-100   Normal101-200 Cyclic201-300 Increasing trend301-400 Decreasing trend401-500 Upward shift501-600 Downward shift","This data consists of synthetically generated control charts.This dataset contains 600 examples of control charts synthetically generated by the process in Alcock and Manolopoulos (1999). There are six different classes of control charts:   1. Normal   2. Cyclic   3. Increasing trend   4. Decreasing trend   5. Upward shift   6. Downward shiftThe following image shows ten examples from each class: data.jpeg, where (A) Downward Trend. (B) Cyclic. (C) Normal. (D) Upward Shift. (E) Upward Trend. (F) Downward Shift.The data is stored in an ASCII file, 600 rows, 60 columns, with a single chart per line. The classes are organized as follows:1-100   Normal101-200 Cyclic201-300 Increasing trend301-400 Decreasing trend401-500 Upward shift501-600 Downward shift"
Auto MPG,Auto MPG,"Revised from CMU StatLib library, data concerns city-cycle fuel consumption",Auto+MPG,https://archive.ics.uci.edu/ml//machine-learning-databases/auto-mpg/,https://archive.ics.uci.edu/ml/datasets/Auto+MPG,"This dataset is a slightly modified version of the dataset provided in the StatLib library.  In line with the use by Ross Quinlan (1993) in predicting the attribute ""mpg"", 8 of the original instances were removed because they had unknown values for the ""mpg"" attribute.  The original dataset is available in the file ""auto-mpg.data-original"".""The data concerns city-cycle fuel consumption in miles per gallon, to be predicted in terms of 3 multivalued discrete and 5 continuous attributes."" (Quinlan, 1993)",Unknown,    1. mpg:           continuous    2. cylinders:     multi-valued discrete    3. displacement:  continuous    4. horsepower:    continuous    5. weight:        continuous    6. acceleration:  continuous    7. model year:    multi-valued discrete    8. origin:        multi-valued discrete    9. car name:      string (unique for each instance),"Revised from CMU StatLib library, data concerns city-cycle fuel consumptionThis dataset is a slightly modified version of the dataset provided in the StatLib library.  In line with the use by Ross Quinlan (1993) in predicting the attribute ""mpg"", 8 of the original instances were removed because they had unknown values for the ""mpg"" attribute.  The original dataset is available in the file ""auto-mpg.data-original"".""The data concerns city-cycle fuel consumption in miles per gallon, to be predicted in terms of 3 multivalued discrete and 5 continuous attributes."" (Quinlan, 1993)    1. mpg:           continuous    2. cylinders:     multi-valued discrete    3. displacement:  continuous    4. horsepower:    continuous    5. weight:        continuous    6. acceleration:  continuous    7. model year:    multi-valued discrete    8. origin:        multi-valued discrete    9. car name:      string (unique for each instance)"
Automobile,Automobile,From 1985 Ward's Automotive Yearbook,Automobile,https://archive.ics.uci.edu/ml//machine-learning-databases/autos/,https://archive.ics.uci.edu/ml/datasets/Automobile,"This data set consists of three types of entities: (a) the specification of an auto in terms of various characteristics, (b) its assigned insurance risk rating, (c) its normalized losses in use as compared to other cars.  The second rating corresponds to the degree to which the auto is more risky than its price indicates. Cars are initially assigned a risk factor symbol associated with its price.   Then, if it is more risky (or less), this symbol is adjusted by moving it up (or down) the scale.  Actuarians call this process ""symboling"".  A value of +3 indicates that the auto is risky, -3 that it is probably pretty safe.The third factor is the relative average loss payment per insured vehicle year.  This value is normalized for all autos within a particular size classification (two-door small, station wagons, sports/speciality, etc...), and represents the average loss per car per year.Note: Several of the attributes in the database could be used as a ""class"" attribute.",Unknown,"Attribute: Attribute Range  1. symboling:                -3, -2, -1, 0, 1, 2, 3.  2. normalized-losses:        continuous from 65 to 256.  3. make:                                                    alfa-romero, audi, bmw, chevrolet, dodge, honda,                               isuzu, jaguar, mazda, mercedes-benz, mercury,                               mitsubishi, nissan, peugot, plymouth, porsche,                               renault, saab, subaru, toyota, volkswagen, volvo  4. fuel-type:                diesel, gas.  5. aspiration:               std, turbo.  6. num-of-doors:             four, two.  7. body-style:               hardtop, wagon, sedan, hatchback, convertible.  8. drive-wheels:             4wd, fwd, rwd.  9. engine-location:          front, rear. 10. wheel-base:               continuous from 86.6 120.9. 11. length:                   continuous from 141.1 to 208.1. 12. width:                    continuous from 60.3 to 72.3. 13. height:                   continuous from 47.8 to 59.8. 14. curb-weight:              continuous from 1488 to 4066. 15. engine-type:              dohc, dohcv, l, ohc, ohcf, ohcv, rotor. 16. num-of-cylinders:         eight, five, four, six, three, twelve, two. 17. engine-size:              continuous from 61 to 326. 18. fuel-system:              1bbl, 2bbl, 4bbl, idi, mfi, mpfi, spdi, spfi. 19. bore:                     continuous from 2.54 to 3.94. 20. stroke:                   continuous from 2.07 to 4.17. 21. compression-ratio:        continuous from 7 to 23. 22. horsepower:               continuous from 48 to 288. 23. peak-rpm:                 continuous from 4150 to 6600. 24. city-mpg:                 continuous from 13 to 49. 25. highway-mpg:              continuous from 16 to 54. 26. price:                    continuous from 5118 to 45400.","From 1985 Ward's Automotive YearbookThis data set consists of three types of entities: (a) the specification of an auto in terms of various characteristics, (b) its assigned insurance risk rating, (c) its normalized losses in use as compared to other cars.  The second rating corresponds to the degree to which the auto is more risky than its price indicates. Cars are initially assigned a risk factor symbol associated with its price.   Then, if it is more risky (or less), this symbol is adjusted by moving it up (or down) the scale.  Actuarians call this process ""symboling"".  A value of +3 indicates that the auto is risky, -3 that it is probably pretty safe.The third factor is the relative average loss payment per insured vehicle year.  This value is normalized for all autos within a particular size classification (two-door small, station wagons, sports/speciality, etc...), and represents the average loss per car per year.Note: Several of the attributes in the database could be used as a ""class"" attribute.Attribute: Attribute Range  1. symboling:                -3, -2, -1, 0, 1, 2, 3.  2. normalized-losses:        continuous from 65 to 256.  3. make:                                                    alfa-romero, audi, bmw, chevrolet, dodge, honda,                               isuzu, jaguar, mazda, mercedes-benz, mercury,                               mitsubishi, nissan, peugot, plymouth, porsche,                               renault, saab, subaru, toyota, volkswagen, volvo  4. fuel-type:                diesel, gas.  5. aspiration:               std, turbo.  6. num-of-doors:             four, two.  7. body-style:               hardtop, wagon, sedan, hatchback, convertible.  8. drive-wheels:             4wd, fwd, rwd.  9. engine-location:          front, rear. 10. wheel-base:               continuous from 86.6 120.9. 11. length:                   continuous from 141.1 to 208.1. 12. width:                    continuous from 60.3 to 72.3. 13. height:                   continuous from 47.8 to 59.8. 14. curb-weight:              continuous from 1488 to 4066. 15. engine-type:              dohc, dohcv, l, ohc, ohcf, ohcv, rotor. 16. num-of-cylinders:         eight, five, four, six, three, twelve, two. 17. engine-size:              continuous from 61 to 326. 18. fuel-system:              1bbl, 2bbl, 4bbl, idi, mfi, mpfi, spdi, spfi. 19. bore:                     continuous from 2.54 to 3.94. 20. stroke:                   continuous from 2.07 to 4.17. 21. compression-ratio:        continuous from 7 to 23. 22. horsepower:               continuous from 48 to 288. 23. peak-rpm:                 continuous from 4150 to 6600. 24. city-mpg:                 continuous from 13 to 49. 25. highway-mpg:              continuous from 16 to 54. 26. price:                    continuous from 5118 to 45400."
StoneFlakes,StoneFlakes,"Stone flakes are waste products of the stone tool production in
the prehistoric era. The variables are means of geometric and
stylistic features of the flakes contained in different inventories.",StoneFlakes,https://archive.ics.uci.edu/ml//machine-learning-databases/00299/,https://archive.ics.uci.edu/ml/datasets/StoneFlakes,"Background information: The data set concerns the earliest historyof mankind. Prehistoric men created the desired shape of a stone toolby striking on a raw stone, thus splitting off flakes, the wasteproducts of the crafting process. Archaelogists do not find many tools,but they do find flakes. The data set is about these flakes. Its rows donot stand for single flakes but for whole inventories of them. The givenfeatures are relative frequencies of binary, and mean values of numericalcharacteristics taken over all pieces found in the inventory. A questionrelated to the data set is: Does the data reflect the technologicalprogress during several hundred thousand years?Annotation:The columns below stand for the identifier of the inventory, a groupdefined by the archaeologists mainly by age and hominid type (1=LowerPaleolithic, Homo ergaster?, oldest; 2=Levallois technique; 3=MiddlePaleolithic, probably Neanderthals; 4=Homo sapiens, youngest), age ofthe stone artefacts (millennia, not to be taken too seriously), mode ofdating (geological=more accurate, typological), stone material (1=flint,2=other), region (mit=Central Germany, d=Non-Central Germany, eur=Europewithout Germany), site (1=gravel pit, 0=other), number of finds ininventory.ID  group age dating mat region site number-------------------------------------------ar    3  -120  geo    2   d      0    34arn   2  -200  typo   1   mit    1     5be    2  -200  typo   1   mit    1   331bi1   1  -300  geo    1   mit    0  4111bi2   1  -300  geo    2   mit    0    77bie   2  -200  geo    1   mit    1     8bn    2  -200  typo   1   mit    1    25bo    2  -200  geo    1   d      1   211by    2  -200  typo   1   mit    1     8c     3   -80  geo    1   mit    1    50   cl    1  -300  geo    1   eur    1   134d     2  -200  geo    1   mit    1   104   e1    3  -120  geo    1   mit    0   772e2    3  -120  geo    2   mit    0   215ey    2  -200  geo    1   mit    1   356fli   1    ?    ?     1   mit    ?   119   g10   3   -80  geo    1   d      0    38g11   3   -80  geo    1   d      0   122g2    3   -80  geo    1   d      0   614g4    3   -80  geo    1   d      0    60g5    3   -80  geo    1   d      0    57g6    3   -80  geo    1   d      0   104ga1   3   -80  geo    1   mit    0   418ga2   3   -80  geo    2   mit    0    44goe   3  -120  geo    1   mit    0    21   gra   3  -120  geo    1   mit    0     7   gro   1  -300  geo    1   mit    1    11gue   2  -200  typo   1   mit    1    95hey   2  -200  typo   1   mit    1    56hu    2  -200  geo    1   mit    1    71hx    2  -200  geo    1   eur    0   135ka    3   -80  geo    1   mit    0   270kb    3   -80  geo    1   mit    0   506kc    3   -80  geo    1   mit    0   190l     3  -120  geo    1   mit    0    20   li    3   -80  geo    1   mit    0   140lue   2  -200  geo    1   mit    1   651   m     2  -200  geo    1   mit    1  2717mar   1  -300  geo    1   mit    1    16ml    1  -300  typo   1   mit    1    62mr    2  -200  typo   1   mit    1   107ms    2  -200  typo   1   mit    1    17n     3  -120  geo    1   mit    0   256   nie   2  -200  typo   1   mit    1    55pb    3   -80  geo    1   mit    0   291r     3  -120  geo    1   mit    0   102r1    3   -80  typo   1   d      1   270r3    3   -80  typo   1   d      1   315reh   2  -200  geo    1   mit    1    36   roe   3   -80  geo    1   mit    1   104   s1    3   -80  geo    1   d      0   159s2    3   -80  geo    1   d      0   299s4    3   -80  geo    1   d      0   153s5    3   -80  geo    1   d      0   100sa1   4   -40  geo    1   eur    0    65   sa2   4   -40  geo    1   eur    0   370   sa3   4   -40  geo    1   eur    0   430   san   1    ?    ?     1   mit    ?   103   sk    2  -200  geo    2   d      0   126sm    3   -80  geo    1   d      0   180so    3   -80  geo    1   d      0   366sz    2  -200  typo   1   d      1   308t1    3  -120  geo    1   mit    0   395t2    3  -120  geo    2   mit    0    58ta    2  -130  geo    2   d      0    59tb    3   -80  geo    1   d      0    42v1    1  -400  geo    1   eur    0   120v2    1  -400  geo    2   eur    0   208va    2  -200  geo    1   mit    1     5w1    3  -120  geo    1   mit    0   537w2    3  -120  geo    2   mit    0    24wd    1  -300  geo    1   mit    1   727we    3   -80  geo    1   mit    0   338   wl    2  -200  typo   2   mit    1   315   wn    1  -300  geo    1   mit    1    39woe   1  -300  geo    1   mit    1    20wol   2  -200  geo    1   mit    1   218wst   2  -200  typo   2   mit    1    69z     2  -200  geo    1   mit    0   214",Unknown,"LBI: Length-breadth index of the striking platformRTI: Relative-thickness index of the striking platformWDI: Width-depth index of the striking platformFLA: Flaking angle (the angle between the striking platform and the splitting surface)PSF: platform primery (yes/no, relative frequency)FSF: Platform facetted (yes/no, relative frequency)ZDF1: Dorsal surface totally worked (yes/no, relative frequency)PROZD: Proportion of worked dorsal surface (continuous)LBI, RTI, WDI, FLA, and PROZD are averages, PSF, FSF, and ZDF1 arerelative frequencies","Stone flakes are waste products of the stone tool production in
the prehistoric era. The variables are means of geometric and
stylistic features of the flakes contained in different inventories.Background information: The data set concerns the earliest historyof mankind. Prehistoric men created the desired shape of a stone toolby striking on a raw stone, thus splitting off flakes, the wasteproducts of the crafting process. Archaelogists do not find many tools,but they do find flakes. The data set is about these flakes. Its rows donot stand for single flakes but for whole inventories of them. The givenfeatures are relative frequencies of binary, and mean values of numericalcharacteristics taken over all pieces found in the inventory. A questionrelated to the data set is: Does the data reflect the technologicalprogress during several hundred thousand years?Annotation:The columns below stand for the identifier of the inventory, a groupdefined by the archaeologists mainly by age and hominid type (1=LowerPaleolithic, Homo ergaster?, oldest; 2=Levallois technique; 3=MiddlePaleolithic, probably Neanderthals; 4=Homo sapiens, youngest), age ofthe stone artefacts (millennia, not to be taken too seriously), mode ofdating (geological=more accurate, typological), stone material (1=flint,2=other), region (mit=Central Germany, d=Non-Central Germany, eur=Europewithout Germany), site (1=gravel pit, 0=other), number of finds ininventory.ID  group age dating mat region site number-------------------------------------------ar    3  -120  geo    2   d      0    34arn   2  -200  typo   1   mit    1     5be    2  -200  typo   1   mit    1   331bi1   1  -300  geo    1   mit    0  4111bi2   1  -300  geo    2   mit    0    77bie   2  -200  geo    1   mit    1     8bn    2  -200  typo   1   mit    1    25bo    2  -200  geo    1   d      1   211by    2  -200  typo   1   mit    1     8c     3   -80  geo    1   mit    1    50   cl    1  -300  geo    1   eur    1   134d     2  -200  geo    1   mit    1   104   e1    3  -120  geo    1   mit    0   772e2    3  -120  geo    2   mit    0   215ey    2  -200  geo    1   mit    1   356fli   1    ?    ?     1   mit    ?   119   g10   3   -80  geo    1   d      0    38g11   3   -80  geo    1   d      0   122g2    3   -80  geo    1   d      0   614g4    3   -80  geo    1   d      0    60g5    3   -80  geo    1   d      0    57g6    3   -80  geo    1   d      0   104ga1   3   -80  geo    1   mit    0   418ga2   3   -80  geo    2   mit    0    44goe   3  -120  geo    1   mit    0    21   gra   3  -120  geo    1   mit    0     7   gro   1  -300  geo    1   mit    1    11gue   2  -200  typo   1   mit    1    95hey   2  -200  typo   1   mit    1    56hu    2  -200  geo    1   mit    1    71hx    2  -200  geo    1   eur    0   135ka    3   -80  geo    1   mit    0   270kb    3   -80  geo    1   mit    0   506kc    3   -80  geo    1   mit    0   190l     3  -120  geo    1   mit    0    20   li    3   -80  geo    1   mit    0   140lue   2  -200  geo    1   mit    1   651   m     2  -200  geo    1   mit    1  2717mar   1  -300  geo    1   mit    1    16ml    1  -300  typo   1   mit    1    62mr    2  -200  typo   1   mit    1   107ms    2  -200  typo   1   mit    1    17n     3  -120  geo    1   mit    0   256   nie   2  -200  typo   1   mit    1    55pb    3   -80  geo    1   mit    0   291r     3  -120  geo    1   mit    0   102r1    3   -80  typo   1   d      1   270r3    3   -80  typo   1   d      1   315reh   2  -200  geo    1   mit    1    36   roe   3   -80  geo    1   mit    1   104   s1    3   -80  geo    1   d      0   159s2    3   -80  geo    1   d      0   299s4    3   -80  geo    1   d      0   153s5    3   -80  geo    1   d      0   100sa1   4   -40  geo    1   eur    0    65   sa2   4   -40  geo    1   eur    0   370   sa3   4   -40  geo    1   eur    0   430   san   1    ?    ?     1   mit    ?   103   sk    2  -200  geo    2   d      0   126sm    3   -80  geo    1   d      0   180so    3   -80  geo    1   d      0   366sz    2  -200  typo   1   d      1   308t1    3  -120  geo    1   mit    0   395t2    3  -120  geo    2   mit    0    58ta    2  -130  geo    2   d      0    59tb    3   -80  geo    1   d      0    42v1    1  -400  geo    1   eur    0   120v2    1  -400  geo    2   eur    0   208va    2  -200  geo    1   mit    1     5w1    3  -120  geo    1   mit    0   537w2    3  -120  geo    2   mit    0    24wd    1  -300  geo    1   mit    1   727we    3   -80  geo    1   mit    0   338   wl    2  -200  typo   2   mit    1   315   wn    1  -300  geo    1   mit    1    39woe   1  -300  geo    1   mit    1    20wol   2  -200  geo    1   mit    1   218wst   2  -200  typo   2   mit    1    69z     2  -200  geo    1   mit    0   214LBI: Length-breadth index of the striking platformRTI: Relative-thickness index of the striking platformWDI: Width-depth index of the striking platformFLA: Flaking angle (the angle between the striking platform and the splitting surface)PSF: platform primery (yes/no, relative frequency)FSF: Platform facetted (yes/no, relative frequency)ZDF1: Dorsal surface totally worked (yes/no, relative frequency)PROZD: Proportion of worked dorsal surface (continuous)LBI, RTI, WDI, FLA, and PROZD are averages, PSF, FSF, and ZDF1 arerelative frequencies"
AutoUniv,AutoUniv,"AutoUniv is an advanced data generator for classifications tasks. The aim is to reflect the nuances and heterogeneity of real data.  Data can be generated in .csv, ARFF or C4.5 formats.",AutoUniv,https://archive.ics.uci.edu/ml//machine-learning-databases/00197/,https://archive.ics.uci.edu/ml/datasets/AutoUniv,"The user first creates a classification model and then generates classified examples from it.To create a model, the following are specified: the number of attributes (up to 1000) and their type (discrete or continuous), the number of classes (up to 10), the complexity of the underlying rules and the noise level. AutoUniv then produces a model through a process of constrained randomised search to satisfy the user's requirements. A model can have up to 3000 rules. Rare class models can be designed. A sequence of models can be designed to reflect concept and/or population drift. AutoUniv creates three text files for a model: a Prolog specification of the model used to generate examples (.aupl);  a user-friendly statement of the classification rules in an 'if ... then' format (.aurules);  a statistical summary of the main properties of the model, including its Bayes rate (.auprops).",Unknown,"Attributes may be discrete with up to 10 values or continuous. A discrete attribute can be nominal with values v1, v2, v3 ... or integer with values 0, 1, 2 , ... . ","AutoUniv is an advanced data generator for classifications tasks. The aim is to reflect the nuances and heterogeneity of real data.  Data can be generated in .csv, ARFF or C4.5 formats.The user first creates a classification model and then generates classified examples from it.To create a model, the following are specified: the number of attributes (up to 1000) and their type (discrete or continuous), the number of classes (up to 10), the complexity of the underlying rules and the noise level. AutoUniv then produces a model through a process of constrained randomised search to satisfy the user's requirements. A model can have up to 3000 rules. Rare class models can be designed. A sequence of models can be designed to reflect concept and/or population drift. AutoUniv creates three text files for a model: a Prolog specification of the model used to generate examples (.aupl);  a user-friendly statement of the classification rules in an 'if ... then' format (.aurules);  a statistical summary of the main properties of the model, including its Bayes rate (.auprops).Attributes may be discrete with up to 10 values or continuous. A discrete attribute can be nominal with values v1, v2, v3 ... or integer with values 0, 1, 2 , ... . "
Statlog Project,Statlog Project,"Various Databases: Vehicle silhouttes, Landsat Sattelite, Shuttle, Australian Credit Approval, Heart Disease, Image Segmentation, German Credit",Statlog+Project,https://archive.ics.uci.edu/ml//machine-learning-databases/statlog/,https://archive.ics.uci.edu/ml/datasets/Statlog+Project,"The databases available here were in used in the European StatLog project, which involves comparing the performances of machine learning, statistical, and neural network algorithms on data sets from real-world industrial areas including medicine, finance, image analysis, and engineering design.  Not all of the databases used in the project are available in this repository.Databases:(a) Vehicle Silhouettes:The original purpose was to find a method of distinguishing 3D objects within a 2D image by application of an ensemble of shape feature extractors to the 2D silhouettes of the objects.(b) Landsat Satellite:The database consists of the multi-spectral values of pixels in 3x3 neighbourhoods in a satellite image, and the classification associated with the central pixel in each neighbourhood. The aim is to predict this classification, given the multi-spectral values. In the sample database, the class of a pixel is coded as a number.(c) Shuttle:The shuttle dataset contains 9 attributes all of which are numerical. Approximately 80% of the data belongs to class 1.(d) Australian Credit Approval:This file concerns credit card applications.  All attribute names and values have been changed to meaningless symbols to protect confidentiality of the data.  This database exists elsewhere in the repository (Credit Screening Database) in a slightly different form.(e) Heart Disease:This dataset is a heart disease database similar to a database already present in the repository (Heart Disease databases) but in a slightly different form.  This database contains 13  attributes (which have been extracted from a larger set of 75).(f) Image Segmentation:This dataset is an image segmentation database similar to a database already present in the repository (Image segmentation database) but in a slightly different form.  The instances were drawn randomly from a database of 7 outdoor images.  The images were handsegmented to create a classification for every pixel.  Each instance is a 3x3 region.(g) German Credit:       This dataset classifies people described by a set of attributes as good or bad credit risks.  Comes in two formats (one all numeric). Also comes with a cost matrix.",Unknown,,"Various Databases: Vehicle silhouttes, Landsat Sattelite, Shuttle, Australian Credit Approval, Heart Disease, Image Segmentation, German CreditThe databases available here were in used in the European StatLog project, which involves comparing the performances of machine learning, statistical, and neural network algorithms on data sets from real-world industrial areas including medicine, finance, image analysis, and engineering design.  Not all of the databases used in the project are available in this repository.Databases:(a) Vehicle Silhouettes:The original purpose was to find a method of distinguishing 3D objects within a 2D image by application of an ensemble of shape feature extractors to the 2D silhouettes of the objects.(b) Landsat Satellite:The database consists of the multi-spectral values of pixels in 3x3 neighbourhoods in a satellite image, and the classification associated with the central pixel in each neighbourhood. The aim is to predict this classification, given the multi-spectral values. In the sample database, the class of a pixel is coded as a number.(c) Shuttle:The shuttle dataset contains 9 attributes all of which are numerical. Approximately 80% of the data belongs to class 1.(d) Australian Credit Approval:This file concerns credit card applications.  All attribute names and values have been changed to meaningless symbols to protect confidentiality of the data.  This database exists elsewhere in the repository (Credit Screening Database) in a slightly different form.(e) Heart Disease:This dataset is a heart disease database similar to a database already present in the repository (Heart Disease databases) but in a slightly different form.  This database contains 13  attributes (which have been extracted from a larger set of 75).(f) Image Segmentation:This dataset is an image segmentation database similar to a database already present in the repository (Image segmentation database) but in a slightly different form.  The instances were drawn randomly from a database of 7 outdoor images.  The images were handsegmented to create a classification for every pixel.  Each instance is a 3x3 region.(g) German Credit:       This dataset classifies people described by a set of attributes as good or bad credit risks.  Comes in two formats (one all numeric). Also comes with a cost matrix.nan"
Statlog (Vehicle Silhouettes),Statlog (Vehicle Silhouettes),3D objects within a 2D image by application of an ensemble of shape feature extractors to the 2D silhouettes of the objects.,Statlog+%28Vehicle+Silhouettes%29,https://archive.ics.uci.edu/ml//machine-learning-databases/statlog/vehicle/,https://archive.ics.uci.edu/ml/datasets/Statlog+%28Vehicle+Silhouettes%29,"The purpose is to classify a given silhouette as one of four types of vehicle, using  a set of features extracted from the silhouette. The vehicle may be viewed from one of many different angles.  HISTORY:This data was originally gathered at the TI in 1986-87 by JP Siebert. It was partially financed by Barr and Stroud Ltd. The original purpose was to find a method of distinguishing 3D objects within a 2D image by application of an ensemble of shape feature extractors to the 2D silhouettes of the objects. Measures of shape features extracted from example silhouettes of objects to be discriminated were used to generate a classification rule tree by means of computer induction.This object recognition strategy was successfully used to discriminate between silhouettes of model cars, vans and buses viewed from constrained elevation but all angles of rotation.The rule tree classification performance compared favourably to MDC (Minimum Distance Classifier) and k-NN (k-Nearest Neighbour) statistical classifiers in terms of both error rate and computational efficiency. An investigation of these rule trees generated by example indicated that the tree structure was heavily influenced by the orientation of the objects, and grouped similar object views into single decisions.DESCRIPTION:The features were extracted from the silhouettes by the HIPS (Hierarchical Image Processing System) extension BINATTS, which extracts a combination of scale independent features utilising both classical moments based measures such as scaled variance, skewness and kurtosis about the major/minor axes and heuristic measures such as hollows, circularity, rectangularity and compactness.Four ""Corgie"" model vehicles were used for the experiment: a double decker bus, Cheverolet van, Saab 9000 and an Opel Manta 400. This particular combination of vehicles was chosen with the expectation that the bus, van and either one of the cars would be readily distinguishable, but it would be more difficult to distinguish between the cars.The images were acquired by a camera looking downwards at the model vehicle from a fixed angle of elevation (34.2 degrees to the horizontal). The vehicles were placed on a diffuse backlit surface (lightbox). The vehicles were painted matte black to minimise highlights. The images were captured using a CRS4000 framestore connected to a vax 750. All images were captured with a spatial resolution of 128x128 pixels quantised to 64 greylevels. These images were thresholded to produce binary vehicle silhouettes, negated (to comply with the processing requirements of BINATTS) and thereafter subjected to shrink-expand-expand-shrink HIPS modules to remove ""salt and pepper"" image noise.The vehicles were rotated and their angle of orientation was measured using a radial graticule beneath the vehicle. 0 and 180 degrees corresponded to ""head on"" and ""rear"" views respectively while 90 and 270 corresponded to profiles in opposite directions. Two sets of 60 images, each set covering a full 360 degree rotation, were captured for each vehicle. The vehicle was rotated by a fixed angle between images. These datasets are known as e2 and e3 respectively. A further two sets of images, e4 and e5, were captured with the camera at elevations of 37.5 degs and 30.8 degs respectively. These sets also contain 60 images per vehicle apart from e4.van which contains only 46 owing to the difficulty of containing the van in the image at some orientations.",Unknown,"ATTRIBUTES		COMPACTNESS	(average perim)**2/area		CIRCULARITY	(average radius)**2/area		DISTANCE CIRCULARITY	area/(av.distance from border)**2		RADIUS RATIO	(max.rad-min.rad)/av.radius		PR.AXIS ASPECT RATIO	(minor axis)/(major axis)		MAX.LENGTH ASPECT RATIO	(length perp. max length)/(max length)		SCATTER RATIO	(inertia about minor axis)/(inertia about major axis)		ELONGATEDNESS		area/(shrink width)**2		PR.AXIS RECTANGULARITY	area/(pr.axis length*pr.axis width)		MAX.LENGTH RECTANGULARITY area/(max.length*length perp. to this)		SCALED VARIANCE 	(2nd order moment about minor axis)/area	ALONG MAJOR AXIS		SCALED VARIANCE 	(2nd order moment about major axis)/area	ALONG MINOR AXIS 		SCALED RADIUS OF GYRATION	(mavar+mivar)/area		SKEWNESS ABOUT 	(3rd order moment about major axis)/sigma_min**3	MAJOR AXIS		SKEWNESS ABOUT 	(3rd order moment about minor axis)/sigma_maj**3	MINOR AXIS	  		KURTOSIS ABOUT 	(4th order moment about major axis)/sigma_min**4	MINOR AXIS  	  		KURTOSIS ABOUT 	(4th order moment about minor axis)/sigma_maj**4	MAJOR AXIS		HOLLOWS RATIO	(area of hollows)/(area of bounding polygon)		 Where sigma_maj**2 is the variance along the major axis and sigma_min**2 is the variance along the minor axis, and		area of hollows= area of bounding poly-area of object 		 The area of the bounding polygon is found as a side result of the computation to find the maximum length. Each individual length computation yields a pair of calipers to the object orientated at every 5 degrees. The object is propagated into an image containing the union of these calipers to obtain an image of the bounding polygon. 	NUMBER OF CLASSES	4	OPEL, SAAB, BUS, VAN","3D objects within a 2D image by application of an ensemble of shape feature extractors to the 2D silhouettes of the objects.The purpose is to classify a given silhouette as one of four types of vehicle, using  a set of features extracted from the silhouette. The vehicle may be viewed from one of many different angles.  HISTORY:This data was originally gathered at the TI in 1986-87 by JP Siebert. It was partially financed by Barr and Stroud Ltd. The original purpose was to find a method of distinguishing 3D objects within a 2D image by application of an ensemble of shape feature extractors to the 2D silhouettes of the objects. Measures of shape features extracted from example silhouettes of objects to be discriminated were used to generate a classification rule tree by means of computer induction.This object recognition strategy was successfully used to discriminate between silhouettes of model cars, vans and buses viewed from constrained elevation but all angles of rotation.The rule tree classification performance compared favourably to MDC (Minimum Distance Classifier) and k-NN (k-Nearest Neighbour) statistical classifiers in terms of both error rate and computational efficiency. An investigation of these rule trees generated by example indicated that the tree structure was heavily influenced by the orientation of the objects, and grouped similar object views into single decisions.DESCRIPTION:The features were extracted from the silhouettes by the HIPS (Hierarchical Image Processing System) extension BINATTS, which extracts a combination of scale independent features utilising both classical moments based measures such as scaled variance, skewness and kurtosis about the major/minor axes and heuristic measures such as hollows, circularity, rectangularity and compactness.Four ""Corgie"" model vehicles were used for the experiment: a double decker bus, Cheverolet van, Saab 9000 and an Opel Manta 400. This particular combination of vehicles was chosen with the expectation that the bus, van and either one of the cars would be readily distinguishable, but it would be more difficult to distinguish between the cars.The images were acquired by a camera looking downwards at the model vehicle from a fixed angle of elevation (34.2 degrees to the horizontal). The vehicles were placed on a diffuse backlit surface (lightbox). The vehicles were painted matte black to minimise highlights. The images were captured using a CRS4000 framestore connected to a vax 750. All images were captured with a spatial resolution of 128x128 pixels quantised to 64 greylevels. These images were thresholded to produce binary vehicle silhouettes, negated (to comply with the processing requirements of BINATTS) and thereafter subjected to shrink-expand-expand-shrink HIPS modules to remove ""salt and pepper"" image noise.The vehicles were rotated and their angle of orientation was measured using a radial graticule beneath the vehicle. 0 and 180 degrees corresponded to ""head on"" and ""rear"" views respectively while 90 and 270 corresponded to profiles in opposite directions. Two sets of 60 images, each set covering a full 360 degree rotation, were captured for each vehicle. The vehicle was rotated by a fixed angle between images. These datasets are known as e2 and e3 respectively. A further two sets of images, e4 and e5, were captured with the camera at elevations of 37.5 degs and 30.8 degs respectively. These sets also contain 60 images per vehicle apart from e4.van which contains only 46 owing to the difficulty of containing the van in the image at some orientations.ATTRIBUTES		COMPACTNESS	(average perim)**2/area		CIRCULARITY	(average radius)**2/area		DISTANCE CIRCULARITY	area/(av.distance from border)**2		RADIUS RATIO	(max.rad-min.rad)/av.radius		PR.AXIS ASPECT RATIO	(minor axis)/(major axis)		MAX.LENGTH ASPECT RATIO	(length perp. max length)/(max length)		SCATTER RATIO	(inertia about minor axis)/(inertia about major axis)		ELONGATEDNESS		area/(shrink width)**2		PR.AXIS RECTANGULARITY	area/(pr.axis length*pr.axis width)		MAX.LENGTH RECTANGULARITY area/(max.length*length perp. to this)		SCALED VARIANCE 	(2nd order moment about minor axis)/area	ALONG MAJOR AXIS		SCALED VARIANCE 	(2nd order moment about major axis)/area	ALONG MINOR AXIS 		SCALED RADIUS OF GYRATION	(mavar+mivar)/area		SKEWNESS ABOUT 	(3rd order moment about major axis)/sigma_min**3	MAJOR AXIS		SKEWNESS ABOUT 	(3rd order moment about minor axis)/sigma_maj**3	MINOR AXIS	  		KURTOSIS ABOUT 	(4th order moment about major axis)/sigma_min**4	MINOR AXIS  	  		KURTOSIS ABOUT 	(4th order moment about minor axis)/sigma_maj**4	MAJOR AXIS		HOLLOWS RATIO	(area of hollows)/(area of bounding polygon)		 Where sigma_maj**2 is the variance along the major axis and sigma_min**2 is the variance along the minor axis, and		area of hollows= area of bounding poly-area of object 		 The area of the bounding polygon is found as a side result of the computation to find the maximum length. Each individual length computation yields a pair of calipers to the object orientated at every 5 degrees. The object is propagated into an image containing the union of these calipers to obtain an image of the bounding polygon. 	NUMBER OF CLASSES	4	OPEL, SAAB, BUS, VAN"
Statlog (Image Segmentation),Statlog (Image Segmentation),This dataset is an image segmentation database similar to a database already present in the repository (Image segmentation database) but in a slightly different form.,Statlog+%28Image+Segmentation%29,https://archive.ics.uci.edu/ml//machine-learning-databases/statlog/segment/,https://archive.ics.uci.edu/ml/datasets/Statlog+%28Image+Segmentation%29,The instances were drawn randomly from a database of 7 outdoor images.  The images were handsegmented to create a classification for every pixel.  Each instance is a 3x3 region.,Unknown,"1.  region-centroid-col:  the column of the center pixel of the region.2.  region-centroid-row:  the row of the center pixel of the region.3.  region-pixel-count:  the number of pixels in a region = 9.4.  short-line-density-5:  the results of a line extractoin algorithm that counts how many lines of length 5 (any orientation) with low contrast, less than or equal to 5, go through the region.5.  short-line-density-2:  same as short-line-density-5 but counts lines of high contrast, greater than 5.6.  vedge-mean:  measure the contrast of horizontally adjacent pixels in the region.  There are 6, the mean and standard deviation are given.  This attribute is used as a vertical edge detector.7.  vegde-sd:  (see 6)8.  hedge-mean:  measures the contrast of vertically adjacent pixels. Used for horizontal line detection. 9.  hedge-sd: (see 8).10. intensity-mean:  the average over the region of (R + G + B)/311. rawred-mean: the average over the region of the R value.12. rawblue-mean: the average over the region of the B value.13. rawgreen-mean: the average over the region of the G value.14. exred-mean: measure the excess red:  (2R - (G + B))15. exblue-mean: measure the excess blue:  (2B - (G + R))16. exgreen-mean: measure the excess green:  (2G - (R + B))17. value-mean:  3-d nonlinear transformation of RGB. (Algorithm can be found in Foley and VanDam, Fundamentals of Interactive Computer Graphics)18. saturatoin-mean:  (see 17)19. hue-mean:  (see 17)Classes: 1 = brickface, 2 = sky, 3 = foliage, 4 = cement, 5 = window, 6 = path, 7 = grass.","This dataset is an image segmentation database similar to a database already present in the repository (Image segmentation database) but in a slightly different form.The instances were drawn randomly from a database of 7 outdoor images.  The images were handsegmented to create a classification for every pixel.  Each instance is a 3x3 region.1.  region-centroid-col:  the column of the center pixel of the region.2.  region-centroid-row:  the row of the center pixel of the region.3.  region-pixel-count:  the number of pixels in a region = 9.4.  short-line-density-5:  the results of a line extractoin algorithm that counts how many lines of length 5 (any orientation) with low contrast, less than or equal to 5, go through the region.5.  short-line-density-2:  same as short-line-density-5 but counts lines of high contrast, greater than 5.6.  vedge-mean:  measure the contrast of horizontally adjacent pixels in the region.  There are 6, the mean and standard deviation are given.  This attribute is used as a vertical edge detector.7.  vegde-sd:  (see 6)8.  hedge-mean:  measures the contrast of vertically adjacent pixels. Used for horizontal line detection. 9.  hedge-sd: (see 8).10. intensity-mean:  the average over the region of (R + G + B)/311. rawred-mean: the average over the region of the R value.12. rawblue-mean: the average over the region of the B value.13. rawgreen-mean: the average over the region of the G value.14. exred-mean: measure the excess red:  (2R - (G + B))15. exblue-mean: measure the excess blue:  (2B - (G + R))16. exgreen-mean: measure the excess green:  (2G - (R + B))17. value-mean:  3-d nonlinear transformation of RGB. (Algorithm can be found in Foley and VanDam, Fundamentals of Interactive Computer Graphics)18. saturatoin-mean:  (see 17)19. hue-mean:  (see 17)Classes: 1 = brickface, 2 = sky, 3 = foliage, 4 = cement, 5 = window, 6 = path, 7 = grass."
Bach Choral Harmony,Bach Choral Harmony,"The data set is composed of 60 chorales (5665 events) by J.S. Bach (1675-1750).
Each event of each chorale is labelled using 1 among 101 chord labels and described
through 14 features.",Bach+Choral+Harmony,https://archive.ics.uci.edu/ml//machine-learning-databases/00298/,https://archive.ics.uci.edu/ml/datasets/Bach+Choral+Harmony,Pitch classes information has been extracted from MIDI sources downloadedfrom (JSB Chorales)[[Web Link]]. Meter information hasbeen computed through the Meter program which is part of the Melismamusic analyser (Melisma)[[Web Link]].Chord labels have been manually annotated by a human expert.,Unknown,"1. Choral ID: corresponding to the file names from (Bach Central)[[Web Link]].2. Event number: index (starting from 1) of the event inside the chorale.3-14. Pitch classes: YES/NO depending on whether a given pitch is present.   Pitch classes/attribute correspondence is as follows:     C       -> 3     C#/Db   -> 4     D       -> 5     ...     B       -> 1415. Bass: Pitch class of the bass note16. Meter: integers from 1 to 5. Lower numbers denote less accented events,   higher numbers denote more accented events.17. Chord label: Chord resonating during the given event.","The data set is composed of 60 chorales (5665 events) by J.S. Bach (1675-1750).
Each event of each chorale is labelled using 1 among 101 chord labels and described
through 14 features.Pitch classes information has been extracted from MIDI sources downloadedfrom (JSB Chorales)[[Web Link]]. Meter information hasbeen computed through the Meter program which is part of the Melismamusic analyser (Melisma)[[Web Link]].Chord labels have been manually annotated by a human expert.1. Choral ID: corresponding to the file names from (Bach Central)[[Web Link]].2. Event number: index (starting from 1) of the event inside the chorale.3-14. Pitch classes: YES/NO depending on whether a given pitch is present.   Pitch classes/attribute correspondence is as follows:     C       -> 3     C#/Db   -> 4     D       -> 5     ...     B       -> 1415. Bass: Pitch class of the bass note16. Meter: integers from 1 to 5. Lower numbers denote less accented events,   higher numbers denote more accented events.17. Chord label: Chord resonating during the given event."
Bach Chorales,Bach Chorales,Time-series data based on chorales; challenge is to learn generative grammar; data in Lisp,Bach+Chorales,https://archive.ics.uci.edu/ml//machine-learning-databases/chorales,https://archive.ics.uci.edu/ml/datasets/Bach+Chorales,"Sequential (time-series) domain.  Single-line melodies of 100 Bach chorales (originally 4 voices).  The melody line can be studied independently of other voices.  The grand challenge is to learn a generative grammar for stylistically valid chorales (see references and discussion in ""Multiple Viewpoint Systems for Music Prediction"").",Unknown,"Number of Attributes: 6 (nominal) per event(a) start-time, measured in 16th notes from chorale beginning (time 0)(b) pitch, MIDI number (60 = C4, 61 = C#4, 72 = C5, etc.)(c) duration, measured in 16th notes(d) key signature, number of sharps or flats, positive if key signature has sharps, negative if key signature has flats(e) time signature, in 16th notes per bar(f) fermata, true or false depending on whether event is under a fermataAttribute domains (all integers): (a) {0,1,2,...}(b) {60,...,75}(c) {1,...,16}(d) {-4,...,+4}(e) {12,16}(f) {0,1}","Time-series data based on chorales; challenge is to learn generative grammar; data in LispSequential (time-series) domain.  Single-line melodies of 100 Bach chorales (originally 4 voices).  The melody line can be studied independently of other voices.  The grand challenge is to learn a generative grammar for stylistically valid chorales (see references and discussion in ""Multiple Viewpoint Systems for Music Prediction"").Number of Attributes: 6 (nominal) per event(a) start-time, measured in 16th notes from chorale beginning (time 0)(b) pitch, MIDI number (60 = C4, 61 = C#4, 72 = C5, etc.)(c) duration, measured in 16th notes(d) key signature, number of sharps or flats, positive if key signature has sharps, negative if key signature has flats(e) time signature, in 16th notes per bar(f) fermata, true or false depending on whether event is under a fermataAttribute domains (all integers): (a) {0,1,2,...}(b) {60,...,75}(c) {1,...,16}(d) {-4,...,+4}(e) {12,16}(f) {0,1}"
Hill-Valley,Hill-Valley,"Each record represents 100 points on a two-dimensional graph. When plotted in order (from 1 through 100) as the Y co-ordinate, the points will create either a Hill (a “bump” in the terrain) or a Valley (a “dip” in the terrain).",Hill-Valley,https://archive.ics.uci.edu/ml//machine-learning-databases/hill-valley/,https://archive.ics.uci.edu/ml/datasets/Hill-Valley,"Each record represents 100 points on a two-dimensional graph. When plotted in order (from 1 through 100) as the Y co-ordinate, the points will create either a Hill (a â€œbumpâ€� in the terrain) or a Valley (a â€œdipâ€� in the terrain).There are six files, as follows:(a) Hill_Valley_without_noise_Training.data(b) Hill_Valley_without_noise_Testing.dataThese first two datasets (without noise) are a training/testing set pair where the hills or valleys have a smooth transition.(c) Hill_Valley_with_noise_Training.data(d) Hill_Valley_with_noise_Testing.dataThese next two datasets (with noise) are a training/testing set pair where the terrain is uneven, and the hill or valley is not as obvious when viewed closely. (e) Hill_Valley_sample_arff.textThe sample ARFF file is useful for setting up experiments, but is not necessary.(f) Hill_Valley_visual_examples.jpgThis graphic file shows two example instances from the data.",Unknown,"1-100: Labeled â€œX##â€�. Floating point values (numeric)101: Labeled â€œclassâ€�. Binary {0, 1} representing {valley, hill}","Each record represents 100 points on a two-dimensional graph. When plotted in order (from 1 through 100) as the Y co-ordinate, the points will create either a Hill (a “bump” in the terrain) or a Valley (a “dip” in the terrain).Each record represents 100 points on a two-dimensional graph. When plotted in order (from 1 through 100) as the Y co-ordinate, the points will create either a Hill (a â€œbumpâ€� in the terrain) or a Valley (a â€œdipâ€� in the terrain).There are six files, as follows:(a) Hill_Valley_without_noise_Training.data(b) Hill_Valley_without_noise_Testing.dataThese first two datasets (without noise) are a training/testing set pair where the hills or valleys have a smooth transition.(c) Hill_Valley_with_noise_Training.data(d) Hill_Valley_with_noise_Testing.dataThese next two datasets (with noise) are a training/testing set pair where the terrain is uneven, and the hill or valley is not as obvious when viewed closely. (e) Hill_Valley_sample_arff.textThe sample ARFF file is useful for setting up experiments, but is not necessary.(f) Hill_Valley_visual_examples.jpgThis graphic file shows two example instances from the data.1-100: Labeled â€œX##â€�. Floating point values (numeric)101: Labeled â€œclassâ€�. Binary {0, 1} representing {valley, hill}"
Spoken Arabic Digit,Spoken Arabic Digit,This dataset contains timeseries of mel-frequency cepstrum coefficients (MFCCs) corresponding to spoken Arabic digits.  Includes data from 44 male and 44 female native Arabic speakers.,Spoken+Arabic+Digit,https://archive.ics.uci.edu/ml//machine-learning-databases/00195/,https://archive.ics.uci.edu/ml/datasets/Spoken+Arabic+Digit,Dataset from 8800(10 digits x 10 repetitions x 88 speakers) time series of 13 Frequency CepstralCoefficients (MFCCs) had taken from 44 males and 44 females Arabic native speakersbetween the ages 18 and 40 to represent ten spoken Arabic digit.,Unknown,"Each line on the data base represents 13 MFCCs coefficients in the increasing order separated byspaces. This corresponds to one analysis frame. The 13 Mel Frequency Cepstral Coefficients(MFCCs) are computed with the followingconditions;Sampling rate: 11025 Hz, 16 bitsWindow applied: hammingFilter pre-emphasized: 1-0.97Z^(-1)","This dataset contains timeseries of mel-frequency cepstrum coefficients (MFCCs) corresponding to spoken Arabic digits.  Includes data from 44 male and 44 female native Arabic speakers.Dataset from 8800(10 digits x 10 repetitions x 88 speakers) time series of 13 Frequency CepstralCoefficients (MFCCs) had taken from 44 males and 44 females Arabic native speakersbetween the ages 18 and 40 to represent ten spoken Arabic digit.Each line on the data base represents 13 MFCCs coefficients in the increasing order separated byspaces. This corresponds to one analysis frame. The 13 Mel Frequency Cepstral Coefficients(MFCCs) are computed with the followingconditions;Sampling rate: 11025 Hz, 16 bitsWindow applied: hammingFilter pre-emphasized: 1-0.97Z^(-1)"
Badges,Badges,"Badges labeled with a ""+"" or ""-"" as a function of a person's name",Badges,https://archive.ics.uci.edu/ml//machine-learning-databases/badges/,https://archive.ics.uci.edu/ml/datasets/Badges,"Part of the problem in using an automated program to discover the unknown target function is to decide how to encode names such that the program can be used.  The data below are presented in the form of a +/- label followed by the person's name.  It is up to the learning-system user to decide how to convert this data into something usable by the system (e.g., what attributes to use if your favorite learner requires feature-vector data).",Unknown,,"Badges labeled with a ""+"" or ""-"" as a function of a person's namePart of the problem in using an automated program to discover the unknown target function is to decide how to encode names such that the program can be used.  The data below are presented in the form of a +/- label followed by the person's name.  It is up to the learning-system user to decide how to convert this data into something usable by the system (e.g., what attributes to use if your favorite learner requires feature-vector data).nan"
Bag of Words,Bag of Words,This data set contains five text collections in the form of bags-of-words.,Bag+of+Words,https://archive.ics.uci.edu/ml//machine-learning-databases/bag-of-words/,https://archive.ics.uci.edu/ml/datasets/Bag+of+Words,"For each text collection, D is the number of documents, W is thenumber of words in the vocabulary, and N is the total number of wordsin the collection (below, NNZ is the number of nonzero counts in thebag-of-words).  After tokenization and removal of stopwords, thevocabulary of unique words was truncated by only keeping words thatoccurred more than ten times.  Individual document names (i.e. aidentifier for each docID) are not provided for copyright reasons.These data sets have no class labels, and for copyright reasons nofilenames or other document-level metadata.  These data sets are idealfor clustering and topic modeling experiments.For each text collection we provide docword.*.txt (the bag of wordsfile in sparse format) and vocab.*.txt (the vocab file).Enron Emails:orig source: www.cs.cmu.edu/~enronD=39861W=28102N=6,400,000 (approx)NIPS full papers:orig source: books.nips.ccD=1500W=12419N=1,900,000 (approx)KOS blog entries:orig source: dailykos.comD=3430W=6906N=467714NYTimes news articles:orig source: ldc.upenn.eduD=300000W=102660N=100,000,000 (approx)PubMed abstracts:orig source: www.pubmed.govD=8200000W=141043N=730,000,000 (approx)",Unknown,"The format of the docword.*.txt file is 3 header lines, followed byNNZ triples:---DWNNZdocID wordID countdocID wordID countdocID wordID countdocID wordID count...docID wordID countdocID wordID countdocID wordID count---The format of the vocab.*.txt file is line  contains wordID=n.","This data set contains five text collections in the form of bags-of-words.For each text collection, D is the number of documents, W is thenumber of words in the vocabulary, and N is the total number of wordsin the collection (below, NNZ is the number of nonzero counts in thebag-of-words).  After tokenization and removal of stopwords, thevocabulary of unique words was truncated by only keeping words thatoccurred more than ten times.  Individual document names (i.e. aidentifier for each docID) are not provided for copyright reasons.These data sets have no class labels, and for copyright reasons nofilenames or other document-level metadata.  These data sets are idealfor clustering and topic modeling experiments.For each text collection we provide docword.*.txt (the bag of wordsfile in sparse format) and vocab.*.txt (the vocab file).Enron Emails:orig source: www.cs.cmu.edu/~enronD=39861W=28102N=6,400,000 (approx)NIPS full papers:orig source: books.nips.ccD=1500W=12419N=1,900,000 (approx)KOS blog entries:orig source: dailykos.comD=3430W=6906N=467714NYTimes news articles:orig source: ldc.upenn.eduD=300000W=102660N=100,000,000 (approx)PubMed abstracts:orig source: www.pubmed.govD=8200000W=141043N=730,000,000 (approx)The format of the docword.*.txt file is 3 header lines, followed byNNZ triples:---DWNNZdocID wordID countdocID wordID countdocID wordID countdocID wordID count...docID wordID countdocID wordID countdocID wordID count---The format of the vocab.*.txt file is line  contains wordID=n."
Human Activity Recognition from Continuous Ambient Sensor Data,Human Activity Recognition from Continuous Ambient Sensor Data,This dataset represents ambient data collected in homes with volunteer residents.  Data are collected continuously while residents perform their normal routines.,Human+Activity+Recognition+from+Continuous+Ambient+Sensor+Data,https://archive.ics.uci.edu/ml//machine-learning-databases/00506/,https://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+from+Continuous+Ambient+Sensor+Data,"4. Relevant Information    -- Data Set Characteristics: Multivariate, Sequential, Time-Series    -- This dataset represents ambient data collected in homes with volunteer residents.       Data are collected continuously while residents perform their normal routines.       Ambient PIR motion sensors, door/temperature sensors, and light switch sensors       are placed throughout the home of the volunteer.  The sensors are placed in locations       throughout the home that are related to specific activites of daily living that we       wish to capture.    -- The classification task is to predict the activity that is occurring in the smart       home and being observed by the ambient sensors.  The sensors communicate using the       ZigBee Pro protocol, forming a mesh network with all battery powered sensors as leaf       nodes and always-on devices (light switches and ZigBee relays) forming the branches       that connect back to the USB gateway on our local SHiB [2] server.    -- The original format captured from the sensors is provided, as well as the feature       vector we generate using a sliding window of 30 sensor events.  Each annotated data       file (ex: csh101/csh101.ann.txt) has a corresponding feature vector CSV file       (ex: csh101/csh101.ann.features.csv).  Most of the sensor data files contain labels       for two months of the collection period, though some contain labels for extended       time periods.    -- We have also included the entire dataset collected at each smart home in the original       format (ex: csh101/csh101.rawdata.txt) and the generated feature vector CSV file       (ex: csh101/csh101.rawdata.features.csv).    -- An analysis of the attributes for each features CSV file is found in the corresponding       readme (ex: csh101/csh101.ann.features.csv is described by       csh101/csh101.ann.features.README.txt).    -- The smart home layout, and sensor placement from the original formats is found       in the included sensor map for each smart home (ex: csh101/csh101.sensor_map.png).    -- The original format is:                      --  is YYYY-MM-DD, in local time.        --  is HH:[Web Link], 24-hour and in local time.        --  is the name of the sensor, this can be found on the sensor map.        --  is the room-level sensor location.        --  is more detailed, usually identifying what in the room the sensor           is aimed at or sensing.        --  is the message generated by the sensor (we define these in more detail           below).        --  is the type of sensor generating the event, so you know what to           expect for a message.  In these earlier smart homes many of the sensors could           be identified by their name, but in later configurations you had to use this           field to identify what sensor was sending the message.        -- Motion Sensor Package           Each motion sensor package contains a PIR motion detector and a resistive photocell           light sensor. The package also reports it's battery level and regularly checks           in with the sensor network (ZigBee Check-Ins).            -- Control4-Motion and Control4-MotionArea               Most motion sensors have a sticker in the lens that limits what it can see               to approximately a 3-foot diameter circle when mounted on the ceiling facing               down. Some motion sensors that do not have any sticker limiting their view               are called Control4-MotionArea and can detect motion within view, though               sensitivity to smaller body movements may be reduced beyond 20 feet.                -- Message Values                   Motion and MotionArea sensors always report ON or OFF.                -- Frequency                   The sensor will instantly send an ON message when detecting motion.                   1.25 seconds after it no longer observes motion the sensor will send OFF.            -- Control4-LightSensor                -- Message Values                   The light sensor will send integer values ranging from 0 to 100 (pitch                   black to very bright). The Motion sensors with stickers in the lens have                   a much more limited amount of light that hits the sensor, and may only                   observe a range from 0 to 10, with a rare spike to a much higher value                   when the lid is removed to replace a battery.                -- Frequency                   The current light level is bit-packed and sent with every message the                   package sends on ZigBee, but the light sensor itself can initiate a ZigBee                   message if the value changes by 15% from the last value it reported.            -- Control4-BatteryPercent                -- Message Values                   The battery percent is always an integer ranging from 0 to 100.                -- Frequency                   The battery levels are only allowed to report once every 6 hours, but                   only report when there is a change.  This means that some battery values                   may not be updated for days as the level has not changed.            -- Control4-Radio               These sensor messages were enabled when we upgraded our data collection systems               around 2014.                -- Message Values                   The ZigBee radio check-in always has the same message, OK.                -- Frequency                   The ZigBee radio checks in with the network about once every 30 minutes.                   A sudden lack of radio check-ins may indicate this sensor's battery has                   died or there is some interference disrupting communication on the ZigBee                   network.        -- Door Sensor Package            -- Control4-Door                -- Message Values                   The door sensor always report OPEN or CLOSE.                -- Frequency                   The sensor sends the message as soon as the magnetic reed switch changes.            -- Control4-Temperature               All door sensor packages have an internal temporature sensor, and the ability               to attach a second temperature probe.  This was used in some of the bathrooms               for measuring the temperature at the door and right next to the shower.                -- Message Values                   Messages are a decimal in Celsius with 0.5 degrees Celsius accuracy.                -- Frequency                   Messages are sent when the sensor detects a change in the measured                   temperature by 0.5 Celsius.            -- Control4-BatteryPercent                -- Message Values                   The battery percent is always an integer ranging from 0 to 100.                -- Frequency                   The battery levels are only allowed to report once every 6 hours, but                   only report when there is a change.  This means that some battery values                   may not be updated for days as the level has not changed.            -- Control4-Radio                -- Message Values                   The ZigBee radio check-in always has the same message, OK.                -- Frequency                   The ZigBee radio checks in with the network about once every 30 minutes.                   A sudden lack of radio check-ins may indicate this sensor's battery has                   died or there is some interference disrupting communication on the ZigBee                   network.        -- Light Switch Package            -- Control4-Light                -- Message Values                   Light switch messages are integer values ranging from 0 to 100.  Some of                   the lights are dimmers, they report the change in value from 0 to 100 as                   they ramp up their brightness.  The switches simply report 0 or 100 when                   they turn off or on.                -- Frequency                   The light switches only report light messages when the value changes.            -- Control4-Button               With the data collection upgrade in 2014 we were able to start collecting               sensor events from residents interacting with the light switches.                -- Message Values                   The buttons have a variety of messages they send.  TAP is sent every time                   the button is pressed.  When the button is doing being tapped, the button                   will send TAP_COUNT_01 if the button was tapped once (we have observed                   tap counts as high as 12, but do not know the limit of the device).                   On the dimmer light switches there are also the DEPRESS and RELEASE messages                   that are sent then the button is held down to slowly dim the light up                   or down.                -- Frequency                   Messages are only sent with a participant interacts with the button.            -- Control4-Radio                -- Message Values                   The ZigBee radio check-in always has the same message, OK.                -- Frequency                   The ZigBee radio checks in with the network about once every 15 minutes.                   A sudden lack of radio check-ins may indicate this sensor's battery has                   died or there is some interference disrupting communication on the ZigBee                   network.",Unknown,"This has a full breakdown for each file in the zip.7. For Each Attribute:--------------------------------------------------------------------------------    lastSensorEventHours    (integer)  Hour of the day, in local time.--------------------------------------------------------------------------------    lastSensorEventSeconds    (decimal)  Seconds since midnight, in local time.--------------------------------------------------------------------------------    lastSensorDayOfWeek    (symbolic-valued integer)  Integer day of the week, in local time.--------------------------------------------------------------------------------    windowDuration    (decimal)  Time duration of the 30 event sliding window in seconds.--------------------------------------------------------------------------------    timeSinceLastSensorEvent    (decimal)  Seconds since the last sensor event.--------------------------------------------------------------------------------    prevDominantSensor1    (symbolic-valued integer)  Dominant sensor ID from the previous window.--------------------------------------------------------------------------------    prevDominantSensor2    (symbolic-valued integer)  Dominant sensor ID from the second previous window.--------------------------------------------------------------------------------    lastSensorID    (symbolic-valued integer)  Last sensor ID in the window.--------------------------------------------------------------------------------    lastSensorLocation    (symbolic-valued integer)  Last sensor location ID in the window.--------------------------------------------------------------------------------    lastMotionLocation    (symbolic-valued integer)  Last motion sensor location ID in the window, can be -1 if none within the sliding window.--------------------------------------------------------------------------------    complexity    (decimal)  Complexity or measure of entropy in sensor counts.--------------------------------------------------------------------------------    activityChange    (decimal)  Change in activity levels between 2 halves of the sliding window, bisected temporally.--------------------------------------------------------------------------------    areaTransitions    (integer)  Number of transitions between major sensor locations in the window.--------------------------------------------------------------------------------    numDistinctSensors    (integer)  Number of distinct sensors in the window, this is currently set to always 0.--------------------------------------------------------------------------------    sensorCount-Bathroom    (decimal)  The weighted count of this sensor, starting at 1.0 for the most recent event each sensor event previous is worth n-0.01 the current event.--------------------------------------------------------------------------------    sensorCount-Bedroom    (decimal)  The weighted count of this sensor, starting at 1.0 for the most recent event each sensor event previous is worth n-0.01 the current event.--------------------------------------------------------------------------------    sensorCount-Chair    (decimal)  The weighted count of this sensor, starting at 1.0 for the most recent event each sensor event previous is worth n-0.01 the current event.--------------------------------------------------------------------------------    sensorCount-DiningRoom    (decimal)  The weighted count of this sensor, starting at 1.0 for the most recent event each sensor event previous is worth n-0.01 the current event.--------------------------------------------------------------------------------    sensorCount-Hall    (decimal)  The weighted count of this sensor, starting at 1.0 for the most recent event each sensor event previous is worth n-0.01 the current event.--------------------------------------------------------------------------------    sensorCount-Ignore    (decimal)  The weighted count of this sensor, starting at 1.0 for the most recent event each sensor event previous is worth n-0.01 the current event.--------------------------------------------------------------------------------    sensorCount-Kitchen    (decimal)  The weighted count of this sensor, starting at 1.0 for the most recent event each sensor event previous is worth n-0.01 the current event.--------------------------------------------------------------------------------    sensorCount-LivingRoom    (decimal)  The weighted count of this sensor, starting at 1.0 for the most recent event each sensor event previous is worth n-0.01 the current event.--------------------------------------------------------------------------------    sensorCount-Office    (decimal)  The weighted count of this sensor, starting at 1.0 for the most recent event each sensor event previous is worth n-0.01 the current event.--------------------------------------------------------------------------------    sensorCount-OutsideDoor    (decimal)  The weighted count of this sensor, starting at 1.0 for the most recent event each sensor event previous is worth n-0.01 the current event.--------------------------------------------------------------------------------    sensorCount-WorkArea    (decimal)  The weighted count of this sensor, starting at 1.0 for the most recent event each sensor event previous is worth n-0.01 the current event.--------------------------------------------------------------------------------    sensorElTime-Bathroom    (decimal)  The number of seconds since this sensor was last seen, up to a maximum of 86400.--------------------------------------------------------------------------------    sensorElTime-Bedroom    (decimal)  The number of seconds since this sensor was last seen, up to a maximum of 86400.--------------------------------------------------------------------------------    sensorElTime-Chair    (decimal)  The number of seconds since this sensor was last seen, up to a maximum of 86400.--------------------------------------------------------------------------------    sensorElTime-DiningRoom    (decimal)  The number of seconds since this sensor was last seen, up to a maximum of 86400.--------------------------------------------------------------------------------    sensorElTime-Hall    (decimal)  The number of seconds since this sensor was last seen, up to a maximum of 86400.--------------------------------------------------------------------------------    sensorElTime-Ignore    (decimal)  The number of seconds since this sensor was last seen, up to a maximum of 86400.--------------------------------------------------------------------------------    sensorElTime-Kitchen    (decimal)  The number of seconds since this sensor was last seen, up to a maximum of 86400.--------------------------------------------------------------------------------    sensorElTime-LivingRoom    (decimal)  The number of seconds since this sensor was last seen, up to a maximum of 86400.--------------------------------------------------------------------------------    sensorElTime-Office    (decimal)  The number of seconds since this sensor was last seen, up to a maximum of 86400.--------------------------------------------------------------------------------    sensorElTime-OutsideDoor    (decimal)  The number of seconds since this sensor was last seen, up to a maximum of 86400.--------------------------------------------------------------------------------    sensorElTime-WorkArea    (decimal)  The number of seconds since this sensor was last seen, up to a maximum of 86400.--------------------------------------------------------------------------------    activity    (class label)  The annotated activity that is currently being observed.","This dataset represents ambient data collected in homes with volunteer residents.  Data are collected continuously while residents perform their normal routines.4. Relevant Information    -- Data Set Characteristics: Multivariate, Sequential, Time-Series    -- This dataset represents ambient data collected in homes with volunteer residents.       Data are collected continuously while residents perform their normal routines.       Ambient PIR motion sensors, door/temperature sensors, and light switch sensors       are placed throughout the home of the volunteer.  The sensors are placed in locations       throughout the home that are related to specific activites of daily living that we       wish to capture.    -- The classification task is to predict the activity that is occurring in the smart       home and being observed by the ambient sensors.  The sensors communicate using the       ZigBee Pro protocol, forming a mesh network with all battery powered sensors as leaf       nodes and always-on devices (light switches and ZigBee relays) forming the branches       that connect back to the USB gateway on our local SHiB [2] server.    -- The original format captured from the sensors is provided, as well as the feature       vector we generate using a sliding window of 30 sensor events.  Each annotated data       file (ex: csh101/csh101.ann.txt) has a corresponding feature vector CSV file       (ex: csh101/csh101.ann.features.csv).  Most of the sensor data files contain labels       for two months of the collection period, though some contain labels for extended       time periods.    -- We have also included the entire dataset collected at each smart home in the original       format (ex: csh101/csh101.rawdata.txt) and the generated feature vector CSV file       (ex: csh101/csh101.rawdata.features.csv).    -- An analysis of the attributes for each features CSV file is found in the corresponding       readme (ex: csh101/csh101.ann.features.csv is described by       csh101/csh101.ann.features.README.txt).    -- The smart home layout, and sensor placement from the original formats is found       in the included sensor map for each smart home (ex: csh101/csh101.sensor_map.png).    -- The original format is:                      --  is YYYY-MM-DD, in local time.        --  is HH:[Web Link], 24-hour and in local time.        --  is the name of the sensor, this can be found on the sensor map.        --  is the room-level sensor location.        --  is more detailed, usually identifying what in the room the sensor           is aimed at or sensing.        --  is the message generated by the sensor (we define these in more detail           below).        --  is the type of sensor generating the event, so you know what to           expect for a message.  In these earlier smart homes many of the sensors could           be identified by their name, but in later configurations you had to use this           field to identify what sensor was sending the message.        -- Motion Sensor Package           Each motion sensor package contains a PIR motion detector and a resistive photocell           light sensor. The package also reports it's battery level and regularly checks           in with the sensor network (ZigBee Check-Ins).            -- Control4-Motion and Control4-MotionArea               Most motion sensors have a sticker in the lens that limits what it can see               to approximately a 3-foot diameter circle when mounted on the ceiling facing               down. Some motion sensors that do not have any sticker limiting their view               are called Control4-MotionArea and can detect motion within view, though               sensitivity to smaller body movements may be reduced beyond 20 feet.                -- Message Values                   Motion and MotionArea sensors always report ON or OFF.                -- Frequency                   The sensor will instantly send an ON message when detecting motion.                   1.25 seconds after it no longer observes motion the sensor will send OFF.            -- Control4-LightSensor                -- Message Values                   The light sensor will send integer values ranging from 0 to 100 (pitch                   black to very bright). The Motion sensors with stickers in the lens have                   a much more limited amount of light that hits the sensor, and may only                   observe a range from 0 to 10, with a rare spike to a much higher value                   when the lid is removed to replace a battery.                -- Frequency                   The current light level is bit-packed and sent with every message the                   package sends on ZigBee, but the light sensor itself can initiate a ZigBee                   message if the value changes by 15% from the last value it reported.            -- Control4-BatteryPercent                -- Message Values                   The battery percent is always an integer ranging from 0 to 100.                -- Frequency                   The battery levels are only allowed to report once every 6 hours, but                   only report when there is a change.  This means that some battery values                   may not be updated for days as the level has not changed.            -- Control4-Radio               These sensor messages were enabled when we upgraded our data collection systems               around 2014.                -- Message Values                   The ZigBee radio check-in always has the same message, OK.                -- Frequency                   The ZigBee radio checks in with the network about once every 30 minutes.                   A sudden lack of radio check-ins may indicate this sensor's battery has                   died or there is some interference disrupting communication on the ZigBee                   network.        -- Door Sensor Package            -- Control4-Door                -- Message Values                   The door sensor always report OPEN or CLOSE.                -- Frequency                   The sensor sends the message as soon as the magnetic reed switch changes.            -- Control4-Temperature               All door sensor packages have an internal temporature sensor, and the ability               to attach a second temperature probe.  This was used in some of the bathrooms               for measuring the temperature at the door and right next to the shower.                -- Message Values                   Messages are a decimal in Celsius with 0.5 degrees Celsius accuracy.                -- Frequency                   Messages are sent when the sensor detects a change in the measured                   temperature by 0.5 Celsius.            -- Control4-BatteryPercent                -- Message Values                   The battery percent is always an integer ranging from 0 to 100.                -- Frequency                   The battery levels are only allowed to report once every 6 hours, but                   only report when there is a change.  This means that some battery values                   may not be updated for days as the level has not changed.            -- Control4-Radio                -- Message Values                   The ZigBee radio check-in always has the same message, OK.                -- Frequency                   The ZigBee radio checks in with the network about once every 30 minutes.                   A sudden lack of radio check-ins may indicate this sensor's battery has                   died or there is some interference disrupting communication on the ZigBee                   network.        -- Light Switch Package            -- Control4-Light                -- Message Values                   Light switch messages are integer values ranging from 0 to 100.  Some of                   the lights are dimmers, they report the change in value from 0 to 100 as                   they ramp up their brightness.  The switches simply report 0 or 100 when                   they turn off or on.                -- Frequency                   The light switches only report light messages when the value changes.            -- Control4-Button               With the data collection upgrade in 2014 we were able to start collecting               sensor events from residents interacting with the light switches.                -- Message Values                   The buttons have a variety of messages they send.  TAP is sent every time                   the button is pressed.  When the button is doing being tapped, the button                   will send TAP_COUNT_01 if the button was tapped once (we have observed                   tap counts as high as 12, but do not know the limit of the device).                   On the dimmer light switches there are also the DEPRESS and RELEASE messages                   that are sent then the button is held down to slowly dim the light up                   or down.                -- Frequency                   Messages are only sent with a participant interacts with the button.            -- Control4-Radio                -- Message Values                   The ZigBee radio check-in always has the same message, OK.                -- Frequency                   The ZigBee radio checks in with the network about once every 15 minutes.                   A sudden lack of radio check-ins may indicate this sensor's battery has                   died or there is some interference disrupting communication on the ZigBee                   network.This has a full breakdown for each file in the zip.7. For Each Attribute:--------------------------------------------------------------------------------    lastSensorEventHours    (integer)  Hour of the day, in local time.--------------------------------------------------------------------------------    lastSensorEventSeconds    (decimal)  Seconds since midnight, in local time.--------------------------------------------------------------------------------    lastSensorDayOfWeek    (symbolic-valued integer)  Integer day of the week, in local time.--------------------------------------------------------------------------------    windowDuration    (decimal)  Time duration of the 30 event sliding window in seconds.--------------------------------------------------------------------------------    timeSinceLastSensorEvent    (decimal)  Seconds since the last sensor event.--------------------------------------------------------------------------------    prevDominantSensor1    (symbolic-valued integer)  Dominant sensor ID from the previous window.--------------------------------------------------------------------------------    prevDominantSensor2    (symbolic-valued integer)  Dominant sensor ID from the second previous window.--------------------------------------------------------------------------------    lastSensorID    (symbolic-valued integer)  Last sensor ID in the window.--------------------------------------------------------------------------------    lastSensorLocation    (symbolic-valued integer)  Last sensor location ID in the window.--------------------------------------------------------------------------------    lastMotionLocation    (symbolic-valued integer)  Last motion sensor location ID in the window, can be -1 if none within the sliding window.--------------------------------------------------------------------------------    complexity    (decimal)  Complexity or measure of entropy in sensor counts.--------------------------------------------------------------------------------    activityChange    (decimal)  Change in activity levels between 2 halves of the sliding window, bisected temporally.--------------------------------------------------------------------------------    areaTransitions    (integer)  Number of transitions between major sensor locations in the window.--------------------------------------------------------------------------------    numDistinctSensors    (integer)  Number of distinct sensors in the window, this is currently set to always 0.--------------------------------------------------------------------------------    sensorCount-Bathroom    (decimal)  The weighted count of this sensor, starting at 1.0 for the most recent event each sensor event previous is worth n-0.01 the current event.--------------------------------------------------------------------------------    sensorCount-Bedroom    (decimal)  The weighted count of this sensor, starting at 1.0 for the most recent event each sensor event previous is worth n-0.01 the current event.--------------------------------------------------------------------------------    sensorCount-Chair    (decimal)  The weighted count of this sensor, starting at 1.0 for the most recent event each sensor event previous is worth n-0.01 the current event.--------------------------------------------------------------------------------    sensorCount-DiningRoom    (decimal)  The weighted count of this sensor, starting at 1.0 for the most recent event each sensor event previous is worth n-0.01 the current event.--------------------------------------------------------------------------------    sensorCount-Hall    (decimal)  The weighted count of this sensor, starting at 1.0 for the most recent event each sensor event previous is worth n-0.01 the current event.--------------------------------------------------------------------------------    sensorCount-Ignore    (decimal)  The weighted count of this sensor, starting at 1.0 for the most recent event each sensor event previous is worth n-0.01 the current event.--------------------------------------------------------------------------------    sensorCount-Kitchen    (decimal)  The weighted count of this sensor, starting at 1.0 for the most recent event each sensor event previous is worth n-0.01 the current event.--------------------------------------------------------------------------------    sensorCount-LivingRoom    (decimal)  The weighted count of this sensor, starting at 1.0 for the most recent event each sensor event previous is worth n-0.01 the current event.--------------------------------------------------------------------------------    sensorCount-Office    (decimal)  The weighted count of this sensor, starting at 1.0 for the most recent event each sensor event previous is worth n-0.01 the current event.--------------------------------------------------------------------------------    sensorCount-OutsideDoor    (decimal)  The weighted count of this sensor, starting at 1.0 for the most recent event each sensor event previous is worth n-0.01 the current event.--------------------------------------------------------------------------------    sensorCount-WorkArea    (decimal)  The weighted count of this sensor, starting at 1.0 for the most recent event each sensor event previous is worth n-0.01 the current event.--------------------------------------------------------------------------------    sensorElTime-Bathroom    (decimal)  The number of seconds since this sensor was last seen, up to a maximum of 86400.--------------------------------------------------------------------------------    sensorElTime-Bedroom    (decimal)  The number of seconds since this sensor was last seen, up to a maximum of 86400.--------------------------------------------------------------------------------    sensorElTime-Chair    (decimal)  The number of seconds since this sensor was last seen, up to a maximum of 86400.--------------------------------------------------------------------------------    sensorElTime-DiningRoom    (decimal)  The number of seconds since this sensor was last seen, up to a maximum of 86400.--------------------------------------------------------------------------------    sensorElTime-Hall    (decimal)  The number of seconds since this sensor was last seen, up to a maximum of 86400.--------------------------------------------------------------------------------    sensorElTime-Ignore    (decimal)  The number of seconds since this sensor was last seen, up to a maximum of 86400.--------------------------------------------------------------------------------    sensorElTime-Kitchen    (decimal)  The number of seconds since this sensor was last seen, up to a maximum of 86400.--------------------------------------------------------------------------------    sensorElTime-LivingRoom    (decimal)  The number of seconds since this sensor was last seen, up to a maximum of 86400.--------------------------------------------------------------------------------    sensorElTime-Office    (decimal)  The number of seconds since this sensor was last seen, up to a maximum of 86400.--------------------------------------------------------------------------------    sensorElTime-OutsideDoor    (decimal)  The number of seconds since this sensor was last seen, up to a maximum of 86400.--------------------------------------------------------------------------------    sensorElTime-WorkArea    (decimal)  The number of seconds since this sensor was last seen, up to a maximum of 86400.--------------------------------------------------------------------------------    activity    (class label)  The annotated activity that is currently being observed."
ICMLA 2014 Accepted Papers Data Set,ICMLA 2014 Accepted Papers Data Set,"This data set compromises the metadata for the 2014 ICMLA conference's accepted papers, including ID, paper titles, author's keywords, abstracts and sessions in which they were exposed.",ICMLA+2014+Accepted+Papers+Data+Set,https://archive.ics.uci.edu/ml//machine-learning-databases/00434/,https://archive.ics.uci.edu/ml/datasets/ICMLA+2014+Accepted+Papers+Data+Set,CSV format where each row is a paper and each column an attribute.,Unknown,"Paper_Id: Number; identifier of the paperPaper_Title: Free text; title of the paper Author_Keywords: Free text; author-generated keywords Abstract: Free text; paper abstractsSession: Categorical; conference organizer's-selected, conference session in which the paper was presented","This data set compromises the metadata for the 2014 ICMLA conference's accepted papers, including ID, paper titles, author's keywords, abstracts and sessions in which they were exposed.CSV format where each row is a paper and each column an attribute.Paper_Id: Number; identifier of the paperPaper_Title: Free text; title of the paper Author_Keywords: Free text; author-generated keywords Abstract: Free text; paper abstractsSession: Categorical; conference organizer's-selected, conference session in which the paper was presented"
Image Segmentation,Image Segmentation,"Image data described by high-level numeric-valued attributes, 7 classes",Image+Segmentation,https://archive.ics.uci.edu/ml//machine-learning-databases/image/,https://archive.ics.uci.edu/ml/datasets/Image+Segmentation,The instances were drawn randomly from a database of 7 outdoor images.  The images were handsegmented to create a classification for every pixel.     Each instance is a 3x3 region.,Unknown,"    1.  region-centroid-col:  the column of the center pixel of the region.    2.  region-centroid-row:  the row of the center pixel of the region.    3.  region-pixel-count:  the number of pixels in a region = 9.    4.  short-line-density-5:  the results of a line extractoin algorithm that counts how many lines of length 5 (any orientation) with low contrast, less than or equal to 5, go through the region.    5.  short-line-density-2:  same as short-line-density-5 but counts lines of high contrast, greater than 5.    6.  vedge-mean:  measure the contrast of horizontally adjacent pixels in the region.  There are 6, the mean and standard deviation are given.  This attribute is used as a vertical edge detector.    7.  vegde-sd:  (see 6)    8.  hedge-mean:  measures the contrast of vertically adjacent pixels. Used for horizontal line detection.     9.  hedge-sd: (see 8).    10. intensity-mean:  the average over the region of (R + G + B)/3    11. rawred-mean: the average over the region of the R value.    12. rawblue-mean: the average over the region of the B value.    13. rawgreen-mean: the average over the region of the G value.    14. exred-mean: measure the excess red:  (2R - (G + B))    15. exblue-mean: measure the excess blue:  (2B - (G + R))    16. exgreen-mean: measure the excess green:  (2G - (R + B))    17. value-mean:  3-d nonlinear transformation of RGB. (Algorithm can be found in Foley and VanDam, Fundamentals of Interactive Computer Graphics)    18. saturatoin-mean:  (see 17)    19. hue-mean:  (see 17)","Image data described by high-level numeric-valued attributes, 7 classesThe instances were drawn randomly from a database of 7 outdoor images.  The images were handsegmented to create a classification for every pixel.     Each instance is a 3x3 region.    1.  region-centroid-col:  the column of the center pixel of the region.    2.  region-centroid-row:  the row of the center pixel of the region.    3.  region-pixel-count:  the number of pixels in a region = 9.    4.  short-line-density-5:  the results of a line extractoin algorithm that counts how many lines of length 5 (any orientation) with low contrast, less than or equal to 5, go through the region.    5.  short-line-density-2:  same as short-line-density-5 but counts lines of high contrast, greater than 5.    6.  vedge-mean:  measure the contrast of horizontally adjacent pixels in the region.  There are 6, the mean and standard deviation are given.  This attribute is used as a vertical edge detector.    7.  vegde-sd:  (see 6)    8.  hedge-mean:  measures the contrast of vertically adjacent pixels. Used for horizontal line detection.     9.  hedge-sd: (see 8).    10. intensity-mean:  the average over the region of (R + G + B)/3    11. rawred-mean: the average over the region of the R value.    12. rawblue-mean: the average over the region of the B value.    13. rawgreen-mean: the average over the region of the G value.    14. exred-mean: measure the excess red:  (2R - (G + B))    15. exblue-mean: measure the excess blue:  (2B - (G + R))    16. exgreen-mean: measure the excess green:  (2G - (R + B))    17. value-mean:  3-d nonlinear transformation of RGB. (Algorithm can be found in Foley and VanDam, Fundamentals of Interactive Computer Graphics)    18. saturatoin-mean:  (see 17)    19. hue-mean:  (see 17)"
Drug Review Dataset (Druglib.com),Drug Review Dataset (Druglib.com),"The dataset provides patient reviews on specific drugs along with related conditions. Reviews and ratings are grouped into reports on the three aspects benefits, side effects and overall comment.",Drug+Review+Dataset+%28Druglib.com%29,https://archive.ics.uci.edu/ml//machine-learning-databases/00461/,https://archive.ics.uci.edu/ml/datasets/Drug+Review+Dataset+%28Druglib.com%29,"The dataset provides patient reviews on specific drugs along with related conditions. Furthermore, reviews are grouped into reports on the three aspects benefits, side effects and overall comment. Additionally, ratings are available concerning overall satisfaction as well as a 5 step side effect rating and a 5 step effectiveness rating. The data was obtained by crawling online pharmaceutical review sites. The intention was to study (1) sentiment analysis of drug experience over multiple facets, i.e. sentiments learned on specific aspects such as effectiveness and side effects,(2) the transferability of models among domains, i.e. conditions, and (3) the transferability of models among different data sources (see 'Drug Review Dataset (Drugs.com)').The data is split into a train (75%) a test (25%) partition (see publication) and stored in two .tsv (tab-separated-values) files, respectively.Important notes:When using this dataset, you agree that you1) only use the data for research purposes2) don't use the data for any commerical purposes3) don't distribute the data to anyone else4) cite us",Unknown,1. urlDrugName (categorical): name of drug2. condition (categorical): name of condition3. benefitsReview (text): patient on benefits4. sideEffectsReview (text): patient on side effects5. commentsReview (text): overall patient comment6. rating (numerical): 10 star patient rating7. sideEffects (categorical): 5 step side effect rating8. effectiveness (categorical): 5 step effectiveness rating,"The dataset provides patient reviews on specific drugs along with related conditions. Reviews and ratings are grouped into reports on the three aspects benefits, side effects and overall comment.The dataset provides patient reviews on specific drugs along with related conditions. Furthermore, reviews are grouped into reports on the three aspects benefits, side effects and overall comment. Additionally, ratings are available concerning overall satisfaction as well as a 5 step side effect rating and a 5 step effectiveness rating. The data was obtained by crawling online pharmaceutical review sites. The intention was to study (1) sentiment analysis of drug experience over multiple facets, i.e. sentiments learned on specific aspects such as effectiveness and side effects,(2) the transferability of models among domains, i.e. conditions, and (3) the transferability of models among different data sources (see 'Drug Review Dataset (Drugs.com)').The data is split into a train (75%) a test (25%) partition (see publication) and stored in two .tsv (tab-separated-values) files, respectively.Important notes:When using this dataset, you agree that you1) only use the data for research purposes2) don't use the data for any commerical purposes3) don't distribute the data to anyone else4) cite us1. urlDrugName (categorical): name of drug2. condition (categorical): name of condition3. benefitsReview (text): patient on benefits4. sideEffectsReview (text): patient on side effects5. commentsReview (text): overall patient comment6. rating (numerical): 10 star patient rating7. sideEffects (categorical): 5 step side effect rating8. effectiveness (categorical): 5 step effectiveness rating"
Sentiment Labelled Sentences,Sentiment Labelled Sentences,The dataset contains sentences labelled with positive or negative sentiment.,Sentiment+Labelled+Sentences,https://archive.ics.uci.edu/ml//machine-learning-databases/00331/,https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences,"This dataset was created for the Paper 'From Group to Individual Labels using Deep Features', Kotzias et. al,. KDD 2015Please cite the paper if you want to use it :)It contains sentences labelled with positive or negative sentiment.=======Format:=======sentence 	 score =======Details:=======Score is either 1 (for positive) or 0 (for negative)	The sentences come from three different websites/fields:imdb.comamazon.comyelp.comFor each website, there exist 500 positive and 500 negative sentences. Those were selected randomly for larger datasets of reviews. We attempted to select sentences that have a clearly positive or negative connotaton, the goal was for no neutral sentences to be selected.",Unknown,"The attributes are text sentences, extracted from reviews of products, movies, and restaurants","The dataset contains sentences labelled with positive or negative sentiment.This dataset was created for the Paper 'From Group to Individual Labels using Deep Features', Kotzias et. al,. KDD 2015Please cite the paper if you want to use it :)It contains sentences labelled with positive or negative sentiment.=======Format:=======sentence 	 score =======Details:=======Score is either 1 (for positive) or 0 (for negative)	The sentences come from three different websites/fields:imdb.comamazon.comyelp.comFor each website, there exist 500 positive and 500 negative sentences. Those were selected randomly for larger datasets of reviews. We attempted to select sentences that have a clearly positive or negative connotaton, the goal was for no neutral sentences to be selected.The attributes are text sentences, extracted from reviews of products, movies, and restaurants"
Sentence Classification,Sentence Classification,"Contains sentences from the abstract and introduction of 30 articles annotated with a modified Argumentative Zones annotation scheme. These articles come from biology, machine learning and psychology.",Sentence+Classification,https://archive.ics.uci.edu/ml//machine-learning-databases/00311/,https://archive.ics.uci.edu/ml/datasets/Sentence+Classification,Please see the README file that accompanies the data.,Unknown,Please see the README file that accompanies the data. ,"Contains sentences from the abstract and introduction of 30 articles annotated with a modified Argumentative Zones annotation scheme. These articles come from biology, machine learning and psychology.Please see the README file that accompanies the data.Please see the README file that accompanies the data. "
seismic-bumps,seismic-bumps,"The data describe the problem of high energy (higher than 10^4 J) seismic bumps forecasting in a coal 
mine. Data come from two of longwalls located in a Polish coal mine.",seismic-bumps,https://archive.ics.uci.edu/ml//machine-learning-databases/00266/,https://archive.ics.uci.edu/ml/datasets/seismic-bumps,"Mining activity was and is always connected with the occurrence of dangers which are commonly called mining hazards. A special case of such threat is a seismic hazard which frequently occurs in many underground mines. Seismic hazard is the hardest detectable and predictable of natural hazards and in this respect it is comparable to an earthquake. More and more advanced seismic and seismoacoustic monitoring systems allow a better understanding rock mass processes and definition of seismic hazard prediction methods. Accuracy of so far created methods is however far from perfect. Complexity of seismic processes and big disproportion between the number of low-energy seismic events and the number of high-energy phenomena (e.g. > 10^4J) causes the statistical techniques to be insufficient to predict seismic hazard. Therefore, it is essential to search for new opportunities of better hazard prediction, also using machine learning methods. In seismic hazard assessment data clustering techniques can be applied (Lesniak A., Isakow Z.: Space-time clustering of seismic events and hazard assessment in the Zabrze-Bielszowice coal mine, Poland. Int. Journal of Rock Mechanics and Mining Sciences, 46(5), 2009, 918-928), and for prediction of seismic tremors artificial neural networks are used (Kabiesz, J.: Effect of the form of data on the quality of mine tremors hazard forecasting using neural networks. Geotechnical and Geological Engineering, 24(5), 2005, 1131-1147). In the majority of applications, the results obtained by mentioned methods are reported in the form of two states which are interpreted as 'hazardous' and 'non-hazardous'. Unbalanced distribution of positive ('hazardous state') and negative ('non-hazardous state') examples is a serious problem in seismic hazard prediction. Currently used methods are still insufficient to achieve good sensitivity and specificity of predictions. In the paper (Bukowska M.: The probability of rockburst occurrence in the Upper Silesian Coal Basin area dependent on natural mining conditions. Journal of Mining Sciences, 42(6), 2006, 570-577) a number of factors having an effect on seismic hazard occurrence was proposed, among other factors, the occurrence of tremors with energy > 10^4J was listed. The task of seismic prediction can be defined in different ways, but the main aim of all seismic hazard assessment methods is to predict (with given precision relating to time and date) of increased seismic activity which can cause a rockburst. In the data set each row contains a summary statement about seismic activity in the rock mass within one shift (8 hours). If decision attribute has the value 1, then in the next shift any seismic bump with an energy higher than 10^4 J was registered. That task of hazards prediction bases on the relationship between the energy of recorded tremors and seismoacoustic activity with the possibility of rockburst occurrence. Hence, such hazard prognosis is not connected with accurate rockburst prediction. Moreover, with the information about the possibility of hazardous situation occurrence, an appropriate supervision service can reduce a risk of rockburst (e.g. by distressing shooting) or withdraw workers from the threatened area. Good prediction of increased seismic activity is therefore a matter of great practical importance.   The presented data set is characterized by unbalanced distribution of positive and negative examples. In the data set there are only 170 positive examples representing class 1.",Unknown,"Attribute information:1. seismic: result of shift seismic hazard assessment in the mine working obtained by the seismic method (a - lack of hazard, b - low hazard, c - high hazard, d - danger state);2. seismoacoustic: result of shift seismic hazard assessment in the mine working obtained by the seismoacoustic method;3. shift: information about type of a shift (W - coal-getting, N -preparation shift);4. genergy: seismic energy recorded within previous shift by the most active geophone (GMax) out of geophones monitoring the longwall;5. gpuls: a number of pulses recorded within previous shift by GMax;6. gdenergy: a deviation of energy recorded within previous shift by GMax from average energy recorded during eight previous shifts;7. gdpuls: a deviation of a number of pulses recorded within previous shift by GMax from average number of pulses recorded during eight previous shifts;8. ghazard: result of shift seismic hazard assessment in the mine working obtained by the seismoacoustic method based on registration coming form GMax only;9. nbumps: the number of seismic bumps recorded within previous shift;10. nbumps2: the number of seismic bumps (in energy range [10^2,10^3)) registered within previous shift;11. nbumps3: the number of seismic bumps (in energy range [10^3,10^4)) registered within previous shift;12. nbumps4: the number of seismic bumps (in energy range [10^4,10^5)) registered within previous shift;13. nbumps5: the number of seismic bumps (in energy range [10^5,10^6)) registered within the last shift;14. nbumps6: the number of seismic bumps (in energy range [10^6,10^7)) registered within previous shift;15. nbumps7: the number of seismic bumps (in energy range [10^7,10^8)) registered within previous shift;16. nbumps89: the number of seismic bumps (in energy range [10^8,10^10)) registered within previous shift;17. energy: total energy of seismic bumps registered within previous shift;18. maxenergy: the maximum energy of the seismic bumps registered within previous shift;19. class: the decision attribute - '1' means that high energy seismic bump occurred in the next shift ('hazardous state'), '0' means that no high energy seismic bumps occurred in the next shift  ('non-hazardous state').","The data describe the problem of high energy (higher than 10^4 J) seismic bumps forecasting in a coal 
mine. Data come from two of longwalls located in a Polish coal mine.Mining activity was and is always connected with the occurrence of dangers which are commonly called mining hazards. A special case of such threat is a seismic hazard which frequently occurs in many underground mines. Seismic hazard is the hardest detectable and predictable of natural hazards and in this respect it is comparable to an earthquake. More and more advanced seismic and seismoacoustic monitoring systems allow a better understanding rock mass processes and definition of seismic hazard prediction methods. Accuracy of so far created methods is however far from perfect. Complexity of seismic processes and big disproportion between the number of low-energy seismic events and the number of high-energy phenomena (e.g. > 10^4J) causes the statistical techniques to be insufficient to predict seismic hazard. Therefore, it is essential to search for new opportunities of better hazard prediction, also using machine learning methods. In seismic hazard assessment data clustering techniques can be applied (Lesniak A., Isakow Z.: Space-time clustering of seismic events and hazard assessment in the Zabrze-Bielszowice coal mine, Poland. Int. Journal of Rock Mechanics and Mining Sciences, 46(5), 2009, 918-928), and for prediction of seismic tremors artificial neural networks are used (Kabiesz, J.: Effect of the form of data on the quality of mine tremors hazard forecasting using neural networks. Geotechnical and Geological Engineering, 24(5), 2005, 1131-1147). In the majority of applications, the results obtained by mentioned methods are reported in the form of two states which are interpreted as 'hazardous' and 'non-hazardous'. Unbalanced distribution of positive ('hazardous state') and negative ('non-hazardous state') examples is a serious problem in seismic hazard prediction. Currently used methods are still insufficient to achieve good sensitivity and specificity of predictions. In the paper (Bukowska M.: The probability of rockburst occurrence in the Upper Silesian Coal Basin area dependent on natural mining conditions. Journal of Mining Sciences, 42(6), 2006, 570-577) a number of factors having an effect on seismic hazard occurrence was proposed, among other factors, the occurrence of tremors with energy > 10^4J was listed. The task of seismic prediction can be defined in different ways, but the main aim of all seismic hazard assessment methods is to predict (with given precision relating to time and date) of increased seismic activity which can cause a rockburst. In the data set each row contains a summary statement about seismic activity in the rock mass within one shift (8 hours). If decision attribute has the value 1, then in the next shift any seismic bump with an energy higher than 10^4 J was registered. That task of hazards prediction bases on the relationship between the energy of recorded tremors and seismoacoustic activity with the possibility of rockburst occurrence. Hence, such hazard prognosis is not connected with accurate rockburst prediction. Moreover, with the information about the possibility of hazardous situation occurrence, an appropriate supervision service can reduce a risk of rockburst (e.g. by distressing shooting) or withdraw workers from the threatened area. Good prediction of increased seismic activity is therefore a matter of great practical importance.   The presented data set is characterized by unbalanced distribution of positive and negative examples. In the data set there are only 170 positive examples representing class 1.Attribute information:1. seismic: result of shift seismic hazard assessment in the mine working obtained by the seismic method (a - lack of hazard, b - low hazard, c - high hazard, d - danger state);2. seismoacoustic: result of shift seismic hazard assessment in the mine working obtained by the seismoacoustic method;3. shift: information about type of a shift (W - coal-getting, N -preparation shift);4. genergy: seismic energy recorded within previous shift by the most active geophone (GMax) out of geophones monitoring the longwall;5. gpuls: a number of pulses recorded within previous shift by GMax;6. gdenergy: a deviation of energy recorded within previous shift by GMax from average energy recorded during eight previous shifts;7. gdpuls: a deviation of a number of pulses recorded within previous shift by GMax from average number of pulses recorded during eight previous shifts;8. ghazard: result of shift seismic hazard assessment in the mine working obtained by the seismoacoustic method based on registration coming form GMax only;9. nbumps: the number of seismic bumps recorded within previous shift;10. nbumps2: the number of seismic bumps (in energy range [10^2,10^3)) registered within previous shift;11. nbumps3: the number of seismic bumps (in energy range [10^3,10^4)) registered within previous shift;12. nbumps4: the number of seismic bumps (in energy range [10^4,10^5)) registered within previous shift;13. nbumps5: the number of seismic bumps (in energy range [10^5,10^6)) registered within the last shift;14. nbumps6: the number of seismic bumps (in energy range [10^6,10^7)) registered within previous shift;15. nbumps7: the number of seismic bumps (in energy range [10^7,10^8)) registered within previous shift;16. nbumps89: the number of seismic bumps (in energy range [10^8,10^10)) registered within previous shift;17. energy: total energy of seismic bumps registered within previous shift;18. maxenergy: the maximum energy of the seismic bumps registered within previous shift;19. class: the decision attribute - '1' means that high energy seismic bump occurred in the next shift ('hazardous state'), '0' means that no high energy seismic bumps occurred in the next shift  ('non-hazardous state')."
Dodgers Loop Sensor,Dodgers Loop Sensor,Loop sensor data was collected for the Glendale on ramp for the 101 North freeway in Los Angeles,Dodgers+Loop+Sensor,https://archive.ics.uci.edu/ml//machine-learning-databases/event-detection/,https://archive.ics.uci.edu/ml/datasets/Dodgers+Loop+Sensor,"This loop sensor data was collected for the Glendale on ramp for the 101 North freeway in Los Angeles.  It is close enough to the stadium to see unusual traffic after a Dodgers game, but not so close and heavily used by game traffic so that the signal for the extra traffic is overly obvious.NOTE: This is an on ramp near the stadium so event traffic BEGINS at or near the END of the event time.The observations were taken over 25 weeks, 288 time slices per day (5 minute count aggregates).  	The goal is to predict the presence of a baseball game at Dodgers stadium ",Unknown,1.  Date: MM/DD/YY2.  Time: (H)H:MM (military time)3.  Count: Number of cars measured for the previous five minutesRows: Each five minute time slice is represented by one row For .events file:1.  Date: MM/DD/YY2.  Begin event time: HH:MM:SS (military) 3.  End event time: HH:MM:SS (military)4.  Game attendance5.  Away team6.  W/L score,"Loop sensor data was collected for the Glendale on ramp for the 101 North freeway in Los AngelesThis loop sensor data was collected for the Glendale on ramp for the 101 North freeway in Los Angeles.  It is close enough to the stadium to see unusual traffic after a Dodgers game, but not so close and heavily used by game traffic so that the signal for the extra traffic is overly obvious.NOTE: This is an on ramp near the stadium so event traffic BEGINS at or near the END of the event time.The observations were taken over 25 weeks, 288 time slices per day (5 minute count aggregates).  	The goal is to predict the presence of a baseball game at Dodgers stadium 1.  Date: MM/DD/YY2.  Time: (H)H:MM (military time)3.  Count: Number of cars measured for the previous five minutesRows: Each five minute time slice is represented by one row For .events file:1.  Date: MM/DD/YY2.  Begin event time: HH:MM:SS (military) 3.  End event time: HH:MM:SS (military)4.  Game attendance5.  Away team6.  W/L score"
Document Understanding,Document Understanding,"Five concepts, expressed as predicates, to be learned",Document+Understanding,https://archive.ics.uci.edu/ml//machine-learning-databases/document-understanding,https://archive.ics.uci.edu/ml/datasets/Document+Understanding,"In the experimentation, 30 single page documents were considered.  They are copies of letters sent by Olivetti. Six trials were performed by randomly selecting 20 documents for the training set and 10 for the test set. Each document is identified by a letter (A to Z) or a pair of letters (AA, AB, AC, AD).   Trial  Training documents     1    A B C D E F G H I J K L M N O P Q R S T     2    C D E F G H I M P R S V X Y W Z AA AB AC AD     3    C D E F G H I J K P R S T U V Y W AA AB AC     4    A B C D E F G J L M N O P Q T V X Z AB AD     5    A B E F G I J K M N O P Q R T V X Z AA AD     6    A B C D E F G I J M Q S T X Y Z AA AB AC AD",Unknown,,"Five concepts, expressed as predicates, to be learnedIn the experimentation, 30 single page documents were considered.  They are copies of letters sent by Olivetti. Six trials were performed by randomly selecting 20 documents for the training set and 10 for the test set. Each document is identified by a letter (A to Z) or a pair of letters (AA, AB, AC, AD).   Trial  Training documents     1    A B C D E F G H I J K L M N O P Q R S T     2    C D E F G H I M P R S V X Y W Z AA AB AC AD     3    C D E F G H I J K P R S T U V Y W AA AB AC     4    A B C D E F G J L M N O P Q T V X Z AB AD     5    A B E F G I J K M N O P Q R T V X Z AA AD     6    A B C D E F G I J M Q S T X Y Z AA AB AC ADnan"
Sales_Transactions_Dataset_Weekly,Sales_Transactions_Dataset_Weekly,Contains weekly purchased quantities of 800 over products over 52 weeks. Normalised values are provided too.,Sales_Transactions_Dataset_Weekly,https://archive.ics.uci.edu/ml//machine-learning-databases/00396/,https://archive.ics.uci.edu/ml/datasets/Sales_Transactions_Dataset_Weekly,52 columns for 52 weeks; normalised values of provided too.,Unknown,"Product_Code52 weeks: W0, W1, ..., W51.Normalised vlaues of weekly data: Normalised 0, Normalised 1, ..., Normalised 51","Contains weekly purchased quantities of 800 over products over 52 weeks. Normalised values are provided too.52 columns for 52 weeks; normalised values of provided too.Product_Code52 weeks: W0, W1, ..., W51.Normalised vlaues of weekly data: Normalised 0, Normalised 1, ..., Normalised 51"
Russian Corpus of Biographical Texts,Russian Corpus of Biographical Texts,Sentence classification (Russian). The corpus contains Wikipedia texts splitted into sentences/ Each sentence has a topic label.,Russian+Corpus+of+Biographical+Texts,https://archive.ics.uci.edu/ml//machine-learning-databases/00576/,https://archive.ics.uci.edu/ml/datasets/Russian+Corpus+of+Biographical+Texts,"The corpus was created for the task of automatic search for fragments containing biographical information in a text in a natural language.  The corpus includes 200 Russian biographical articles (Wikipedia, 2018).Text pre-processing and selection included the following steps:- firstly, initial collection of texts was carried out automatically using open Python libraries;- we deleted short texts containing only years of a personÃ¢â‚¬â„¢s life and a list of his places of work;- we have deleted all sections except the 'Biography' section. This is due to the fact that biographical articles on Wikipedia contain lists of awards, scientific works, works and other sections that are inconvenient for marking up.The corpus includes biographies of individuals whose main activity is related to one of the following areas:- military and law enforcement officers;- figures of culture and art;- figures of science, technology and education;- politicians and public figures;- entrepreneurs and managers;- religious figures.",Unknown,"The corpus is a text collection, divided into sentences. Each sentence refers to one or two thematic classes: non-biographical fact (none); personal events (personal_events); professional events (professional_events); birth death nationality information about the parental family (parenting)); affiliation education family place of residence, residence (residence); occupation, position (occupation); other biographical facts (other).The corpus of biographical texts consists of the following elements:- texts presented in .xml format (each sentence includes the attributes 'text' and 'type' (thematic class), if available - 'additional_type' (additional thematic class);- a file with a description of the corps in .csv format, which contains information about the texts (name of the person, years of life, area of main activity). ","Sentence classification (Russian). The corpus contains Wikipedia texts splitted into sentences/ Each sentence has a topic label.The corpus was created for the task of automatic search for fragments containing biographical information in a text in a natural language.  The corpus includes 200 Russian biographical articles (Wikipedia, 2018).Text pre-processing and selection included the following steps:- firstly, initial collection of texts was carried out automatically using open Python libraries;- we deleted short texts containing only years of a personÃ¢â‚¬â„¢s life and a list of his places of work;- we have deleted all sections except the 'Biography' section. This is due to the fact that biographical articles on Wikipedia contain lists of awards, scientific works, works and other sections that are inconvenient for marking up.The corpus includes biographies of individuals whose main activity is related to one of the following areas:- military and law enforcement officers;- figures of culture and art;- figures of science, technology and education;- politicians and public figures;- entrepreneurs and managers;- religious figures.The corpus is a text collection, divided into sentences. Each sentence refers to one or two thematic classes: non-biographical fact (none); personal events (personal_events); professional events (professional_events); birth death nationality information about the parental family (parenting)); affiliation education family place of residence, residence (residence); occupation, position (occupation); other biographical facts (other).The corpus of biographical texts consists of the following elements:- texts presented in .xml format (each sentence includes the attributes 'text' and 'type' (thematic class), if available - 'additional_type' (additional thematic class);- a file with a description of the corps in .csv format, which contains information about the texts (name of the person, years of life, area of main activity). "
Tennis Major Tournament Match Statistics,Tennis Major Tournament Match Statistics,This is a collection of 8 files containing the match statistics for both women and men at the four major tennis tournaments of the year 2013. Each file has 42 columns and a minimum of 76 rows.,Tennis+Major+Tournament+Match+Statistics,https://archive.ics.uci.edu/ml//machine-learning-databases/00300/,https://archive.ics.uci.edu/ml/datasets/Tennis+Major+Tournament+Match+Statistics,,Unknown,Player 1              Name of Player 1Player 2              Name of Player 2Result                Result of the match (0/1) - Referenced on Player 1 is Result = 1 if Player 1 wins (FNL.1>FNL.2)FSP.1                 First Serve Percentage for player 1 (Real Number)FSW.1                 First Serve Won by player 1 (Real Number)SSP.1                 Second Serve Percentage for player 1 (Real Number)SSW.1                 Second Serve Won by player 1 (Real Number)ACE.1                 Aces won by player 1 (Numeric-Integer)DBF.1                 Double Faults committed by player 1 (Numeric-Integer)WNR.1                 Winners earned by player 1 (Numeric)UFE.1                 Unforced Errors committed by player 1 (Numeric)BPC.1                 Break Points Created by player 1   (Numeric)  BPW.1                 Break Points Won by player 1    (Numeric) NPA.1                 Net Points Attempted by player 1 (Numeric)NPW.1                 Net Points Won by player 1  (Numeric)      TPW.1                 Total Points Won by player 1 (Numeric)ST1.1                 Set 1 result for Player 1 (Numeric-Integer)ST2.1                 Set 2 Result for Player 1 (Numeric-Integer)ST3.1                 Set 3 Result for Player 1 (Numeric-Integer)ST4.1                 Set 4 Result for Player 1 (Numeric-Integer)ST5.1                 Set 5 Result for Player 1 (Numeric-Integer) FNL.1                 Final Number of Games Won by Player 1 (Numeric-Integer)FSP.2                 First Serve Percentage for player 2 (Real Number)FSW.2                 First Serve Won by player 2 (Real Number)SSP.2                 Second Serve Percentage for player 2 (Real Number)SSW.2                 Second Serve Won by player 2 (Real Number)ACE.2                 Aces won by player 2 (Numeric-Integer)DBF.2                 Double Faults committed by player 2 (Numeric-Integer)WNR.2                 Winners earned by player 2 (Numeric)UFE.2                 Unforced Errors committed by player 2 (Numeric)BPC.2                 Break Points Created by player 2   (Numeric)  BPW.2                 Break Points Won by player 2    (Numeric) NPA.2                 Net Points Attempted by player 2 (Numeric)NPW.2                 Net Points Won by player 2  (Numeric)      TPW.2                 Total Points Won by player 2 (Numeric)ST1.2                 Set 1 result for Player 2 (Numeric-Integer)ST2.2                 Set 2 Result for Player 2 (Numeric-Integer)ST3.2                 Set 3 Result for Player 2 (Numeric-Integer)ST4.2                 Set 4 Result for Player 2 (Numeric-Integer)ST5.2                 Set 5 Result for Player 2 (Numeric-Integer) FNL.2                 Final Number of Games Won by Player 2 (Numeric-Integer)Round                 Round of the tournament at which game is played (Numeric-Integer),This is a collection of 8 files containing the match statistics for both women and men at the four major tennis tournaments of the year 2013. Each file has 42 columns and a minimum of 76 rows.nanPlayer 1              Name of Player 1Player 2              Name of Player 2Result                Result of the match (0/1) - Referenced on Player 1 is Result = 1 if Player 1 wins (FNL.1>FNL.2)FSP.1                 First Serve Percentage for player 1 (Real Number)FSW.1                 First Serve Won by player 1 (Real Number)SSP.1                 Second Serve Percentage for player 1 (Real Number)SSW.1                 Second Serve Won by player 1 (Real Number)ACE.1                 Aces won by player 1 (Numeric-Integer)DBF.1                 Double Faults committed by player 1 (Numeric-Integer)WNR.1                 Winners earned by player 1 (Numeric)UFE.1                 Unforced Errors committed by player 1 (Numeric)BPC.1                 Break Points Created by player 1   (Numeric)  BPW.1                 Break Points Won by player 1    (Numeric) NPA.1                 Net Points Attempted by player 1 (Numeric)NPW.1                 Net Points Won by player 1  (Numeric)      TPW.1                 Total Points Won by player 1 (Numeric)ST1.1                 Set 1 result for Player 1 (Numeric-Integer)ST2.1                 Set 2 Result for Player 1 (Numeric-Integer)ST3.1                 Set 3 Result for Player 1 (Numeric-Integer)ST4.1                 Set 4 Result for Player 1 (Numeric-Integer)ST5.1                 Set 5 Result for Player 1 (Numeric-Integer) FNL.1                 Final Number of Games Won by Player 1 (Numeric-Integer)FSP.2                 First Serve Percentage for player 2 (Real Number)FSW.2                 First Serve Won by player 2 (Real Number)SSP.2                 Second Serve Percentage for player 2 (Real Number)SSW.2                 Second Serve Won by player 2 (Real Number)ACE.2                 Aces won by player 2 (Numeric-Integer)DBF.2                 Double Faults committed by player 2 (Numeric-Integer)WNR.2                 Winners earned by player 2 (Numeric)UFE.2                 Unforced Errors committed by player 2 (Numeric)BPC.2                 Break Points Created by player 2   (Numeric)  BPW.2                 Break Points Won by player 2    (Numeric) NPA.2                 Net Points Attempted by player 2 (Numeric)NPW.2                 Net Points Won by player 2  (Numeric)      TPW.2                 Total Points Won by player 2 (Numeric)ST1.2                 Set 1 result for Player 2 (Numeric-Integer)ST2.2                 Set 2 Result for Player 2 (Numeric-Integer)ST3.2                 Set 3 Result for Player 2 (Numeric-Integer)ST4.2                 Set 4 Result for Player 2 (Numeric-Integer)ST5.2                 Set 5 Result for Player 2 (Numeric-Integer) FNL.2                 Final Number of Games Won by Player 2 (Numeric-Integer)Round                 Round of the tournament at which game is played (Numeric-Integer)
Firm-Teacher_Clave-Direction_Classification,Firm-Teacher_Clave-Direction_Classification,The data are binary attack-point vectors and their clave-direction class(es) according to the partido-alto-based paradigm.,Firm-Teacher_Clave-Direction_Classification,https://archive.ics.uci.edu/ml//machine-learning-databases/00324/,https://archive.ics.uci.edu/ml/datasets/Firm-Teacher_Clave-Direction_Classification,"The data consist of 16 binary inputs and one 'four-bit' one-hot classification output. The 16-bit inputs are binary-valued attack-point vectors. 1 indicates the substantial presence (0, absence) of an onset (note start) in a certain time window during one bar of 4/4 time music (not limited to percussion, hence *onset* vectors without duration) quantized to 16th-note subdivisions. Each vector has 16 positions in which there may be or not be an onset. The output classes (left to right: neutral, reverse clave, forward clave, and incoherent) were determined through the music-theoretic/ethnomusicological portion of the my dissertation studies, based on both double-blind listening tests and informal interviews with with four professional master-musicians, as well as decades of studying the music. Future uploads (subject only to formatting) can include an additional column of fuzzy descriptors (of the degree of match to the output class).",Unknown,"In terms of divisive rhythm counting, the first 16 attributes (input bits) correspond to a significant onset at:1 e & a 2 e & a 3 e & a 4 e & a of one bar of 4/4 time.The last four are the output classes (3 - neutral, 2 - reverse clave, 1 - forward clave, 0 - incoherent) in one-hot (one-up) encoding.","The data are binary attack-point vectors and their clave-direction class(es) according to the partido-alto-based paradigm.The data consist of 16 binary inputs and one 'four-bit' one-hot classification output. The 16-bit inputs are binary-valued attack-point vectors. 1 indicates the substantial presence (0, absence) of an onset (note start) in a certain time window during one bar of 4/4 time music (not limited to percussion, hence *onset* vectors without duration) quantized to 16th-note subdivisions. Each vector has 16 positions in which there may be or not be an onset. The output classes (left to right: neutral, reverse clave, forward clave, and incoherent) were determined through the music-theoretic/ethnomusicological portion of the my dissertation studies, based on both double-blind listening tests and informal interviews with with four professional master-musicians, as well as decades of studying the music. Future uploads (subject only to formatting) can include an additional column of fuzzy descriptors (of the degree of match to the output class).In terms of divisive rhythm counting, the first 16 attributes (input bits) correspond to a significant onset at:1 e & a 2 e & a 3 e & a 4 e & a of one bar of 4/4 time.The last four are the output classes (3 - neutral, 2 - reverse clave, 1 - forward clave, 0 - incoherent) in one-hot (one-up) encoding."
