{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80ab0322-2636-4825-82ae-8d830a00a4ac",
   "metadata": {},
   "source": [
    "# Testing for Bert and LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b29b215a-4f9e-444a-ba3a-936f298aec45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xuzhi\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "from transformers import TFBertModel\n",
    "\n",
    "model_name = \"allenai/scibert_scivocab_uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98588aab-c861-46b4-a1d6-dc62e3c855d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "large_capacity_model = tf.keras.models.load_model('sci_classification_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85f8eafe-72b8-4d9b-b2d8-f67ced48832a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"test data.csv\")\n",
    "\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import re\n",
    "\n",
    "regex = r\"(\\$+)(?:(?!\\1)[\\s\\S])*\\1\"\n",
    "\n",
    "x = df['abstract'].to_numpy()\n",
    "y = df['category'].to_numpy()\n",
    "\n",
    "\n",
    "df['encoded_cat'] = df['category'].astype('category').cat.codes\n",
    "\n",
    "processed_x = []\n",
    "\n",
    "\n",
    "for t in x:\n",
    "    string_encode = t.encode(\"ascii\", \"ignore\")\n",
    "    t = string_encode.decode()\n",
    "    new_t = re.sub(regex, '', t)\n",
    "    new_t = new_t.replace('\\n', ' ')\n",
    "    processed_x.append(new_t)\n",
    "\n",
    "df['processed abstract'] = processed_x\n",
    "\n",
    "df.groupby('encoded_cat').describe()\n",
    "df.to_csv('processed_labeled_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e988b034-2568-424e-bcae-4279514183f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "X_input_ids = np.zeros((len(df), 256))\n",
    "X_attn_masks = np.zeros((len(df), 256))\n",
    "\n",
    "def generate_training_data(df, ids, masks, tokenizer):\n",
    "    for i, text in tqdm(enumerate(df['processed abstract'])):\n",
    "        tokenized_text = tokenizer.encode_plus(\n",
    "            text,\n",
    "            max_length=256, \n",
    "            truncation=True, \n",
    "            padding='max_length', \n",
    "            add_special_tokens=True,\n",
    "            return_tensors='tf'\n",
    "        )\n",
    "        ids[i, :] = tokenized_text.input_ids\n",
    "        masks[i, :] = tokenized_text.attention_mask\n",
    "    return ids, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16e6156e-5986-45e4-a936-1c11ca741971",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1400it [00:03, 404.80it/s]\n"
     ]
    }
   ],
   "source": [
    "X_input_ids, X_attn_masks = generate_training_data(df, X_input_ids, X_attn_masks, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57479c93-d131-4609-92f3-f1a93b30b086",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.zeros((len(df), 7))\n",
    "labels[np.arange(len(df)), df['encoded_cat'].values] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d424cf30-e3a3-485c-9a39-fdcb6e061d12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dae0fe58-df0e-4826-a157-7586b2cf33ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((X_input_ids, X_attn_masks, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "504e5ffc-feb4-4a72-9557-ffc9bb6b6e2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset shapes: ({input_ids: (256,), attention_mask: (256,)}, (7,)), types: ({input_ids: tf.float64, attention_mask: tf.float64}, tf.float64)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def MyMap(input_ids, attn_masks, labels):\n",
    "    return {\n",
    "        'input_ids': input_ids,\n",
    "        'attention_mask': attn_masks\n",
    "    }, labels\n",
    "\n",
    "dataset = dataset.map(MyMap)\n",
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cfffc72f-d406-49b1-ab89-34c9a2e51a9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset shapes: ({input_ids: (100, 256), attention_mask: (100, 256)}, (100, 7)), types: ({input_ids: tf.float64, attention_mask: tf.float64}, tf.float64)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.shuffle(10000).batch(100, drop_remainder=True)\n",
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "edbb1a6f-296b-4397-bb7e-fa8fca105960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 16s 1s/step - loss: 0.2994 - top_k_categorical_accuracy: 0.9779\n",
      "15.607146501541138\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "acc1 = tf.keras.metrics.TopKCategoricalAccuracy(k=2)\n",
    "large_capacity_model.compile(loss='categorical_crossentropy', metrics=[acc1])\n",
    "results = large_capacity_model.evaluate(dataset)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be372477-07a4-4700-abec-1428b6b43c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('LSTM_tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14608162-b9fa-42f4-96aa-c34f85046c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "test_abstract = df['processed abstract']\n",
    "processed_x = []\n",
    "\n",
    "for t in test_abstract:\n",
    "    string_encode = t.encode(\"ascii\", \"ignore\")\n",
    "    t = string_encode.decode()\n",
    "    new_t = re.sub(regex, '', t)\n",
    "    for word in STOPWORDS:\n",
    "        token = ' ' + word + ' '\n",
    "        new_t = new_t.replace(token, ' ')\n",
    "        new_t = new_t.replace(' ', ' ')\n",
    "    processed_x.append(new_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ae50ddb-b486-4b00-8098-b77d2116b6cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The need modern data analytics combine relational, procedural, map-reduce-style functional processing widely recognized. State-of-the-art systems like Spark added SQL front-ends relational query optimization, promise increase expressiveness performance. But good extensions extracting high performance modern hardware platforms?   While Spark made impressive progress, show relational workloads, still significant gap compared best-of-breed query engines. And stepping outside relational world, query optimization techniques ineffective large parts computation treated user-defined functions (UDFs).   We present Flare: new back-end Spark brings performance closer best SQL engines, without giving added expressiveness Spark. We demonstrate order magnitude speedups relational workloads TPC-H, well range machine learning kernels combine relational iterative functional processing.   Flare achieves results (1) compilation native code, (2) replacing parts Spark runtime system, (3) extending scope optimization code generation large classes UDFs.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e598a21-1e30-41a4-a262-a173eda22682",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "vocab_size = 8000\n",
    "embedding_dim = 256\n",
    "max_length = 180\n",
    "trunc_type = 'post'\n",
    "padding_type = 'post'\n",
    "oov_tok = '<OOV>'\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(processed_x)\n",
    "padded_x = pad_sequences(sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81b7091c-1136-4460-9172-7b72d3dd2f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1400, 7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14534a77-a6f6-432e-ba8c-7b33f8bf6dee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1400, 180)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef6ad299-731d-49b4-9f48-5d7d16e3956c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = tf.keras.models.load_model('fine_tuned_student model attention')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62088dea-1da0-48a4-9c86-a0a53443e322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 1s 16ms/step - loss: 0.4444 - top_k_categorical_accuracy: 0.8964\n",
      "0.7929182052612305\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "results_1 = lstm.evaluate(padded_x, labels)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1deade1-5ac2-421f-b498-f83049de6df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 1s 15ms/step - loss: 0.4444 - top_k_categorical_accuracy: 0.9479\n",
      "1.3225352764129639\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "acc1 = tf.keras.metrics.TopKCategoricalAccuracy(k=2)\n",
    "lstm.compile(loss='categorical_crossentropy', metrics=[acc1])\n",
    "results_2 = lstm.evaluate(padded_x, labels)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
